{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "P20_A6X-Lqcc",
        "-ogWos1DLuQM",
        "4swcEs_LMaGG",
        "-0r7CnKexIRx",
        "8oqqUNuibPGh",
        "dfhRrxWq3ui-"
      ],
      "authorship_tag": "ABX9TyOvfB+f69JAtYJDbPOWB/52",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndrewDavidRatnam/Deep-Learning-Workshop/blob/main/Deep_Learning_workshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Pytorch\n",
        "---\n",
        "GROK\n",
        "\n",
        "---\n",
        "\n",
        "Deep Learning with PyTorch: Lecture Summary and Autograd Focus\n",
        "- üîπ Key Takeaways\n",
        "\n",
        "  - PyTorch Overview: PyTorch is a dynamic deep learning framework centered around tensors, offering flexibility for building models like feedforward neural networks (ANNs), convolutional neural networks (CNNs), and recurrent neural networks (RNNs). Its evolving nature (e.g., version 2.0) simplifies operations and enhances deployment capabilities.\n",
        "  - Tensors as Core: Tensors are multidimensional arrays (akin to NumPy arrays but GPU-compatible) that represent inputs, parameters, and outputs in deep learning models. PyTorch provides robust tensor manipulation on both CPU and GPU.\n",
        "  - torch.nn Module: The torch.nn module simplifies neural network construction, abstracting low-level tensor operations to define layers and architectures efficiently, reducing error-prone manual computations.\n",
        "  - Autograd for Gradients: PyTorch‚Äôs autograd module automatically computes gradients for backpropagation, eliminating the need to manually define backward passes, which is critical for training deep learning models.\n",
        "  - Deployment and Optimization: PyTorch supports model optimization (e.g., via JIT compilation) and deployment across hardware, with utilities like multiprocessing and domain-specific libraries (e.g., torchvision, torchtext).\n",
        "  - Why PyTorch?: Compared to frameworks like TensorFlow, PyTorch‚Äôs dynamic computation graph and Pythonic API make it intuitive for research and debugging, with interoperability (e.g., ONNX) for cross-framework use.\n",
        "  - Importance of Basics: Understanding tensor operations, memory layout (e.g., strides), and hardware interactions is crucial for debugging, optimizing, and scaling models, especially when performance issues arise.\n",
        "  - Domain-Specific Libraries: Libraries like Hugging Face (built on PyTorch and TensorFlow) simplify NLP tasks, but mastering PyTorch fundamentals enables seamless transitions to such tools.\n",
        "\n",
        "- üî¢ Mathematical Insight\n",
        "The autograd module in PyTorch is central to training neural networks via gradient-based optimization. For a neural network with parameters $(\\theta)$, the goal is to minimize a loss function $(L(y, \\hat{y})$), where $(y)$ is the true label and $(\\hat{y} = f(x; \\theta))$ is the model‚Äôs prediction. The gradient of the loss with respect to the parameters, $(\\frac{\\partial L}{\\partial \\theta})$, is computed using the chain rule during backpropagation.\n",
        "For a simple feedforward layer, consider:$ [ z = Wx + b ]$ and $ [ a = \\sigma(z) ]$ where $(W)$ is the weight matrix, $(b)$ is the bias, $(x)$ is the input, and $(\\sigma)$ is an activation function $(e.g., ReLU)$. The loss $(L)$ depends on $(a)$, and autograd computes:$[ \\frac{\\partial L}{\\partial W} = \\frac{\\partial L}{\\partial a} \\cdot \\frac{\\partial a}{\\partial z} \\cdot \\frac{\\partial z}{\\partial W} ]$ Here, $(\\frac{\\partial z}{\\partial W} = x)$, and autograd tracks these dependencies automatically by building a dynamic computation graph during the forward pass. This graph records operations on tensors with requires_grad=True, enabling efficient gradient computation in the backward pass.\n",
        "- üß† PyTorch Code\n",
        "Below is a concise example demonstrating autograd in a simple linear layer with a mean squared error (MSE) loss, showcasing automatic gradient computation.\n",
        "\n",
        "```\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define a simple linear layer\n",
        "x = torch.tensor([[1.0, 2.0]], requires_grad=False)  # Input\n",
        "y_true = torch.tensor([[3.0]])  # Target\n",
        "W = torch.tensor([[0.5, 1.0]], requires_grad=True)  # Weights\n",
        "b = torch.tensor([[0.1]], requires_grad=True)  # Bias\n",
        "\n",
        "# Forward pass\n",
        "z = x @ W.t() + b  # Linear transformation\n",
        "y_pred = z  # No activation for simplicity\n",
        "loss = nn.MSELoss()(y_pred, y_true)  # Compute MSE loss\n",
        "\n",
        "# Backward pass (autograd computes gradients)\n",
        "loss.backward()\n",
        "\n",
        "# Access gradients\n",
        "print(\"Gradient w.r.t. W:\", W.grad)\n",
        "print(\"Gradient w.r.t. b:\", b.grad)\n",
        "```\n",
        "This code defines a linear layer, computes the loss, and uses autograd to calculate gradients for (W) and (b), which can be used for parameter updates in gradient descent.\n",
        "- üí° Analogy or Story\n",
        "Think of autograd as a meticulous accountant in a busy restaurant kitchen. The chef (the neural network) prepares a dish (the forward pass) by combining ingredients (tensors) in specific ways (operations like matrix multiplication or activation). The accountant tracks every step of the recipe, noting how each ingredient contributes to the final dish. When the food critic (the loss function) provides feedback (the loss value), the accountant quickly calculates how much each ingredient‚Äôs quantity (parameters) needs adjustment to improve the dish (minimize the loss). This tracking and adjustment process is seamless, allowing the chef to focus on cooking (model design) without manually recalculating contributions (gradients).\n",
        "- üîÅ Relation to Previous Concepts\n",
        "This lecture builds on foundational deep learning principles, such as the role of tensors as the universal data structure for inputs, weights, and outputs, which may have been introduced in earlier lessons on linear algebra or NumPy. The emphasis on autograd connects to prior discussions of backpropagation, where gradients are manually derived for simple networks. Here, PyTorch‚Äôs autograd automates this process, reinforcing the importance of the chain rule and computation graphs. The torch.nn module extends concepts of neural network layers (e.g., linear transformations, activations) by providing a high-level API, aligning with earlier lessons on designing ANNs. The focus on debugging and optimization ties back to performance analysis techniques, such as monitoring gradient flow to diagnose issues like vanishing gradients, which may have been covered in gradient-based optimization lectures.\n",
        "Prerequisites: Learners should have basic knowledge of linear algebra (matrices, vectors), calculus (derivatives, chain rule), and Python programming. Familiarity with NumPy and introductory neural network concepts (e.g., forward/backward passes) is helpful but not mandatory, as the lecture introduces PyTorch-specific implementations.\n",
        "\n",
        "---\n",
        "Perplexity\n",
        "\n",
        "---\n",
        "üîπ **Key Takeaways**\n",
        "\n",
        "- PyTorch is a leading deep learning framework, preferred for its flexibility, Pythonic interface, and rapid evolution (notably, from version 1.8 to 2.0, with ongoing simplifications and new modules)[1].\n",
        "- At its core, PyTorch is built around *tensors*‚Äîmulti-dimensional arrays that generalize vectors and matrices, serving as the fundamental data structure for all deep learning computations[1].\n",
        "- PyTorch provides robust support for both CPU and GPU computation, making large-scale model training and deployment efficient and accessible[1].\n",
        "- The framework is modular: low-level APIs (like tensor operations), mid-level modules (like `torch.nn` for building neural networks), and high-level, domain-specific libraries (like `torchvision` and `torchtext`)[1].\n",
        "- Automatic differentiation (autograd) is seamlessly integrated, allowing gradients to be computed automatically and enabling efficient backpropagation[1].\n",
        "- Understanding the *internals* (e.g., tensor memory layout, strides, device management) is crucial for debugging, optimizing, and deploying models, especially as models and datasets scale[1].\n",
        "- PyTorch‚Äôs design encourages both rapid prototyping (with high-level APIs) and deep customization (via low-level tensor operations), making it suitable for both research and production[1].\n",
        "- The lecture emphasizes the importance of foundational understanding‚Äîknowing how tensors work, how memory is managed, and why frameworks like PyTorch are necessary compared to NumPy or native Python[1].\n",
        "\n",
        "üî¢ **Mathematical Insight**\n",
        "\n",
        "- A **tensor** is a generalization of scalars (rank-0), vectors (rank-1), and matrices (rank-2) to higher dimensions. Mathematically, a tensor of rank $ n $ can be represented as an $ n $-dimensional array:\n",
        "\n",
        "  $\n",
        "  \\text{Tensor} \\in \\mathbb{R}^{d_1 \\times d_2 \\times \\cdots \\times d_n}\n",
        "  $\n",
        "\n",
        "- In deep learning, inputs (images, text, audio), parameters (weights, kernels), and outputs are all represented as tensors.\n",
        "- **Backpropagation** leverages the chain rule for efficient gradient computation, which PyTorch automates with its autograd engine:\n",
        "\n",
        "  $\n",
        "  \\frac{\\partial L}{\\partial \\theta} = \\frac{\\partial L}{\\partial y} \\cdot \\frac{\\partial y}{\\partial \\theta}\n",
        "  $\n",
        "\n",
        "  where $ L $ is the loss, $ y $ is the output, and $ \\theta $ are the parameters.\n",
        "\n",
        "üß† **PyTorch Code**\n",
        "\n",
        "Below is a concise example showing the essentials: tensor creation, moving to GPU, defining a simple neural network (feedforward), and leveraging autograd for gradient computation.\n",
        "\n",
        "```python\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# 1. Create a tensor on CPU and move to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "x = torch.randn(64, 28*28, device=device)  # batch of 64, input size 28x28\n",
        "\n",
        "# 2. Define a simple feedforward neural network using torch.nn\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 100)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(100, 10)  # 10 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        return self.fc2(x)\n",
        "\n",
        "model = SimpleNN().to(device)\n",
        "\n",
        "# 3. Forward pass and compute loss\n",
        "y_true = torch.randint(0, 10, (64,), device=device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "y_pred = model(x)\n",
        "loss = criterion(y_pred, y_true)\n",
        "\n",
        "# 4. Backward pass (autograd)\n",
        "loss.backward()\n",
        "\n",
        "# Inspect gradients\n",
        "print(model.fc1.weight.grad.shape)  # Should be [100, 784]\n",
        "```\n",
        "\n",
        "üí° **Analogy or Story**\n",
        "\n",
        "*Think of PyTorch as a box of Lego blocks.* Each tensor is a block, and operations (like matrix multiplication or convolution) are ways of connecting them. You can build a simple toy (a small neural network) or an elaborate structure (a large language model)‚Äîthe difference is only in the number and arrangement of blocks. The framework gives you both the raw blocks (tensors, low-level ops) and pre-built pieces (modules like `torch.nn`) to assemble anything you imagine. The more you understand how these blocks fit and interact (memory layout, device placement), the more robust and efficient your creations become.\n",
        "\n",
        "üîÅ **Relation to Previous Concepts**\n",
        "\n",
        "- Builds directly on foundational knowledge of linear algebra (vectors, matrices, and their operations), as all deep learning computations are tensor manipulations[1].\n",
        "- Extends the principles of supervised learning: data is represented as tensors, models as compositions of tensor operations, and learning as iterative optimization via backpropagation.\n",
        "- The transition from NumPy to PyTorch is motivated by the need for GPU acceleration, automatic differentiation, and scalable deployment‚Äîkey requirements for modern deep learning[1].\n",
        "- Understanding PyTorch‚Äôs architecture and internals sets the stage for advanced topics: convolutional neural networks (CNNs), recurrent neural networks (RNNs), transformers, and efficient model deployment[1].\n",
        "\n",
        "Citations:\n",
        "[1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/63649134/5065b4d5-154e-4783-b341-d0514085c45c/paste-1.txt\n"
      ],
      "metadata": {
        "id": "EJWQQh-kxvZz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Deep Learning with PyTorch: Lecture 2 Summary and Tensors Explanation\n",
        "\n",
        "---\n",
        "#GROK\n",
        "\n",
        "---\n",
        "## üîπ Key Ideas from the Lecture\n",
        "\n",
        "- **Tensors as Core Data Structures**: Tensors in PyTorch are multidimensional arrays that store data (e.g., inputs, weights) and support operations like matrix multiplication. They are created with a single line (e.g., `torch.tensor()`) and have attributes like shape, device, and gradient tracking.\n",
        "- **Tensor Attributes**: Key attributes include `shape` (dimensions), `device` (CPU/GPU), `requires_grad` (for gradient computation), `stride` (memory layout), and `grad` (stored gradients). These are critical for optimization and debugging.\n",
        "- **CPU to GPU Movement**: Moving tensors from CPU to GPU is computationally expensive due to differing memory formats. This is necessary for parallelized operations like matrix multiplication, but requires careful management (e.g., pinned memory).\n",
        "- **Memory Storage**: Tensors are stored in contiguous memory as a flattened 1D array (row-major order in PyTorch), with a logical multidimensional view created using strides. This impacts performance and optimization.\n",
        "- **Dimensionality and Access**: Accessing elements in a tensor reduces its dimensionality (e.g., a 2D tensor becomes 1D), which can cause dimension mismatch errors in operations like matrix multiplication if not handled properly.\n",
        "- **PyTorch vs. NumPy**: Unlike NumPy arrays, PyTorch tensors support GPU acceleration and autograd for gradient computation. Mixing NumPy arrays with PyTorch tensors requires conversion to ensure compatibility, especially for gradient tracking.\n",
        "- **Practical Debugging**: Understanding tensor properties (e.g., dimensionality, strides) is essential for debugging errors like dimension mismatches or optimizing performance, particularly in large-scale models.\n",
        "- **PyTorch 2.0 Features**: The lecture highlights PyTorch 2.0‚Äôs updated features, emphasizing the need to check hardware compatibility (e.g., NVIDIA GPUs) and refer to documentation for installation and debugging.\n",
        "\n",
        "## üî¢ Tensors: Mathematical Foundations\n",
        "\n",
        "Tensors are multidimensional arrays that generalize scalars $(rank-0)$, vectors $(rank-1)$, and matrices $(rank-2)$ to higher ranks. A tensor $\\( \\mathbf{T} \\in \\mathbb{R}^{n_1 \\times n_2 \\times \\cdots \\times n_k} \\)$ has $\\( k \\)$ dimensions, where each $\\( n_i \\)$ is the size of the $\\( i \\)$-th axis. For example:\n",
        "- A 2D tensor $(matrix)$: $\\( \\mathbf{M} \\in \\mathbb{R}^{m \\times n} \\)$, e.g., $\\( \\begin{bmatrix} 0 & 2 \\\\ 1 & 1 \\end{bmatrix} \\)$.\n",
        "- A 3D tensor $(e.g., RGB image)$: $\\( \\mathbf{T} \\in \\mathbb{R}^{height \\times width \\times 3} \\)$.\n",
        "\n",
        "In deep learning, tensors represent inputs, parameters, and outputs. For a linear layer:\n",
        "$\\[ \\mathbf{z} = \\mathbf{W} \\mathbf{x} + \\mathbf{b} \\]$\n",
        "where $\\( \\mathbf{x} \\in \\mathbb{R}^n \\)$ $(input tensor)$, $\\( \\mathbf{W} \\in \\mathbb{R}^{m \\times n} \\)$ $(weight tensor)$, $\\( \\mathbf{b} \\in \\mathbb{R}^m \\)$ $(bias tensor)$, and $\\( \\mathbf{z} \\in \\mathbb{R}^m $ $(output tensor)$. The operation requires compatible dimensions $(e.g., \\( n \\) must match)$. Accessing an element, e.g., $ \\mathbf{M}[0] $, reduces the tensor‚Äôs rank (from 2 to 1), which can lead to errors if subsequent operations expect the original shape.\n",
        "\n",
        "Tensors are stored in contiguous memory as a 1D array, with strides defining how to navigate the logical multidimensional structure. For a 2x2 matrix $ \\mathbf{M} $, stored as $ [0, 2, 1, 1] $, the stride $ [2, 1] $ indicates steps in memory to move along rows $(2 elements)$ or columns $(1 element)$. This enables efficient operations like transposition without copying data, as only strides are updated.\n",
        "\n",
        "## üß† PyTorch Code\n",
        "\n",
        "Below is a concise PyTorch snippet demonstrating tensor creation, attributes, and dimensionality reduction, highlighting practical usage.\n",
        "\n",
        "```python\n",
        "import torch\n",
        "\n",
        "# Create a 2D tensor\n",
        "x = torch.tensor([[0, 2], [1, 1]], dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "# Access attributes\n",
        "print(\"Tensor:\\n\", x)\n",
        "print(\"Shape:\", x.shape)\n",
        "print(\"Strides:\", x.stride())\n",
        "print(\"Device:\", x.device)\n",
        "print(\"Requires grad:\", x.requires_grad)\n",
        "\n",
        "# Access element (reduces dimension)\n",
        "y = x[0]  # 1D tensor\n",
        "print(\"Accessed element (1D):\\n\", y, \"Shape:\", y.shape)\n",
        "\n",
        "# Matrix multiplication\n",
        "z = torch.matmul(x, x.t())  # Requires compatible dimensions\n",
        "print(\"Matrix product:\\n\", z)\n",
        "```\n",
        "\n",
        "This code creates a 2D tensor, displays its attributes, shows dimensionality reduction when accessing an element, and performs a matrix multiplication, illustrating tensor operations.\n",
        "\n",
        "## üí° Analogy: Tensors as a Warehouse\n",
        "\n",
        "Imagine a massive warehouse storing goods (data) in PyTorch. Each item is packed into boxes (tensors) of varying shapes: a single item (scalar), a row of items (vector), a grid of shelves (matrix), or stacked grids (higher-rank tensor). In NLP, a tensor might be a stack of word embeddings (batch √ó sequence length √ó embedding dimension), while in computer vision, it‚Äôs a grid of pixels (height √ó width √ó channels). The warehouse‚Äôs inventory system (PyTorch) tracks each box‚Äôs properties: size (shape), location (CPU/GPU), and whether it needs updating (requires_grad). Goods are stored in a single, continuous row (contiguous memory), but the system uses a map (strides) to view them as multidimensional structures, like organizing shelves logically without moving items.\n",
        "\n",
        "Moving boxes from the main storage (CPU) to a high-speed processing unit (GPU) is time-consuming, like transporting goods to a faster distribution center. Accessing an item (e.g., a row from a grid) unpacks a smaller box (lower-rank tensor), which can cause issues if a machine expects the original grid for processing (dimension mismatch). The warehouse‚Äôs efficiency (optimization) depends on understanding this map and avoiding unnecessary moves, mirroring tensor management in deep learning.\n",
        "\n",
        "## üîÅ Connection to Prior Lessons\n",
        "\n",
        "This lecture builds on your NLP studies, where text data (e.g., tokenized sentences) is represented as tensors for transformer models, similar to the multidimensional arrays discussed here. The focus on tensor operations connects to your gradient descent discussions, where weights (tensors) are updated iteratively, requiring autograd compatibility that NumPy lacks. The dimensionality issues echo preprocessing challenges in decision tree models (e.g., California Housing dataset), where feature arrays must align correctly. Understanding tensor attributes like strides prepares you for optimizing NLP models in Hugging Face, as efficient memory management is critical for large transformer models.\n",
        "\n",
        "**Word Count**: ~650 words\n",
        "\n",
        "**Prerequisites**: Basic linear algebra (vectors, matrices), Python programming, and familiarity with NumPy. Prior exposure to machine learning concepts (e.g., gradient descent, NLP data processing) is helpful but not required.\n",
        "\n",
        "---\n",
        "#Perplexity\n",
        "\n",
        "---\n",
        "üîπ **Key Takeaways from \"Lecture 2: Tensors\" (PyTorch Deep Learning)**\n",
        "\n",
        "- **Tensors as the Foundation of Deep Learning**  \n",
        "  - In PyTorch, *tensors* are the core data structure, generalizing scalars, vectors, and matrices to N-dimensional arrays.\n",
        "  - Creating a tensor is straightforward: `torch.tensor(data)` constructs a tensor object, which has numerous associated methods and attributes (e.g., `shape`, `stride`, `device`, `requires_grad`, `grad_fn`).\n",
        "  - Every tensor in PyTorch is an object that stores data in contiguous memory, typically as a flattened (1D) C/C++ array. The logical N-dimensional shape is a *view* on this flat storage, managed via *strides*.\n",
        "\n",
        "- **Memory Layout and Strides**  \n",
        "  - The *stride* of a tensor determines how many memory steps you need to move along each dimension. It‚Äôs crucial for understanding how PyTorch efficiently accesses elements and performs operations.\n",
        "  - PyTorch (like NumPy) uses *row-major* order (C-style), meaning elements in the last dimension are contiguous in memory.\n",
        "\n",
        "- **Device Management: CPU vs. GPU**  \n",
        "  - Tensors can reside on either the CPU or GPU. Moving a tensor between devices (`tensor.to('cuda')`) is a *costly* operation, as it involves copying and potentially reformatting data for the target hardware.\n",
        "  - The *pin_memory* argument is relevant when transferring data between CPU and GPU, optimizing data transfer speed, especially for large datasets.\n",
        "\n",
        "- **Tensor Attributes and Creation**  \n",
        "  - When creating tensors, key arguments include:\n",
        "    - `data`: The initial values (list, array, etc.)\n",
        "    - `dtype`: Data type (e.g., `torch.float32`)\n",
        "    - `device`: Where to store the tensor (`'cpu'` or `'cuda'`)\n",
        "    - `requires_grad`: Whether to track gradients for automatic differentiation\n",
        "    - `pin_memory`: Optimizes transfer to GPU (advanced use)\n",
        "  - Example:  \n",
        "    ```python\n",
        "    x = torch.tensor([1, 2, 3], dtype=torch.float32, device='cuda', requires_grad=True)\n",
        "    ```\n",
        "\n",
        "- **Scalar, 1D, and Multi-Dimensional Tensors**  \n",
        "  - Passing a single value creates a *scalar* (0D tensor).  \n",
        "  - Passing a list creates a 1D tensor, a list of lists a 2D tensor, and so on.\n",
        "  - Accessing elements reduces the tensor‚Äôs dimensionality by one. For example, accessing an element of a 2D tensor returns a 1D tensor.\n",
        "  - This reduction in dimension is critical: it can cause shape mismatches in later operations, especially in matrix multiplication or broadcasting.\n",
        "\n",
        "- **Accessing Tensor Data**  \n",
        "  - For *scalars* (0D tensors), use `.item()` to extract the value.\n",
        "  - For higher-dimensional tensors, standard Python indexing applies, but always be mindful of the resulting shape and dimension.\n",
        "\n",
        "- **Interoperability and Gradient Tracking**  \n",
        "  - PyTorch tensors are not interchangeable with NumPy arrays or other frameworks‚Äô data structures, especially if you need gradient computation.\n",
        "  - All operations requiring gradients must be performed with PyTorch tensors (`requires_grad=True`), as PyTorch‚Äôs autograd system tracks only its own tensors.\n",
        "\n",
        "- **Practical Debugging and Internals**  \n",
        "  - Understanding tensor attributes and memory layout helps in debugging shape and device errors.\n",
        "  - PyTorch‚Äôs internal organization is modular, with a C++ backend and Pythonic front-end. Most tensor operations ultimately call optimized C++ code for performance.\n",
        "\n",
        "- **Installation and Compatibility**  \n",
        "  - Installing PyTorch with GPU support requires careful attention to hardware and CUDA version compatibility. Errors here are often cryptic and difficult to debug.\n",
        "\n",
        "---\n",
        "\n",
        "### **Mathematical Foundations**\n",
        "\n",
        "- **Tensor Definition:**  \n",
        "  A tensor of rank $ n $ is an $ n $-dimensional array:  \n",
        "  $\n",
        "  \\text{Tensor} \\in \\mathbb{R}^{d_1 \\times d_2 \\times \\cdots \\times d_n}\n",
        "  $\n",
        "- **Stride Calculation:**  \n",
        "  For a tensor $ X $ with shape $(d_1, d_2, ..., d_n)$, the stride tells you how many memory steps to take to move along each dimension.\n",
        "- **Gradient Tracking:**  \n",
        "  If $ y = f(x) $ and $ x $ is a tensor with `requires_grad=True`, PyTorch will automatically compute  \n",
        "  $\n",
        "  \\frac{\\partial y}{\\partial x}\n",
        "  $\n",
        "  during backpropagation.\n",
        "\n",
        "---\n",
        "\n",
        "### **Practical Code Example**\n",
        "\n",
        "```python\n",
        "import torch\n",
        "\n",
        "# Create a scalar tensor\n",
        "scalar = torch.tensor(9)\n",
        "print(\"Scalar:\", scalar, \"| Shape:\", scalar.shape, \"| Dim:\", scalar.ndim)\n",
        "\n",
        "# Create a 1D tensor\n",
        "vec = torch.tensor([9])\n",
        "print(\"1D Tensor:\", vec, \"| Shape:\", vec.shape, \"| Dim:\", vec.ndim)\n",
        "\n",
        "# Create a 2D tensor\n",
        "mat = torch.tensor([[0, 2], [1, 1]])\n",
        "print(\"2D Tensor:\", mat, \"| Shape:\", mat.shape, \"| Dim:\", mat.ndim)\n",
        "\n",
        "# Move tensor to GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "mat_gpu = mat.to(device)\n",
        "\n",
        "# Demonstrate requires_grad\n",
        "param = torch.tensor([1.0, 2.0], requires_grad=True)\n",
        "y = (param ** 2).sum()\n",
        "y.backward()\n",
        "print(\"Gradient:\", param.grad)\n",
        "\n",
        "# Accessing elements and observing dimension reduction\n",
        "elem = mat[0]\n",
        "print(\"Element mat[0]:\", elem, \"| Shape:\", elem.shape, \"| Dim:\", elem.ndim)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **Analogy: Tensors as Apartment Buildings**\n",
        "\n",
        "Imagine a tensor as a *large apartment building*:\n",
        "\n",
        "- The **building** itself is a single, long corridor of rooms (the contiguous memory array).\n",
        "- The **floors, wings, and rooms** represent dimensions:  \n",
        "  - 1st dimension = floors  \n",
        "  - 2nd dimension = wings on each floor  \n",
        "  - 3rd dimension = rooms in each wing, etc.\n",
        "- The **address** of a specific room (element) is calculated using *strides*‚Äîhow many steps to take to move between floors, wings, or rooms.\n",
        "- The **logical layout** (floors, wings, rooms) is just a way to help people (and programs) find rooms quickly, but all rooms are still arranged in a single corridor.\n",
        "- **Moving the building** (CPU to GPU) means copying all rooms to a new location, possibly rearranging them to fit the new city‚Äôs (device‚Äôs) rules‚Äîthis takes time and planning.\n",
        "- **Accessing a room** (element) on a particular floor and wing (dimension) gives you a smaller building (tensor) with one less floor (dimension).\n",
        "\n",
        "**Why is this important?**  \n",
        "Just as knowing the building‚Äôs layout helps you find rooms efficiently and avoid getting lost, understanding tensor shapes, strides, and devices helps you write bug-free, high-performance deep learning code. If you forget how the rooms are arranged (lose track of dimensions), you might not be able to deliver the pizza (compute the operation) to the right room (tensor element)!\n",
        "\n",
        "---\n",
        "\n",
        "### **Connecting to Prior Lessons**\n",
        "\n",
        "- Builds on the idea that *all* deep learning computations are ultimately tensor operations.\n",
        "- Reinforces the importance of device management for leveraging hardware acceleration.\n",
        "- Highlights the need for careful attention to tensor shapes and dimensions to avoid subtle bugs in model implementation.\n",
        "- Prepares you for more advanced topics, such as broadcasting, automatic differentiation, and efficient data pipelines.\n",
        "\n",
        "---\n",
        "\n",
        "**Summary:**  \n",
        "Understanding PyTorch tensors‚Äîtheir creation, attributes, memory layout, device management, and interaction with autograd‚Äîis foundational for all deep learning work. Mastery here leads to fewer bugs, faster code, and a deeper intuition for building and debugging neural networks.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "v9GNAes2GFGV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attributes to tensors\n",
        "\n",
        "---\n",
        "#GROK\n",
        "# Deep Learning with PyTorch: Lecture 3 Attributes Tensors Summary and Strides Explanation\n",
        "\n",
        "As a deep learning instructor with over a decade of experience specializing in PyTorch, I‚Äôll summarize the key ideas from the \"Lecture 3 Attributes Tensors\" video, focusing on the mathematical foundations and practical applications of **tensor strides**, a critical concept highlighted in the transcript. The summary of key ideas will be at least 600 words to capture the essence of the lecture. I‚Äôll explain strides using analogies and real-world examples, connecting to your prior studies in natural language processing (NLP), gradient descent, and decision trees, as noted in our previous conversations (e.g., NLP tensor representations, gradient descent as iterative refinement). The response will adhere to the requested format, include a concise code snippet (‚â§35 lines), and focus on mathematical foundations and practical applications.\n",
        "\n",
        "## üîπ Key Ideas from the Lecture (Summary, ~650 words)\n",
        "\n",
        "- **Tensor Dimensions and Structure**: Tensors are multidimensional arrays, with dimensionality determined by nested brackets. A scalar (0D) has no brackets, a 1D tensor (vector) has one set (e.g., `[1, 2, 3]`), and a 2D tensor (matrix) has two (e.g., `[[1, 2], [3, 4]]`). Each dimension‚Äôs size must match (e.g., a 3x3 matrix has three rows, each with three elements). This structure is crucial for operations like matrix multiplication in neural networks, where dimension mismatches cause errors.\n",
        "- **Memory Storage and Flattening**: Internally, tensors are stored in contiguous memory as a flattened 1D array in row-major order (e.g., a 2x2 matrix `[[0, 2], [1, 1]]` is stored as `[0, 2, 1, 1]`). The logical multidimensional view is constructed using metadata like shape and strides, enabling efficient access without restructuring memory.\n",
        "- **Stride Concept**: Strides are metadata that define the number of memory steps to move along each dimension. For a 3x3 matrix, strides `[3, 1]` indicate 3 steps to move to the next row and 1 step to the next column. Strides enable operations like accessing elements or summing along dimensions without copying data, critical for performance.\n",
        "- **Accessing Elements and Dimensionality Reduction**: Accessing an element in a tensor reduces its dimensionality (e.g., accessing `x[1]` in a 3x3 matrix returns a 1D tensor of length 3). This can lead to dimension mismatch errors in operations like matrix multiplication if not managed, especially in complex models.\n",
        "- **Reduction Operations**: Operations like sum or max (e.g., `torch.sum(x, dim=0)`) reduce a dimension by aggregating elements along it, resulting in a tensor with one fewer dimension. For example, summing a 3x3 matrix along `dim=0` (rows) produces a 1x3 tensor. Strides guide these operations internally to ensure correct element selection.\n",
        "- **Practical Implications for Debugging**: Understanding strides and dimensions is essential for debugging semantic errors, such as incorrect reduction operations that don‚Äôt throw errors but degrade model performance (e.g., summing along the wrong dimension in NLP batch processing). These errors are hard to detect without a grasp of tensor mechanics.\n",
        "- **Stride-Based Efficiency**: Operations like transposition or extracting diagonal elements use strides to avoid copying data, significantly reducing computational cost. For a 1000x1000 matrix, extracting diagonals using strides requires \\( O(n) \\) operations, not \\( O(n^2) \\), enhancing efficiency in large-scale models.\n",
        "- **Cautions with Tensor Operations**: Converting NumPy arrays to PyTorch tensors or copying tensors (e.g., using `clone()`) involves memory interactions that can affect performance or gradients. In-place operations (e.g., modifying a tensor directly) can disrupt gradient computation, requiring careful handling in training.\n",
        "- **Real-World Applications**: In NLP, tensors represent batched sequences (e.g., batch √ó sequence length √ó embedding dimension), requiring correct dimension handling for operations like attention. In computer vision, transposing image tensors (e.g., height √ó width √ó channels) involves specifying dimensions to avoid incorrect channel swaps, as shown in the lecture‚Äôs image example.\n",
        "- **Foundational Importance**: Like backpropagation or tree traversal in prior studies, mastering tensor attributes is foundational but challenging. The lecture emphasizes practicing with small tensors to build intuition, as errors in dimension handling can compound in complex architectures like CNNs or transformers, echoing the need to revisit basics.\n",
        "\n",
        "## üî¢ Strides: Mathematical Foundations\n",
        "\n",
        "Strides define how a tensor‚Äôs flattened 1D memory array is navigated to form its logical multidimensional structure. For a tensor \\( \\mathbf{T} \\in \\mathbb{R}^{n_1 \\times n_2 \\times \\cdots \\times n_k} \\), the stride for dimension \\( i \\) is the number of elements to skip in memory to move one step along that dimension. For a 3x3 matrix \\( \\mathbf{M} \\):\n",
        "\\[ \\mathbf{M} = \\begin{bmatrix} 0.1 & 0.2 & 0.3 \\\\ 0.4 & 0.5 & 0.6 \\\\ 0.7 & 0.8 & 0.9 \\end{bmatrix} \\]\n",
        "Stored as `[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]`, the strides are `[3, 1]`:\n",
        "- Stride for `dim=0` (rows): 3, as moving to the next row skips 3 elements.\n",
        "- Stride for `dim=1` (columns): 1, as moving to the next column skips 1 element.\n",
        "\n",
        "To access \\( \\mathbf{M}[i, j] \\), the memory index is:\n",
        "\\[ \\text{index} = i \\cdot \\text{stride}[0] + j \\cdot \\text{stride}[1] \\]\n",
        "For \\( \\mathbf{M}[1, 2] \\):\n",
        "\\[ \\text{index} = 1 \\cdot 3 + 2 \\cdot 1 = 5 \\]\n",
        "This points to `0.6`. For reduction, summing along `dim=0`:\n",
        "\\[ \\text{sum}[j] = \\sum_{i=0}^{2} \\mathbf{M}[i, j] \\]\n",
        "The stride `[3, 1]` guides iteration over rows for each column, yielding `[1.2, 1.5, 1.8]`. Strides ensure efficient operations without reshaping memory.\n",
        "\n",
        "## üß† PyTorch Code\n",
        "\n",
        "Below is a concise PyTorch snippet demonstrating strides and reduction operations, illustrating their role in tensor manipulation.\n",
        "\n",
        "```python\n",
        "import torch\n",
        "\n",
        "# Create a 3x3 tensor\n",
        "x = torch.tensor([[0.1, 0.2, 0.3],\n",
        "                  [0.4, 0.5, 0.6],\n",
        "                  [0.7, 0.8, 0.9]])\n",
        "\n",
        "# Access attributes\n",
        "print(\"Tensor:\\n\", x)\n",
        "print(\"Shape:\", x.shape)\n",
        "print(\"Strides:\", x.stride())\n",
        "\n",
        "# Access element (reduces dimension)\n",
        "row = x[1]  # 1D tensor [0.4, 0.5, 0.6]\n",
        "print(\"Row (dim=0, index=1):\\n\", row, \"Shape:\", row.shape)\n",
        "\n",
        "# Reduction operation: sum along dim=0\n",
        "sum_dim0 = torch.sum(x, dim=0)\n",
        "print(\"Sum along dim=0:\\n\", sum_dim0, \"Shape:\", sum_dim0.shape)\n",
        "```\n",
        "\n",
        "This code creates a 3x3 tensor, displays its strides, accesses a row (reducing dimensionality), and performs a sum along `dim=0`, showing stride-guided reduction.\n",
        "\n",
        "## üí° Analogy: Strides as a Library Catalog\n",
        "\n",
        "Imagine a library where books (tensor elements) are stored in a single, continuous row on a shelf (contiguous memory). The library‚Äôs catalog (strides) provides instructions to navigate this row as if books were arranged in multidimensional shelves (e.g., rows and columns for a matrix). For a 3x3 matrix, the catalog lists strides `[3, 1]`, meaning move 3 books to reach the next row or 1 book for the next column. To find a book (e.g., `M[1, 2]`), the catalog calculates its position without rearranging shelves, ensuring quick access.\n",
        "\n",
        "In NLP, a tensor of batched sentences (batch √ó sequence length √ó embedding dimension) is like a library with books organized by batch, sentence, and word features. Summing embeddings across sentences (e.g., `dim=1`) uses the catalog to add books element-wise, reducing the sentence dimension. Misinterpreting the catalog (strides) can lead to adding the wrong books, like summing across batches instead, causing errors in model performance, similar to misaligned data in your NLP preprocessing.\n",
        "\n",
        "## üîÅ Connection to Prior Lessons\n",
        "\n",
        "This lecture builds on your NLP studies, where tensors represent batched sequences for transformers, requiring precise dimension handling (e.g., batch √ó sequence length √ó embedding dimension). Strides connect to your gradient descent discussions, as efficient tensor operations (guided by strides) accelerate parameter updates, akin to optimizing iterative refinement. The dimensionality reduction issue echoes preprocessing challenges in decision trees (e.g., California Housing dataset), where feature arrays must align. Understanding strides prepares you for debugging NLP models in Hugging Face, where incorrect reduction operations (e.g., summing across wrong dimensions) can degrade transformer performance, reinforcing the need to master foundational tensor mechanics.\n",
        "\n",
        "**Prerequisites**: Basic linear algebra (vectors, matrices), Python programming, and familiarity with NumPy. Prior exposure to NLP tensor representations and gradient descent is helpful but not required.\n",
        "\n",
        "---\n",
        "#Perplexity\n",
        "\n",
        "---\n",
        "üîπ **Summary of Key Ideas from \"Lecture 3: Attributes and Tensors\" (PyTorch Deep Learning)**\n",
        "\n",
        "- **Tensors: Structure, Dimensions, and Memory**\n",
        "  - Tensors are the fundamental data structure in PyTorch, generalizing scalars, vectors, and matrices to N-dimensional arrays.\n",
        "  - The *dimension* of a tensor (also called ‚Äúrank‚Äù) is determined by the number of nested brackets or axes. For example, a list forms a 1D tensor, a list of lists forms a 2D tensor, and so on.\n",
        "  - Each dimension can be accessed and indexed, and accessing an element reduces the tensor‚Äôs dimensionality by one.\n",
        "  - Internally, all tensor elements are stored in a contiguous, flattened memory block. The logical multi-dimensional structure is a *view* managed by *stride* and *shape* metadata.\n",
        "\n",
        "- **Stride: The Key to Efficient Access**\n",
        "  - *Stride* is a tuple that tells how many steps in memory you need to take to move along each dimension. For a 1D tensor, the stride is typically 1; for a 2D tensor (matrix), it‚Äôs usually (number of columns, 1) in row-major order.\n",
        "  - Stride enables efficient element access: accessing an element by index is a constant-time (O(1)) operation, simply an offset calculation in memory.\n",
        "  - When slicing or indexing tensors, PyTorch uses stride and shape to create ‚Äúviews‚Äù without copying data, making operations efficient but sometimes surprising if you expect a copy.\n",
        "\n",
        "- **Indexing and Dimensionality**\n",
        "  - Indexing a tensor with fewer indices than its rank returns a tensor of lower dimension (e.g., indexing a matrix with one index returns a vector/1D tensor).\n",
        "  - This reduction in dimension is crucial for understanding the outputs of operations and for debugging shape mismatches in code.\n",
        "\n",
        "- **Reduction Operations and Axes**\n",
        "  - Operations like `sum`, `mean`, or `max` across a particular dimension are called *reductions* because they reduce the tensor‚Äôs rank by one.\n",
        "  - The `dim` (or `axis`) parameter specifies which dimension to reduce. For example, summing along `dim=0` means summing across rows (i.e., column-wise sum), while `dim=1` means summing across columns (row-wise sum).\n",
        "  - The choice of axis is critical: incorrect axes can lead to silent semantic errors that are hard to debug, especially in large models.\n",
        "\n",
        "- **Practical Implications for Deep Learning**\n",
        "  - In deep learning, tensors often have 4 or more dimensions (e.g., batches, channels, height, width in vision; batches, sequence length, embedding size in NLP), so mastering dimensions and strides is essential.\n",
        "  - Reduction operations are ubiquitous‚Äîfor loss calculation, aggregation, or pooling‚Äîand mistakes in axis specification can silently degrade model performance.\n",
        "  - PyTorch (like NumPy and TensorFlow) always stores tensors as flat arrays with metadata for shape and stride, allowing efficient logical views and operations.\n",
        "\n",
        "- **Copying, Views, and In-Place Operations**\n",
        "  - Assigning one tensor to another (e.g., `y = x`) creates a view, not a copy; changes to one affect the other. To make a true copy, use `x.clone()`.\n",
        "  - Converting between NumPy arrays and PyTorch tensors often creates shared-memory views, so changes in one may reflect in the other‚Äîbe cautious!\n",
        "  - In-place operations (`x.add_()`, `x.copy_()`, etc.) can interfere with gradient computation and should generally be avoided unless you fully understand the implications.\n",
        "\n",
        "- **Transposing and Manipulating Dimensions**\n",
        "  - Transposing multi-dimensional tensors (e.g., images with shape `[height, width, channels]`) requires specifying which dimensions to swap.\n",
        "  - Simple `transpose()` calls may not behave as expected for tensors with more than two dimensions; always specify axes explicitly.\n",
        "\n",
        "- **Debugging and Best Practices**\n",
        "  - Always check tensor shapes, strides, and device placements when debugging.\n",
        "  - For complex operations, start with small, interpretable tensors to build intuition before scaling up.\n",
        "  - Practice and repeated exposure are necessary to build intuition for multi-dimensional tensor operations.\n",
        "\n",
        "---\n",
        "\n",
        "**Mathematical Foundations & Equations**\n",
        "\n",
        "- **Tensor Definition:**  \n",
        "  $ \\text{Tensor} \\in \\mathbb{R}^{d_1 \\times d_2 \\times \\cdots \\times d_n} $\n",
        "- **Stride Calculation:**  \n",
        "  For a tensor $ X $ with shape $(d_0, d_1, ..., d_{n-1})$, the stride for dimension $ i $ is the product of all dimensions to its right:\n",
        "  $\n",
        "  \\text{stride}_i = \\prod_{j=i+1}^{n-1} d_j\n",
        "  $\n",
        "- **Reduction Example (Sum along axis):**  \n",
        "  For a 2D tensor $ X $ of shape $(m, n)$:\n",
        "  $\n",
        "  \\text{sum}(X, \\text{dim}=0) \\rightarrow \\text{shape: } (n)\n",
        "  $\n",
        "  (sums over rows, giving column-wise sum)\n",
        "\n",
        "---\n",
        "\n",
        "**Practical Code Example**\n",
        "\n",
        "```python\n",
        "import torch\n",
        "\n",
        "# Create a 3D tensor (batch, rows, cols)\n",
        "x = torch.tensor([\n",
        "    [[1, 2], [3, 4], [5, 6]],\n",
        "    [[7, 8], [9, 10], [11, 12]]\n",
        "], dtype=torch.float32)\n",
        "\n",
        "print(\"Shape:\", x.shape)  # (2, 3, 2)\n",
        "print(\"Stride:\", x.stride())\n",
        "\n",
        "# Sum along different axes\n",
        "sum_dim0 = x.sum(dim=0)  # Sums over batch\n",
        "sum_dim1 = x.sum(dim=1)  # Sums over rows\n",
        "sum_dim2 = x.sum(dim=2)  # Sums over columns\n",
        "\n",
        "print(\"Sum along dim 0 (batch):\", sum_dim0)\n",
        "print(\"Sum along dim 1 (rows):\", sum_dim1)\n",
        "print(\"Sum along dim 2 (cols):\", sum_dim2)\n",
        "\n",
        "# Demonstrate view vs copy\n",
        "y = x[0]\n",
        "y[0, 0] = 100\n",
        "print(\"Original x after modifying y:\", x)\n",
        "\n",
        "# Proper copy\n",
        "z = x.clone()\n",
        "z[0, 0, 0] = 999\n",
        "print(\"x unchanged after modifying z:\", x)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "**Analogy: Tensors as Multi-Level Office Buildings**\n",
        "\n",
        "Imagine a tensor as a multi-level office building:\n",
        "\n",
        "- **Floors** represent the first dimension; **rooms** on each floor represent the second; **desks** in each room represent the third, and so on.\n",
        "- The *stride* tells you how many steps you need to take to move from one desk to the next, or from one room to the next floor.\n",
        "- When you sum along a dimension, it‚Äôs like collecting all the papers from every desk on the same floor (dimension) and combining them into a single report‚Äîreducing the number of floors (dimensions) in the building.\n",
        "- Assigning one floor plan to another (view) means they share the same physical space: changes in one are reflected in the other. Making a copy is like building a new, identical floor elsewhere.\n",
        "- When working in a building with many floors and rooms, knowing the exact layout (shape and stride) is crucial to efficiently finding and organizing information‚Äîjust as in deep learning, where correct tensor manipulation is vital for model correctness and performance.\n",
        "\n",
        "**Takeaway:**  \n",
        "Just as a building‚Äôs structure determines how people move and interact, a tensor‚Äôs shape and stride determine how data is accessed and manipulated. Mastering this ‚Äúarchitecture‚Äù is essential for building robust, efficient deep learning models.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "EoOBGPyDsXir"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Autograds\n",
        "---\n",
        "#GROK\n",
        "\n",
        "---\n",
        "# Deep Learning with PyTorch: Lecture 4 Autograd Summary and Explanation\n",
        "\n",
        "## üîπ Key Ideas from the Lecture (Summary, ~650 words)\n",
        "\n",
        "- **Autograd as the Engine of Deep Learning**: Autograd is PyTorch‚Äôs automatic differentiation system, computing gradients for tensor operations, likened to the engine of a neural network, with tensors as the fuel. It enables parameter updates via backpropagation, critical for training models like neural networks, CNNs, and transformers.\n",
        "- **Tensor Attributes and Gradients**: Tensors have attributes like `shape`, `device`, `requires_grad`, and `grad`. The `requires_grad=True` flag marks tensors (typically parameters like weights) for gradient computation. After backpropagation, gradients are stored in the `grad` attribute (e.g., `x.grad`), accessible for optimization.\n",
        "- **Gradient Computation Process**: Autograd tracks operations during the forward pass, building a computation graph. For a neuron‚Äôs output $ z = \\sigma(\\mathbf{w}^T \\mathbf{x} + b) $, autograd computes gradients like $ \\frac{\\partial L}{\\partial \\mathbf{w}} $ (where \\( L \\) is the loss) by applying the chain rule during the backward pass, accumulating gradients across samples.\n",
        "- **Forward and Backward Methods**: Every operation (e.g., matrix multiplication, activation) has a forward method (computing the output) and a backward method (computing gradients). For example, for multiplication $ z = x \\cdot y $, the backward method computes $ \\frac{\\partial L}{\\partial x} = \\frac{\\partial L}{\\partial z} \\cdot y $. These are defined for elementary operations, allowing modular network construction.\n",
        "- **Tape-Based Autodiff**: Autograd uses a tape-based approach, storing forward operations and their inputs (e.g., via `ctx.save_for_backward`) for use in backward passes. Unlike finite difference methods, which are numerically unstable and computationally expensive, tape-based autodiff is efficient and stable, leveraging pre-defined backward methods.\n",
        "- **Elementary Operations as Lego Blocks**: Operations like matrix multiplication, addition, and activations are elementary building blocks. By defining forward and backward methods for each, autograd enables flexible network architectures (e.g., combining CNNs and RNNs in encoder-decoder models) without requiring users to compute gradients manually.\n",
        "- **Practical Benefits for Debugging and Research**: Understanding autograd aids debugging (e.g., identifying vanishing gradients) and research (e.g., designing custom operations). It simplifies user interaction by abstracting gradient computation, requiring only forward pass and loss definitions, as seen in frameworks like PyTorch and TensorFlow.\n",
        "- **Operation Composition**: Complex operations (e.g., a linear layer $ \\mathbf{z} = \\mathbf{W} \\mathbf{x} + \\mathbf{b} $) are composed of elementary operations (matrix multiplication and addition). Autograd handles their gradients automatically, ensuring scalability across architectures like transformers, introduced post-2017, which PyTorch supports flexibly.\n",
        "- **Avoiding Common Pitfalls**: Users must ensure operations use PyTorch tensors (not NumPy arrays) for autograd compatibility. In-place operations can disrupt gradient tracking, requiring careful use (e.g., using `clone()` for copies). These considerations are critical for stable training.\n",
        "- **Connection to Neural Network Training**: Autograd‚Äôs gradient accumulation (e.g., summing gradients over samples) supports stochastic gradient descent, enabling parameter updates. This is foundational for training complex models, as emphasized in the lecture‚Äôs sigmoid neuron example, where gradients drive learning.\n",
        "\n",
        "## üî¢ Autograd: Mathematical Foundations\n",
        "\n",
        "Autograd computes gradients using reverse-mode automatic differentiation, tracking operations in a computation graph. For a function $ z = f(\\mathbf{x}, \\mathbf{y}) $, where $ \\mathbf{x} $ and $ \\mathbf{y} $ are input tensors, autograd records the forward pass and computes gradients during the backward pass. Consider a simple operation $ z = x \\cdot y $:\n",
        "- Forward: $ z = x \\cdot y $.\n",
        "- Backward: Given the gradient $ \\frac{\\partial L}{\\partial z} $, compute:\n",
        "  $ \\frac{\\partial L}{\\partial x} = \\frac{\\partial L}{\\partial z} \\cdot \\frac{\\partial z}{\\partial x} = \\frac{\\partial L}{\\partial z} \\cdot y $\n",
        " $ \\frac{\\partial L}{\\partial y} = \\frac{\\partial L}{\\partial z} \\cdot \\frac{\\partial z}{\\partial y} = \\frac{\\partial L}{\\partial z} \\cdot x $\n",
        "\n",
        "For a neural network layer $ \\mathbf{z} = \\mathbf{W} \\mathbf{x} + \\mathbf{b} $, followed by a sigmoid activation $ \\sigma(\\mathbf{z}) $ and loss $ L $, autograd builds a graph:\n",
        "$ L = f(\\sigma(\\mathbf{W} \\mathbf{x} + \\mathbf{b}), \\mathbf{y}) $\n",
        "During backpropagation, autograd applies the chain rule:\n",
        "$ \\frac{\\partial L}{\\partial \\mathbf{W}} = \\frac{\\partial L}{\\partial \\sigma} \\cdot \\frac{\\partial \\sigma}{\\partial \\mathbf{z}} \\cdot \\frac{\\partial \\mathbf{z}}{\\partial \\mathbf{W}} $\n",
        "where $ \\frac{\\partial \\mathbf{z}}{\\partial \\mathbf{W}} = \\mathbf{x}^T $, and $ \\frac{\\partial \\sigma}{\\partial \\mathbf{z}} = \\sigma(\\mathbf{z}) \\cdot (1 - \\sigma(\\mathbf{z})) $. Autograd stores intermediate values e.g., $ \\mathbf{x} $ and function pointers (e.g., `grad_fn`) to compute these efficiently.\n",
        "\n",
        "## üß† PyTorch Code\n",
        "\n",
        "Below is a concise PyTorch snippet demonstrating autograd for a simple neural network layer, highlighting gradient computation.\n",
        "\n",
        "```python\n",
        "import torch\n",
        "\n",
        "# Define tensors\n",
        "x = torch.tensor([1.0, 2.0], requires_grad=False)  # Input\n",
        "W = torch.tensor([[0.5, 1.0], [1.5, 2.0]], requires_grad=True)  # Weights\n",
        "b = torch.tensor([0.1, 0.2], requires_grad=True)  # Bias\n",
        "\n",
        "# Forward pass\n",
        "z = torch.matmul(W, x) + b\n",
        "y = torch.sigmoid(z)\n",
        "loss = y.sum()  # Dummy loss\n",
        "\n",
        "# Backward pass\n",
        "loss.backward()\n",
        "\n",
        "# Access gradients\n",
        "print(\"Gradient w.r.t. W:\\n\", W.grad)\n",
        "print(\"Gradient w.r.t. b:\\n\", b.grad)\n",
        "```\n",
        "\n",
        "This code defines a linear layer, applies a sigmoid activation, computes a loss, and uses autograd to calculate gradients, illustrating its role in training.\n",
        "\n",
        "## üí° Analogy: Autograd as a GPS Navigator\n",
        "\n",
        "Imagine training a neural network as driving a car (model) to a destination (optimal parameters) using a GPS navigator (autograd). The car‚Äôs fuel (tensors) powers the journey, but the GPS calculates the best route by analyzing slopes (gradients) at each turn. During the drive (forward pass), the GPS records the path (computation graph), noting operations like turns (matrix multiplication) or speed changes (activations). On the return trip (backward pass), it uses these records to compute slopes, guiding the car back to adjust its route (update parameters) via the chain rule, like following road signs backward.\n",
        "\n",
        "In NLP, a transformer model processes batched sentences (tensors) to predict translations. Autograd navigates through operations (e.g., attention, feedforward layers), computing gradients to adjust weights, ensuring accurate predictions. Missteps, like using NumPy arrays, are like ignoring GPS instructions, leading to crashes (gradient errors). This mirrors debugging in your NLP studies, where correct tensor operations ensure model convergence.\n",
        "\n",
        "## üîÅ Connection to Prior Lessons\n",
        "\n",
        "This lecture builds on your NLP studies, where tensors represent batched sequences for transformers, requiring autograd for gradient-based training, similar to the gradient descent iterative refinement you explored with Archimedes‚Äô method. The emphasis on elementary operations echoes decision tree preprocessing (e.g., California Housing dataset), where data alignment ensures model correctness. Autograd‚Äôs role in debugging connects to your NLP challenges with ambiguous text processing, where gradient issues (e.g., vanishing gradients) require careful tensor management, preparing you for optimizing transformer models in Hugging Face.\n",
        "\n",
        "**Prerequisites**: Linear algebra (matrices, derivatives), Python programming, and familiarity with gradient descent. Prior exposure to NLP tensors and machine learning basics is helpful but not required.\n",
        "\n",
        "---\n",
        "#Perplexity\n",
        "\n",
        "---\n",
        "##üîπ **Key Ideas from \"Lecture 4: Autograd\"**  \n",
        "- **Autograd as Deep Learning's Engine**:  \n",
        "  - PyTorch's `autograd` automates gradient computation for tensors with `requires_grad=True`, enabling backpropagation without manual derivative calculations.  \n",
        "  - Every tensor operation is tracked in a **computation graph**, allowing gradients to flow backward through the network.  \n",
        "\n",
        "- **Core Components**:  \n",
        "  - **Tensor Attributes**:  \n",
        "    - `grad`: Stores computed gradients  \n",
        "    - `grad_fn`: Points to the function that created the tensor (e.g., `AddBackward`, `SigmoidBackward`)  \n",
        "    - `is_leaf`: Identifies tensors not created by operations (e.g., input data/parameters)  \n",
        "  - **Local Gradients**: Precomputed derivatives for elementary operations (e.g., multiplication: ‚àÇz/‚àÇx = y) used in chain rule calculations.  \n",
        "\n",
        "- **Forward vs. Backward Pass**:  \n",
        "  - **Forward**: Operations are recorded with their backward methods.  \n",
        "  - **Backward**: Receives upstream gradient (‚àÇL/‚àÇz), computes local gradients (‚àÇz/‚àÇx), and propagates ‚àÇL/‚àÇx = ‚àÇL/‚àÇz * ‚àÇz/‚àÇx.  \n",
        "\n",
        "- **Efficiency Over Finite Differences**:  \n",
        "  - Autograd uses symbolic differentiation (exact gradients) instead of numerical approximation, avoiding instability and redundant computations.  \n",
        "\n",
        "- **Modular Design**:  \n",
        "  - **Elementary Operations**: 100+ predefined ops (matrix mult, ReLU, etc.) with custom backward methods.  \n",
        "  - **Composition**: Complex networks are built by chaining these ops, with gradients computed automatically via the chain rule.  \n",
        "\n",
        "üî¢ **Mathematical Foundations**  \n",
        "- **Chain Rule**:  \n",
        "  For operation $ z = f(x, y) $, gradients propagate as:  \n",
        "  $\n",
        "  \\frac{\\partial L}{\\partial x} = \\frac{\\partial L}{\\partial z} \\cdot \\frac{\\partial z}{\\partial x}\n",
        "  $  \n",
        "- **Local Gradient Example (Multiplication)**:  \n",
        "  If $ z = x \\cdot y $:  \n",
        "  $\n",
        "  \\frac{\\partial z}{\\partial x} = y, \\quad \\frac{\\partial z}{\\partial y} = x\n",
        "  $  \n",
        "\n",
        "üß† **Practical Code Example**  \n",
        "```python\n",
        "import torch\n",
        "\n",
        "# Custom layer demonstrating autograd\n",
        "class CustomLayer(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.weight = torch.nn.Parameter(torch.randn(3, 3))  # Tracked for gradients\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x @ self.weight  # Matrix multiplication tracked by autograd\n",
        "\n",
        "# Forward pass\n",
        "x = torch.randn(5, 3, requires_grad=True)\n",
        "layer = CustomLayer()\n",
        "y = layer(x)\n",
        "loss = y.sum()\n",
        "\n",
        "# Backward pass (autograd computes ‚àÇloss/‚àÇweight and ‚àÇloss/‚àÇx)\n",
        "loss.backward()\n",
        "\n",
        "print(\"Weight gradient:\", layer.weight.grad.shape)  # [3, 3]\n",
        "print(\"Input gradient:\", x.grad.shape)  # [5, 3]\n",
        "```\n",
        "\n",
        "üí° **Analogy: Autograd as Factory Quality Control**  \n",
        "*Imagine a car factory:*  \n",
        "- **Forward Pass**: Assembly line workers (operations) build a car (output) using parts (input tensors). Each worker stamps a unique ID on their contribution.  \n",
        "- **Backward Pass**: A defect is found (loss). Quality control (autograd) traces the ID stamps backward:  \n",
        "  - Asks Worker C: \"How did you install this defective part?\"  \n",
        "  - Worker C: \"I used Part B from Worker B.\"  \n",
        "  - Asks Worker B: \"How did you make Part B?\"  \n",
        "  - Continues until reaching the original faulty part supplier (parameter).  \n",
        "- **Result**: Identifies exactly which workers (operations) contributed to the defect and by how much (gradients).  \n",
        "\n",
        "**Why It Matters**:  \n",
        "Just as efficient defect tracing improves car manufacturing, autograd's operation-specific backward methods enable precise gradient computation for million-parameter networks.\n",
        "\n",
        "üîÅ **Connection to Prior Lessons**  \n",
        "- Builds on tensor attributes (`grad_fn`, `requires_grad`) from Lecture 2-3.  \n",
        "- Enables parameter updates (Lecture 1's \"fuel + engine\" analogy) through gradient computation.  \n",
        "- Foundation for implementing advanced architectures (CNNs, transformers) covered in later lectures.  \n",
        "\n",
        "**Key Innovation**:  \n",
        "Autograd decouples network design (forward ops) from gradient math, letting researchers focus on architecture rather than derivative calculations.\n",
        "\n"
      ],
      "metadata": {
        "id": "NVXWrvkLhm11"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lecture 5 Computational graphs for deep neural networks\n",
        "---\n",
        "#GROK\n",
        "\n",
        "---\n",
        "# Deep Learning with PyTorch: Lecture 5 Computational Graphs Summary and Explanation\n",
        "\n",
        "## üîπ Key Ideas from the Lecture (Summary, ~650 words)\n",
        "\n",
        "- **Computational Graphs as the Backbone**: Computational graphs represent neural network operations as a directed acyclic graph (DAG), where nodes are tensors (leaf or non-leaf) and edges are operations (e.g., multiplication, sigmoid). They enable automatic gradient computation via autograd, forming the backbone of deep learning frameworks like PyTorch.\n",
        "- **Leaf vs. Non-Leaf Tensors**: Leaf tensors are user-created (e.g., inputs $\\( \\mathbf{x} \\)$, weights $\\( \\mathbf{W} \\))$ with `requires_grad` set manually (True for parameters, False for inputs). Non-leaf tensors (e.g., $\\( \\mathbf{y} = \\mathbf{W} \\mathbf{x} \\)$) result from operations, inheriting `requires_grad=True` if any input tensor has it, but their gradients are not stored to save memory.\n",
        "- **Gradient Tracking and Inheritance**: Setting `requires_grad=True` on a tensor (e.g., $\\( \\mathbf{W} \\)$) ensures autograd tracks operations involving it. Resulting tensors (e.g., $\\( \\mathbf{y} = \\sigma(\\mathbf{W} \\mathbf{x}) \\)$) inherit this property, with `grad_fn` pointing to the backward method (e.g., `SigmoidBackward`). This enables chain-rule-based gradient computation.\n",
        "- **Backward Pass Mechanics**: Calling `loss.backward()` initiates backpropagation, starting with $\\( \\frac{\\partial L}{\\partial L} = 1 \\)$. Autograd traverses the graph backward, computing local gradients (e.g., $\\( \\frac{\\partial z}{\\partial y} \\)$) and multiplying them with incoming gradients (e.g.,$ \\( \\frac{\\partial L}{\\partial z} \\)$) to produce gradients like \\( \\frac{\\partial L}{\\partial \\mathbf{W}} \\), stored only for leaf tensors.\n",
        "- **Operation-Specific Backward Methods**: Each operation (e.g., multiplication, sigmoid) has a predefined backward method in PyTorch, computing local gradients. For example, for \\( z = x \\cdot y \\), the backward method computes \\( \\frac{\\partial z}{\\partial x} = y \\). Since 2017, PyTorch has expanded to include methods for complex operations like FFT, reducing the need for custom implementations.\n",
        "- **Memory Efficiency**: Non-leaf tensor gradients are discarded after backpropagation to minimize memory usage, critical for large networks. Leaf tensor gradients (e.g., \\( \\mathbf{W}.grad \\)) are retained for parameter updates, balancing efficiency and functionality.\n",
        "- **Extensibility for Innovation**: PyTorch allows custom operations by defining forward and backward methods, enabling researchers to implement novel functions (e.g., FFT in 2017). This flexibility supports diverse architectures, from CNNs to transformers, and extends beyond deep learning to differentiable programming.\n",
        "- **Practical Debugging and Scalability**: Understanding computational graphs aids debugging (e.g., detecting gradient flow issues) and scaling complex networks. The graph‚Äôs structure ensures gradients are computed correctly, regardless of architecture, supporting innovations like encoder-decoder models combining CNNs and RNNs.\n",
        "- **Graph Construction**: Operations like $\\( \\mathbf{y} = \\mathbf{W} \\mathbf{x} + \\mathbf{b} \\)$ form a graph with nodes for tensors and operations. Each operation stores inputs (via `ctx.save_for_backward`) and points to its backward method (via `grad_fn`), automating gradient computation during backpropagation.\n",
        "- **Real-World Relevance**: In applications like NLP (e.g., transformer models), computational graphs manage batched sequence operations, ensuring efficient gradient computation for attention layers. In computer vision, they handle image tensor operations, supporting scalable training of deep networks.\n",
        "\n",
        "## üî¢ Computational Graphs: Mathematical Foundations\n",
        "\n",
        "A computational graph is a DAG where nodes represent tensors or operations, and edges denote data flow. For a linear layer $\\( \\mathbf{z} = \\mathbf{W} \\mathbf{x} + \\mathbf{b} \\)$, followed by a sigmoid $\\( \\mathbf{y} = \\sigma(\\mathbf{z}) \\)$ and loss $\\( L \\)$, the graph includes:\n",
        "- Leaf nodes: $\\( \\mathbf{x} \\)$, $\\( \\mathbf{W} \\), \\( \\mathbf{b} \\)$ (user-created tensors).\n",
        "- Non-leaf nodes: $\\( \\mathbf{z} \\)$, \\( \\mathbf{y} \\), \\( L \\) (resulting tensors).\n",
        "- Operations: Matrix multiplication $(\\( \\mathbf{W} \\mathbf{x} \\))$, addition $(\\( + \\mathbf{b} \\))$, sigmoid $(\\( \\sigma \\))$.\n",
        "\n",
        "During backpropagation, autograd computes gradients using the chain rule. For $\\( \\frac{\\partial L}{\\partial \\mathbf{W}} \\)$:\n",
        "$\\[ \\frac{\\partial L}{\\partial \\mathbf{W}} = \\frac{\\partial L}{\\partial \\mathbf{y}} \\cdot \\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{z}} \\cdot \\frac{\\partial \\mathbf{z}}{\\partial \\mathbf{W}} \\]$\n",
        "where:\n",
        "- $\\( \\frac{\\partial \\mathbf{z}}{\\partial \\mathbf{W}} = \\mathbf{x}^T \\)$,\n",
        "- $\\( \\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{z}} = \\sigma(\\mathbf{z}) \\cdot (1 - \\sigma(\\mathbf{z})) \\)$,\n",
        "- $\\( \\frac{\\partial L}{\\partial \\mathbf{y}} \\)$ is provided by the loss function.\n",
        "\n",
        "The graph stores local gradients (e.g., $\\( \\frac{\\partial \\mathbf{z}}{\\partial \\mathbf{W}} \\))$ and intermediate values (e.g.,$ \\( \\mathbf{x} \\)$) during the forward pass, enabling efficient backward computation.\n",
        "\n",
        "## üß† PyTorch Code\n",
        "\n",
        "Below is a concise PyTorch snippet demonstrating a computational graph for a simple neural network layer, highlighting gradient computation.\n",
        "\n",
        "```python\n",
        "import torch\n",
        "\n",
        "# Leaf tensors\n",
        "x = torch.tensor([1.0, 2.0], requires_grad=False)  # Input\n",
        "W = torch.tensor([[0.5, 1.0], [1.5, 2.0]], requires_grad=True)  # Weights\n",
        "b = torch.tensor([0.1, 0.2], requires_grad=True)  # Bias\n",
        "\n",
        "# Operations forming computational graph\n",
        "z = torch.matmul(W, x) + b  # Non-leaf tensor\n",
        "y = torch.sigmoid(z)  # Non-leaf tensor\n",
        "loss = y.sum()  # Scalar loss\n",
        "\n",
        "# Backward pass\n",
        "loss.backward()\n",
        "\n",
        "# Access gradients (leaf tensors only)\n",
        "print(\"Gradient w.r.t. W:\\n\", W.grad)\n",
        "print(\"Gradient w.r.t. b:\\n\", b.grad)\n",
        "print(\"y.grad (non-leaf, None):\\n\", y.grad)\n",
        "```\n",
        "\n",
        "This code creates a computational graph for a linear layer with sigmoid activation, computes gradients via `backward()`, and shows that only leaf tensor gradients are stored.\n",
        "\n",
        "## üí° Analogy: Computational Graphs as a Recipe Book\n",
        "\n",
        "Imagine training a neural network as cooking a complex dish (model) using a recipe book (computational graph). Ingredients (leaf tensors like \\( \\mathbf{W} \\), \\( \\mathbf{x} \\)) are mixed through steps (operations like multiplication, sigmoid) to produce intermediate dishes (non-leaf tensors like \\( \\mathbf{z} \\), \\( \\mathbf{y} \\)) and a final dish (loss). The recipe book records each step‚Äôs instructions (forward method) and how to adjust ingredients if the dish fails (backward method). When tasting reveals the dish needs tweaking (backpropagation), the book guides adjustments to ingredients (gradients for \\( \\mathbf{W} \\), \\( \\mathbf{b} \\)), but discards notes on intermediate mixtures (non-leaf gradients) to save space.\n",
        "\n",
        "In NLP, a transformer model processes batched sentences (tensors) to predict translations. The recipe book (graph) tracks operations like attention, ensuring gradients adjust weights efficiently, akin to refining a recipe. Mistakes, like skipping a step (e.g., not setting `requires_grad=True`), ruin the dish, mirroring gradient issues in your Lecture 4 autograd studies.\n",
        "\n",
        "## üîÅ Connection to Prior Lessons\n",
        "\n",
        "This lecture builds on Lecture 2 (tensors), where you learned tensors are the fuel, with attributes like `requires_grad` setting the stage for computational graphs. Lecture 3 (strides) emphasized memory efficiency, mirrored here in discarding non-leaf gradients. Lecture 4 (autograd) introduced forward and backward methods, which computational graphs organize into a DAG for scalable gradient computation. The graph‚Äôs role in debugging extends Lecture 4‚Äôs focus on gradient flow, ensuring correct gradient propagation in complex models like those in your NLP studies.\n",
        "\n",
        "---\n",
        "#Perplexity\n",
        "\n",
        "---\n",
        "üîπ **Key Concepts from Lecture 5: Autograd in Practice (PyTorch)**\n",
        "\n",
        "**1. What is Autograd?**  \n",
        "- PyTorch‚Äôs `autograd` is an engine for automatic differentiation, enabling efficient computation of gradients (partial derivatives) for all tensor operations that involve parameters requiring optimization[1][2].\n",
        "- It dynamically builds a computational graph at runtime, allowing for flexible model architectures, including those with control flow and variable-length loops[1][2].\n",
        "\n",
        "**2. How Autograd Works in Neural Network Training**  \n",
        "- **Forward Pass:**  \n",
        "  - The model processes input data through its layers to make predictions[2].\n",
        "  - All operations on tensors with `requires_grad=True` are tracked in a dynamic computation graph[1][2].\n",
        "- **Loss Computation:**  \n",
        "  - The difference between predictions and actual labels is computed using a loss function[2].\n",
        "- **Backward Pass:**  \n",
        "  - Calling `.backward()` on the loss tensor triggers autograd to traverse the computation graph in reverse, computing gradients for each parameter using the chain rule[1][2].\n",
        "  - Gradients are stored in each parameter‚Äôs `.grad` attribute, ready for optimization[2][3].\n",
        "\n",
        "**3. Practical Example: Autograd in Action**  \n",
        "```python\n",
        "import torch\n",
        "\n",
        "# Create input tensor with gradients enabled\n",
        "a = torch.linspace(0., 2. * torch.pi, steps=25, requires_grad=True)\n",
        "\n",
        "# Example operation\n",
        "y = torch.sin(a) * 2\n",
        "\n",
        "# Compute a scalar output (e.g., sum for loss)\n",
        "loss = y.sum()\n",
        "\n",
        "# Backward pass: compute gradients\n",
        "loss.backward()\n",
        "\n",
        "# Access gradients\n",
        "print(a.grad)\n",
        "```\n",
        "- In this example, `a.grad` contains the derivative of `loss` with respect to each element of `a`[1].\n",
        "\n",
        "**4. Using Autograd in Model Training**  \n",
        "- Define a model as a subclass of `torch.nn.Module`. All parameters are tracked automatically for gradients.\n",
        "- Example training loop:\n",
        "```\n",
        "model = TinyModel()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "```\n",
        "```\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()          # Clear previous gradients\n",
        "    output = model(input)          # Forward pass\n",
        "    loss = loss_fn(output, target) # Compute loss\n",
        "    loss.backward()                # Backward pass (autograd)\n",
        "    optimizer.step()               # Update parameters\n",
        "```\n",
        "\n",
        "- This loop is the core of neural network training in PyTorch[2][3].\n",
        "\n",
        "\n",
        "**5. Fine-Grained Control: Turning Autograd Off and On**  \n",
        "- Temporarily disable autograd for inference or evaluation using `with torch.no_grad():` or by setting `requires_grad=False` on tensors[1].\n",
        "- This saves memory and computation when gradients are not needed.\n",
        "\n",
        "**6. Handling Non-Scalar Outputs**  \n",
        "- `.backward()` requires a scalar output. For non-scalar tensors, you must supply a gradient argument representing the vector-Jacobian product[1][2]:\n",
        "```python\n",
        "x = torch.randn(3, requires_grad=True)\n",
        "y = x * 2\n",
        "while y.data.norm() < 1000:\n",
        "    y = y * 2\n",
        "v = torch.tensor([0.1, 1.0, 0.0001])\n",
        "y.backward(v)  # Supplies external gradients\n",
        "print(x.grad)\n",
        "```\n",
        "- This is essential for advanced use cases, such as custom loss functions or vector-valued outputs[1][2].\n",
        "\n",
        "**7. Computational Graph and Dynamic Nature**  \n",
        "- PyTorch‚Äôs computation graph is recreated on each forward pass, enabling dynamic models (e.g., those with if/else logic or loops)[1][2].\n",
        "- After `.backward()` is called, the graph is freed for memory efficiency.\n",
        "\n",
        "---\n",
        "\n",
        "### **Mathematical Foundation**\n",
        "\n",
        "- **Chain Rule in Backpropagation:**  \n",
        "  For a function $ L = f(x) $, autograd computes  \n",
        "  $\n",
        "  \\frac{\\partial L}{\\partial x}\n",
        "  $\n",
        "  by chaining local derivatives through the computation graph.\n",
        "\n",
        "- **Vector-Jacobian Product:**  \n",
        "  When backward is called on a vector output $ y $ with external gradient $ v $, autograd computes  \n",
        "  $\n",
        "  v^T \\cdot J\n",
        "  $\n",
        "  where $ J $ is the Jacobian of $ y $ with respect to $ x $[1][2].\n",
        "\n",
        "---\n",
        "\n",
        "### **Analogy: Autograd as a Dynamic Assembly Line**\n",
        "\n",
        "Imagine a factory where each operation (addition, multiplication, activation) is a worker on an assembly line.  \n",
        "- As data (tensors) flows forward, each worker logs how they transformed the product.\n",
        "- When a defect (loss) is found, inspectors (autograd) trace steps backward, using each worker‚Äôs log to compute how much each contributed to the defect (gradient).\n",
        "- Because the assembly line is rebuilt for each product (dynamic graph), the factory can flexibly change its process for every new order (input/model structure).\n",
        "\n",
        "---\n",
        "\n",
        "### **Best Practices and Debugging**\n",
        "\n",
        "- Always check `.grad` attributes after `.backward()` to ensure gradients are computed.\n",
        "- Use `torch.no_grad()` or `.detach()` to prevent unwanted gradient tracking during evaluation or inference.\n",
        "- Zero gradients with `optimizer.zero_grad()` before each backward pass to avoid accumulation[3].\n",
        "\n",
        "---\n",
        "\n",
        "**Summary:**  \n",
        "PyTorch‚Äôs autograd system is the backbone of neural network training, enabling flexible, dynamic, and efficient gradient computation. It tracks operations on tensors, builds a computation graph at runtime, and computes gradients automatically during backpropagation, allowing you to focus on model design and experimentation rather than manual differentiation[1][2][3].\n",
        "\n",
        "Citations:\n",
        "[1] https://pytorch.org/tutorials/beginner/introyt/autogradyt_tutorial.html\n",
        "[2] https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html\n",
        "[3] https://pyimagesearch.com/2021/10/11/pytorch-transfer-learning-and-image-classification/\n",
        "[4] https://isip.piconepress.com/courses/temple/ece_4822/resources/books/Deep-Learning-with-PyTorch.pdf\n",
        "[5] https://pytorch.org/tutorials/beginner/knowledge_distillation_tutorial.html\n",
        "[6] https://www.youtube.com/watch?v=E-I2DNVzQLg\n",
        "[7] https://www.linkedin.com/learning/hands-on-pytorch-machine-learning/understand-pytorch-autograd\n",
        "[8] https://www.docker.com/blog/how-to-train-and-deploy-a-linear-regression-model-using-pytorch-part-1/\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "qmvu8wj_hmzM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#\n",
        "\n",
        "---\n",
        "#GROK\n",
        "\n",
        "---\n",
        "# Deep Learning with PyTorch: Lecture 6 Autograd Implementation Summary and Explanation\n",
        "\n",
        "## üîπ Key Ideas from the Lecture (Summary, ~650 words)\n",
        "\n",
        "- **Autograd and Tensor Binding**: Autograd, PyTorch‚Äôs automatic differentiation engine, works alongside the tensor library (aten) to compute gradients. Setting `requires_grad=True` binds a tensor to autograd, enabling it to track operations and build a computational graph, essential for gradient-based optimization in neural networks.\n",
        "- **Leaf and Non-Leaf Tensors**: Leaf tensors (e.g., inputs $\\( \\mathbf{x} \\)$, weights $\\( \\mathbf{W} \\))$ are user-created, with `requires_grad` set manually. Non-leaf tensors (e.g., $\\( \\mathbf{y} = \\sigma(\\mathbf{W} \\mathbf{x}) \\)$) result from operations, inheriting `requires_grad=True` if any input has it. Only leaf tensor gradients are stored post-backpropagation to optimize memory.\n",
        "- **Forward and Backward Passes**: During the forward pass, autograd saves inputs (via `ctx.save_for_backward`) for use in the backward pass. For example, in $\\( \\mathbf{y} = \\mathbf{W} \\mathbf{x} \\)$, $\\( \\mathbf{x} \\)$ is saved. The backward pass, triggered by `loss.backward()`, computes gradients using the chain rule, storing results in `tensor.grad` for leaf tensors.\n",
        "- **Dynamic Computational Graphs**: PyTorch uses dynamic computational graphs, rebuilt and deleted each iteration after `backward()`. This contrasts with TensorFlow‚Äôs static graphs, offering flexibility (e.g., for dropout, where network structure changes per iteration) but requiring careful gradient management to avoid accumulation.\n",
        "- **Gradient Accumulation and Zeroing**: Gradients accumulate across iterations unless explicitly reset (e.g., `W.grad.zero_()`). This is critical in stochastic gradient descent (SGD), where parameters are updated per sample, and batch gradient descent (GD), where gradients accumulate over all samples before updating.\n",
        "- **Context Managers for Parameter Updates**: Updating parameters (e.g., $\\( \\mathbf{W} = \\mathbf{W} - \\eta \\cdot \\frac{\\partial L}{\\partial \\mathbf{W}} \\)$) via operations makes them non-leaf, disrupting gradient tracking. The `torch.no_grad()` context manager disables autograd during updates, ensuring parameters remain leaf tensors.\n",
        "- **Hooks for Debugging**: Hooks allow monitoring or modifying gradients of non-leaf tensors during backpropagation. For example, registering a hook on \\( \\mathbf{y} \\) captures its gradient, useful for visualizing gradient flow in complex networks like transformers to diagnose issues like vanishing gradients.\n",
        "- **Practical Implementation in SGD**: The lecture demonstrates training a sigmoid neuron $(\\( \\hat{y} = \\sigma(\\mathbf{W} \\mathbf{x} + b) \\))$ using SGD on synthetic data. The process involves forward propagation, loss computation, backward propagation, and parameter updates under `torch.no_grad()`, with hooks to track gradient changes.\n",
        "- **Memory and Error Handling**: Errors arise if `backward()` is called without `requires_grad=True` or if parameters become non-leaf. The aten-autograd binding, implemented in C++, simplifies tensor operations but requires understanding error messages for debugging, especially in complex networks.\n",
        "- **Transition to Higher-Level APIs**: The lecture prepares for using `torch.nn`, which automates parameter initialization and gradient updates, abstracting low-level autograd details. This simplifies building neural networks, as demonstrated with a three-layer network for binary classification, highlighting practical scalability.\n",
        "\n",
        "## üî¢ Autograd Implementation: Mathematical Foundations\n",
        "\n",
        "Autograd implements reverse-mode automatic differentiation, constructing a dynamic computational graph for gradient computation. For a neural network layer \\( \\hat{y} = \\sigma(\\mathbf{W} \\mathbf{x} + b) \\) with loss $\\( L = \\frac{1}{2} \\sum (\\hat{y} - y)^2 \\)$, autograd tracks operations:\n",
        "- Forward: Compute $\\( \\mathbf{z} = \\mathbf{W} \\mathbf{x} + b \\)$, then $\\( \\hat{y} = \\sigma(\\mathbf{z}) \\)$, storing $\\( \\mathbf{x} \\)$, $\\( \\mathbf{W} \\), \\( b \\)$.\n",
        "- Backward: Compute gradients via the chain rule:\n",
        "  $\\[ \\frac{\\partial L}{\\partial \\mathbf{W}} = \\frac{\\partial L}{\\partial \\hat{y}} \\cdot \\frac{\\partial \\hat{y}}{\\partial \\mathbf{z}} \\cdot \\frac{\\partial \\mathbf{z}}{\\partial \\mathbf{W}} \\]$\n",
        "  where:\n",
        "  - $\\( \\frac{\\partial L}{\\partial \\hat{y}} = \\hat{y} - y \\)$,\n",
        "  - $\\( \\frac{\\partial \\hat{y}}{\\partial \\mathbf{z}} = \\sigma(\\mathbf{z}) \\cdot (1 - \\sigma(\\mathbf{z})) \\)$,\n",
        "  - $\\( \\frac{\\partial \\mathbf{z}}{\\partial \\mathbf{W}} = \\mathbf{x}^T \\)$.\n",
        "\n",
        "Parameter updates follow:\n",
        "$\\[ \\mathbf{W} \\leftarrow \\mathbf{W} - \\eta \\cdot \\frac{\\partial L}{\\partial \\mathbf{W}} \\]$\n",
        "Under `torch.no_grad()`, this ensures $\\( \\mathbf{W} \\)$ remains a leaf tensor. Hooks capture intermediate gradients, e.g., $\\( \\frac{\\partial L}{\\partial \\mathbf{z}} \\)$, for analysis.\n",
        "\n",
        "## üß† PyTorch Code\n",
        "\n",
        "Below is a concise PyTorch snippet implementing autograd for a sigmoid neuron, including hooks and context managers.\n",
        "\n",
        "```python\n",
        "import torch\n",
        "\n",
        "# Leaf tensors\n",
        "x = torch.tensor([3.0], requires_grad=True)  # Input\n",
        "w = torch.tensor([0.5], requires_grad=True)  # Weight\n",
        "b = torch.tensor([1.0], requires_grad=True)  # Bias\n",
        "eta = 0.1  # Learning rate\n",
        "\n",
        "# Hook to track gradients\n",
        "grads = []\n",
        "def hook(grad):\n",
        "    grads.append(grad.item())\n",
        "\n",
        "# Forward pass\n",
        "z = w * x + b\n",
        "z.register_hook(hook)  # Hook on non-leaf tensor\n",
        "y = torch.sigmoid(z)\n",
        "loss = y.sum()  # Dummy loss\n",
        "\n",
        "# Backward pass\n",
        "loss.backward()\n",
        "\n",
        "# Parameter update\n",
        "with torch.no_grad():\n",
        "    w -= eta * w.grad\n",
        "    b -= eta * b.grad\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "\n",
        "print(\"Gradient w.r.t. w:\", w.grad)  # None (zeroed)\n",
        "print(\"Hooked gradient for z:\", grads)  # Captured gradient\n",
        "```\n",
        "\n",
        "This code demonstrates autograd with a hook to track gradients and `torch.no_grad()` for parameter updates.\n",
        "\n",
        "## üí° Analogy: Autograd as a Factory Assembly Line\n",
        "\n",
        "Imagine training a neural network as running a factory assembly line (autograd) to produce a product (model). Raw materials (leaf tensors like $\\( \\mathbf{W} \\)$, $\\( \\mathbf{x} \\))$ enter workstations (operations like multiplication, sigmoid), producing intermediate parts (non-leaf tensors like $\\( \\mathbf{z} \\)$, $\\( \\mathbf{y} \\)$). The line‚Äôs blueprint (computational graph) is redrawn each shift (iteration) to adapt to changes (dynamic graph), unlike a fixed factory layout (static graph). Quality checks (backpropagation) adjust materials based on defects (gradients), but adjustments (parameter updates) occur in a no-tracking zone (`torch.no_grad()`) to keep materials intact. Inspectors (hooks) monitor part quality (gradients) without halting the line, aiding troubleshooting.\n",
        "\n",
        "In NLP, a transformer model processes batched sentences (tensors) to predict translations. The assembly line (autograd) tracks operations like attention, adjusting weights via gradients. Hooks inspect gradient flow, helping diagnose issues like vanishing gradients, as seen in Lecture 4‚Äôs debugging focus. Errors, like updating weights without `torch.no_grad()`, are like mislabeling materials, disrupting production, echoing Lecture 5‚Äôs gradient management.\n",
        "\n",
        "## üîÅ Connection to Prior Lessons\n",
        "\n",
        "This lecture builds on Lecture 2 (tensors), where tensors‚Äô `requires_grad` attribute enables autograd binding, and Lecture 3 (strides), where memory efficiency aligns with discarding non-leaf gradients. Lecture 4 (autograd) introduced forward/backward methods, now implemented with dynamic graphs in Lecture 5 (computational graphs), which this lecture operationalizes. The use of hooks extends Lecture 5‚Äôs debugging focus, while `torch.no_grad()` addresses Lecture 5‚Äôs non-leaf tensor issues, preparing for Lecture 7‚Äôs `torch.nn` automation.\n",
        "\n",
        "<br><br>\n",
        "\n",
        "---\n",
        "#Perplexity\n",
        "\n",
        "---\n",
        "\n",
        "üîπ **Key Ideas from Lecture 6: Autograd Implementation (PyTorch)**  \n",
        "\n",
        "- **Autograd Engine Workflow**:  \n",
        "  - Tracks operations on tensors with `requires_grad=True` to build dynamic computation graphs.  \n",
        "  - **Forward Pass**: Records operations and their backward methods (e.g., `MulBackward`, `AddBackward`).  \n",
        "  - **Backward Pass**: Uses chain rule to compute gradients via `loss.backward()`, stored in `.grad` attributes.  \n",
        "\n",
        "- **Dynamic vs. Static Graphs**:  \n",
        "  - **Dynamic**: PyTorch rebuilds the graph each iteration (flexible for models with changing architectures, e.g., dropout).  \n",
        "  - **Static**: Predefined graph (e.g., TensorFlow 1.x), efficient but inflexible.  \n",
        "\n",
        "- **Parameter Updates & Context Managers**:  \n",
        "  - Use `torch.no_grad()` during updates to avoid tracking operations (e.g., `w = w - Œ∑ * w.grad`).  \n",
        "  - **Gradient Accumulation**: Must call `optimizer.zero_grad()` to reset gradients between iterations.  \n",
        "\n",
        "- **Hooks for Debugging**:  \n",
        "  - Register hooks (e.g., `tensor.register_hook()`) to monitor/modify gradients during backward passes.  \n",
        "  - Critical for visualizing gradient flow in complex networks (e.g., diagnosing vanishing gradients).  \n",
        "\n",
        "- **Practical Challenges**:  \n",
        "  - **Non-leaf Tensors**: Operations on parameters create non-leaf tensors; use `retain_graph=True` to retain gradients.  \n",
        "  - **Data Type Mismatch**: Gradients require float tensors (e.g., `dtype=torch.float32`).  \n",
        "\n",
        "---\n",
        "\n",
        "üî¢ **Mathematical Foundations**  \n",
        "- **Chain Rule in Backprop**:  \n",
        "  For a loss $ L $ and parameter $ \\theta $:  \n",
        "  $\n",
        "  \\frac{\\partial L}{\\partial \\theta} = \\frac{\\partial L}{\\partial y} \\cdot \\frac{\\partial y}{\\partial \\theta}\n",
        "  $  \n",
        "- **Vector-Jacobian Product**:  \n",
        "  For non-scalar outputs, backward pass uses:  \n",
        "  $\n",
        "  \\text{grad_output} = v^T \\cdot J\n",
        "  $  \n",
        "  where $ J $ is the Jacobian of outputs w.r.t inputs.  \n",
        "\n",
        "---\n",
        "\n",
        "üß† **Practical Code Example**  \n",
        "```python\n",
        "import torch\n",
        "\n",
        "# Manual parameter training (SGD)\n",
        "X = torch.randn(100, 3, requires_grad=True)  # Inputs\n",
        "y_true = torch.randn(100, 1)                 # Labels\n",
        "w = torch.randn(3, 1, requires_grad=True)    # Weights\n",
        "b = torch.randn(1, requires_grad=True)       # Bias\n",
        "lr = 0.01\n",
        "\n",
        "for epoch in range(100):\n",
        "    # Forward pass\n",
        "    y_pred = X @ w + b\n",
        "    loss = ((y_pred - y_true) ** 2).mean()\n",
        "    \n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    \n",
        "    # Update parameters (disable autograd tracking)\n",
        "    with torch.no_grad():\n",
        "        w -= lr * w.grad\n",
        "        b -= lr * b.grad\n",
        "    \n",
        "    # Reset gradients\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "üí° **Analogy: Autograd as a Construction Site Foreman**  \n",
        "*Imagine building a skyscraper (neural network):*  \n",
        "- **Workers (Operations)**: Each worker (e.g., `torch.mm` for matrix multiplication) logs their task in a blueprint (computation graph).  \n",
        "- **Foreman (Autograd)**: After construction (forward pass), inspects flaws (loss) and traces back via the blueprint to identify faulty work (gradients).  \n",
        "- **Dynamic Blueprint**: Unlike static blueprints (traditional engineering), PyTorch allows modifying the design mid-construction (dynamic graphs) for adaptive fixes.  \n",
        "- **Quality Control (Hooks)**: Install cameras (hooks) on specific floors (layers) to monitor material flow (gradients) in real-time.  \n",
        "\n",
        "**Why It Matters**:  \n",
        "Just as a foreman ensures each worker‚Äôs contribution aligns with the final structure, autograd ensures gradients correctly update parameters, enabling iterative improvement.  \n",
        "\n",
        "---\n",
        "\n",
        "üîÅ **Connection to Prior Lessons**  \n",
        "- Builds on **tensor attributes** (Lecture 2-3): `.grad`, `.grad_fn`, and `requires_grad` enable gradient tracking.  \n",
        "- Extends **dynamic computation graphs** (Lecture 4-5): Flexibility crucial for modern architectures (e.g., transformers with adaptive attention).  \n",
        "- **Parameter initialization** (Lecture 1): Correct `dtype` and device placement ensure autograd compatibility.  \n",
        "\n",
        "**Innovation**: Autograd decouples model design (forward logic) from derivative math, enabling rapid experimentation without manual gradient calculations.\n",
        "\n",
        "Citations:\n",
        "[1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/63649134/c0e48859-b0e3-41a2-806c-1acc16f87deb/paste-2.txt\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "EScbuMZLhmwv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lecture 7 : NN Module\n",
        "---\n",
        "#GROK\n",
        "\n",
        "---\n",
        "# Deep Learning with PyTorch: Lecture 7 NN Module Summary and Explanation\n",
        "\n",
        "As a deep learning instructor with over a decade of experience specializing in PyTorch, I‚Äôll summarize the key ideas from the \"Lecture 7 NN Module\" video, focusing on the mathematical foundations and practical applications of the **torch.nn.Module** class, the central concept highlighted in the transcript. The summary of key ideas will be at least 800 words to capture the lecture‚Äôs essence. I‚Äôll explain `torch.nn.Module` using analogies and real-world examples, connecting to your prior deep learning studies in this conversation (e.g., tensors, strides, autograd, computational graphs, autograd implementation from Lectures 2‚Äì6). The response will adhere to the requested format, include a concise code snippet (‚â§50 lines), and focus on mathematical foundations and practical applications.\n",
        "\n",
        "## üîπ Key Ideas from the Lecture (Summary, ~850 words)\n",
        "\n",
        "- **Role of torch.nn.Module**: The `torch.nn.Module` class is a cornerstone of PyTorch, providing a framework to define and manage neural network architectures. It abstracts repetitive tasks like parameter initialization, forward propagation, and gradient computation, simplifying the construction of complex models compared to using `torch.tensor` alone.\n",
        "- **Leaf and Non-Leaf Tensors Recap**: Leaf tensors (e.g., weights \\( \\mathbf{W} \\), biases \\( \\mathbf{b} \\)) are user-created with `requires_grad` set manually (True for parameters). Non-leaf tensors (e.g., \\( \\mathbf{y} = \\mathbf{W} \\mathbf{x} \\)) result from operations, inheriting `requires_grad=True` if inputs require gradients, but their gradients are not stored to save memory, as discussed in Lecture 5.\n",
        "- **Dynamic Computational Graphs**: PyTorch‚Äôs dynamic computational graphs, introduced in Lecture 5, are rebuilt and destroyed each iteration, offering flexibility (e.g., for dropout) over TensorFlow‚Äôs static graphs. `nn.Module` integrates with this dynamic system, automatically managing graph construction and gradient computation via autograd (Lecture 4).\n",
        "- **Automating Repetitive Tasks**: Building neural networks with raw tensors involves repetitive code for parameter initialization, forward passes, and gradient updates. `nn.Module` automates these by encapsulating layers (e.g., linear, convolutional) as modular components, reducing boilerplate code and errors, especially for large architectures with millions of parameters.\n",
        "- **Modularization with Layers**: Layers like `nn.Linear` abstract operations (e.g., \\( \\mathbf{y} = \\mathbf{W} \\mathbf{x} + \\mathbf{b} \\)). Users specify input and output dimensions, and `nn.Module` initializes parameters (e.g., \\( \\mathbf{W} \\in \\mathbb{R}^{\\text{out} \\times \\text{in}} \\), \\( \\mathbf{b} \\in \\mathbb{R}^{\\text{out}} \\)) with `requires_grad=True`, handling their management internally.\n",
        "- **Forward Method Definition**: Each `nn.Module` subclass defines a `forward` method, specifying how inputs are transformed (e.g., matrix multiplication, activation). The backward pass is handled automatically by autograd, leveraging predefined backward methods for operations like matrix multiplication (`MulBackward`) or addition (`AddBackward`), as seen in Lecture 6.\n",
        "- **Parameter Management with nn.Parameter**: The `nn.Parameter` class, a subclass of `torch.Tensor`, automatically sets `requires_grad=True`, marking tensors as learnable parameters. This simplifies parameter tracking, as `nn.Module` collects all `nn.Parameter` instances for optimization, eliminating manual gradient management.\n",
        "- **Stateful Parameters**: Parameters like \\( \\mathbf{W} \\) and \\( \\mathbf{b} \\) are stateful, maintaining their values across iterations. `nn.Module` manages their state via the constructor (`__init__`), initializing them (e.g., using normal distributions) and updating them during training, as demonstrated in Lecture 6‚Äôs SGD example.\n",
        "- **Training and Inference Modes**: `nn.Module` supports switching between training and inference modes (e.g., `model.train()`, `model.eval()`). In inference mode, gradient computation is disabled, akin to `torch.no_grad()` from Lecture 6, ensuring efficient evaluation without tracking computational graphs.\n",
        "- **Pretrained Models and State Dict**: The `state_dict` attribute stores a model‚Äôs parameters, enabling saving and loading pretrained models. This supports transfer learning (e.g., using Hugging Face‚Äôs pretrained transformers), where parameters are fine-tuned for specific tasks, a practical application for NLP models.\n",
        "- **Hooks for Debugging**: Hooks, introduced in Lecture 6, allow monitoring or modifying gradients of non-leaf tensors. `nn.Module` integrates hooks seamlessly, enabling visualization of gradient flow in large networks, critical for diagnosing issues like vanishing gradients in deep architectures.\n",
        "- **Scalability for Large Architectures**: For small networks (10‚Äì20 layers), raw tensor operations are manageable, but large networks (e.g., transformers with billions of parameters) require `nn.Module`‚Äôs abstraction. It simplifies code maintenance, debugging, and hyperparameter tuning (e.g., via tools like Weights & Biases), as highlighted in the lecture.\n",
        "- **Layer Types and Lego Blocks**: `nn.Module` provides predefined layers (e.g., `nn.Linear`, `nn.Conv2d`, `nn.Embedding`, `nn.LSTM`) as modular ‚ÄúLego blocks,‚Äù allowing flexible architecture construction. Custom layers can be created by subclassing `nn.Module`, defining new operations for research or specialized tasks, as seen in Lecture 5‚Äôs extensibility discussion.\n",
        "- **Optimization Integration**: `nn.Module` works with optimizers (e.g., `torch.optim.SGD`, `torch.optim.Adam`), automating parameter updates. Users specify the optimizer and learning rate, and `nn.Module` provides parameters via `model.parameters()`, streamlining the training loop compared to manual updates in Lecture 6.\n",
        "- **Practical Applications in Frameworks**: High-level frameworks like Hugging Face build on `nn.Module`, using it to define transformer architectures. The lecture emphasizes its role in simplifying code for real-world applications, such as NLP (text classification) or computer vision (image segmentation), by abstracting low-level tensor operations.\n",
        "- **Error Prevention and Simplification**: Manual tensor operations risk errors (e.g., forgetting `grad.zero_()` or mismanaging `requires_grad`), as seen in Lecture 6. `nn.Module` mitigates these by automating gradient zeroing, parameter initialization, and mode switching, enhancing robustness for complex models.\n",
        "\n",
        "## üî¢ torch.nn.Module: Mathematical Foundations\n",
        "\n",
        "The `nn.Module` class encapsulates neural network layers, managing parameters and computations. For a linear layer \\( \\mathbf{y} = \\mathbf{W} \\mathbf{x} + \\mathbf{b} \\), where \\( \\mathbf{x} \\in \\mathbb{R}^{\\text{in}} \\), \\( \\mathbf{W} \\in \\mathbb{R}^{\\text{out} \\times \\text{in}} \\), \\( \\mathbf{b} \\in \\mathbb{R}^{\\text{out}} \\), the module:\n",
        "- Initializes \\( \\mathbf{W} \\), \\( \\mathbf{b} \\) as `nn.Parameter` with `requires_grad=True`.\n",
        "- Defines the forward pass:\n",
        "  \\[ \\mathbf{y} = \\mathbf{W} \\mathbf{x} + \\mathbf{b} \\]\n",
        "- Autograd computes gradients during backpropagation:\n",
        "  \\[ \\frac{\\partial L}{\\partial \\mathbf{W}} = \\frac{\\partial L}{\\partial \\mathbf{y}} \\cdot \\mathbf{x}^T, \\quad \\frac{\\partial L}{\\partial \\mathbf{b}} = \\frac{\\partial L}{\\partial \\mathbf{y}} \\]\n",
        "where \\( \\frac{\\partial L}{\\partial \\mathbf{y}} \\) depends on the loss \\( L \\). The optimizer updates parameters:\n",
        "\\[ \\mathbf{W} \\leftarrow \\mathbf{W} - \\eta \\cdot \\frac{\\partial L}{\\partial \\mathbf{W}}, \\quad \\mathbf{b} \\leftarrow \\mathbf{b} - \\eta \\cdot \\frac{\\partial L}{\\partial \\mathbf{b}} \\]\n",
        "`nn.Module` automates parameter tracking, gradient computation, and updates, ensuring mathematical correctness.\n",
        "\n",
        "## üß† PyTorch Code\n",
        "\n",
        "Below is a concise PyTorch snippet defining a custom linear layer using `nn.Module`, demonstrating its use in a simple neural network.\n",
        "\n",
        "```python\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Custom linear layer\n",
        "class LinearLayer(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(LinearLayer, self).__init__()\n",
        "        self.W = nn.Parameter(torch.randn(out_features, in_features))\n",
        "        self.b = nn.Parameter(torch.randn(out_features))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return torch.matmul(x, self.W.t()) + self.b #LOL GROK MADE WEE ERROR\n",
        "\n",
        "# Simple neural network\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        self.layer1 = LinearLayer(2, 10)\n",
        "        self.layer2 = LinearLayer(10, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.sigmoid(x)\n",
        "        x = self.layer2(x)\n",
        "        return x\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "model = SimpleNet()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# Sample data\n",
        "x = torch.randn(5, 2)\n",
        "y = torch.ones(5, 1)\n",
        "\n",
        "# Training step\n",
        "model.train()\n",
        "optimizer.zero_grad()\n",
        "output = model(x)\n",
        "loss = criterion(output, y)\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "\n",
        "print(\"Loss:\", loss.item())\n",
        "```\n",
        "\n",
        "This code defines a custom linear layer and a simple network, showcasing `nn.Module`‚Äôs automation of parameter management and training.\n",
        "\n",
        "## üí° Analogy: torch.nn.Module as a Construction Blueprint\n",
        "\n",
        "Imagine building a neural network as constructing a skyscraper (model). Raw materials (tensors) are assembled manually for small buildings, but a skyscraper requires a detailed blueprint (`nn.Module`). The blueprint specifies floors (layers like `nn.Linear`), automatically sizing materials (parameters \\( \\mathbf{W} \\), \\( \\mathbf{b} \\)) and ensuring they‚Äôre adjustable (`requires_grad=True`). Workers (autograd) follow the blueprint‚Äôs instructions (forward method) to build floors, while inspectors (optimizers) adjust materials based on quality checks (gradients). The blueprint adapts each day (dynamic graph), allowing structural changes (e.g., dropout), and switches to maintenance mode (inference) to save resources.\n",
        "\n",
        "In NLP, a transformer model processes text (tensors) for tasks like translation. The blueprint (`nn.Module`) organizes layers (e.g., attention, feedforward), automating parameter initialization and gradient updates, as seen in Lecture 6‚Äôs SGD example. Hooks, from Lecture 6, act like sensors monitoring construction quality, ensuring stable training, while `nn.Module` prevents errors like those in Lecture 5‚Äôs non-leaf tensor issues.\n",
        "\n",
        "## üîÅ Connection to Prior Lessons\n",
        "\n",
        "This lecture builds on Lecture 2 (tensors), where tensors‚Äô `requires_grad` enables autograd, now automated by `nn.Module`. Lecture 3 (strides) highlighted memory efficiency, mirrored in `nn.Module`‚Äôs non-leaf gradient discarding. Lecture 4 (autograd) and Lecture 5 (computational graphs) introduced dynamic graphs and gradient computation, which `nn.Module` encapsulates. Lecture 6 (autograd implementation) used manual tensor operations and hooks, now streamlined by `nn.Module`‚Äôs layers and optimizer integration, transitioning from low-level to high-level PyTorch usage.\n",
        "\n",
        "**Prerequisites**: Linear algebra (matrices, derivatives), Python programming, and familiarity with tensors, autograd, and computational graphs (from Lectures 2‚Äì6). Knowledge of neural network basics is essential.\n",
        "<br><br>\n",
        "\n",
        "---\n",
        "#Perplexity\n",
        "---\n",
        "üîπ **Key Ideas from Lecture 7: PyTorch's `nn.Module`**  \n",
        "\n",
        "- **Purpose of `nn.Module`**:  \n",
        "  - Acts as a **template** for building neural networks, abstracting repetitive code for parameter management, forward/backward passes, and device handling.  \n",
        "  - Essential for large networks (e.g., CNNs, transformers) to avoid manual tracking of millions of parameters.  \n",
        "\n",
        "- **Core Components**:  \n",
        "  - **`__init__()`**: Defines layers/parameters (e.g., `self.linear = nn.Linear(100, 10)`).  \n",
        "  - **`forward()`**: Specifies computation steps (e.g., `x = self.linear(x)`).  \n",
        "  - Inherits utilities:  \n",
        "    - `.parameters()`: Accesses all trainable weights/biases.  \n",
        "    - `.to(device)`: Moves model to GPU/CPU.  \n",
        "    - `.train()`/`.eval()`: Switches between training/inference modes.  \n",
        "\n",
        "- **Dynamic Computation Graph**:  \n",
        "  - PyTorch rebuilds the graph **each forward pass**, enabling flexible architectures (e.g., variable-length inputs, dynamic dropout).  \n",
        "  - Contrasts with static graphs (TensorFlow 1.x), which predefine operations.  \n",
        "\n",
        "- **Parameter Management**:  \n",
        "  - **Leaf tensors**: Model parameters (`requires_grad=True` by default).  \n",
        "  - **Non-leaf tensors**: Intermediate outputs (no gradient storage by default).  \n",
        "  - `zero_grad()`: Resets gradients to prevent accumulation across batches.  \n",
        "\n",
        "- **Automatic Differentiation**:  \n",
        "  - Backward pass (`loss.backward()`) computes gradients via chain rule, stored in `.grad` of leaf tensors.  \n",
        "  - Optimizers (e.g., SGD, Adam) update parameters using these gradients.  \n",
        "\n",
        "- **Custom Layers**:  \n",
        "  - Subclass `nn.Module` to create reusable blocks (e.g., custom linear/convolutional layers).  \n",
        "  - Example:  \n",
        "    ```python\n",
        "    class CustomLinear(nn.Module):\n",
        "        def __init__(self, in_features, out_features):\n",
        "            super().__init__()\n",
        "            self.weight = nn.Parameter(torch.randn(in_features, out_features))\n",
        "            self.bias = nn.Parameter(torch.randn(out_features))\n",
        "        \n",
        "        def forward(self, x):\n",
        "            return x @ self.weight + self.bias\n",
        "    ```\n",
        "\n",
        "üî¢ **Mathematical Foundations**  \n",
        "- **Linear Layer Operation**:  \n",
        "  For input $$ x \\in \\mathbb{R}^{B \\times D} $$ and weights $$ W \\in \\mathbb{R}^{D \\times H} $$:  \n",
        "  $$\n",
        "  z = xW^T + b \\quad \\text{(output of a linear layer)}\n",
        "  $$  \n",
        "- **Chain Rule in Backprop**:  \n",
        "  For loss $$ L $$, gradient of weight $$ W_{ij} $$:  \n",
        "  $$\n",
        "  \\frac{\\partial L}{\\partial W_{ij}} = \\sum_{k} \\frac{\\partial L}{\\partial z_k} \\cdot \\frac{\\partial z_k}{\\partial W_{ij}}\n",
        "  $$  \n",
        "\n",
        "üß† **Practical Code Example**  \n",
        "```python\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define a neural network using nn.Module\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, input_dim=784, hidden_dim=128, output_dim=10):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, output_dim)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "# Usage\n",
        "model = SimpleNN()\n",
        "x = torch.randn(32, 784)  # Batch of 32 samples\n",
        "y_pred = model(x)          # Forward pass\n",
        "print(y_pred.shape)        # [32, 10]\n",
        "```\n",
        "\n",
        "üí° **Analogy: `nn.Module` as LEGO Blocks**  \n",
        "Imagine building a spaceship (neural network) with LEGO:  \n",
        "- **Standard Blocks (`nn.Module` layers)**: Pre-designed pieces (wheels, windows) = linear layers, convolutions.  \n",
        "- **Custom Blocks (Subclassing)**: Create unique parts (e.g., laser cannons) by combining existing blocks.  \n",
        "- **Instructions (`forward()`)**: Manual says how to snap blocks together.  \n",
        "- **Quality Check (`backward()`)**: Inspector traces assembly steps to fix loose blocks (update parameters).  \n",
        "- **Dynamic Design**: Modify spaceship mid-construction (change layers during training).  \n",
        "\n",
        "**Why It Matters**:  \n",
        "Just as LEGO abstracts complex engineering into reusable blocks, `nn.Module` abstracts tensor operations into layers, enabling rapid prototyping of complex models.  \n",
        "\n",
        "üîÅ **Connection to Prior Lessons**  \n",
        "- **Tensors (Lectures 2-3)**: `nn.Module` layers manipulate tensors, using strides/shapes for efficiency.  \n",
        "- **Autograd (Lectures 4-6)**: `forward()` builds dynamic graphs; `backward()` computes gradients automatically.  \n",
        "- **Dynamic Graphs (Lecture 6)**: `nn.Module` leverages PyTorch‚Äôs graph flexibility for adaptive architectures.  \n",
        "\n",
        "**Innovation**: `nn.Module` decouples layer design (what the model does) from optimization (how it learns), letting researchers focus on architecture rather than manual differentiation.\n",
        "\n",
        "Citations:\n",
        "[1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/63649134/c3cad299-b027-4622-8f27-35a1f43fd62b/paste-2.txt\n",
        "[2] https://pytorch.org/docs/stable/generated/torch.nn.Module.html\n",
        "[3] https://www.codecademy.com/resources/docs/pytorch/nn\n",
        "[4] https://stackoverflow.com/questions/51804692/what-exactly-is-the-definition-of-a-module-in-pytorch\n",
        "[5] https://fall-2023-python-programming-for-data-science.readthedocs.io/en/latest/Lectures/Theme_3-Model_Engineering/Lecture_18-NNs_with_PyTorch/Lecture_18-NNs_with_PyTorch.html\n",
        "[6] https://pytorch.org/tutorials/recipes/recipes/defining_a_neural_network.html\n",
        "[7] https://www.cs.toronto.edu/~lczhang/aps360_20191/lec/w03/nn.html\n",
        "[8] https://www.bookey.app/book/deep-learning-with-pytorch\n",
        "[9] https://stackoverflow.com/questions/42480111/how-do-i-print-the-model-summary-in-pytorch\n",
        "[10] https://isip.piconepress.com/courses/temple/ece_4822/resources/books/Deep-Learning-with-PyTorch.pdf\n",
        "[11] https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html\n",
        "[12] https://pytorch.org/tutorials/beginner/pytorch_with_examples.html\n",
        "[13] https://discuss.pytorch.org/t/understanding-how-torch-nn-module-works/122\n",
        "[14] https://www.geeksforgeeks.org/deep-learning-with-pytorch-an-introduction/\n",
        "[15] https://www.youtube.com/watch?v=t67ZS14hw1g\n",
        "[16] https://www.geeksforgeeks.org/create-model-using-custom-module-in-pytorch/\n",
        "[17] https://www.cs.toronto.edu/~lczhang/360/lec/w03/nn.html\n"
      ],
      "metadata": {
        "id": "4QHe5B6DhmuQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lecture 8 : NN Module Implementation\n",
        "\n",
        "---\n",
        "#GROK\n",
        "\n",
        "---\n",
        "# Deep Learning with PyTorch: Lecture 8 NN Module Implementation Summary and Explanation\n",
        "\n",
        "As a deep learning instructor with over a decade of experience specializing in PyTorch, I‚Äôll summarize the key ideas from the \"Lecture 8: NN Module: Implementation\" video, focusing on the mathematical foundations and practical applications of **torch.nn.Module implementation**, the central concept highlighted in the transcript. The summary of key ideas will be at least 800 words to capture the lecture‚Äôs essence. I‚Äôll explain `torch.nn.Module` implementation using analogies and real-world examples, connecting to your prior deep learning studies in this conversation (e.g., tensors, strides, autograd, computational graphs, autograd implementation, NN module from Lectures 2‚Äì7). The response will adhere to the requested format, include a concise code snippet (‚â§50 lines), and focus on mathematical foundations and practical applications.\n",
        "\n",
        "## üîπ Key Ideas from the Lecture (Summary, ~850 words)\n",
        "\n",
        "- **torch.nn.Module as a Framework**: The `torch.nn.Module` class is PyTorch‚Äôs foundation for building neural networks, encapsulating layers like `nn.Linear` to simplify parameter management, forward propagation, and gradient computation. It automates tasks that are repetitive when using raw `torch.tensor`, as introduced in Lecture 7.\n",
        "- **Subclassing nn.Module**: Creating custom layers or networks involves subclassing `nn.Module`, defining a constructor (`__init__`) to initialize parameters and a `forward` method to specify computations. For a linear layer, the constructor sets up weights \\( \\mathbf{W} \\) and biases \\( \\mathbf{b} \\), while `forward` computes \\( \\mathbf{y} = \\mathbf{W} \\mathbf{x} + \\mathbf{b} \\).\n",
        "- **Automatic Parameter Management**: Parameters are defined using `nn.Parameter`, a `torch.Tensor` subclass with `requires_grad=True` by default, ensuring they‚Äôre tracked for gradients. `nn.Module` automatically collects parameters via `model.parameters()`, simplifying optimizer integration, unlike manual tracking in Lecture 6.\n",
        "- **Inherited Methods**: Subclassing `nn.Module` inherits methods like `parameters()`, `named_parameters()`, `zero_grad()`, and `state_dict()`. These handle parameter access, gradient zeroing, and model state management, reducing errors like gradient accumulation seen in Lecture 6.\n",
        "- **Dynamic Computational Graphs**: PyTorch‚Äôs dynamic graphs, discussed in Lectures 5‚Äì6, are seamlessly integrated with `nn.Module`. Each forward pass builds a graph, and `backward()` computes gradients, with `nn.Module` managing the process automatically, supporting flexible architectures like dropout.\n",
        "- **Forward vs. __call__**: The `forward` method defines computations, but models are called as functions (e.g., `model(x)`) via the `__call__` magic method. `__call__` performs checks (e.g., input validity) before invoking `forward`, ensuring robustness, a refinement over Lecture 7‚Äôs manual forward calls.\n",
        "- **Built-in Layers like nn.Linear**: The `nn.Linear` layer abstracts \\( \\mathbf{y} = \\mathbf{W} \\mathbf{x} + \\mathbf{b} \\), requiring only input and output dimensions (e.g., 784 to 10 for MNIST). It initializes parameters internally, using optimized schemes (e.g., Kaiming initialization) rather than random initialization, improving convergence over Lecture 6‚Äôs manual approach.\n",
        "- **Optimizers and Training Loop**: The `torch.optim` module (e.g., `optim.SGD`) integrates with `nn.Module`, using `model.parameters()` to update weights via `optimizer.step()`. The training loop involves forward pass, loss computation, `loss.backward()`, and `optimizer.step()`, with `optimizer.zero_grad()` preventing gradient accumulation, as emphasized in Lecture 6.\n",
        "- **Real-World Dataset Application**: The lecture applies `nn.Linear` to the MNIST dataset, reshaping 28x28 images into 784-dimensional vectors and predicting 10 classes. This demonstrates practical use of `nn.Module` for computer vision tasks, building on Lecture 7‚Äôs theoretical discussion.\n",
        "- **Softmax and Loss Functions**: Post-linear layer, `torch.softmax` computes class probabilities, and `nn.CrossEntropyLoss` combines log-softmax and negative log-likelihood loss, simplifying loss computation. This abstracts manual loss calculations from Lecture 6, enhancing efficiency.\n",
        "- **Visualization and Debugging**: Accessing parameters (e.g., `model.parameters()`) allows visualization of learned patterns, such as weight heatmaps for MNIST digits. Hooks (Lecture 6) can animate gradient changes, aiding debugging of convergence issues in complex networks.\n",
        "- **nn.Sequential for Simple Networks**: The `nn.Sequential` container chains layers (e.g., `nn.Linear`, `nn.Sigmoid`, `nn.Softmax`) for simple architectures. It‚Äôs a shorthand for sequential computations, ideal for small networks, complementing Lecture 7‚Äôs custom layer creation.\n",
        "- **Data Preprocessing with torchvision**: The `torchvision` library loads datasets like MNIST, with `transforms` converting images to tensors and normalizing them (e.g., scaling to [0,1]). This preprocesses data for `nn.Module`, ensuring compatibility with neural network inputs.\n",
        "- **Scalability and Modularity**: `nn.Module`‚Äôs modular design (e.g., `nn.Linear`, `nn.Conv2d`) acts as ‚ÄúLego blocks,‚Äù enabling scalable architectures like CNNs or transformers. Custom layers can be defined for research, extending Lecture 5‚Äôs extensibility concept.\n",
        "- **Error Handling and Initialization**: Errors (e.g., forgetting `super()` in `__init__`) are fixable, as shown in the lecture. `nn.Linear` uses advanced initialization (e.g., Kaiming) to stabilize training, addressing Lecture 6‚Äôs random initialization limitations.\n",
        "- **Transition to Advanced Topics**: The lecture previews `torch.utils.data` for batching and multiprocessing, and CNN implementation in Lecture 9. This builds on `nn.Module`‚Äôs foundation, preparing for industry practices like multi-GPU training and large-scale data handling.\n",
        "\n",
        "## üî¢ torch.nn.Module Implementation: Mathematical Foundations\n",
        "\n",
        "For a linear layer implemented via `nn.Module`, the computation is \\( \\mathbf{y} = \\mathbf{W} \\mathbf{x} + \\mathbf{b} \\), where \\( \\mathbf{x} \\in \\mathbb{R}^{\\text{in}} \\), \\( \\mathbf{W} \\in \\mathbb{R}^{\\text{out} \\times \\text{in}} \\), \\( \\mathbf{b} \\in \\mathbb{R}^{\\text{out}} \\). The module:\n",
        "- Initializes \\( \\mathbf{W} \\), \\( \\mathbf{b} \\) as `nn.Parameter`, with `requires_grad=True`.\n",
        "- Forward pass:\n",
        "  \\[ \\mathbf{y} = \\mathbf{W} \\mathbf{x} + \\mathbf{b} \\]\n",
        "- Backward pass (via autograd):\n",
        "  \\[ \\frac{\\partial L}{\\partial \\mathbf{W}} = \\frac{\\partial L}{\\partial \\mathbf{y}} \\cdot \\mathbf{x}^T, \\quad \\frac{\\partial L}{\\partial \\mathbf{b}} = \\frac{\\partial L}{\\partial \\mathbf{y}} \\]\n",
        "  where \\( L \\) is the loss (e.g., cross-entropy). The optimizer updates:\n",
        "  \\[ \\mathbf{W} \\leftarrow \\mathbf{W} - \\eta \\cdot \\frac{\\partial L}{\\partial \\mathbf{W}}, \\quad \\mathbf{b} \\leftarrow \\mathbf{b} - \\eta \\cdot \\frac{\\partial L}{\\partial \\mathbf{b}} \\]\n",
        "`nn.Module` automates parameter initialization (e.g., Kaiming), gradient computation, and updates, ensuring mathematical precision.\n",
        "\n",
        "## üß† PyTorch Code\n",
        "\n",
        "Below is a concise PyTorch snippet implementing a linear layer for MNIST classification, showcasing `nn.Module` usage.\n",
        "\n",
        "```python\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define model\n",
        "class MNISTNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNISTNet, self).__init__()\n",
        "        self.linear = nn.Linear(784, 10)  # 28x28 to 10 classes\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)  # Reshape to vector\n",
        "        x = self.linear(x)\n",
        "        return x\n",
        "\n",
        "# Load MNIST\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
        "x, y = train_dataset[0][0], train_dataset[0][1]\n",
        "\n",
        "# Initialize model, loss, optimizer\n",
        "model = MNISTNet()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training step\n",
        "model.train()\n",
        "optimizer.zero_grad()\n",
        "output = model(x)\n",
        "loss = criterion(output, y.unsqueeze(0))\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "\n",
        "print(\"Loss:\", loss.item())\n",
        "```\n",
        "\n",
        "This code uses `nn.Linear` for MNIST, demonstrating `nn.Module`‚Äôs automation of parameters, gradients, and training.\n",
        "\n",
        "## üí° Analogy: torch.nn.Module as a Factory Manager\n",
        "\n",
        "Imagine building a neural network as running a factory (model) producing goods (predictions). Workers (tensors) manually assemble products in small shops, but a large factory needs a manager (`nn.Module`). The manager assigns tasks to departments (layers like `nn.Linear`), automatically ordering materials (parameters) and setting up assembly lines (forward method). Each shift (iteration) rebuilds the line (dynamic graph), allowing changes like skipping stations (dropout). The manager checks inputs (`__call__`) before production, uses quality control (autograd) to adjust materials, and visualizes output patterns (weights), ensuring scalability.\n",
        "\n",
        "In NLP, a transformer processes text (tensors) for tasks like sentiment analysis. The manager (`nn.Module`) organizes layers (e.g., attention), automating parameter setup and updates, as in Lecture 7‚Äôs custom layers. Hooks (Lecture 6) monitor production quality, while `nn.Module` prevents errors like Lecture 6‚Äôs gradient accumulation, streamlining complex tasks.\n",
        "\n",
        "## üîÅ Connection to Prior Lessons\n",
        "\n",
        "This lecture builds on Lecture 2 (tensors), where `requires_grad` enabled gradient tracking, now automated by `nn.Parameter`. Lecture 3 (strides) emphasized memory efficiency, mirrored in `nn.Module`‚Äôs parameter management. Lectures 4‚Äì5 (autograd, computational graphs) introduced dynamic graphs, which `nn.Module` leverages. Lecture 6 (autograd implementation) used manual training loops, now simplified by `nn.Module`‚Äôs optimizers and layers, as previewed in Lecture 7 (NN module). The MNIST application extends Lecture 7‚Äôs theoretical `nn.Module` discussion to practical use.\n",
        "\n",
        "**Prerequisites**: Linear algebra (matrices, derivatives), Python programming, and familiarity with tensors, autograd, computational graphs, and `nn.Module` (Lectures 2‚Äì7). Knowledge of neural network training is essential.\n",
        "<br><br>\n",
        "\n",
        "---\n",
        "#Perplexity\n",
        "---\n",
        "üîπ **Key Ideas from Lecture 8: NN Module Implementation in PyTorch (850+ Word Summary)**\n",
        "\n",
        "### **1. Core Components of `nn.Module`**\n",
        "- **Template for Neural Networks**:  \n",
        "  - `nn.Module` provides a structured way to define neural networks by encapsulating layers, parameters, and forward logic.  \n",
        "  - Subclassing `nn.Module` is mandatory for custom models to leverage PyTorch's autograd and parameter management.  \n",
        "\n",
        "- **Essential Methods**:  \n",
        "  - **`__init__()`**: Initializes layers/parameters (e.g., `self.linear = nn.Linear(784, 10)`).  \n",
        "  - **`forward()`**: Defines the computation graph (e.g., `return x @ self.weights + self.bias`).  \n",
        "  - Inherited utilities: `.parameters()`, `.to(device)`, `.train()`, `.eval()`.  \n",
        "\n",
        "- **Parameter Management**:  \n",
        "  - **Leaf vs. Non-Leaf Tensors**:  \n",
        "    - Leaf tensors (parameters) have `requires_grad=True` by default.  \n",
        "    - Non-leaf tensors (intermediate outputs) don‚Äôt track gradients unless specified.  \n",
        "  - **Zeroing Gradients**: Critical to avoid gradient accumulation across batches (`optimizer.zero_grad()`).  \n",
        "\n",
        "### **2. Dynamic Computation Graphs**\n",
        "- **Graph Construction**:  \n",
        "  - PyTorch rebuilds the computation graph **every forward pass**, enabling flexibility (e.g., variable-length inputs, dynamic architectures).  \n",
        "  - Contrasts with static graphs (TensorFlow 1.x), which predefine operations.  \n",
        "\n",
        "- **Autograd Integration**:  \n",
        "  - Automatic differentiation via `loss.backward()` computes gradients for all parameters with `requires_grad=True`.  \n",
        "  - Gradients are stored in `.grad` attributes of leaf tensors.  \n",
        "\n",
        "### **3. Custom Layer Implementation**\n",
        "- **Steps to Create Custom Layers**:  \n",
        "  1. Subclass `nn.Module`.  \n",
        "  2. Define parameters in `__init__` using `nn.Parameter`.  \n",
        "  3. Implement `forward()` logic.  \n",
        "\n",
        "```python\n",
        "class CustomLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.randn(out_features, in_features))\n",
        "        self.bias = nn.Parameter(torch.randn(out_features))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return x @ self.weight.T + self.bias\n",
        "```\n",
        "\n",
        "### **4. Training Workflow**\n",
        "- **Key Steps**:  \n",
        "  - **Data Preparation**: Use `torch.utils.data.DataLoader` for batching and shuffling.  \n",
        "  - **Loss Calculation**: Built-in losses (e.g., `nn.CrossEntropyLoss`) or custom implementations.  \n",
        "  - **Optimization**: Update parameters using optimizers (e.g., `torch.optim.SGD`).  \n",
        "\n",
        "- **Critical Code Snippets**:  \n",
        "  - Instantiate model: `model = NeuralNetwork()`.  \n",
        "  - Forward pass: `outputs = model(inputs)`.  \n",
        "  - Backward pass: `loss.backward()`.  \n",
        "  - Parameter update: `optimizer.step()`.  \n",
        "\n",
        "### **5. Debugging and Best Practices**\n",
        "- **Parameter Inspection**:  \n",
        "  - Use `model.parameters()` to access weights/biases.  \n",
        "  - Check tensor shapes and device placement (`print(param.shape, param.device)`).  \n",
        "- **Hooks**:  \n",
        "  - Register hooks to monitor gradients during backpropagation:  \n",
        "    ```python\n",
        "    def gradient_hook(grad):\n",
        "        print(f\"Gradient shape: {grad.shape}\")\n",
        "    tensor.register_hook(gradient_hook)\n",
        "    ```\n",
        "\n",
        "### **6. Mathematical Foundations**\n",
        "- **Linear Layer Operation**:  \n",
        "  For input $$ x \\in \\mathbb{R}^{B \\times D} $$ and weights $$ W \\in \\mathbb{R}^{D \\times H} $$:  \n",
        "  $$\n",
        "  z = xW^T + b\n",
        "  $$  \n",
        "- **Cross-Entropy Loss**:  \n",
        "  $$\n",
        "  L = -\\frac{1}{N} \\sum_{i=1}^N \\log\\left(\\frac{e^{x_{i,y_i}}}{\\sum_{j=1}^C e^{x_{i,j}}}\\right)\n",
        "  $$  \n",
        "\n",
        "---\n",
        "\n",
        "üß† **Practical Code Example (50+ Lines)**  \n",
        "```python\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Define a custom neural network\n",
        "class CustomNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(28*28, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 10)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        return self.layers(x)\n",
        "\n",
        "# Step 2: Load MNIST dataset\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "train_data = datasets.MNIST(root='data', train=True, download=True, transform=transform)\n",
        "test_data = datasets.MNIST(root='data', train=False, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=64)\n",
        "\n",
        "# Step 3: Initialize model, loss, and optimizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CustomNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Step 4: Training loop\n",
        "def train(epochs):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        for batch, (X, y) in enumerate(train_loader):\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            \n",
        "            # Forward pass\n",
        "            outputs = model(X)\n",
        "            loss = criterion(outputs, y)\n",
        "            \n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            if batch % 100 == 0:\n",
        "                print(f\"Epoch {epoch+1}/{epochs}, Batch {batch}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Step 5: Evaluation\n",
        "def evaluate():\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in test_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            outputs = model(X)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct += (predicted == y).sum().item()\n",
        "    accuracy = 100 * correct / len(test_data)\n",
        "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "# Execute training and evaluation\n",
        "train(epochs=5)\n",
        "evaluate()\n",
        "\n",
        "# Step 6: Visualize predictions\n",
        "def plot_predictions():\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        X, y = next(iter(test_loader))\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        outputs = model(X)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        \n",
        "    fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
        "    for idx, ax in enumerate(axes.flat):\n",
        "        ax.imshow(X[idx].cpu().squeeze(), cmap='gray')\n",
        "        ax.set_title(f\"Pred: {preds[idx].item()}, True: {y[idx].item()}\")\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_predictions()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "üí° **Analogy: Neural Networks as Modular Factories**  \n",
        "Imagine building a car factory:  \n",
        "- **`nn.Module` = Assembly Line Template**: Each station (layer) has specific roles (linear layer, activation).  \n",
        "- **`forward()` = Production Flow**: Raw materials (input data) move through stations to become cars (predictions).  \n",
        "- **Autograd = Quality Control**: Inspects defects (loss) and traces them back to faulty stations (layers) to improve processes (gradient updates).  \n",
        "- **Optimizer = Efficiency Expert**: Adjusts machine settings (parameters) to reduce defects (loss) over time.  \n",
        "\n",
        "**Why It Matters**:  \n",
        "Just as a factory‚Äôs efficiency depends on well-coordinated stations, a neural network‚Äôs performance hinges on properly defined layers and optimized parameters.  \n",
        "\n",
        "---\n",
        "\n",
        "üîÅ **Connection to Prior Lessons**  \n",
        "- **Autograd (Lectures 4-6)**: `nn.Module` leverages autograd for gradient computation but abstracts manual chain rule calculations.  \n",
        "- **Tensors (Lectures 2-3)**: Layers manipulate tensors, relying on strides/shapes for efficient operations.  \n",
        "- **Dynamic Graphs (Lecture 6)**: Enables adaptive architectures like variable-length sequences or dynamic dropout.  \n",
        "\n",
        "**Innovation**: `nn.Module` democratizes deep learning by letting researchers focus on architecture design rather than low-level math.\n",
        "\n",
        "Citations:\n",
        "[1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/63649134/ff0aca16-a810-40cc-a87a-e9bf12275701/paste.txt\n",
        "[2] https://pytorch.org/tutorials/beginner/nn_tutorial.html\n",
        "[3] https://pytorch.org/tutorials/beginner/pytorch_with_examples.html\n",
        "[4] https://brsoff.github.io/tutorials/beginner/examples_nn/two_layer_net_module.html\n",
        "[5] https://machinelearningmastery.com/creating-custom-layers-loss-functions-pytorch/\n",
        "[6] https://www.codecademy.com/resources/docs/pytorch/nn\n",
        "[7] https://www.geeksforgeeks.org/create-custom-neural-network-in-pytorch/\n",
        "[8] https://www.geeksforgeeks.org/create-model-using-custom-module-in-pytorch/\n",
        "[9] https://www.digitalocean.com/community/tutorials/pytorch-101-advanced\n",
        "[10] https://pytorch.org/docs/stable/generated/torch.nn.Module.html\n",
        "[11] https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html\n",
        "[12] https://www.geeksforgeeks.org/create-model-using-custom-module-in-pytorch/\n",
        "[13] https://pytorch.org/docs/stable/nn.html\n",
        "[14] https://www.coursehero.com/file/215181513/Lecture-8-PyTorch/\n",
        "[15] https://stackoverflow.com/questions/51804692/what-exactly-is-the-definition-of-a-module-in-pytorch\n",
        "[16] https://beerensahu.wordpress.com/2018/03/23/pytorch-tutorial-lesson-5-custom-network-modules/\n",
        "[17] https://fall-2023-python-programming-for-data-science.readthedocs.io/en/latest/Lectures/Theme_3-Model_Engineering/Lecture_18-NNs_with_PyTorch/Lecture_18-NNs_with_PyTorch.html\n",
        "[18] https://isip.piconepress.com/courses/temple/ece_4822/resources/books/Deep-Learning-with-PyTorch.pdf\n",
        "[19] https://discuss.pytorch.org/t/custom-linear-regression-layer/169512\n",
        "[20] https://pytorch.org/tutorials/beginner/examples_nn/polynomial_module.html\n",
        "[21] https://www.youtube.com/watch?v=kt0umOGNzGk\n",
        "[22] https://github.com/pytorch/pytorch/blob/main/torch/nn/modules/linear.py\n",
        "[23] https://github.com/pytorch/pytorch/blob/main/torch/nn/modules/module.py\n",
        "[24] https://www.datacamp.com/tutorial/pytorch-tutorial-building-a-simple-neural-network-from-scratch\n",
        "[25] https://www.machinelearningmastery.com/creating-a-training-loop-for-pytorch-models/\n",
        "[26] https://www.datacamp.com/tutorial/building-a-transformer-with-py-torch\n",
        "[27] https://codingnomads.com/deep-learning-pytorch-linear-layer\n",
        "[28] https://pytorch.org/tutorials/beginner/introyt/trainingyt.html\n",
        "[29] https://www.geeksforgeeks.org/linear-regression-using-pytorch/\n",
        "[30] https://pytorch.org/docs/stable/notes/modules.html\n",
        "[31] https://sebastianraschka.com/faq/docs/training-loop-in-pytorch.html\n",
        "[32] https://cs230.stanford.edu/blog/pytorch/\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "A43jfCpRhmrr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lecture 9 : TorchData\n",
        "\n",
        "---\n",
        "#GROK\n",
        "\n",
        "---\n",
        "# Deep Learning with PyTorch: Lecture 9 Torch Data Summary and Explanation\n",
        "\n",
        "As a deep learning instructor with over a decade of experience specializing in PyTorch, I‚Äôll summarize the key ideas from the \"Lecture 9: Torch Data\" video, focusing on the mathematical foundations and practical applications of **torch.utils.data** for efficient data handling in deep learning. The summary of key ideas will be at least 800 words to capture the lecture‚Äôs essence. I‚Äôll explain `torch.utils.data` using analogies and real-world examples, connecting to your prior deep learning studies in this conversation (e.g., tensors, autograd, computational graphs, NN module, and implementations from Lectures 2‚Äì8). The response will adhere to the requested format, include a concise code snippet (‚â§50 lines) with explanations of key concepts, and focus on mathematical foundations and practical applications.\n",
        "\n",
        "## üîπ Key Ideas from the Lecture (Summary, ~850 words)\n",
        "\n",
        "- **Role of torch.utils.data**: The `torch.utils.data` module, encompassing `Dataset` and `DataLoader`, streamlines data loading, preprocessing, and batching for deep learning models. It addresses inefficiencies in manual data access (e.g., Python slicing), enabling scalable training on large datasets like CIFAR-10.\n",
        "- **Interaction of PyTorch Components**: PyTorch‚Äôs core components‚Äî`torch.Tensor`, `torch.autograd`, `torch.nn`, and `torch.optim`‚Äîintegrate with `torch.utils.data`. Tensors store data, autograd computes gradients, `nn.Module` defines models, optimizers update parameters, and `DataLoader` feeds preprocessed batches, forming a cohesive pipeline.\n",
        "- **Limitations of Python Slicing**: Accessing data via Python slicing (e.g., `data[0:5]`) is inefficient for large datasets due to Python‚Äôs Global Interpreter Lock (GIL), which prevents parallel data loading and model training. This causes idle time, slowing training, especially for datasets with millions of samples.\n",
        "- **DataLoader for Parallel Processing**: `DataLoader` overcomes GIL limitations by leveraging C++-based multiprocessing, fetching batches in parallel with model training. It uses multiple CPU cores to preprocess and load data, minimizing model wait times, critical for NLP and computer vision tasks.\n",
        "- **Dataset Class for Custom Data**: The `Dataset` class (e.g., `torch.utils.data.Dataset`) enables custom data handling. Users define `__getitem__` to access samples and `__len__` for dataset size, converting raw data (e.g., images, text) into PyTorch tensors, supporting diverse formats.\n",
        "- **Transformations for Preprocessing**: `torchvision.transforms` preprocesses data (e.g., converting images to tensors, normalizing with mean and variance). For CIFAR-10, images (32x32x3) are transformed to tensors and normalized (e.g., mean=[0.5, 0.5, 0.5]), ensuring model-compatible inputs.\n",
        "- **Batching and Shuffling**: `DataLoader` batches samples (e.g., batch_size=4) and shuffles them for training to reduce overfitting, as seen in Lecture 8‚Äôs MNIST example. It adds a batch dimension (e.g., [4, 3, 32, 32] for CIFAR-10), streamlining model input.\n",
        "- **GPU Integration**: `DataLoader` moves data to GPUs (e.g., `data.to(device)`), aligning with models on GPUs for faster computation. This extends Lecture 8‚Äôs GPU usage, ensuring data and model reside on the same device to avoid costly CPU-GPU transfers.\n",
        "- **CNN Architecture for CIFAR-10**: The lecture implements a convolutional neural network (CNN) using `nn.Module` for CIFAR-10 classification (10 classes, 50,000 images). It includes `nn.Conv2d` (e.g., 3 to 6 channels), `nn.MaxPool2d`, and `nn.Linear` layers, demonstrating `DataLoader`‚Äôs role in feeding complex data.\n",
        "- **Convolutional Layers**: `nn.Conv2d` applies convolution with kernels (e.g., 6 kernels of size 5x5), reducing spatial dimensions unless padded. Parameters are initialized (e.g., Kaiming), and gradients are computed via autograd, as in Lecture 7.\n",
        "- **Training Loop with DataLoader**: The training loop uses `DataLoader` to iterate over batches, computing logits, cross-entropy loss, and gradients. `optimizer.step()` updates parameters, and `zero_grad()` prevents gradient accumulation, refining Lecture 8‚Äôs loop.\n",
        "- **Evaluation Mode**: Models switch to evaluation mode (`model.eval()`) for testing, disabling gradient computation, akin to `torch.no_grad()` from Lecture 6. This ensures test data doesn‚Äôt update parameters, a critical step missed initially in the lecture.\n",
        "- **Performance Metrics**: The CNN achieves ~54% accuracy on CIFAR-10 after one epoch, reasonable given the dataset‚Äôs complexity (small 32x32 images). Accuracy and loss are tracked per batch, extending Lecture 8‚Äôs visualization techniques.\n",
        "- **Custom Dataset Handling**: For non-standard datasets, users convert data to `Dataset` format, then use `DataLoader`. The lecture references a separate notebook for this, building on Lecture 8‚Äôs `torchvision` datasets like MNIST.\n",
        "- **Scalability for Large Projects**: `DataLoader` is vital for large-scale NLP or vision projects, where preprocessing (e.g., tokenization, normalization) is complex. It separates data handling from model training, improving code modularity and performance.\n",
        "- **Multiprocessing and Hardware Utilization**: `DataLoader` leverages multiple CPU cores (e.g., 40 multiprocessors on a Tesla T4 GPU) for data loading, optimizing hardware usage. This supports industry practices like multi-GPU training, previewed for Lecture 10.\n",
        "\n",
        "## üî¢ torch.utils.data: Mathematical Foundations\n",
        "\n",
        "`DataLoader` processes a dataset $\\( D = \\{(\\mathbf{x}_i, y_i)\\}_{i=1}^N \\)$, where $\\( \\mathbf{x}_i \\in \\mathbb{R}^{C \\times H \\times W} \\)$ (e.g., CIFAR-10 images with $\\( C=3 \\)$, $\\( H=W=32 \\)$) and $\\( y_i \\in \\{0, \\dots, 9\\} \\)$. It:\n",
        "- Batches samples: For batch size \\( B \\), outputs $\\( \\mathbf{X} \\in \\mathbb{R}^{B \\times C \\times H \\times W} \\)$, $\\( \\mathbf{y} \\in \\mathbb{R}^B \\)$.\n",
        "- Applies transformations: Normalizes $\\( \\mathbf{x}_i \\leftarrow \\frac{\\mathbf{x}_i - \\mu}{\\sigma} \\)$, where $\\( \\mu, \\sigma \\)$ are channel-wise mean and variance.\n",
        "- Feeds $\\( \\mathbf{X} \\)$ to a CNN, computing logits $\\( \\mathbf{z} = f(\\mathbf{X}; \\theta) \\)$, where $\\( f \\)$ is the model (e.g., convolutions, linear layers), and $\\( \\theta \\)$ are parameters.\n",
        "- Computes loss: Cross-entropy $\\( L = -\\frac{1}{B} \\sum_{i=1}^B \\log p(y_i | \\mathbf{z}_i) \\)$, where $\\( p(y_i | \\mathbf{z}_i) = \\text{softmax}(\\mathbf{z}_i) \\)$.\n",
        "- Backpropagates: $\\( \\frac{\\partial L}{\\partial \\theta} \\)$ via autograd, updating $\\( \\theta \\leftarrow \\theta - \\eta \\cdot \\frac{\\partial L}{\\partial \\theta} \\)$.\n",
        "\n",
        "`DataLoader` ensures efficient batch delivery, minimizing computational overhead.\n",
        "\n",
        "## üß† PyTorch Code\n",
        "\n",
        "Below is a concise PyTorch snippet for training a CNN on CIFAR-10 using `DataLoader`, with key concepts explained.\n",
        "\n",
        "```python\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Device setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Load CIFAR-10\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
        "\n",
        "# CNN model\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Initialize model, loss, optimizer\n",
        "model = CNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Training step (one batch)\n",
        "model.train()\n",
        "for data in trainloader:\n",
        "    inputs, labels = data[0].to(device), data[1].to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    break  # Single batch for demo\n",
        "print(\"Loss:\", loss.item())\n",
        "```\n",
        "\n",
        "**Key Concepts in Code**:\n",
        "- **Transformations**: `transforms.ToTensor()` converts images to tensors; `transforms.Normalize` standardizes pixel values, ensuring model compatibility.\n",
        "- **DataLoader**: `batch_size=4` groups samples; `num_workers=2` enables multiprocessing for faster data loading; `shuffle=True` randomizes batches.\n",
        "- **Device Handling**: `.to(device)` moves data and model to GPU, aligning with Lecture 8‚Äôs GPU usage.\n",
        "- **Training Loop**: `zero_grad()`, `backward()`, and `step()` manage gradients and updates, as in Lecture 8.\n",
        "\n",
        "## üí° Analogy: torch.utils.data as a Kitchen Prep Team\n",
        "\n",
        "Imagine training a neural network as cooking a feast (model) in a restaurant. Ingredients (data samples) need preparation before cooking. A slow chef (Python slicing) chops vegetables one by one, pausing cooking to fetch more, wasting time. A prep team (`DataLoader`) works in parallel, chopping and plating batches while the chef cooks, using multiple stations (CPU cores) to keep the kitchen (GPU) busy. The team transforms raw ingredients (e.g., normalizing images) into ready-to-cook formats (tensors), delivering plated dishes (batches) efficiently.\n",
        "\n",
        "In NLP, tokenizing text (data) for a transformer is like prepping ingredients. The prep team (`DataLoader`) processes text in parallel, batching it for the model, as Lecture 8 batched MNIST images. The team ensures ingredients reach the chef (model) on time, avoiding delays, and supports complex recipes (CNNs), extending Lecture 7‚Äôs modularity.\n",
        "\n",
        "## üîÅ Connection to Prior Lessons\n",
        "\n",
        "This lecture builds on Lecture 2 (tensors), where tensors store data, now preprocessed by `DataLoader`. Lecture 3 (strides) emphasized memory efficiency, mirrored in `DataLoader`‚Äôs multiprocessing. Lectures 4‚Äì6 (autograd, computational graphs, implementation) introduced gradient computation, now fed by batched data. Lecture 7‚Äì8 (NN module, implementation) used `nn.Module` for models, now paired with `DataLoader` for scalable training, as seen in the CIFAR-10 CNN.\n",
        "\n",
        "**Prerequisites**: Linear algebra (matrices, derivatives), Python programming, and familiarity with tensors, autograd, `nn.Module`, and neural network training (Lectures 2‚Äì8). Understanding of data preprocessing is helpful.\n",
        "\n",
        "---\n",
        "#Perplexity\n",
        "\n",
        "---\n",
        "üîπ **Key Ideas from Lecture 9: Torch Data & CNN Implementation** (850+ Words)\n",
        "\n",
        "### **1. Core Components of PyTorch Workflow**\n",
        "- **Tensor-Autograd-nn.Module Triad**:\n",
        "  - **Tensors**: Foundational data structure for all operations (CPU/GPU).\n",
        "  - **Autograd**: Automatic differentiation engine for gradient computation.\n",
        "  - **nn.Module**: Abstraction for neural network layers and models.\n",
        "  - *Interaction*: Tensors flow through `nn.Module` layers, autograd tracks gradients, and optimizers update parameters.\n",
        "\n",
        "- **Training Loop**:\n",
        "  ```python\n",
        "  for epoch in epochs:\n",
        "      for batch in dataloader:\n",
        "          inputs, labels = batch\n",
        "          outputs = model(inputs)\n",
        "          loss = criterion(outputs, labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          optimizer.zero_grad()\n",
        "  ```\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Data Loading Challenges**\n",
        "- **Python Slicing Bottleneck**:\n",
        "  - Sequential data access forces the model to wait during batch fetching.\n",
        "  - No parallelism between data loading and model training.\n",
        "  - Critical issue for large datasets (e.g., NLP or high-res images).\n",
        "\n",
        "- **Solution: `torch.utils.data`**:\n",
        "  - **DataLoader**: Parallelizes batch loading using C++ backend.\n",
        "  - **Key Features**:\n",
        "    - Prefetching next batch during model training.\n",
        "    - Multiprocessing with `num_workers`.\n",
        "    - Memory pinning (`pin_memory=True` for faster GPU transfers).\n",
        "\n",
        "---\n",
        "\n",
        "### **3. DataLoader & Dataset Abstractions**\n",
        "- **Dataset Types**:\n",
        "  - **Map-Style**: Implements `__getitem__` and `__len__` (e.g., images on disk).\n",
        "  - **Iterable-Style**: Implements `__iter__` (e.g., streaming from databases).\n",
        "\n",
        "- **DataLoader Configuration**:\n",
        "  ```python\n",
        "  DataLoader(\n",
        "      dataset,\n",
        "      batch_size=64,\n",
        "      shuffle=True,\n",
        "      num_workers=4,\n",
        "      pin_memory=True,\n",
        "      drop_last=False\n",
        "  )\n",
        "  ```\n",
        "\n",
        "---\n",
        "\n",
        "### **4. Practical Application: CIFAR-10 CNN**\n",
        "#### **Dataset & Preprocessing**\n",
        "- **CIFAR-10**:\n",
        "  - 50k training / 10k test images (32x32x3).\n",
        "  - 10 classes: airplane, automobile, bird, etc.\n",
        "  - Transforms:\n",
        "    ```python\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "    ```\n",
        "\n",
        "#### **Model Architecture**\n",
        "```python\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)    # 3 input channels, 6 output channels\n",
        "        self.pool = nn.MaxPool2d(2, 2)     # Reduces spatial dimensions by half\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16*5*5, 120)  # Flattened after conv2\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # Output: [B, 6, 14, 14]\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # Output: [B, 16, 5, 5]\n",
        "        x = x.view(-1, 16*5*5)                # Flatten for FC layers\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "```\n",
        "\n",
        "#### **Training Pipeline**\n",
        "```python\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Device setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Dataset & DataLoader\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "train_set = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_set = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_set, batch_size=64, shuffle=True, num_workers=4, pin_memory=True)\n",
        "test_loader = DataLoader(test_set, batch_size=64, shuffle=False)\n",
        "\n",
        "# Model, Loss, Optimizer\n",
        "model = CNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        if i % 200 == 199:\n",
        "            print(f'Epoch {epoch+1}, Batch {i+1}: Loss {running_loss/200:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "print(f'Test Accuracy: {100 * correct / total:.2f}%')\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **5. Model Training Insights**\n",
        "- **GPU Utilization**:\n",
        "  - Move both model and data to GPU: `tensor.to(device)`.\n",
        "  - `pin_memory=True` accelerates CPU-to-GPU transfers.\n",
        "\n",
        "- **Key Hyperparameters**:\n",
        "  - **Batch Size**: Balances memory usage and gradient stability.\n",
        "  - **num_workers**: Matches CPU core count for optimal parallelism.\n",
        "  - **Normalization**: Stabilizes training by scaling inputs to [-1, 1].\n",
        "\n",
        "---\n",
        "\n",
        "### **6. Mathematical Foundations**\n",
        "- **Convolution Operation**:\n",
        "  For input $$X \\in \\mathbb{R}^{B \\times C_{in} \\times H \\times W}$$ and kernel $$K \\in \\mathbb{R}^{C_{out} \\times C_{in} \\times k \\times k}$$:\n",
        "  $\n",
        "  Y_{b,c_out,i,j} = \\sum_{c_in=0}^{C_{in}-1} \\sum_{m=0}^{k-1} \\sum_{n=0}^{k-1} X_{b,c_in,i+m,j+n} \\cdot K_{c_out,c_in,m,n}\n",
        "  $\n",
        "\n",
        "- **Cross-Entropy Loss**:\n",
        "  $\n",
        "  L = -\\frac{1}{N} \\sum_{i=1}^N \\log\\left(\\frac{e^{x_{i,y_i}}}{\\sum_{j=1}^C e^{x_{i,j}}}\\right)\n",
        "  $\n",
        "\n",
        "---\n",
        "\n",
        "üí° **Analogy: DataLoader as a Pizza Delivery Kitchen**  \n",
        "Imagine a busy pizza restaurant:  \n",
        "- **Chefs (GPU)**: Train models (bake pizzas) at high speed.  \n",
        "- **Prep Staff (DataLoader)**: Chop toppings (preprocess data) in parallel.  \n",
        "- **Conveyor Belt (Dataloader Queues)**: Supplies prepped ingredients (batches) to chefs without pauses.  \n",
        "- **Manager (num_workers)**: Coordinates multiple prep stations to avoid bottlenecks.  \n",
        "\n",
        "**Why It Matters**:  \n",
        "Just as chefs can‚Äôt work without prepped ingredients, GPUs stall without DataLoader‚Äôs parallel batch loading. The kitchen (training loop) only runs smoothly when both teams work simultaneously.\n",
        "\n",
        "---\n",
        "\n",
        "üîÅ **Connection to Prior Lessons**  \n",
        "- **Tensors (Lectures 2-3)**: DataLoader outputs batched tensors for model ingestion.  \n",
        "- **Autograd (Lectures 4-6)**: Gradients flow through CNN layers just like in MLPs.  \n",
        "- **nn.Module (Lectures 7-8)**: CNN layers subclass `nn.Module`, reusing parameter management.  \n",
        "\n",
        "**Innovation**: DataLoader decouples data logistics from model training, enabling PyTorch to handle petabyte-scale datasets efficiently.\n",
        "\n",
        "Citations:\n",
        "[1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/63649134/45cd4d46-593f-422c-a952-e5d0f079d0c0/paste-2.txt\n",
        "[2] https://www.machinelearningmastery.com/deep-learning-with-pytorch-9-day-mini-course/\n",
        "[3] https://pytorch.org/docs/stable/data.html\n",
        "[4] https://www.geeksforgeeks.org/deep-learning-with-pytorch-an-introduction/\n",
        "[5] https://www.digitalocean.com/community/tutorials/dataloaders-abstractions-pytorch\n",
        "[6] https://isip.piconepress.com/courses/temple/ece_4822/resources/books/Deep-Learning-with-PyTorch.pdf\n",
        "[7] https://www.youtube.com/watch?v=V_xro1bcAuA\n",
        "[8] https://cs230.stanford.edu/blog/pytorch/\n",
        "[9] https://multix.io/data-science-book-uva-2023/docs/lectures/lec9.html\n",
        "[10] https://sebastianraschka.com/blog/2021/pytorch-deeplearning-review.html\n",
        "[11] https://pytorch.org/tutorials/beginner/pytorch_with_examples.html\n",
        "[12] https://www.udacity.com/course/deep-learning-pytorch--ud188\n",
        "[13] https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
        "[14] https://www.learnpytorch.io/01_pytorch_workflow/\n",
        "[15] https://codesignal.com/learn/courses/building-a-neural-network-in-pytorch/lessons/training-a-neural-network-model-with-pytorch\n",
        "[16] https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html\n",
        "[17] https://www.kaggle.com/code/kanncaa1/pytorch-tutorial-for-deep-learning-lovers\n",
        "[18] https://github.com/mrdbourke/pytorch-deep-learning\n",
        "[19] https://www.datacamp.com/tutorial/pytorch-lightning-tutorial\n",
        "[20] https://pytorch.org/tutorials/\n",
        "[21] https://www.youtube.com/watch?v=c36lUUr864M\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "KxmxPHuY1bYH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lecture 10: CNN\n",
        "---\n",
        "#GROK\n",
        "\n",
        "---\n",
        "# Deep Learning with PyTorch: Lecture 10 CNN Summary and Explanation\n",
        "\n",
        "As a deep learning instructor with over a decade of experience specializing in PyTorch, I‚Äôll summarize the key ideas from the \"Lecture 10: CNN\" video, focusing on the mathematical foundations and practical applications of **pre-trained CNNs and transfer learning**. The summary of key ideas will be at least 800 words to capture the lecture‚Äôs essence. I‚Äôll explain pre-trained CNNs and transfer learning using analogies and real-world examples, connecting to your prior deep learning studies in this conversation (e.g., tensors, autograd, computational graphs, NN module, torch data from Lectures 2‚Äì9). The response will adhere to the requested format, include a concise code snippet (‚â§50 lines) with explanations of key concepts, and focus on mathematical foundations and practical applications.\n",
        "\n",
        "## üîπ Key Ideas from the Lecture (Summary, ~850 words)\n",
        "\n",
        "- **Pre-trained CNN Architectures**: PyTorch‚Äôs `torchvision.models` provides access to numerous pre-trained CNN architectures (e.g., AlexNet, ResNet, DenseNet, MobileNet) and vision transformers, trained on large datasets like ImageNet (1,000 classes). These models are ready for immediate use or fine-tuning, reducing the need to build models from scratch.\n",
        "- **AlexNet for Image Classification**: The lecture uses AlexNet, pre-trained on ImageNet, to classify CIFAR-10 images or random internet images. AlexNet‚Äôs architecture, defined via `nn.Module`, includes convolutional and fully connected layers, with pre-trained weights loaded when `pretrained=True`, avoiding random initialization.\n",
        "- **Data Preprocessing Requirements**: Input images must match the training conditions of pre-trained models (e.g., 256x256 for AlexNet). Transformations via `torchvision.transforms` resize images, convert to tensors, normalize (e.g., mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), and add a batch dimension (e.g., [1, 3, 256, 256]).\n",
        "- **Inference with Pre-trained Models**: During inference, models are set to evaluation mode (`model.eval()`), disabling gradient computation. For an input image, AlexNet outputs logits for 1,000 classes, processed with `torch.softmax` to obtain probabilities, and `torch.argmax` identifies the predicted class (e.g., goldfish).\n",
        "- **ResNet‚Äôs Superior Performance**: ResNet (e.g., ResNet-18), with residual connections and deeper layers, outperforms AlexNet, achieving higher confidence (e.g., 99.9% for goldfish vs. AlexNet‚Äôs 18.98% for jellyfish). Residual connections mitigate vanishing gradients, improving training stability.\n",
        "- **Transfer Learning Concept**: Transfer learning adapts pre-trained models for new tasks (e.g., binary classification). The final layer (e.g., 1,000 neurons for ImageNet) is replaced with a task-specific layer (e.g., 2 neurons), and the model is retrained, either fine-tuning all layers or freezing earlier layers to retain learned features.\n",
        "- **Freezing Parameters**: In transfer learning, freezing parameters (setting `requires_grad=False`) preserves pre-trained weights, reducing training time and data needs. Fine-tuning adjusts all parameters, allowing adaptation to new data distributions, as needed for CIFAR-10 or custom datasets.\n",
        "- **ImageNet Dataset**: ImageNet, with 1,000 diverse classes, provides robust features for general image recognition. Pre-trained models leverage these features, making them versatile for tasks like classifying CIFAR-10 or internet images, unlike Lecture 9‚Äôs custom CNN.\n",
        "- **Model Weight Loading**: Setting `pretrained=True` loads the model‚Äôs architecture (`nn.Module`) and its `state_dict` (pre-trained weights), typically large files (e.g., 233 MB for AlexNet). This contrasts with Lecture 9‚Äôs random initialization, enhancing performance out-of-the-box.\n",
        "- **Softmax and Logits**: Pre-trained models output logits (unnormalized scores). Softmax converts logits to probabilities: \\( p_i = \\frac{e^{z_i}}{\\sum_j e^{z_j}} \\), where \\( z_i \\) is the logit for class \\( i \\). Argmax selects the class with the highest probability, as in Lecture 8‚Äôs MNIST example.\n",
        "- **Architecture Modularity**: Pre-trained models use `nn.Sequential` to chain layers (e.g., convolutions, pooling, fully connected), simplifying complex architectures. This builds on Lecture 7‚Äôs modularity, allowing easy layer replacement for transfer learning.\n",
        "- **Practical Applications**: Pre-trained models are widely used in industry for tasks like object detection, image segmentation, and medical imaging, where training from scratch is impractical due to data scarcity or computational constraints, extending Lecture 9‚Äôs scalability focus.\n",
        "- **Evaluation Mode Importance**: `model.eval()` ensures no gradients are computed during inference, akin to `torch.no_grad()` from Lecture 6, preventing unintended parameter updates, a lesson reinforced after the lecture‚Äôs initial test set error.\n",
        "- **Transformers in Vision**: The lecture notes vision transformers (e.g., ViT) in `torchvision.models`, reflecting recent advances (post-2021). These models, trained on ImageNet, offer alternatives to CNNs, highlighting the evolving landscape of deep learning architectures.\n",
        "- **Dataset-Specific Challenges**: CIFAR-10‚Äôs small 32x32 images challenge pre-trained models designed for 256x256 inputs, requiring careful preprocessing. This contrasts with Lecture 9‚Äôs direct use of CIFAR-10, emphasizing adaptation for pre-trained models.\n",
        "- **Transfer Learning Flexibility**: Transfer learning supports diverse tasks by modifying output layers and retraining, applicable to binary classification, multi-class problems, or regression, building on Lecture 8‚Äôs custom layer creation.\n",
        "\n",
        "## üî¢ Pre-trained CNNs and Transfer Learning: Mathematical Foundations\n",
        "\n",
        "For a pre-trained CNN like AlexNet, the forward pass maps an input image $\\( \\mathbf{x} \\in \\mathbb{R}^{3 \\times 256 \\times 256} \\)$ to logits $\\( \\mathbf{z} \\in \\mathbb{R}^{1000} \\)$:\n",
        "$\\[ \\mathbf{z} = f(\\mathbf{x}; \\theta), \\]$\n",
        "where \\( f \\) is the CNN (convolutions, pooling, fully connected layers), and $\\( \\theta \\)$ are pre-trained parameters. The softmax probability for class $\\( i \\)$ is:\n",
        "$\\[ p_i = \\frac{e^{z_i}}{\\sum_{j=1}^{1000} e^{z_j}}. \\]$\n",
        "The predicted class is:\n",
        "$\\[ \\hat{y} = \\arg\\max_i p_i. \\]$\n",
        "In transfer learning for a binary task, the final layer is replaced with $\\( \\mathbf{W}_{\\text{new}} \\in \\mathbb{R}^{2 \\times d} \\)$, $\\( \\mathbf{b}_{\\text{new}} \\in \\mathbb{R}^2 \\)$, where $\\( d \\)$ is the feature dimension from the previous layer. The new output is:\n",
        "$\\[ \\mathbf{z}_{\\text{new}} = \\mathbf{W}_{\\text{new}} \\mathbf{h} + \\mathbf{b}_{\\text{new}}, \\]$\n",
        "where $\\( \\mathbf{h} \\)$ is the feature vector. Loss (e.g., cross-entropy) is:\n",
        "$\\[ L = -\\sum_{i=1}^2 y_i \\log p_i, \\]$\n",
        "and gradients $\\( \\frac{\\partial L}{\\partial \\theta} \\)$ update $\\( \\theta \\)$ (or only the new layer if others are frozen).\n",
        "\n",
        "## üß† PyTorch Code\n",
        "\n",
        "Below is a concise PyTorch snippet using AlexNet for image classification, with key concepts explained.\n",
        "\n",
        "```python\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Device setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load pre-trained AlexNet\n",
        "model = models.alexnet(pretrained=True).to(device)\n",
        "model.eval()  # Inference mode\n",
        "\n",
        "# Transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load and preprocess image\n",
        "image = Image.open(\"goldfish.jpg\")  # Example image\n",
        "input_tensor = transform(image).unsqueeze(0).to(device)  # Add batch dimension\n",
        "\n",
        "# Predict\n",
        "with torch.no_grad():\n",
        "    logits = model(input_tensor)\n",
        "    probs = torch.softmax(logits, dim=1)\n",
        "    pred_class = torch.argmax(probs, dim=1).item()\n",
        "\n",
        "# Load ImageNet class labels\n",
        "with open(\"imagenet_classes.txt\") as f:\n",
        "    labels = [line.strip() for line in f]\n",
        "print(f\"Predicted class: {labels[pred_class]}, Confidence: {probs[0, pred_class].item():.2%}\")\n",
        "```\n",
        "\n",
        "**Key Concepts in Code**:\n",
        "- **Pre-trained Model**: `models.alexnet(pretrained=True)` loads AlexNet with ImageNet weights, avoiding random initialization (Lecture 9).\n",
        "- **Transformations**: `Resize`, `ToTensor`, and `Normalize` preprocess the image to match AlexNet‚Äôs training conditions, adding a batch dimension with `unsqueeze(0)` (Lecture 9).\n",
        "- **Inference Mode**: `model.eval()` and `torch.no_grad()` disable gradients, ensuring efficient prediction (Lecture 6).\n",
        "- **Softmax and Argmax**: `torch.softmax` computes probabilities, and `torch.argmax` selects the predicted class, as in Lecture 8.\n",
        "\n",
        "## üí° Analogy: Pre-trained CNNs as a Skilled Chef\n",
        "\n",
        "Imagine a neural network as a chef preparing a dish (prediction). Building a CNN from scratch (Lecture 9) is like training a novice chef, requiring time and ingredients (data). A pre-trained CNN (e.g., AlexNet) is a master chef trained at a culinary school (ImageNet), skilled in diverse recipes (1,000 classes). For a new dish (e.g., CIFAR-10 classification), the chef applies learned techniques (pre-trained weights), needing only minor adjustments (preprocessing). Transfer learning is like retraining the chef for a specific cuisine (binary classification), tweaking their skills (final layer) while retaining core expertise (frozen layers).\n",
        "\n",
        "In medical imaging, a pre-trained CNN classifies X-rays for disease detection. The chef (model) uses ImageNet skills (feature extraction), adapted via transfer learning for medical patterns, as Lecture 8 customized layers. Preprocessing (Lecture 9) ensures ingredients (images) match the chef‚Äôs training, while evaluation mode (Lecture 6) prevents skill updates during service.\n",
        "\n",
        "## üîÅ Connection to Prior Lessons\n",
        "\n",
        "This lecture builds on Lecture 2 (tensors), where tensors store images, now preprocessed for pre-trained models. Lecture 3 (strides) emphasized memory efficiency, relevant for large pre-trained weights. Lectures 4‚Äì6 (autograd, computational graphs, implementation) underpin gradient-free inference. Lecture 7‚Äì8 (NN module, implementation) introduced `nn.Module`, now used in pre-trained architectures. Lecture 9 (torch data) provided `DataLoader` and transformations, critical for feeding pre-trained CNNs like AlexNet.\n",
        "\n",
        "**Prerequisites**: Linear algebra (matrices, derivatives), Python programming, and familiarity with tensors, autograd, `nn.Module`, `torch.utils.data`, and CNN basics (Lectures 2‚Äì9). Understanding of image preprocessing is essential.\n",
        "\n",
        "---\n",
        "#Perplexity\n",
        "\n",
        "---\n",
        "üîπ **Key Ideas from Lecture 10: Advanced Model Training & Optimization in PyTorch** (850+ Words)\n",
        "\n",
        "### **1. Core Concepts in Advanced Training**\n",
        "- **Transfer Learning**:  \n",
        "  - Leverage pre-trained models (e.g., ResNet, BERT) for new tasks by fine-tuning final layers.  \n",
        "  - Freeze early layers to preserve feature extraction capabilities.  \n",
        "\n",
        "- **Learning Rate Scheduling**:  \n",
        "  - Dynamically adjust learning rates (e.g., `ReduceLROnPlateau`, `CosineAnnealing`) to escape local minima.  \n",
        "  - Example scheduler:  \n",
        "    ```python\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "    ```\n",
        "\n",
        "- **Gradient Clipping**:  \n",
        "  - Prevent exploding gradients in RNNs/transformers:  \n",
        "    ```python\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    ```\n",
        "\n",
        "- **Mixed Precision Training**:  \n",
        "  - Use `torch.cuda.amp` for FP16/FP32 hybrid training to reduce memory usage and speed up computation.  \n",
        "\n",
        "---\n",
        "\n",
        "### **2. Custom Loss Functions & Metrics**\n",
        "- **Implementing F1 Score**:  \n",
        "  - Combine precision and recall for imbalanced datasets:  \n",
        "    $$ F1 = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}} $$  \n",
        "  - PyTorch implementation:  \n",
        "    ```python\n",
        "    def f1_score(y_pred, y_true):\n",
        "        tp = (y_true * y_pred).sum().float()\n",
        "        precision = tp / (y_pred.sum().float() + 1e-8)\n",
        "        recall = tp / (y_true.sum().float() + 1e-8)\n",
        "        return 2 * (precision * recall) / (precision + recall + 1e-8)\n",
        "    ```\n",
        "\n",
        "---\n",
        "\n",
        "### **3. Distributed Training**\n",
        "- **DataParallel vs. DistributedDataParallel**:  \n",
        "  - **DataParallel**: Single-process, multi-threaded (easy but less efficient).  \n",
        "  - **DistributedDataParallel**: Multi-process, optimized for multi-GPU nodes.  \n",
        "\n",
        "- **Code Setup for Multi-GPU**:  \n",
        "  ```python\n",
        "  torch.distributed.init_process_group(backend='nccl')\n",
        "  model = torch.nn.parallel.DistributedDataParallel(model)\n",
        "  ```\n",
        "\n",
        "---\n",
        "\n",
        "### **4. Hyperparameter Optimization**\n",
        "- **Grid Search**:  \n",
        "  - Exhaustively test combinations of learning rates, batch sizes, etc.  \n",
        "- **Bayesian Optimization**:  \n",
        "  - Use libraries like `Ax` or `Optuna` for efficient hyperparameter tuning.  \n",
        "\n",
        "---\n",
        "\n",
        "üß† **Practical Code Example: Advanced CNN Training (50+ Lines)**  \n",
        "```python\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "import numpy as np\n",
        "\n",
        "# Device setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Data augmentation & normalization\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load ImageNet subset\n",
        "train_data = datasets.ImageFolder('data/train', transform=train_transform)\n",
        "val_data = datasets.ImageFolder('data/val', transform=val_transform)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=128, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_loader = DataLoader(val_data, batch_size=64, num_workers=4, pin_memory=True)\n",
        "\n",
        "# Model definition (pretrained ResNet-50)\n",
        "model = torchvision.models.resnet50(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 1000)  # Adjust for 1000 classes\n",
        "\n",
        "# Freeze all layers except final\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "model.fc.requires_grad = True\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss, optimizer, scheduler\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2)\n",
        "scaler = GradScaler()  # For mixed precision\n",
        "\n",
        "# Training loop with mixed precision\n",
        "def train(epochs):\n",
        "    best_val_loss = float('inf')\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for X, y in train_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            with autocast():\n",
        "                outputs = model(X)\n",
        "                loss = criterion(outputs, y)\n",
        "            \n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            \n",
        "            train_loss += loss.item()\n",
        "        \n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for X, y in val_loader:\n",
        "                X, y = X.to(device), y.to(device)\n",
        "                outputs = model(X)\n",
        "                loss = criterion(outputs, y)\n",
        "                val_loss += loss.item()\n",
        "        \n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "        scheduler.step(avg_val_loss)\n",
        "        \n",
        "        print(f'Epoch {epoch+1}: Train Loss: {train_loss/len(train_loader):.4f}, Val Loss: {avg_val_loss:.4f}')\n",
        "        \n",
        "        # Save best model\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "            best_val_loss = avg_val_loss\n",
        "\n",
        "# Execute training\n",
        "train(epochs=10)\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate():\n",
        "    model.load_state_dict(torch.load('best_model.pth'))\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in val_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            outputs = model(X)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += y.size(0)\n",
        "            correct += (predicted == y).sum().item()\n",
        "    print(f'Validation Accuracy: {100 * correct / total:.2f}%')\n",
        "\n",
        "evaluate()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **5. Mathematical Foundations**\n",
        "- **Learning Rate Decay**:  \n",
        "  For learning rate $ \\eta_t $ at step $ t $:  \n",
        "  $ \\eta_t = \\eta_0 \\cdot \\gamma^{\\lfloor t / s \\rfloor} $  \n",
        "  where $ \\gamma $ = decay rate, $ s $ = step size.  \n",
        "\n",
        "- **Cross-Entropy Loss**:  \n",
        "  $ L = -\\frac{1}{N} \\sum_{i=1}^N \\sum_{c=1}^C y_{i,c} \\log(p_{i,c}) $\n",
        "\n",
        "---\n",
        "\n",
        "üí° **Analogy: Training as a Refinery Process**  \n",
        "Imagine training a model as refining crude oil:  \n",
        "- **Raw Data (Crude Oil)**: Requires preprocessing (distillation) via DataLoader.  \n",
        "- **Model Architecture (Refinery Structure)**: CNNs/ResNets act like distillation columns separating features.  \n",
        "- **Optimizer (Temperature Control)**: Adjusts \"heat\" (learning rate) to maximize output quality.  \n",
        "- **Mixed Precision (Catalyst)**: Accelerates reactions (computations) without changing the outcome.  \n",
        "- **Gradient Clipping (Pressure Valve)**: Prevents system explosions (gradient issues).  \n",
        "\n",
        "**Why It Matters**:  \n",
        "Just as refineries optimize each stage for peak efficiency, advanced training techniques ensure models learn efficiently without instability.\n",
        "\n",
        "---\n",
        "\n",
        "üîÅ **Connection to Prior Lessons**  \n",
        "- **Autograd (Lectures 4-6)**: Gradient clipping builds on backpropagation fundamentals.  \n",
        "- **nn.Module (Lectures 7-8)**: Transfer learning extends modular design principles.  \n",
        "- **DataLoader (Lecture 9)**: Essential for feeding augmented data in distributed training.  \n",
        "\n",
        "**Innovation**: PyTorch‚Äôs flexibility allows seamless integration of cutting-edge techniques (mixed precision, distributed training) into standard workflows, mirroring industry-grade ML pipelines.\n",
        "\n",
        "Citations:\n",
        "[1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/63649134/d104de6f-52ea-428a-8b21-93c79d81ca27/paste.txt\n",
        "[2] https://www.datacamp.com/tutorial/pytorch-tutorial-building-a-simple-neural-network-from-scratch\n",
        "[3] https://pyimagesearch.com/2021/07/19/pytorch-training-your-first-convolutional-neural-network-cnn/\n",
        "[4] https://assemblyai.com/blog/end-to-end-speech-recognition-pytorch\n",
        "[5] https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
        "[6] https://isip.piconepress.com/courses/temple/ece_4822/resources/books/Deep-Learning-with-PyTorch.pdf\n",
        "[7] https://pytorch.org/tutorials/beginner/introyt/trainingyt.html\n",
        "[8] https://sebastianraschka.com/blog/2021/dl-course.html\n",
        "[9] https://www.udemy.com/course/pytorch-for-deep-learning/\n",
        "[10] https://deeplearningcourses.com/c/pytorch-deep-learning\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "de6SwLTX1bPe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LECTURE NOTES AND WORK THROUGHS"
      ],
      "metadata": {
        "id": "P20_A6X-Lqcc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DAY 1"
      ],
      "metadata": {
        "id": "-ogWos1DLuQM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n"
      ],
      "metadata": {
        "id": "cwLnS5CfLqEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smNf2eBoxr4v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c3ad9f2c-db97-422f-c4ee-6c2f11e42210"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.6.0+cu124'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "torch.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating a Tensor"
      ],
      "metadata": {
        "id": "4swcEs_LMaGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_var = torch.tensor(2)\n",
        "first_var"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiAZQR-jMYKL",
        "outputId": "f12b4fb8-4c1b-4078-d966-41b97b86ad9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_var.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wXzVip_MLsP",
        "outputId": "74caa29e-0cb4-4dcb-dddb-4b4e3fdee75d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([2, 3, 4, 5])"
      ],
      "metadata": {
        "id": "5TYJBXJEMgLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.ndim, a.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ng3qbsX4Mk-n",
        "outputId": "1b04def7-e49a-4d97-d4b6-fcb990191afc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, torch.Size([4]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = torch.tensor([[1,2,3],[3,4,5]])"
      ],
      "metadata": {
        "id": "6u9u48X-MmYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cobfhWGjMrWw",
        "outputId": "278061fc-f085-4e80-92ed-5e25b22b0aaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [3, 4, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b.shape, b.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-k6y33XrMr9n",
        "outputId": "cb08afea-e644-4c3b-c349-596e801c04d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2, 3]), torch.int64)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([1.3,2.4,3], dtype = torch.float32)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7NCtvfTMvvX",
        "outputId": "37d0665f-05d9-4584-e5d9-db4e719ff2a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.3000, 2.4000, 3.0000])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dz18ear3M0Qo",
        "outputId": "ac395136-061c-4511-e6e2-74a6fa21fd19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = torch.tensor(a, dtype = torch.int32)\n",
        "b\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Us6-9A2WM1gX",
        "outputId": "3668eb9f-810f-472f-a363-21a847913cba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-f6c5014cccc9>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  b = torch.tensor(a, dtype = torch.int32)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3], dtype=torch.int32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = torch.empty((2,3), dtype=torch.int64)\n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gujGIbjWM3LR",
        "outputId": "203e6980-62ff-44ce-e967-eafcaddd9193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 0, 0],\n",
              "        [0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXxqyoK5OXkF",
        "outputId": "b66680a4-4b04-4245-8133-b06b54eb1f70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "136891228412944"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.zeros(3, 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twGSRjoTObXe",
        "outputId": "0a92ccce-3991-4fae-f5f5-466a7c2f9b8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.ones(4, 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7jSwhXCOli_",
        "outputId": "2272ff40-4144-448b-a899-4190eaa1269f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(43)\n",
        "a = torch.rand(3, 4)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_y5PQ6qqOpEn",
        "outputId": "35b64530-1c26-4956-fcc0-ef304c079916"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4540, 0.1965, 0.9210, 0.3462],\n",
              "        [0.1481, 0.0858, 0.5909, 0.0659],\n",
              "        [0.7476, 0.6253, 0.9392, 0.1338]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.arange(0,10,2) #start,end,skip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bsLMpPJPYX3",
        "outputId": "e8bcc37b-ec38-44b2-effc-43e1b8d82b76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 2, 4, 6, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.linspace(5,20, 4) #start, end, no of parts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vH9Tfmg1PgzW",
        "outputId": "72b15166-5f84-43d9-f6b0-02caf2a282ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 5., 10., 15., 20.])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.eye(5) #identity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAClFkFYPqcH",
        "outputId": "352e5db6-75eb-4d32-cf46-e509fc33433c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 1., 0.],\n",
              "        [0., 0., 0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.diag(torch.tensor([2, 5, 7, 8]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "je4C3yXjPtje",
        "outputId": "db1abc3f-7382-4bfe-9f42-d828fe3f106f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 0, 0, 0],\n",
              "        [0, 5, 0, 0],\n",
              "        [0, 0, 7, 0],\n",
              "        [0, 0, 0, 8]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.full((2,5), 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQfGJ3WPPzl4",
        "outputId": "45df0f8f-eb9d-4168-9106-5ce8b912f933"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4, 4, 4, 4, 4],\n",
              "        [4, 4, 4, 4, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### SHAPE"
      ],
      "metadata": {
        "id": "Mfv4sKviP8su"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.tensor([[2,3],[1,4],[5,6], [0,9]])\n",
        "t1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aO4xr-zP342",
        "outputId": "477c2026-df69-49cb-99cd-9163aa1e6141"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 3],\n",
              "        [1, 4],\n",
              "        [5, 6],\n",
              "        [0, 9]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1.dim(),t1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fA-TsYWTWse",
        "outputId": "ce731602-3cc1-4971-c4bf-254c02840b49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, torch.Size([4, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1.reshape(2, 2, 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMQRD850TYG-",
        "outputId": "d749ef0d-5d4b-47e1-fc67-cf70205cffb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[2, 3],\n",
              "         [1, 4]],\n",
              "\n",
              "        [[5, 6],\n",
              "         [0, 9]]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1.flatten(),t1.flatten().shape,t1.flatten().dim()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D49z07ESTY1W",
        "outputId": "95443667-4f31-4d9d-e0a6-30a6ef5e84fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([2, 3, 1, 4, 5, 6, 0, 9]), torch.Size([8]), 1)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mat = torch.rand(3,2,3,2)\n",
        "print(mat.shape, mat.dim())\n",
        "print(\"---\"*4)\n",
        "print(mat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHejw9fvTkUW",
        "outputId": "24b8ab78-0c5e-4bbd-e2a1-fe0bbd7ae6df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 2, 3, 2]) 4\n",
            "------------\n",
            "tensor([[[[0.4444, 0.9035],\n",
            "          [0.0774, 0.7154],\n",
            "          [0.9692, 0.0257]],\n",
            "\n",
            "         [[0.5430, 0.6641],\n",
            "          [0.5673, 0.5144],\n",
            "          [0.9642, 0.9548]]],\n",
            "\n",
            "\n",
            "        [[[0.5277, 0.7184],\n",
            "          [0.3546, 0.3031],\n",
            "          [0.3461, 0.8369]],\n",
            "\n",
            "         [[0.9357, 0.8380],\n",
            "          [0.5298, 0.6604],\n",
            "          [0.2814, 0.4207]]],\n",
            "\n",
            "\n",
            "        [[[0.1089, 0.6978],\n",
            "          [0.1944, 0.9844],\n",
            "          [0.5572, 0.7541]],\n",
            "\n",
            "         [[0.4072, 0.6215],\n",
            "          [0.0473, 0.0926],\n",
            "          [0.2488, 0.9848]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ans = 1\n",
        "for x in mat.shape:\n",
        "  ans*=x\n",
        "ans"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zl0HWzbT8Bm",
        "outputId": "783652e4-e942-45f0-c9d3-a12f5d750dd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(mat.flatten())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsDATPxIUHAm",
        "outputId": "8931b90f-6602-4a57-f7c5-621a1fbe4053"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mat = torch.rand(3,2,4)\n",
        "mat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcNPmVjNUiNn",
        "outputId": "1a67be96-b00e-4064-b303-a45e6a778a48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.7570, 0.7742, 0.9853, 0.7406],\n",
              "         [0.7091, 0.3286, 0.3252, 0.8579]],\n",
              "\n",
              "        [[0.9265, 0.1611, 0.7019, 0.3931],\n",
              "         [0.9865, 0.4413, 0.4129, 0.4582]],\n",
              "\n",
              "        [[0.4290, 0.9433, 0.3099, 0.7041],\n",
              "         [0.5546, 0.9049, 0.8079, 0.1751]]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.permute(mat, (2,0,1)).size() #4x3x2, ie [2]dim is now first ...."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVAwHA4MVySd",
        "outputId": "e5f2479d-c270-4885-c1e0-895cc85ca27c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Returns a new tensor with a dimension of size one inserted at the specified position.\n",
        "\n",
        "The returned tensor shares the same underlying data with this tensor.\n",
        "\n",
        "A dim value within the range [-input.dim() - 1, input.dim() + 1) can be used. Negative dim will correspond to unsqueeze() applied at dim = dim + input.dim() + 1.\n",
        "Parameters\n",
        "input (Tensor) ‚Äì the input tensor.\n",
        "\n",
        "dim (int) ‚Äì the index at which to insert the singleton dimension\n",
        "```\n",
        "x = torch.tensor([1, 2, 3, 4])\n",
        "torch.unsqueeze(x, 0)\n",
        "OUTPUT:tensor([[ 1,  2,  3,  4]])\n",
        "torch.unsqueeze(x, 1)\n",
        "OUTPUT:tensor([[ 1],\n",
        "        [ 2],\n",
        "        [ 3],\n",
        "        [ 4]])\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "jpvrMQB5Wk6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.unsqueeze(mat, dim=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVA2xJkgV4dd",
        "outputId": "65df0a20-86ae-4cd9-e332-762b9b19e36f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0.7570, 0.7742, 0.9853, 0.7406]],\n",
              "\n",
              "         [[0.7091, 0.3286, 0.3252, 0.8579]]],\n",
              "\n",
              "\n",
              "        [[[0.9265, 0.1611, 0.7019, 0.3931]],\n",
              "\n",
              "         [[0.9865, 0.4413, 0.4129, 0.4582]]],\n",
              "\n",
              "\n",
              "        [[[0.4290, 0.9433, 0.3099, 0.7041]],\n",
              "\n",
              "         [[0.5546, 0.9049, 0.8079, 0.1751]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Returns a tensor with all specified dimensions of input of size 1 removed.\n",
        "b = torch.rand(1,5,3,1)\n",
        "torch.squeeze(b).size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzVuQZ42WXAF",
        "outputId": "c9d2b004-bb9f-4f13-d5fe-65ef594d5fc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = torch.squeeze(b)\n",
        "torch.unsqueeze(c, ).size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "prOEU3ZaYVb9",
        "outputId": "2b898188-2717-4df7-e77c-55e414985d49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "unsqueeze() missing 1 required positional arguments: \"dim\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-9f3b200bb94d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: unsqueeze() missing 1 required positional arguments: \"dim\""
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Similiar Shape Tensors"
      ],
      "metadata": {
        "id": "ourEM63QavVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.rand(2, 3)"
      ],
      "metadata": {
        "id": "U0WSCjJ8Y0qd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t2 = torch.empty_like(t1)"
      ],
      "metadata": {
        "id": "e4ci9dqCazm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyu1vTlQa3bm",
        "outputId": "2eed2f54-4320-4d2f-8189-708c18f91f44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7017, 0.1618, 0.0797],\n",
              "        [0.2850, 0.8346, 0.5442]])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7n71Ca7a4wF",
        "outputId": "49162318-2aa8-476e-a2a8-413da162ab95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[       nan, 4.4664e-41, 3.1146e-04],\n",
              "        [0.0000e+00, 5.9835e-43, 0.0000e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.ones_like(t1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xAokw_Fa5P1",
        "outputId": "dead14f8-da97-4518-db8a-2ccd1a5e4b1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.rand_like(t1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Srmnb5koa-I9",
        "outputId": "927ef204-8274-4b0d-f7c9-01adf65ae704"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9588, 0.7089, 0.4048],\n",
              "        [0.9270, 0.7090, 0.6647]])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Mathematical Operations"
      ],
      "metadata": {
        "id": "ovImOQpAbFV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#scalar addiditon\n",
        "import torch"
      ],
      "metadata": {
        "id": "qBy_lh6Ea__9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor(2)\n",
        "b = torch.tensor(3)\n",
        "a+b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neSgFXKjdGB1",
        "outputId": "ba0b4b3d-2efb-429b-aa3a-968f019ca93d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a-b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiisC9a5WCbk",
        "outputId": "cc2f94ec-331a-4dfa-d5eb-927ab9242a60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-1)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a*b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgJh0nokWEZQ",
        "outputId": "ff415b00-bc16-4f3f-a96d-c3f0eae296ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a/b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIHcd3TBWF2Y",
        "outputId": "c5543a89-2b1c-4c53-d000-f4c7196e1f52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6667)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b%a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrVj96_JWGVg",
        "outputId": "03eb7c0f-dca0-4a0a-9ecb-a134ad3a9b75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b**2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvbgYmMsWK8s",
        "outputId": "2ac58837-b204-4a77-f6ad-f39994456d81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(9)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Element wise Operations"
      ],
      "metadata": {
        "id": "hiU6f5L1WN6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.tensor([[-1,2,3], [4,5,-6]])\n",
        "t2 = torch.tensor( [[1,1,1], [2,2,2]])"
      ],
      "metadata": {
        "id": "BksjyaX-WMxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.add(t1, t2), t1+t2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHe7FDp2WVAD",
        "outputId": "0d9037da-67aa-4a98-8e39-30eaf5c73dd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0,  3,  4],\n",
              "         [ 6,  7, -4]]),\n",
              " tensor([[ 0,  3,  4],\n",
              "         [ 6,  7, -4]]))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1*t2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrY2UnPdWXrx",
        "outputId": "6f04743b-fb81-46b5-d43a-db6da6c9dd3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ -1,   2,   3],\n",
              "        [  8,  10, -12]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.abs(t1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0uzLsJOWdbX",
        "outputId": "4f09571c-deed-4d46-8d79-d01353125a0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.neg(t1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1J8ittcUWe3Q",
        "outputId": "2b092b51-e4c3-49ff-b9e6-d2409ed26a26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1, -2, -3],\n",
              "        [-4, -5,  6]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t3= torch.tensor([-5,-2, 0 ,1,2,3,4])\n",
        "t3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0vclmytWiG4",
        "outputId": "1136a88e-951e-4749-fade-fa41d6c2e6ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-5, -2,  0,  1,  2,  3,  4])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.clamp(t3, min=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8hsj2PPXhFr",
        "outputId": "1403752b-2c84-4501-e656-d862f0487126"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 1, 2, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### STATS"
      ],
      "metadata": {
        "id": "hlCGlnWSXlrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3tTQz4MXkFg",
        "outputId": "235a8193-40a4-449f-f8ec-3475f17b6cf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1,  2,  3],\n",
              "        [ 4,  5, -6]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKcxmfwlXnrn",
        "outputId": "ee5cd949-400e-4ce8-e4ff-b0d6e66db7f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1.sum(axis=0) #column wise\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgxqZkcZXo2_",
        "outputId": "30e55bf6-becb-45e9-c97a-c1ac382a55eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 3,  7, -3])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1.sum(axis=1) #row wise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nt6azHKnXsGw",
        "outputId": "c72b0765-4e5d-48fa-ab14-65446e82c858"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t2 = torch.tensor([[1,2,4], [2,5,6]], dtype= torch.float)\n",
        "t2.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2822k2fXxjA",
        "outputId": "09bbee26-c129-4c50-e7a3-f2b47f03668a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.3333)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t2.mean(axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-ug3za_X4mx",
        "outputId": "3ae26ddc-772c-4adc-bec0-c6a212df2a3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.3333, 4.3333])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t2.median()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ygQQ8U7X7pw",
        "outputId": "7bb2ecc2-6f55-4469-dd67-e7bb71d909f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t2.max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQ9vjQKCYKzn",
        "outputId": "a2ad2281-c7fb-4214-bc69-e60a194c02ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6.)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t2.min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pB3bAQiMYLyA",
        "outputId": "34867316-383e-47f8-d2e1-9bdc115f8be5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xBKylk8YRxg",
        "outputId": "56ebd88c-05f8-4dfa-bc3d-7919f72cbfa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 4.],\n",
              "        [2., 5., 6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t2.argmax(),t2.flatten()[5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3LqlS2GYNAU",
        "outputId": "ed6b851b-7670-436a-e4b5-43f56669954d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(5), tensor(6.))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t2.argmin(),t2.flatten()[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LheC8SKEYOf_",
        "outputId": "49c98b9d-ed8f-41b2-9a78-1344abde696d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0), tensor(1.))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t2.std()"
      ],
      "metadata": {
        "id": "XeBM8oSEYabw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbd5f0f3-754b-46cc-f940-7f0a68fd1416"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.9664)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Matrix Operation"
      ],
      "metadata": {
        "id": "6M5I-91NJ5Y5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.tensor([[1,2,3], [4,5,6]])\n",
        "t2 = torch.tensor([[1,2],[3,4], [5,6]])"
      ],
      "metadata": {
        "id": "gBkpbyTvJ2KZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.matmul(t1, t2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iY_dXJHLLRcC",
        "outputId": "cb37ba97-f47a-45ea-f79b-131f1e02f4ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[22, 28],\n",
              "        [49, 64]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.tensor([1,2,3])\n",
        "t2 = torch.tensor([4,5,6])\n",
        "torch.dot(t1,t2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-JTWcgiMeeB",
        "outputId": "c0e9d367-c2fb-41d3-956b-d944da197bca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(32)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "torch.transpos(tensor,dim0,dim1)\n",
        "Parameters\n",
        "input (Tensor) ‚Äì the input tensor.\n",
        "\n",
        "dim0 (int) ‚Äì the first dimension to be transposed\n",
        "\n",
        "dim1 (int) ‚Äì the second dimension to be transposed\n",
        "```"
      ],
      "metadata": {
        "id": "kT2pf_jVNFEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.tensor([[1,2,3], [4,5,6]])\n",
        "torch.transpose(t1, 0 , 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0zZUuddMz9x",
        "outputId": "3f5e0cae-ce57-4518-e6d5-db4d0135f274"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 4],\n",
              "        [2, 5],\n",
              "        [3, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#determinant\n",
        "torch.linalg.det(torch.rand(3,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7Vgb_f3NUvZ",
        "outputId": "c11988a3-4b52-4ddf-98d6-ae2b1c3fb068"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.0506)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#inverse\n",
        "a = torch.rand(3,3)\n",
        "torch.linalg.inv(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hW0Zes8NNbqx",
        "outputId": "8857a8e9-69b9-4a8a-c571-004eea930047"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ -7.6451,   6.1997,  16.8615],\n",
              "        [ 25.7923, -22.5995, -47.1180],\n",
              "        [-16.3149,  15.7867,  28.9891]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Comparision"
      ],
      "metadata": {
        "id": "uMUnw19HNpaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.tensor([[1, 2], [3,4]])\n",
        "t2 = torch.tensor([[5, 1], [0,7]])"
      ],
      "metadata": {
        "id": "nmDLI_n3NhzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t1 > t2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ptx_mW_HaoTa",
        "outputId": "a642198e-9441-4cb8-e8f5-f9b8798868e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False,  True],\n",
              "        [ True, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1 < t2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEnh_Ezcapab",
        "outputId": "99be4441-1a72-4d83-8637-466712c17a18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ True, False],\n",
              "        [False,  True]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1 == t2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8cp0wsmaqxK",
        "outputId": "c380cbc6-73b7-408f-d440-75197b8d85e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False, False],\n",
              "        [False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Important Functions"
      ],
      "metadata": {
        "id": "kEee-MVEatPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.log(t1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejNgxRIyarla",
        "outputId": "8858ffe9-06e7-424d-a64a-4b26f161d542"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.6931],\n",
              "        [1.0986, 1.3863]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.exp(t1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ac0hktAMbFl7",
        "outputId": "773854d4-70b2-4d5b-d0c1-feb68f22469d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.7183,  7.3891],\n",
              "        [20.0855, 54.5981]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.square(t1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NK9Nv-xGbIBL",
        "outputId": "0da1b433-8410-4cae-faad-7c9939db09fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1,  4],\n",
              "        [ 9, 16]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sqrt(t1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnkLHbmibKnj",
        "outputId": "877c456a-9ec5-45c9-e597-f2d9bb78fa8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 1.4142],\n",
              "        [1.7321, 2.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "1/(1 + torch.exp(-t1)) #sigmoid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVnSBCPubMxL",
        "outputId": "c80d3e56-cd25-428c-f30e-1795fe9f42e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7311, 0.8808],\n",
              "        [0.9526, 0.9820]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.tensor([[1, 2], [3,4]], dtype= torch.float32)\n",
        "torch.softmax(t1, axis = 1 ) # each row adds up to 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UyIn31XbTjj",
        "outputId": "a482147a-3a43-4b3b-cb3c-c40bed1ddb99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2689, 0.7311],\n",
              "        [0.2689, 0.7311]])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.softmax(t1, axis = 0 ) #each column adds up to 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQjpn8NYbaoq",
        "outputId": "1d02079e-2b04-4acd-9d54-6c8eaadd391a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1192, 0.1192],\n",
              "        [0.8808, 0.8808]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.softmax(t1, dim = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoDujVkwbqlC",
        "outputId": "12e8bce8-289b-47cb-ec28-445c15dff09d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2689, 0.7311],\n",
              "        [0.2689, 0.7311]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.tensor([[-1,2], [3,-4]], dtype= torch.float32)\n",
        "torch.relu(t1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3qApGE_bv4z",
        "outputId": "dae557b3-7435-4066-cd15-714e80365376"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 2.],\n",
              "        [3., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Inplace Operation"
      ],
      "metadata": {
        "id": "ygF0mX46fPlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([1,2,3])\n",
        "b = torch.tensor([4,5,6])\n",
        "c = a+b"
      ],
      "metadata": {
        "id": "bO-yTf22bxlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c == a.add_(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLJZRjO1fj9k",
        "outputId": "15666631-e62a-40d8-b752-765c0d438072"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([True, True, True])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.tensor([4, 5, 6])\n",
        "grad = torch.tensor([2,1,3])\n",
        "\n",
        "w.subtract_(grad)\n",
        "w"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7N11VUKqfmhL",
        "outputId": "cee40408-c70c-4b46-fb4f-0e7bada6fa97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 4, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w.zero_()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmtBnIY9fxNr",
        "outputId": "f9b51ce3-d965-45ad-ecd2-b377a6a42792"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YY1LDCKxfzub",
        "outputId": "cc545a48-f2de-4827-f0e4-cbd3833f2746"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Clone"
      ],
      "metadata": {
        "id": "kjWMd2O6f1fw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([1, 2, 3])\n",
        "b = a"
      ],
      "metadata": {
        "id": "eP-ifqD2fz-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id(b) == id(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LX9dVqDcgFr7",
        "outputId": "f1997a6c-657c-4caa-fed7-d04b97662224"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b.add_(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilKnUTt-gHMr",
        "outputId": "fb788370-1d84-4f5c-c4b7-0cbb9126650e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzjXGZ7rgJkr",
        "outputId": "5608fee8-2e06-4cef-de74-6056fb5e3ac0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = torch.clone(b)"
      ],
      "metadata": {
        "id": "k_I5MCeygKeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id(c) == id(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1kDjqnNgPRz",
        "outputId": "3cfb7190-1f21-43e8-f785-ac33000b0d2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c.add_(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxw_ALwDgQcL",
        "outputId": "d210fed7-50ab-4893-d121-84988c39c57a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 4, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c == b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jaf4gJaagTND",
        "outputId": "1c826a07-5e30-464c-f729-9509a0cc961b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tensor Operations on GPU"
      ],
      "metadata": {
        "id": "mRd9Osaagd1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "4Gr1ORZUgUDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.device_count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpuWJOcHrBvM",
        "outputId": "5cf0e4cc-488b-4a68-8eaa-e6b0e76ffca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eC0UnvoarBtZ",
        "outputId": "c2044f3d-d0ff-4a74-d858-75b20459eb1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  torch.cuda.get_device_properties()\n",
        "except:\n",
        "  print(\"No GPU\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vgh-5Y0prBqj",
        "outputId": "a8994dd9-e435-4d39-8cff-dfb1e64527cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  gpu_count = torch.cuda.device_count()\n",
        "  print(f\"Number of GPUs available: {gpu_count}\\n\")\n",
        "\n",
        "  #Iterate through the GPUs\n",
        "  for i in range(gpu_count):\n",
        "    props = torch.cuda.get_device_properties(i)\n",
        "    print(f\"GPU{i}:{props.name}\")\n",
        "    print(f\"- Total Memory:{props.total_memory/1e9:.2f} GB\")\n",
        "    print(f\"- Compute Capability:{props.major}.{props.minor}\\n\")\n",
        "    print(f\"- Multiprocessor Count:{props.multi_processor_count}\\n\")\n",
        "else:\n",
        "  print(\"NO GPUS Available \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDBDLbRYrBn7",
        "outputId": "18d49aa1-b3c4-4a20-8c9c-7a5eab401283"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NO GPUS Available \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  torch.device(0)\n",
        "except Exception as e:\n",
        "  print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWK3DOZrrBl6",
        "outputId": "ba6a7851-89eb-4dd3-e55a-d17162bf4264"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cannot access accelerator device when none is available.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  print(torch.device(type='cuda',index=0))\n",
        "except Exception as e:\n",
        "  print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4kVHxoFrBje",
        "outputId": "a7ec94c4-719e-483d-a725-e7b4a6b3d1ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  print()\n",
        "except Exception as e:\n",
        "  print(e)"
      ],
      "metadata": {
        "id": "u7cteBplrBf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\"\n",
        "except Exception as e:\n",
        "  print(e)"
      ],
      "metadata": {
        "id": "zXep06Q2rBdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor([1,2,3], device = device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3adz_KhRrBbb",
        "outputId": "1303ea09-f3e9-4af8-f3da-98c2b44536d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mat1 = torch.tensor([1,2,3])\n",
        "mat1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-3xkZNJrBYw",
        "outputId": "1bf13639-1866-4112-cf07-2062af73c1eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mat1.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXJzEql7xCUn",
        "outputId": "58fdfb35-bca3-4409-c6b4-7b251f11a257"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.nn.Linear(10,1)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEQXE_b_xEL1",
        "outputId": "894f1ecb-3d66-4828-ddb7-e6f799fa5619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=10, out_features=1, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Day 2 Workshop"
      ],
      "metadata": {
        "id": "-0r7CnKexIRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch"
      ],
      "metadata": {
        "id": "DAlyccIzxFxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numpy_array = np.array([[1,2,3], [4,5,6]])\n",
        "numpy_array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tqsR1l5xL4f",
        "outputId": "ce58eead-a948-4b0f-d852-3ab84144984a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2, 3],\n",
              "       [4, 5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numpy_array.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwMrGE89x3-l",
        "outputId": "8575a743-7f29-4d24-bcda-91aa8fdb377d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('int64')"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "a whole-ass new tensor"
      ],
      "metadata": {
        "id": "GeBQKcMJzLMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor(numpy_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYdI5C8Yy06F",
        "outputId": "16cb3abb-afd7-4ca7-dbdc-3939ea929204"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The returned tensor and ndarray share the same memory. Modifications to the tensor will be reflected in the ndarray and vice versa. The returned tensor is not resizable.\n",
        "\n",
        "It currently accepts ndarray with dtypes of numpy.float64, numpy.float32, numpy.float16, numpy.complex64, numpy.complex128, numpy.int64, numpy.int32, numpy.int16, numpy.int8, numpy.uint8, and bool."
      ],
      "metadata": {
        "id": "r1wxXQE5zFKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.from_numpy(numpy_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MWBa1SDy3ql",
        "outputId": "7d7adf7b-e3f5-46e4-9590-be13a5a4caf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pandas DataFrame to Tensor"
      ],
      "metadata": {
        "id": "mE04XBDQzOIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\"gender\":[\"male\",\"female\",\"male\"], \"scores\":[40, 50, 46]}\n",
        "df = pd.DataFrame(data)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "wor9TzPHy7dV",
        "outputId": "26c7f501-461e-4563-abd4-23e8329642ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   gender  scores\n",
              "0    male      40\n",
              "1  female      50\n",
              "2    male      46"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-37b2041d-8aef-4463-8a6b-84bc8f05b5ba\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>scores</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>male</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>female</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>male</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-37b2041d-8aef-4463-8a6b-84bc8f05b5ba')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-37b2041d-8aef-4463-8a6b-84bc8f05b5ba button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-37b2041d-8aef-4463-8a6b-84bc8f05b5ba');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-699fa80e-7c46-40c9-8454-6f6aaee86a50\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-699fa80e-7c46-40c9-8454-6f6aaee86a50')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-699fa80e-7c46-40c9-8454-6f6aaee86a50 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_c1ab1bce-4f6f-4e17-ae3d-61fab4f1967a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c1ab1bce-4f6f-4e17-ae3d-61fab4f1967a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"gender\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"female\",\n          \"male\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"scores\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 40,\n        \"max\": 50,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          40,\n          50\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kr0w0-4YzoLd",
        "outputId": "c433410b-0d81-4b0d-f4f9-b414116adb89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['male', 40],\n",
              "       ['female', 50],\n",
              "       ['male', 46]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  torch.tensor(df.values)\n",
        "except Exception as e:\n",
        "  print(\"CANT CONVERT OBJECTS\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0soIrAS0AK9",
        "outputId": "74ec0b8d-904c-405c-cb60-03875988e997"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CANT CONVERT OBJECTS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = pd.get_dummies(data=df, columns=[\"gender\"],dtype=float) # pd.get_dummies()-->Converts categorical variable into dummy/indicator variables."
      ],
      "metadata": {
        "id": "rFi6bsly0DaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor(c.values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qtp_Goe40YO2",
        "outputId": "24cbca46-e819-4313-bc1d-c108c69f959b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[40.,  0.,  1.],\n",
              "        [50.,  1.,  0.],\n",
              "        [46.,  0.,  1.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "wyx10FzC09M2",
        "outputId": "57a808d0-e01a-45ba-cb34-e0ec6e3bfab6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   gender  scores\n",
              "0    male      40\n",
              "1  female      50\n",
              "2    male      46"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6c1e3096-f4a4-47fc-be54-f0fc15bc30cb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>scores</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>male</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>female</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>male</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c1e3096-f4a4-47fc-be54-f0fc15bc30cb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6c1e3096-f4a4-47fc-be54-f0fc15bc30cb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6c1e3096-f4a4-47fc-be54-f0fc15bc30cb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2f670944-7731-433d-a737-98a58db380e4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2f670944-7731-433d-a737-98a58db380e4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2f670944-7731-433d-a737-98a58db380e4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_d835ea0f-2ccc-4611-9886-40372879a32d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d835ea0f-2ccc-4611-9886-40372879a32d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"gender\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"female\",\n          \"male\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"scores\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 40,\n        \"max\": 50,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          40,\n          50\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "df2= df.copy()\n",
        "df2[\"gender\"] = le.fit_transform(df['gender'])\n",
        "torch.tensor(df2.values), df #always use df.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1NGRt6V079s",
        "outputId": "edfc45ef-ee80-411f-bb06-3aa0af660882"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 1, 40],\n",
              "         [ 0, 50],\n",
              "         [ 1, 46]]),\n",
              "    gender  scores\n",
              " 0    male      40\n",
              " 1  female      50\n",
              " 2    male      46)"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### AUTOGRAD"
      ],
      "metadata": {
        "id": "K7Pz2iWu1d55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "q_1(z) = z^2\\\\\n",
        "q_2(z) = z^3\\\\\n",
        "q_3(z) = e^z\\\\\n",
        "p(z) = \\dfrac{q_1}{q_2} + q_3\\\\\n",
        "= \\dfrac{z^2}{z^3} + e^z = \\dfrac{1}{z} + e^z\\\\\n",
        "\\dfrac{\\partial p(z)}{\\partial z} = \\dfrac{-1}{z^2} + e^z\n",
        "$$\n",
        "\n",
        "## derivation along multiple path\n",
        "$\\dfrac{\\partial p(z)}{\\partial z} = \\dfrac{\\partial p}{\\partial q1}\\dfrac{\\partial q1}{\\partial z}+ \\dfrac{\\partial p}{\\partial q2}\\dfrac{\\partial q2}{\\partial z}+\\dfrac{\\partial p}{\\partial q3}\\dfrac{\\partial q3}{\\partial z}$\n",
        "\n",
        "= $(\\dfrac{1}{q_2}) * 2z + (\\dfrac{-q_1}{q_2^2}) * 3z^2 + (1) * e^z$\n",
        "\n",
        "= $\\dfrac{2}{z^2} - \\dfrac{3}{z^2} +  e^z$\n",
        "\n",
        "=  $\\dfrac{-1}{z^2} + e^z$"
      ],
      "metadata": {
        "id": "zVq-mYPp1h8R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensor.requires_grad <br>\n",
        "Is True if gradients need to be computed for this Tensor, False otherwi"
      ],
      "metadata": {
        "id": "CgWPlyiR19CT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.tensor(2.0, requires_grad=True)"
      ],
      "metadata": {
        "id": "ZcsflGyT0cS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q1 = z**2\n",
        "q1.retain_grad() #safer\n",
        "q2 = z**3\n",
        "q3 = torch.exp(z)\n",
        "p = (q1/q2) + q3\n",
        "p"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8wW5kQi103m",
        "outputId": "ba7026ca-0dcf-4c4d-b7a4-4096b949cfe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7.8891, grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Tensor.retains_grad<br>\n",
        "Is True if this Tensor is non-leaf and its grad is enabled to be populated during backward(), False otherwise.\n",
        "\n",
        "- Tensor.retain_grad <br>\n",
        "Enables this Tensor to have their grad populated during backward(). This is a no-op for leaf tensors."
      ],
      "metadata": {
        "id": "hjYKt-Uc2Soc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q1 = z**2\n",
        "q2 = z**3\n",
        "q3 = torch.exp(z)\n",
        "p = (q1/q2) + q3\n",
        "p.backward()"
      ],
      "metadata": {
        "id": "c6bKVMmJ2aY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch.tensor.backward() <br>\n",
        "Computes the gradient of current tensor wrt graph leaves.<br>\n",
        "\n",
        "The graph is differentiated using the chain rule. If the tensor is non-scalar (i.e. its data has more than one element) and requires gradient, the function additionally requires specifying a gradient. It should be a tensor of matching type and shape, that represents the gradient of the differentiated function w.r.t. self"
      ],
      "metadata": {
        "id": "2EZ_oL4H2z-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gdub_PvQ2meM",
        "outputId": "35af9f39-55a8-4387-f959-2ceedabce61e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7.1391)"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z.grad.zero_() #inplace function"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mxvR5Fy4Xi8",
        "outputId": "5282a225-5e9f-474b-edea-c3eb4afd30d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.)"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch.tensor.grad <br>\n",
        "This attribute is None by default and becomes a Tensor the first time a call to backward() computes gradients for self. The attribute will then contain the gradients computed and future calls to backward() will accumulate (add) gradients into it."
      ],
      "metadata": {
        "id": "JKlb8Z7R3IGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c =  torch.tensor(z**2, requires_grad=True)\n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsKuKnIt2-F2",
        "outputId": "59e8dee0-0109-45f7-b538-115a66ea08e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-113-f74cdb8b8e4a>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  c =  torch.tensor(z**2, requires_grad=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4., requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AU1TpJ7X3Plo",
        "outputId": "2aa16ef7-9f40-4756-a5ac-bc4507f44e94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "1/z + q3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zM0ByGCz3bFO",
        "outputId": "a5054682-815e-4aed-c7c2-801fe24c3451"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7.8891, grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = (q1/q2) + q3\n",
        "p.backward() #if you want you can do it again , but retain_graph = true, or define tensors from z --> p and then calculate again\n",
        "z.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u__TiLXk4esW",
        "outputId": "d56927be-e53c-4461-ae23-e91d4ba4bb2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7.1391)"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q1.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYXIcay34hMQ",
        "outputId": "b177952f-d416-4cdc-8662-afef55546b16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1250)"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q2.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cS7kGA755A5O",
        "outputId": "33c501a5-6b48-486b-bf9c-617287106067"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-122-0db897d12018>:1: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /pytorch/build/aten/src/ATen/core/TensorBody.h:489.)\n",
            "  q2.grad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzj-mI9k5CDm",
        "outputId": "cf031f17-710c-4006-f528-26d33084d827"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7.1391)"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install torchviz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFfmcezp5FGu",
        "outputId": "9f453254-9bdb-4130-cdd7-1278e297982a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchviz\n",
            "  Downloading torchviz-0.0.3-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from torchviz) (2.6.0+cu124)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from torchviz) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->torchviz)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->torchviz)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->torchviz)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->torchviz)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->torchviz)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->torchviz)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->torchviz)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->torchviz)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->torchviz)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->torchviz)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->torchviz) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->torchviz) (3.0.2)\n",
            "Downloading torchviz-0.0.3-py3-none-any.whl (5.7 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchviz\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torchviz-0.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchviz import make_dot\n",
        "make_dot(p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "iIpjKKqg5SQO",
        "outputId": "1c74ac37-1bf2-4390-f98c-6809d4d38b0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"277pt\" height=\"326pt\"\n viewBox=\"0.00 0.00 277.00 326.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 322)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-322 273,-322 273,4 -4,4\"/>\n<!-- 139788359270576 -->\n<g id=\"node1\" class=\"node\">\n<title>139788359270576</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"197.5,-31 143.5,-31 143.5,0 197.5,0 197.5,-31\"/>\n<text text-anchor=\"middle\" x=\"170.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n</g>\n<!-- 139788356085040 -->\n<g id=\"node2\" class=\"node\">\n<title>139788356085040</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"215,-86 126,-86 126,-67 215,-67 215,-86\"/>\n<text text-anchor=\"middle\" x=\"170.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n</g>\n<!-- 139788356085040&#45;&gt;139788359270576 -->\n<g id=\"edge9\" class=\"edge\">\n<title>139788356085040&#45;&gt;139788359270576</title>\n<path fill=\"none\" stroke=\"black\" d=\"M170.5,-66.79C170.5,-60.07 170.5,-50.4 170.5,-41.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"174,-41.19 170.5,-31.19 167,-41.19 174,-41.19\"/>\n</g>\n<!-- 139788356084896 -->\n<g id=\"node3\" class=\"node\">\n<title>139788356084896</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"162,-141 73,-141 73,-122 162,-122 162,-141\"/>\n<text text-anchor=\"middle\" x=\"117.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">DivBackward0</text>\n</g>\n<!-- 139788356084896&#45;&gt;139788356085040 -->\n<g id=\"edge1\" class=\"edge\">\n<title>139788356084896&#45;&gt;139788356085040</title>\n<path fill=\"none\" stroke=\"black\" d=\"M126.25,-121.75C133.97,-114.03 145.4,-102.6 154.72,-93.28\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"157.31,-95.64 161.91,-86.09 152.36,-90.69 157.31,-95.64\"/>\n</g>\n<!-- 139788356084992 -->\n<g id=\"node4\" class=\"node\">\n<title>139788356084992</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"89,-196 0,-196 0,-177 89,-177 89,-196\"/>\n<text text-anchor=\"middle\" x=\"44.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">PowBackward0</text>\n</g>\n<!-- 139788356084992&#45;&gt;139788356084896 -->\n<g id=\"edge2\" class=\"edge\">\n<title>139788356084992&#45;&gt;139788356084896</title>\n<path fill=\"none\" stroke=\"black\" d=\"M56.23,-176.98C67.23,-169 83.92,-156.88 97.1,-147.31\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"99.52,-149.88 105.56,-141.17 95.41,-144.21 99.52,-149.88\"/>\n</g>\n<!-- 139788356090608 -->\n<g id=\"node5\" class=\"node\">\n<title>139788356090608</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"202,-251 101,-251 101,-232 202,-232 202,-251\"/>\n<text text-anchor=\"middle\" x=\"151.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 139788356090608&#45;&gt;139788356084992 -->\n<g id=\"edge3\" class=\"edge\">\n<title>139788356090608&#45;&gt;139788356084992</title>\n<path fill=\"none\" stroke=\"black\" d=\"M134.31,-231.98C117.25,-223.54 90.87,-210.47 71.1,-200.68\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"72.52,-197.47 62,-196.17 69.41,-203.75 72.52,-197.47\"/>\n</g>\n<!-- 139788356078848 -->\n<g id=\"node7\" class=\"node\">\n<title>139788356078848</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"196,-196 107,-196 107,-177 196,-177 196,-196\"/>\n<text text-anchor=\"middle\" x=\"151.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">PowBackward0</text>\n</g>\n<!-- 139788356090608&#45;&gt;139788356078848 -->\n<g id=\"edge6\" class=\"edge\">\n<title>139788356090608&#45;&gt;139788356078848</title>\n<path fill=\"none\" stroke=\"black\" d=\"M151.5,-231.75C151.5,-224.8 151.5,-214.85 151.5,-206.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"155,-206.09 151.5,-196.09 148,-206.09 155,-206.09\"/>\n</g>\n<!-- 139788356084848 -->\n<g id=\"node8\" class=\"node\">\n<title>139788356084848</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"269,-141 180,-141 180,-122 269,-122 269,-141\"/>\n<text text-anchor=\"middle\" x=\"224.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">ExpBackward0</text>\n</g>\n<!-- 139788356090608&#45;&gt;139788356084848 -->\n<g id=\"edge8\" class=\"edge\">\n<title>139788356090608&#45;&gt;139788356084848</title>\n<path fill=\"none\" stroke=\"black\" d=\"M165.61,-231.95C177.58,-224.03 194.36,-211.19 204.5,-196 213.53,-182.48 218.67,-164.65 221.47,-151.33\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"224.94,-151.86 223.31,-141.39 218.05,-150.59 224.94,-151.86\"/>\n</g>\n<!-- 139788359170768 -->\n<g id=\"node6\" class=\"node\">\n<title>139788359170768</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"178.5,-318 124.5,-318 124.5,-287 178.5,-287 178.5,-318\"/>\n<text text-anchor=\"middle\" x=\"151.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n</g>\n<!-- 139788359170768&#45;&gt;139788356090608 -->\n<g id=\"edge4\" class=\"edge\">\n<title>139788359170768&#45;&gt;139788356090608</title>\n<path fill=\"none\" stroke=\"black\" d=\"M151.5,-286.92C151.5,-279.22 151.5,-269.69 151.5,-261.43\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"155,-261.25 151.5,-251.25 148,-261.25 155,-261.25\"/>\n</g>\n<!-- 139788356078848&#45;&gt;139788356084896 -->\n<g id=\"edge5\" class=\"edge\">\n<title>139788356078848&#45;&gt;139788356084896</title>\n<path fill=\"none\" stroke=\"black\" d=\"M145.89,-176.75C141.18,-169.42 134.33,-158.73 128.53,-149.7\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"131.36,-147.62 123.01,-141.09 125.46,-151.4 131.36,-147.62\"/>\n</g>\n<!-- 139788356084848&#45;&gt;139788356085040 -->\n<g id=\"edge7\" class=\"edge\">\n<title>139788356084848&#45;&gt;139788356085040</title>\n<path fill=\"none\" stroke=\"black\" d=\"M215.58,-121.75C207.72,-114.03 196.07,-102.6 186.58,-93.28\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"188.84,-90.6 179.25,-86.09 183.94,-95.59 188.84,-90.6\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x7f23034c6790>"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w1 = torch.tensor([[1., 1., 0.],[0., 1., 1.],[0., 1., 1.]], requires_grad=True)\n",
        "w2 = torch.tensor([[1., 1., 0.],[1., 1., 0.],[1., 1., 1.]], requires_grad=True)\n",
        "w3 = torch.tensor([[1., 1., 1.],[0., 0., 1.], [0., 0., 1.]], requires_grad=True)"
      ],
      "metadata": {
        "id": "LbubJrB1502x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w1.ndim, w2.ndim, w3.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wX_3sQl454wp",
        "outputId": "3e16b0ae-fb70-4e23-c3b8-ee7035c5a410"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 2, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor([[1.0, 0, 1]], requires_grad=False)\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxyoOzNg58IG",
        "outputId": "3265e6a3-0a8a-490e-b459-043f22cbbeca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a1 = torch.matmul(X,w1)"
      ],
      "metadata": {
        "id": "NxklcZHl5-7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpR4-vbV6C3O",
        "outputId": "d0a674a6-4387-47ac-f63e-d9bac2529f15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 1.]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h1 = torch.sigmoid(a1)\n",
        "a2 = torch.matmul(h1,w2)\n",
        "h2 = torch.sigmoid(a2)\n",
        "a3 = torch.matmul(h2,w3)\n",
        "y_pred = torch.softmax(a3, dim = 1)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPlW9IVG6EQ_",
        "outputId": "f90e9fe3-f625-453e-8150-3130ccd49ff3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1451, 0.1451, 0.7098]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.tensor([0,0,1.0], requires_grad=False)"
      ],
      "metadata": {
        "id": "_dInMqQp6Zj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = - torch.log(y_pred[0][2])"
      ],
      "metadata": {
        "id": "2EptHc1s6byv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0MdOXJk6eCp",
        "outputId": "c6cab5ea-9af2-445d-a235-534103198e38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.3428, grad_fn=<NegBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()"
      ],
      "metadata": {
        "id": "GfvDkaxY6e62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w1.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onrXXwxe6jam",
        "outputId": "7fd3f6c4-2e15-468b-d184-c02b0d36fdfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0046, -0.0024, -0.0171],\n",
              "        [-0.0000, -0.0000, -0.0000],\n",
              "        [-0.0046, -0.0024, -0.0171]])"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "make_dot(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XowJhAxD6ls-",
        "outputId": "6385b840-6a59-4adb-ac16-9e80bf52c82e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"302pt\" height=\"735pt\"\n viewBox=\"0.00 0.00 302.00 735.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 731)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-731 298,-731 298,4 -4,4\"/>\n<!-- 139788341823632 -->\n<g id=\"node1\" class=\"node\">\n<title>139788341823632</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"207.5,-31 153.5,-31 153.5,0 207.5,0 207.5,-31\"/>\n<text text-anchor=\"middle\" x=\"180.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n</g>\n<!-- 139788346501840 -->\n<g id=\"node2\" class=\"node\">\n<title>139788346501840</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"225,-86 136,-86 136,-67 225,-67 225,-86\"/>\n<text text-anchor=\"middle\" x=\"180.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">NegBackward0</text>\n</g>\n<!-- 139788346501840&#45;&gt;139788341823632 -->\n<g id=\"edge16\" class=\"edge\">\n<title>139788346501840&#45;&gt;139788341823632</title>\n<path fill=\"none\" stroke=\"black\" d=\"M180.5,-66.79C180.5,-60.07 180.5,-50.4 180.5,-41.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"184,-41.19 180.5,-31.19 177,-41.19 184,-41.19\"/>\n</g>\n<!-- 139788346497616 -->\n<g id=\"node3\" class=\"node\">\n<title>139788346497616</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"225,-141 136,-141 136,-122 225,-122 225,-141\"/>\n<text text-anchor=\"middle\" x=\"180.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">LogBackward0</text>\n</g>\n<!-- 139788346497616&#45;&gt;139788346501840 -->\n<g id=\"edge1\" class=\"edge\">\n<title>139788346497616&#45;&gt;139788346501840</title>\n<path fill=\"none\" stroke=\"black\" d=\"M180.5,-121.75C180.5,-114.8 180.5,-104.85 180.5,-96.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"184,-96.09 180.5,-86.09 177,-96.09 184,-96.09\"/>\n</g>\n<!-- 139788346503952 -->\n<g id=\"node4\" class=\"node\">\n<title>139788346503952</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"234,-196 127,-196 127,-177 234,-177 234,-196\"/>\n<text text-anchor=\"middle\" x=\"180.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">SelectBackward0</text>\n</g>\n<!-- 139788346503952&#45;&gt;139788346497616 -->\n<g id=\"edge2\" class=\"edge\">\n<title>139788346503952&#45;&gt;139788346497616</title>\n<path fill=\"none\" stroke=\"black\" d=\"M180.5,-176.75C180.5,-169.8 180.5,-159.85 180.5,-151.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"184,-151.09 180.5,-141.09 177,-151.09 184,-151.09\"/>\n</g>\n<!-- 139788346504000 -->\n<g id=\"node5\" class=\"node\">\n<title>139788346504000</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"234,-251 127,-251 127,-232 234,-232 234,-251\"/>\n<text text-anchor=\"middle\" x=\"180.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">SelectBackward0</text>\n</g>\n<!-- 139788346504000&#45;&gt;139788346503952 -->\n<g id=\"edge3\" class=\"edge\">\n<title>139788346504000&#45;&gt;139788346503952</title>\n<path fill=\"none\" stroke=\"black\" d=\"M180.5,-231.75C180.5,-224.8 180.5,-214.85 180.5,-206.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"184,-206.09 180.5,-196.09 177,-206.09 184,-206.09\"/>\n</g>\n<!-- 139788346498336 -->\n<g id=\"node6\" class=\"node\">\n<title>139788346498336</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"237,-306 124,-306 124,-287 237,-287 237,-306\"/>\n<text text-anchor=\"middle\" x=\"180.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\">SoftmaxBackward0</text>\n</g>\n<!-- 139788346498336&#45;&gt;139788346504000 -->\n<g id=\"edge4\" class=\"edge\">\n<title>139788346498336&#45;&gt;139788346504000</title>\n<path fill=\"none\" stroke=\"black\" d=\"M180.5,-286.75C180.5,-279.8 180.5,-269.85 180.5,-261.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"184,-261.09 180.5,-251.09 177,-261.09 184,-261.09\"/>\n</g>\n<!-- 139788346503232 -->\n<g id=\"node7\" class=\"node\">\n<title>139788346503232</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"222,-361 139,-361 139,-342 222,-342 222,-361\"/>\n<text text-anchor=\"middle\" x=\"180.5\" y=\"-349\" font-family=\"monospace\" font-size=\"10.00\">MmBackward0</text>\n</g>\n<!-- 139788346503232&#45;&gt;139788346498336 -->\n<g id=\"edge5\" class=\"edge\">\n<title>139788346503232&#45;&gt;139788346498336</title>\n<path fill=\"none\" stroke=\"black\" d=\"M180.5,-341.75C180.5,-334.8 180.5,-324.85 180.5,-316.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"184,-316.09 180.5,-306.09 177,-316.09 184,-316.09\"/>\n</g>\n<!-- 139788346501936 -->\n<g id=\"node8\" class=\"node\">\n<title>139788346501936</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"175,-416 62,-416 62,-397 175,-397 175,-416\"/>\n<text text-anchor=\"middle\" x=\"118.5\" y=\"-404\" font-family=\"monospace\" font-size=\"10.00\">SigmoidBackward0</text>\n</g>\n<!-- 139788346501936&#45;&gt;139788346503232 -->\n<g id=\"edge6\" class=\"edge\">\n<title>139788346501936&#45;&gt;139788346503232</title>\n<path fill=\"none\" stroke=\"black\" d=\"M128.46,-396.98C137.63,-389.15 151.44,-377.34 162.53,-367.86\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"165.03,-370.33 170.36,-361.17 160.48,-365.01 165.03,-370.33\"/>\n</g>\n<!-- 139788346497904 -->\n<g id=\"node9\" class=\"node\">\n<title>139788346497904</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"160,-477 77,-477 77,-458 160,-458 160,-477\"/>\n<text text-anchor=\"middle\" x=\"118.5\" y=\"-465\" font-family=\"monospace\" font-size=\"10.00\">MmBackward0</text>\n</g>\n<!-- 139788346497904&#45;&gt;139788346501936 -->\n<g id=\"edge7\" class=\"edge\">\n<title>139788346497904&#45;&gt;139788346501936</title>\n<path fill=\"none\" stroke=\"black\" d=\"M118.5,-457.79C118.5,-449.6 118.5,-437.06 118.5,-426.55\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"122,-426.24 118.5,-416.24 115,-426.24 122,-426.24\"/>\n</g>\n<!-- 139788346500784 -->\n<g id=\"node10\" class=\"node\">\n<title>139788346500784</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"113,-538 0,-538 0,-519 113,-519 113,-538\"/>\n<text text-anchor=\"middle\" x=\"56.5\" y=\"-526\" font-family=\"monospace\" font-size=\"10.00\">SigmoidBackward0</text>\n</g>\n<!-- 139788346500784&#45;&gt;139788346497904 -->\n<g id=\"edge8\" class=\"edge\">\n<title>139788346500784&#45;&gt;139788346497904</title>\n<path fill=\"none\" stroke=\"black\" d=\"M65.65,-518.79C75.17,-509.73 90.3,-495.34 101.93,-484.27\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"104.48,-486.67 109.31,-477.24 99.66,-481.6 104.48,-486.67\"/>\n</g>\n<!-- 139788346500880 -->\n<g id=\"node11\" class=\"node\">\n<title>139788346500880</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"98,-599 15,-599 15,-580 98,-580 98,-599\"/>\n<text text-anchor=\"middle\" x=\"56.5\" y=\"-587\" font-family=\"monospace\" font-size=\"10.00\">MmBackward0</text>\n</g>\n<!-- 139788346500880&#45;&gt;139788346500784 -->\n<g id=\"edge9\" class=\"edge\">\n<title>139788346500880&#45;&gt;139788346500784</title>\n<path fill=\"none\" stroke=\"black\" d=\"M56.5,-579.79C56.5,-571.6 56.5,-559.06 56.5,-548.55\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"60,-548.24 56.5,-538.24 53,-548.24 60,-548.24\"/>\n</g>\n<!-- 139788346494064 -->\n<g id=\"node12\" class=\"node\">\n<title>139788346494064</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"107,-660 6,-660 6,-641 107,-641 107,-660\"/>\n<text text-anchor=\"middle\" x=\"56.5\" y=\"-648\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 139788346494064&#45;&gt;139788346500880 -->\n<g id=\"edge10\" class=\"edge\">\n<title>139788346494064&#45;&gt;139788346500880</title>\n<path fill=\"none\" stroke=\"black\" d=\"M56.5,-640.79C56.5,-632.6 56.5,-620.06 56.5,-609.55\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"60,-609.24 56.5,-599.24 53,-609.24 60,-609.24\"/>\n</g>\n<!-- 139788363686704 -->\n<g id=\"node13\" class=\"node\">\n<title>139788363686704</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"86,-727 27,-727 27,-696 86,-696 86,-727\"/>\n<text text-anchor=\"middle\" x=\"56.5\" y=\"-703\" font-family=\"monospace\" font-size=\"10.00\"> (3, 3)</text>\n</g>\n<!-- 139788363686704&#45;&gt;139788346494064 -->\n<g id=\"edge11\" class=\"edge\">\n<title>139788363686704&#45;&gt;139788346494064</title>\n<path fill=\"none\" stroke=\"black\" d=\"M56.5,-695.92C56.5,-688.22 56.5,-678.69 56.5,-670.43\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"60,-670.25 56.5,-660.25 53,-670.25 60,-670.25\"/>\n</g>\n<!-- 139788346502080 -->\n<g id=\"node14\" class=\"node\">\n<title>139788346502080</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"232,-538 131,-538 131,-519 232,-519 232,-538\"/>\n<text text-anchor=\"middle\" x=\"181.5\" y=\"-526\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 139788346502080&#45;&gt;139788346497904 -->\n<g id=\"edge12\" class=\"edge\">\n<title>139788346502080&#45;&gt;139788346497904</title>\n<path fill=\"none\" stroke=\"black\" d=\"M172.2,-518.79C162.53,-509.73 147.16,-495.34 135.34,-484.27\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"137.53,-481.52 127.83,-477.24 132.74,-486.63 137.53,-481.52\"/>\n</g>\n<!-- 139788547283024 -->\n<g id=\"node15\" class=\"node\">\n<title>139788547283024</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"211,-605 152,-605 152,-574 211,-574 211,-605\"/>\n<text text-anchor=\"middle\" x=\"181.5\" y=\"-581\" font-family=\"monospace\" font-size=\"10.00\"> (3, 3)</text>\n</g>\n<!-- 139788547283024&#45;&gt;139788346502080 -->\n<g id=\"edge13\" class=\"edge\">\n<title>139788547283024&#45;&gt;139788346502080</title>\n<path fill=\"none\" stroke=\"black\" d=\"M181.5,-573.92C181.5,-566.22 181.5,-556.69 181.5,-548.43\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"185,-548.25 181.5,-538.25 178,-548.25 185,-548.25\"/>\n</g>\n<!-- 139788346502032 -->\n<g id=\"node16\" class=\"node\">\n<title>139788346502032</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"294,-416 193,-416 193,-397 294,-397 294,-416\"/>\n<text text-anchor=\"middle\" x=\"243.5\" y=\"-404\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 139788346502032&#45;&gt;139788346503232 -->\n<g id=\"edge14\" class=\"edge\">\n<title>139788346502032&#45;&gt;139788346503232</title>\n<path fill=\"none\" stroke=\"black\" d=\"M233.38,-396.98C224.06,-389.15 210.03,-377.34 198.76,-367.86\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"200.71,-364.93 190.81,-361.17 196.21,-370.29 200.71,-364.93\"/>\n</g>\n<!-- 139788355889744 -->\n<g id=\"node17\" class=\"node\">\n<title>139788355889744</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"273,-483 214,-483 214,-452 273,-452 273,-483\"/>\n<text text-anchor=\"middle\" x=\"243.5\" y=\"-459\" font-family=\"monospace\" font-size=\"10.00\"> (3, 3)</text>\n</g>\n<!-- 139788355889744&#45;&gt;139788346502032 -->\n<g id=\"edge15\" class=\"edge\">\n<title>139788355889744&#45;&gt;139788346502032</title>\n<path fill=\"none\" stroke=\"black\" d=\"M243.5,-451.92C243.5,-444.22 243.5,-434.69 243.5,-426.43\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"247,-426.25 243.5,-416.25 240,-426.25 247,-426.25\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x7f230273f810>"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w1.is_leaf, w2.is_leaf, w3.is_leaf, X.is_leaf, a1.is_leaf, a2.is_leaf, a3.is_leaf, y_pred.is_leaf, y.is_leaf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JF1psvg36olu",
        "outputId": "b1ab49ad-6b2c-409b-a055-269a653f7124"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, True, True, True, False, False, False, False, True)"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ANN\n",
        "\n",
        "- Training Pipeline\n",
        "  - Define Model\n",
        "  - for epoch in range(epochs):\n",
        "    - Forward pass\n",
        "    - Loss calculation\n",
        "    - Backward pass\n",
        "    - Parameters update\n",
        "- Model Evaluation\n",
        "- Improve Training Pipeline using nn.Module and torch.optim\n",
        "  - nn.Linear\n",
        "  - Activation Functions(nn.ReLU, nn.Sigmoid,  nn.Softmax)\n",
        "  - nn.Sequential Container\n",
        "  - Loss Functions (nn.BCELoss, nn.CrossEntropyLoss etc.)\n",
        "     \n",
        "- torch.optim (SGD,ADAM etc)"
      ],
      "metadata": {
        "id": "i327ML2P69Iu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from sklearn.datasets import load_diabetes\n",
        "import torch\n",
        "\n",
        "X , y = load_diabetes(return_X_y=True)\n",
        "print(f\"Shapes:{X.shape}, {y.shape}\")\n",
        "print(f\"X.head: \\n {X[:5]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1d5P-4O62n3",
        "outputId": "48f87827-7fe2-4798-a13f-5b86fb9ddc6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes:(442, 10), (442,)\n",
            "X.head: \n",
            " [[ 0.03807591  0.05068012  0.06169621  0.02187239 -0.0442235  -0.03482076\n",
            "  -0.04340085 -0.00259226  0.01990749 -0.01764613]\n",
            " [-0.00188202 -0.04464164 -0.05147406 -0.02632753 -0.00844872 -0.01916334\n",
            "   0.07441156 -0.03949338 -0.06833155 -0.09220405]\n",
            " [ 0.08529891  0.05068012  0.04445121 -0.00567042 -0.04559945 -0.03419447\n",
            "  -0.03235593 -0.00259226  0.00286131 -0.02593034]\n",
            " [-0.08906294 -0.04464164 -0.01159501 -0.03665608  0.01219057  0.02499059\n",
            "  -0.03603757  0.03430886  0.02268774 -0.00936191]\n",
            " [ 0.00538306 -0.04464164 -0.03638469  0.02187239  0.00393485  0.01559614\n",
            "   0.00814208 -0.00259226 -0.03198764 -0.04664087]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train__, X_test__, y_train__, y_test__ = train_test_split(X,y, test_size=0.2, random_state=20)"
      ],
      "metadata": {
        "id": "KBlm4qi8_VN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = torch.tensor(X_train__, dtype= torch.float32)\n",
        "X_test = torch.tensor(X_test__, dtype= torch.float32)\n",
        "y_train = torch.tensor(y_train__, dtype= torch.float32)\n",
        "y_test = torch.tensor(y_test__, dtype= torch.float32)"
      ],
      "metadata": {
        "id": "qJxjqxXr_Xgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Information about Tensors: \\n X_train: {X_train.shape},\\n y_train: {y_train.shape},\\n X_test: {X_test.shape},\\n y_test: {y_test.shape},\\n X.dtype: {X_train.dtype}, y.dtype: {y_train.dtype}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xSrb0dCAFqg",
        "outputId": "0c698eaa-3f0c-44cf-e93e-ad19657676c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Information about Tensors: \n",
            " X_train: torch.Size([353, 10]),\n",
            " y_train: torch.Size([353]),\n",
            " X_test: torch.Size([89, 10]),\n",
            " y_test: torch.Size([89]),\n",
            " X.dtype: torch.float32, y.dtype: torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### MODEL Class\n",
        "- Use module class\n",
        "- create layers\n",
        "- def forward\n",
        "- model.train() to ready parameters for tranining\n",
        "- train model\n",
        " - define a loss function\n",
        " - set epochs\n",
        " - get pred\n",
        " - get loss, print it\n",
        " - make the optimizer zero_grad\n",
        " - loss,backward\n",
        " - optimizer.step --> (update weights)"
      ],
      "metadata": {
        "id": "oBPPVUi2AqRG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class myModel(torch.nn.Module):\n",
        "  def __init__(self, in_features):\n",
        "    super().__init__()\n",
        "    self.network = torch.nn.Sequential(\n",
        "        torch.nn.Linear(in_features=in_features, out_features=8),\n",
        "        torch.nn.Sigmoid(),\n",
        "        torch.nn.Linear(in_features=8, out_features=8),\n",
        "        torch.nn.Sigmoid(),\n",
        "        torch.nn.Linear(in_features=8, out_features=1)\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    return self.network(x)"
      ],
      "metadata": {
        "id": "_oExnqK6AQun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "model = myModel(X_train.shape[1])\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "loss_fn = torch.nn.functional.mse_loss\n",
        "\n",
        "EPOCHS = 20\n",
        "for epoch in range(EPOCHS):\n",
        "  model.train()\n",
        "  y_pred = model.forward(X_train)\n",
        "  loss = loss_fn(y_pred.squeeze(), y_train)\n",
        "  print(f\"Loss: {loss}\")\n",
        "  optimizer.zero_grad()\n",
        "  #-----------\n",
        "      # make gradients zero\n",
        "  # model.zero_grad()\n",
        "  #--------------\n",
        "  loss.backward()\n",
        "  #--------\n",
        "  optimizer.step()\n",
        "  #----------------\n",
        "  # with torch.no_grad(): # gradient tracking is off\n",
        "  #   for param in model.parameters():\n",
        "  #     param.data -= learning_rate * param.grad\n",
        "  #-----------------------"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pLofyMvCRU3",
        "outputId": "a7e50b6a-3e30-448f-f739-738ac584eb8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 29737.88671875\n",
            "Loss: 27117.708984375\n",
            "Loss: 22267.203125\n",
            "Loss: 17253.533203125\n",
            "Loss: 13552.642578125\n",
            "Loss: 11046.998046875\n",
            "Loss: 9359.0048828125\n",
            "Loss: 8223.3720703125\n",
            "Loss: 7459.619140625\n",
            "Loss: 6946.03125\n",
            "Loss: 6600.685546875\n",
            "Loss: 6368.474609375\n",
            "Loss: 6212.337890625\n",
            "Loss: 6107.35205078125\n",
            "Loss: 6036.7607421875\n",
            "Loss: 5989.29443359375\n",
            "Loss: 5957.37841796875\n",
            "Loss: 5935.9169921875\n",
            "Loss: 5921.4853515625\n",
            "Loss: 5911.78076171875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"y_pred:\", y_pred.shape)\n",
        "print(\"y_train:\", y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4V_gCefCWm4",
        "outputId": "78585c4f-d0c8-4608-bd0a-680bb64cc48d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_pred: torch.Size([353, 1])\n",
            "y_train: torch.Size([353])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dropouts and Batch Normalization"
      ],
      "metadata": {
        "id": "eUFYWZeVL9Mt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "1FJuzISbQ7TM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NormalizationAndDropout(torch.nn.Module):\n",
        "  def __init__(self, in_features):\n",
        "    super().__init__()\n",
        "\n",
        "    self.network = nn.Sequential(\n",
        "        nn.Linear(in_features=in_features, out_features=8),\n",
        "        nn.BatchNorm1d(8),\n",
        "        nn.Sigmoid(),\n",
        "        nn.Dropout(0.3),\n",
        "        nn.Linear(in_features=8, out_features=8),\n",
        "        nn.BatchNorm1d(8),\n",
        "        nn.Sigmoid(),\n",
        "        nn.Dropout(0.4),\n",
        "        nn.Linear(in_features=8, out_features=1))\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.network(x)\n",
        "\n",
        "torch.manual_seed(42)\n",
        "model1 = NormalizationAndDropout(X_train.shape[1])\n",
        "optimizer = torch.optim.SGD(model1.parameters(), lr=0.01)\n"
      ],
      "metadata": {
        "id": "cdHPYCs8EJIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 30\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "model1.train()\n",
        "for epoch in range(epochs):\n",
        "  y_pred = model1.forward(X_train)\n",
        "  loss = loss_fn(y_train, y_pred.squeeze())\n",
        "  print(loss)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCvkKn3RMsbJ",
        "outputId": "1393f8b4-4637-4a20-a76d-584c4ebb05c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(29756.5078, grad_fn=<MseLossBackward0>)\n",
            "tensor(27017.7793, grad_fn=<MseLossBackward0>)\n",
            "tensor(23280.1016, grad_fn=<MseLossBackward0>)\n",
            "tensor(18266.6875, grad_fn=<MseLossBackward0>)\n",
            "tensor(14411.6006, grad_fn=<MseLossBackward0>)\n",
            "tensor(11875.5879, grad_fn=<MseLossBackward0>)\n",
            "tensor(10283.5088, grad_fn=<MseLossBackward0>)\n",
            "tensor(9155.9434, grad_fn=<MseLossBackward0>)\n",
            "tensor(8844.9346, grad_fn=<MseLossBackward0>)\n",
            "tensor(8379.2334, grad_fn=<MseLossBackward0>)\n",
            "tensor(7723.3384, grad_fn=<MseLossBackward0>)\n",
            "tensor(7082.4502, grad_fn=<MseLossBackward0>)\n",
            "tensor(7076.6616, grad_fn=<MseLossBackward0>)\n",
            "tensor(6922.3784, grad_fn=<MseLossBackward0>)\n",
            "tensor(6579.4092, grad_fn=<MseLossBackward0>)\n",
            "tensor(6202.2876, grad_fn=<MseLossBackward0>)\n",
            "tensor(6102.1870, grad_fn=<MseLossBackward0>)\n",
            "tensor(6138.5396, grad_fn=<MseLossBackward0>)\n",
            "tensor(5798.8872, grad_fn=<MseLossBackward0>)\n",
            "tensor(5380.3931, grad_fn=<MseLossBackward0>)\n",
            "tensor(5470.5146, grad_fn=<MseLossBackward0>)\n",
            "tensor(5606.7910, grad_fn=<MseLossBackward0>)\n",
            "tensor(5765.5747, grad_fn=<MseLossBackward0>)\n",
            "tensor(5593.9414, grad_fn=<MseLossBackward0>)\n",
            "tensor(5786.2656, grad_fn=<MseLossBackward0>)\n",
            "tensor(5346.6284, grad_fn=<MseLossBackward0>)\n",
            "tensor(5416.0596, grad_fn=<MseLossBackward0>)\n",
            "tensor(5189.8740, grad_fn=<MseLossBackward0>)\n",
            "tensor(5229.3433, grad_fn=<MseLossBackward0>)\n",
            "tensor(5846.2817, grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EErB8juKNEcZ",
        "outputId": "cd8f29d3-2f58-429e-91f4-e5faae1725a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NormalizationAndDropout(\n",
              "  (network): Sequential(\n",
              "    (0): Linear(in_features=10, out_features=8, bias=True)\n",
              "    (1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): Sigmoid()\n",
              "    (3): Dropout(p=0.3, inplace=False)\n",
              "    (4): Linear(in_features=8, out_features=8, bias=True)\n",
              "    (5): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): Sigmoid()\n",
              "    (7): Dropout(p=0.4, inplace=False)\n",
              "    (8): Linear(in_features=8, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Minibatch Gradient Descent"
      ],
      "metadata": {
        "id": "RUExkvjoYa3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "metadata": {
        "id": "39iE6ajpQKgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=10, shuffle=True)\n",
        "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=10, shuffle=False)"
      ],
      "metadata": {
        "id": "XKeLba73YnmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for features, labels in train_loader: #for batchnorm always need more than one input in a batch\n",
        "  print(features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiP5GgpNYtj6",
        "outputId": "362e84d7-b19b-47bd-83f4-90556ec3de9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 10])\n",
            "torch.Size([10, 10])\n",
            "torch.Size([10, 10])\n",
            "torch.Size([10, 10])\n",
            "torch.Size([10, 10])\n",
            "torch.Size([10, 10])\n",
            "torch.Size([10, 10])\n",
            "torch.Size([10, 10])\n",
            "torch.Size([10, 10])\n",
            "torch.Size([10, 10])\n",
            "torch.Size([10, 10])\n",
            "torch.Size([10, 10])\n",
            "torch.Size([10, 10])\n",
            "torch.Size([10, 10])\n",
            "torch.Size([10, 10])\n",
            "torch.Size([10, 10])\n",
            "torch.Size([10, 10])\n",
            "torch.Size([10, 10])\n",
            "torch.Size([10, 10])\n",
            "torch.Size([10, 10])\n",
            "torch.Size([10, 10])\n",
            "torch.Size([10, 10])\n",
            "torch.Size([10, 10])\n",
            "torch.Size([10, 10])\n",
            "torch.Size([10, 10])\n",
            "torch.Size([10, 10])\n",
            "torch.Size([10, 10])\n",
            "torch.Size([10, 10])\n",
            "torch.Size([10, 10])\n",
            "torch.Size([10, 10])\n",
            "torch.Size([10, 10])\n",
            "torch.Size([10, 10])\n",
            "torch.Size([10, 10])\n",
            "torch.Size([10, 10])\n",
            "torch.Size([10, 10])\n",
            "torch.Size([3, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "model2 = NormalizationAndDropout(X_train.shape[1])\n",
        "optimizer = torch.optim.SGD(model2.parameters(), lr=0.01)\n",
        "loss_fn = torch.nn.MSELoss()"
      ],
      "metadata": {
        "id": "lehOvbSKY-Oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#del(loss)"
      ],
      "metadata": {
        "id": "ekr9MZBKZoTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "model2.train()\n",
        "for epoch in range(epochs):\n",
        "  loss_per_epoch = 0\n",
        "  for features, labels in train_loader:\n",
        "    y_pred = model2.forward(features)\n",
        "    loss = loss_fn(labels, y_pred.squeeze())\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    loss_per_epoch += loss\n",
        "  print(\"avg loss per epoch =\", loss_per_epoch/X_train.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-toVCbtZIU6",
        "outputId": "6a9f2d30-f940-43d0-ac66-31170867ede4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg loss per epoch = tensor(540.1666, grad_fn=<DivBackward0>)\n",
            "avg loss per epoch = tensor(586.5269, grad_fn=<DivBackward0>)\n",
            "avg loss per epoch = tensor(608.5913, grad_fn=<DivBackward0>)\n",
            "avg loss per epoch = tensor(602.3675, grad_fn=<DivBackward0>)\n",
            "avg loss per epoch = tensor(566.4669, grad_fn=<DivBackward0>)\n",
            "avg loss per epoch = tensor(591.8240, grad_fn=<DivBackward0>)\n",
            "avg loss per epoch = tensor(542.8103, grad_fn=<DivBackward0>)\n",
            "avg loss per epoch = tensor(540.6816, grad_fn=<DivBackward0>)\n",
            "avg loss per epoch = tensor(550.0402, grad_fn=<DivBackward0>)\n",
            "avg loss per epoch = tensor(540.0875, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Day 3 Workshop"
      ],
      "metadata": {
        "id": "8oqqUNuibPGh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset : [Dataset From Kaggle](https://www.google.com/url?q=https%3A%2F%2Fwww.kaggle.com%2Fdatasets%2Farjuntejaswi%2Fplant-village)"
      ],
      "metadata": {
        "id": "4ffSND3PbVEO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Loading Basics"
      ],
      "metadata": {
        "id": "GneYb5aTfDeJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle"
      ],
      "metadata": {
        "id": "c2ADrayTbUm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Upload kaggle.json (from your Kaggle account > Account > Create New API Token)\n",
        "#DO THE ABOVE BEFORE RUNNIN CELL\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "4do3KRaBcfte",
        "outputId": "02397ae8-4b7b-4c37-fc1b-9d497d40e2e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fd35d212-643b-4641-ba5e-096fc5612210\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fd35d212-643b-4641-ba5e-096fc5612210\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d arjuntejaswi/plant-village\n",
        "!unzip -q plant-village.zip -d /content/plant_village"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6zmpBHBZyzS",
        "outputId": "8125d5c8-b39d-4692-b49a-f8f709d3b6aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/arjuntejaswi/plant-village\n",
            "License(s): unknown\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Dataset , random_split"
      ],
      "metadata": {
        "id": "tw1l1ehTczzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "base_path = \"/content/plant_village/PlantVillage\"\n",
        "target_path = \"/content/potato_dataset\"\n",
        "\n",
        "os.makedirs(target_path, exist_ok=True)\n",
        "\n",
        "for folder in [\"Potato___healthy\", \"Potato___Late_blight\", \"Potato___Early_blight\"]:\n",
        "    shutil.copytree(os.path.join(base_path, folder), os.path.join(target_path, folder))"
      ],
      "metadata": {
        "id": "AdoBz2lhczup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "potato_dataset = datasets.ImageFolder(root=target_path, transform = None) # get Image() class , we need a tensor, so transform=ToTensor()"
      ],
      "metadata": {
        "id": "A_hX3CfbmcA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "potato_dataset.classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ne-vfO63ZVVV",
        "outputId": "685f1dd2-7746-4b10-c9bc-a58d6bc4d2da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = potato_dataset[0]"
      ],
      "metadata": {
        "id": "Cd4glfY7ZVSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "SrIu05mIZbXy",
        "outputId": "4dfc052f-622d-433e-aae8-4e6b7a1bb31b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=256x256>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAAEACAIAAADTED8xAAEAAElEQVR4AWz9d5hk21Uf/FdVV3dXp+qcc5yc7ty5OSdd5YRABkSwDS/YGJsHjP3axjw4YjBgsowxkgBJSEJZutLNOc3cyamnc865urs69+9z6kj35Y/feXrOnNpnx7W/a+211157n+i//7e/2dXVlUqlNjc319fX8/Pzd3d3Ozo6rl27VlxcnJubOzIyUlVVVVZW5nlgYCAvLy+dTmdlZRUWFu7t7a2urnoWU4T+/v7t7W3R4vG4TKLRaFNTU1Y0evPmzUQi0draOjw87OHkyZOiXbp0SVbj4+MNDQ1ra2sHDx4sKip68803I5F9GZaUlNy4ceNHfuRHzp07Nzc3pyyRFxYW1HNlZaW9vT0nJ0dxkuzs7LS0tKi5EAkVvby8HIlE5KBuo6Oj9fX1wgU+8sgj3/nOd5aWlg8fPtzT06NupaWl4tx9992vvvqqIlRYQ+T59ttvHzp0SEGJ3PzxydmCgkK1ys7JypBoRZ0fePD+ycnxZDLpftdddwmPxWIqXFpeMjE5Wl1btbSwvL+/v725PT8/39l2QLbxWLa2PPrI40tLS2olpKKqfGxiNpGoyC9Izs1PNjfXLy3OKWV+dkGPTIxMirO5kZ6fn15Zmi9K5pZVFNU3Nm5vxXb3Io+958lvfvObm1u7MzMzxSVlqLqzta2ZyaKCmZmpU8eOLy0tTo+PVVRVbu9H1zc2RFATldRNKoA++g6J+vr6qqurvc3OzkY6bdfdW1tbXo2NjSG4XtOhGohWSC0HbwsKCpQlQ6nCHkc6cWQrRNdvbGzU1dW5SyJbkQV6VuhKalkceQqUShJ5ukQW04NAD2GGkLa/F/EzrF5YbVmhrazcvXIJUQ0ZaggYAINKZnKNhVVSnEB5uoRIKIlLJjFpoEoCjdejYVWmpqZQqqamxk/Q9FYxOl4aHCIQnpBek0TTTx7AURltbW1yl488BQ4ODiKoImQ1NDQEi+LI57XXXpPD9PR0ZWXlPffco04TExPPP/+83FAcvtVMWd3d3ah89OhRWNQf3gpEWR0g/9raWj1UUVHR3Nz86KOPKkU4QkguZtgW5BAeMrAKCPzoRz+qLe9///tB/+LFiz/1Uz/17LPPqtji4iJkKPf8+fM6+/r166LdfvvtyNLY2CAfDNPT03369BkMDB+5uXmKvu++B3p7e1VSWxB3eHCkrbUznpVbUlyeLCqtrKw+euTk7Mz80uKKv5LiMpmjm6w0Wdc31NatrS5VlCeb6mt2t9fT6eWqsmRZSd7oYG9hYTw/L766slCSLPixH/1YXW11PBbd3dxaXlbTxb/+zF8BR252nPgoLUkuLSwikRzVZG97T7u0ZWp6dnJiWvjk5KS7tsMBaaI3VUCvaZrkiKbV6EkM6XfPIVJJBLwhFTroU9Gg0Ct003cie4YE4cpVGQygdzyjlbQArS/kJu27l7cykUpM8YHBJSt3gaLJU/WkdRdHCFi70FZuYSlhESELiSOJaCJ4llBu0oqj2q4wYaacgCv8lBCGXUSq5+if/fFfhB2PFsqQBSLKC84kcGmt7NQPLdTeT90PVWrjEi4Xd+1RngZLIj4cQ6cIK0tLCoMV4WTtiy++qMYy0Qc6UhK11xOzs7OErq4i4oWArDzVW1bGDRIRTbGTENVQSvjKSPWVr3zl9OnTcpAVGXzgwAGN9Kwh2EBv4RwN9KzaeAa1VUzpr7zyym233aZEz97qNuhUsePHjyMivvX82KNPjE9NV1ZUGw/3I7vp9NpHPvKRW7durqfXVAxXw5NApcOBZkqSWl1X+trqKjKq84GugxfPn0fP9tY27PTOO++oDLbf2dk+cuSIytzq7q+vr43sb+bkRqZnJtpaGtXZAEJ6trd1dF/vrq6pXFpYaGisqa6pmJyaHp2Ya2nt2NzcXk1vjI5NZGXnYEV0vuOOOxS3uryiDpMTY/X1dUvzC9mJXLgmeMEdVfWRu5rrDmQpLy9HE/DSI5qs/iijN3GLZ9HCTkdJ1A4RFnY06IRIAAN56g5NRgFpZSWyvpazcKnkL6uQGfzML8jz0ys0cYWlyNYrgZK7/JR/mCoWzdI1LpGV5f4Pf4oc8EemCE0Lr7BcOQgX309ZeVBJl8B3yxIY/b3f+UPlEYFaRVdBPsTyTKQJJwP0hxBAkZicQLuwuu6q4q7BSCYvMEJH2JVEf1y4cAGsK8rKxDHog4t8dL9meFY/3QZtMIHu0E/oZjgqUJz05RtvvKEsoMEzjz32mNKpEKiMAcBOUzX+wQcfxB4u5A6bqrek1Uh1EKjlLrUK1SRJDh06TGaHLVVJabE6RF6+fFnN1dB48qd/+qeGHSXm5xXWNjS+/PLL6ENxOnfubTVsamrQ8epw+vbbipMlQ8OD2vLZz/7VRz/68YnxyY3N3WPHTlSUlc/OTWt+0CU7u9XVlSNDw2CRX5B4/PHHr1y5Mjg4oO03r1+traqMxfZ2dtPZOZHJiaHa2koj9GpqPScn79vf+l5qKSA+5tne3nrs8UeWlpePnDg9O79cW9d47frNWHbO3n50YmIyr6AgFosjbLKgUHfEovvA3VBbu7O/pxIEqS5AH6RAmRCLulL3aTtCIYu6GfeMw1qKdUNgaRcihHiSuYRaI3/NxyGSqJu3svJWzi7Ywga6ScywRxQa5u9Bbjm52QFNMjqMEPFdqqcsWYnpEs1P4Urc3NhSHECK46dCQ0DLQf7uChXZXQRJwhzebazA8FKWhMLDV2GhXkW/+uVvAoFKa5IYShIDPiAGgYyJsnZHULwhFyhBAlUJk3grUEYkihxAFvkkVGmUxRgYQFrsFEod4wxiIRkcq6v2SCuylhDPQnJysnELPYFYve+++7AHwd/Y2EhxIu/Fp2XpJ0CUg3zQmuTGUSF8VVL15CYanKkDKGOwABANDVo3NTWNH6SiJxg6wvgoaOigcel+aZV469Ytup+6LSyt4BMFIQLQC9R2P9Xw8OGDg4PDjY2B+lReUZYsKh4ZGWtq7BwcENiYkxs36mD4nu6blNvSYvVNvv7GqxUV5RWlZVvbG9ijvCyZF48UFcS3dlLTM6OjI70NjfV6amxsYmF2ZWR4cmx0qra2YWVxhXDB2P/sl35pNxK/0d1TW9e0ub3T0NS8vLI6Mj7R1t6ZSq2qRk52Qilrq8EoCp1InVeQP7ewoGeRSK+Hcg01hITU0y7NRBAR1BaJ0McrNAFEOXjwVubhg+Z7kFxH6zhsI0RxIfg8y0HRJJFnHQpO4T1E6t5+wIcu8V3hs+Ty9CxbzwGf5OR4kMP6WqBlCHGJLzdVkqHchLgLDCPIQYi3MhHNPQwPSwlDwvz/Yfzo//hvvycZsQc3gKVIhNB+PzXbK1URKL3uBxc9oVSN9EojAREVyFqvwqpAmwdwlESTNtNppRKxKCWO+LI1ByVQiXxKCNgBH3yjuzacOnXSdMKAIwdauymmV7CiPtApT3wCfApVuruylKjZ8CHasWPHdJU4uEhCIxhlDKCxqwx18Llz79x///1aBKP0HA8Ircm4SIh6YgzDjtkhXV9VB4eH5SSOgkLcyFMNcbvmYCrVjsWC7lSB/PzkxNj8xMTUAw88MDIyZBBobm6YHB/1hhIfJekDhXX3/Nm3n3zyye2dzfNn34rvr+fnxXIS+7t766mVuXgg+Ogqu/t78e9+8/sb6f2+wXR7U0lOTm5WNH7g0MHahpZ7778/Kzs3Gosvp9a3d/dyE/mlFZWBOpRF9UoruufWTeJD9SKxKEoS1zoCBYgDFNBZ2oXUfupHQsorbKPgED36FwDQVhzxdbT4aK7J0upNEUI8iIMyytK5cKJzJURSEbwKkSqC0t0FirO7F6jsLoFBUzNDQQjW8KdwJSpaIHmXFYvLEN28FS4T4Up3V+0wmmfh3kK2Z/ewRA9SiSwHdz/fvUQIrxgSqDfBoIUSi6pU78BFA6QXrt6IBUlnzpzRWoXpdalCkS8JeQmFUnllVMUkIkslKyTzSv5ArxlAKU+ZQxicGTdIC8YfceCbfBUNSyAfDUER8pREvUlrCdFLTFQWDr7KAneoZS8ywtCq8TBTlXmtEYAqJdA4oF3GATWR6j3veQ8+QTtmKLkpyIUIphmo+frrr8Ox6smZpgQ9w4ODbS1NNVUVE2Mj9TW18zNQPddY1xjbj8Wj8eGBwRNHj9XX1lZVVKRNIscncuLB1Hagt6eyvHRnK11ZXnzHPafjiej03OjgyK1r189HY1vgfuvWxYH+G/fcfWppeXo5NbO1nSpK5jS1VReWxAtLcg4cbq2oKtmN7IxNpg8fqtyN7Kc3t0dGxweGRq5dvTw7NbGxujLY25NaXtrZCoZTTKtpJSXF0dj+2npqenZmnDqVufSCwVxzQurpGq2DBj0F1t4iC2oIwdVGA/mghrdoDlJ+ohIkYP4QBiiMLOQRnkFhkcXERaHEAQypkFTC8PJT/i556ggXwMhQ57o8AIlL9cRXlprAiTjhFVYjBLc4Lt0UFuo5zDAsSPyMMIopKHwlKxm6RJOPQPfwwXNYXAw55AjfYWKxxQjHNTEAF4HAFJVBUxyX5kEJEiCElvuJOmFhaA2vqiIy9tBs8UlWHYBzCGbCXrhUilCozDXm3nvvFUcjZegtlQNXmKSStWafp06dQiltwAMyBHcCW92k1WcyQS+DibQ0N69g/ed+7ufo9FQ7mauAyKLpIQL7pZde0l5MIp+33npLfBx+9epVgcxHaiIO5tQxeFg1qqtRqJIgxJAoq55IEfYBXoIAgMOEFy6cf/DBB2qqy6OR3arK4qtXz3/8R588eerQyFhvZVVRbt7e5PRAVXXRXmStpDj7+PGOza2l557/9ksvP51bED94uKO9s2U3srUf3SmvLC0uTW5ub6xvrp06c7qkPLK1u/dTP/tPfvxTP3PbXXenN7Zx7ze/+XUAUW5rS5NhMLWy1NXVsb66huzoo7NUD7mM6mqL7Cqsjbo1FPN6SgQEQVVqjLe60lv0J4P0rCQhWNEtBIok4ouDFqFkEQ1hMYMKKDcEsULDhF6J7PJTWa4wXDQJQ2CoKuRgQsWhszgq8C5wlSg3aFQ3/esV9pOhwHdfeVC0e4hskfWabJUlUMWkFcHbMGfNCdPKRx0gEMCif/Hnf6UZYsCoB1VRLQ1AHQhDIHf5ghfhgVgaoBLeqrckIRXCrOWOOgSzxogmUA3KS0s1GyO5K0/l5KaIUEshoWEXtsyYT5w4oayenlvqpxmqJBWK44EnnnhCcR4UZ7psiFCENiCf/oYJsh8TAj0QS+jtU089JaYZ56c//WkwFQF7qHZjYxNjkZpoKakP+gKVgnzwob1YVFbEv8sk26BTW1f9l//nr44cOVqcLNVGs0EMrFC1raqqmJqeYAH6xI9+/DOf+b8UpYLcAjk888L3jcMb26tr68tvv/PG7t7W3NxManmjprqwobampDh5z113Hz54kJbS2Fg7MjHIzB+N7eQmIjOzU6+8/NrkxNyPfuJTWxtZ//2//hHDf25O4T/+2Z+/5577+m51f+9bXytO5j/00GPMhLX1zVeud5eUlVfU1GbFcodGhltaWoke0FfP1PLK5nZg8VxdX9fZykJVgCAU9BHSIaYm6FOTKxIBPfWsrtFxWFoP6jJU0gvioJg80RYQPSCaOzqLLEORhYsvT5noZfkgkbuOU7RXyCt+NPYDMS8amkvuCtlM3VzCAUBBruAhK1hYgBl3RWhCWIraqptquJQuB4j3VhzZusTHOWEp7/KAh/Cte1hunGaPFpCqzSBO/gmRKSgLJPnUSWGaoQEy1bawBmH9VEKbiQeAdlcJlVZd9QAjUpbZWkxSmaxl/leWQPdwEFAouBDV5rvuCB1SXBwdKU+5YQxKvFfyUT2QVRPKkjYQbAKtcMG0JCQ3TMtc5Pe+9734WVWNG34S/2ihUfRJz6S7vlFzHEhMYkL6GMVJEsmtiz322GPY+9q1q0ePHMIVSDw3N1tX22BSbkpgZtLZ2Tk1NVFcUrS6VnDunTfz8rNaWhvWVlYK8wsmp3pfeP7bo5NDWzvpsvLi0YmFnd3IyZM1H/sXHxoaHOhqba8oLy3KL/reU1+vb2yYmh/LzY8XldSsrK3Oj86YzGcnCo+faptfTNdWt07PpTepgbH1189eiGTnNdbW1DU03LpxbXZu7qGHH7t6swe5mlvaegcGs+KBSUcrEN+lI/RaRWElKomDUPoUBfSjPgVEoAwlGpJCP+hoO4J7CyXaKwlkCwR9fYeSet8rAHAXH4D0smevpPKsL7xVCswgr2ele+vuWfIA3/s/ENh6VqAkHlySe6vmovkpPHy1u7MnMBwElKVdclMxpYfZaktYqBBpRQ6Ty9AVRnNXK9HkEMaRoUAxo//vr/8GqQkiYmg2kYDjlY1eIe8qAFC0EH2FSykXIR5EEKJIVXEJDwPlJhzdFYABFAzu8lEhSVAWq8A9bT4sQlqZq5lS8K0MTZHpKjAtENap5vqJRIFX6JcQCdw/+MEPWj4j5FDZT9RRrt6iEwMofUw3qxW8GhD8PHv2bFNTsxwUwcyKDURQMQ8K0qmmwnKGA6kw5JEjh5cW51XS5BK9nnj8vbRkciHUla/fuFrfUGMdgAHm4MEDsay9v/vC37z26huNjeXDo/P5yUgiP3rHnSdLK0uKivP393aOHjpsFlxRUrqxvnH9ylWT2ubWtj/44z/6wpe/dPP65azcWGVlOR7e2Y42NrSPjS3+m3/9WyXJmrXVre1dsMv+5//8n3e2Nn32z/+ovbX59jvugvii4rK5hcXjJ07d7OktKDR8LVSUVxkea6or1Vm7TIJVmxVIt2odEgG9ZyIAEZBLQ/CJDhIf/gwU+k64jsP2elBywyNqEFVIFPZy0Nk/tNUI1K3Irgv0skxkpRT4ARLJZQ4VIsgE6fLyA7tFgLx/cImmGtLKRIbeiO8SbW93X7YhOIVDjmdCyis9Jb5UmM0rpQRNzlxhDcO7gLC2YaHi6313PwOWYAXSbMjzQ6ioakkX1H4xtCGknUARUEeIFiovRBsaIaWqEBWKR9lQrhD/PxAbGbOS+MBHlitCZPlAHhqptJh6XT4uP63hq4+GhTqGTISTzebf5DSk4k+AVlxYPTHVWSVDvlIZ4cYBE+uMvN9WH2MaFQ6AsAFzoXpKoiGATrxpqVqhLCZUlnyoBAYrZGptbVleWigtLb5xo5uF8fHHn3jxhZdRv7klsCAVFRWWlScnJkcWF+euXb/05luvzc0sV1dm3X//Pa3tLQXJxNjkcGU9ji3ISWRzUlicm8/Oiufn5BXmF+2kt2P70d//w//V2Nb+iR//UQvFJWVliTxGkmhtTfPT33vpT/7oMwuLm+trEQtge/tZqN3e0bqyMHvyUNe//pV/deHiVUtgOYm8/IKixZVUZVXN+PgEjLa1dmhdWWmgt0hCouUkcolTGA0Nu2ZN6BO+Qm1c4afullYXC0cBIaiBpGirLzwjFxjpRA/w5xk6FQQSgIu8IX5QRrhU8tHL4oupFKkU5K6IomSgG4dZhbmFfKVQDy5vPQfQzCSPRoJw9Ze5olVGhooGejF1nJ8KFUGgu7QCQ4iLL5N3Lz8zJfx/FlKlBBYujScb5KjewK1aFGvS18+w0pJ5kLXIAuXu2aVglwaHPCoHzZapO9ipDTBpBzuMQQalAF0lmD4RQu2BW0JCPaS+5OwWiUQulHvQK8pCWZygVp4ffvhhCUHc/FjHhBHkA8TkvfYTfjJ0GRMwGGQrDoEUfeedd/7u7/6uQUBygfoDA+hs2crcZe6uGvgEo7KlYk5Nw3iVFWV9tzYfeeSx5qbWa9euR/Z2srOik2PjJ44eHR7pf/bp7778ygvLK3PUwFhW5H/9wW+88/YrDY3VZdWF27sbuXmRnNz9vf3N1GqKPckIkFpeZbu7cfXKzNT81trG3Xfc2T3YlxPPGhka1ASLPr2Dw33dE3/6J3/Z3nYsdfFmc1M1sw0iNDc1rK6nfv4Xf76hvHJmYbmguHQ/EmvvOnD12g2+I5BLN2IbDTGh4ZqfF7gkFGzt7CCLWYFOIZ5QiTqKe7UUw6ODPhUfNTQfw3iFtsJDkYw+Lj91ug6VP3qClHzcAQOneTZKCEd5HSQaeiKynMEmBI+fnpH0XfDAjxygxYNsEdzdsxCXV+K79th5M+ZOMJOJzBXnQXGuMIkivBUZ9BURliWa5zBzr1RM0dri2SuXUoI6/OZ/+M8w4Z3sQujIBUXgMowhHHUEao+YWFC+KKUYJBOuEnLXZrJcYFgkimhSYMPJaPBBFzY3yzBsqibJlgBWoVDj8mDOSvlOp9fJbxXQAfJUnDZDqrJkqJ74RObmu6YNmi1crXSbu4FFBCinLwkHZWOFyuNDxUEAnrl69ZqyuACZY6gt9zg4wP8qxvrkQf3NueVjEKDTDvX1ovahQ0dUKSc7D3qee+45XHr69lOvvPICqT8w2H3wUPvJU0dGRodOnTwSj27Es/cKkoUbO+vp7fXymgrJt3e3VldS9TX1sUhWfD9eVVp9+Z1L594+ry3bsa33fuC9mlZSin5VppRPPPaLRckI2X/w4NGpyYWDBw/9P//PzxcW54+MDsxMTVZVVOXn8FlYqmtsmpyasbLKiBKiR7vi0UAxqKoshxw22cGR4fsffLAwmaTqIKMI3moIiKOPEFf4gGH0qctbZCG/wjuC6G7UcEkbdh90iiktqqq0HBDZW/0lgr4GJDnoERH0oEAXmMoqEg1U5Xev8FX4ViDiixPiRAVcRgAhHrQRdpWiXD/lrPeBBA3VzU9vPUjrgm/hYUKtdsk8aENmmUwO4duAAf7Nr/17CrfcVVoV4V6NZeGdECUpUmul1zBA91Puoqm0gUIlUFOgtJhB1gQ2fMOoTAJaZyxcJLq5plLFNwrTMYyb4CiVGZgSqSsaAKnHjx/DEma9KChb8fWNakhrsisfrdKdBDYtyDBF/ItGd3/00UcxADnqLtu///u/D1V52X7oQx9i0jEsSE6Kq2T4LAlNSemag2eUi0BoKn+lZFoav+eOM729t/gvBtyYChZMvv71r09NTe7uba6kFtIbm5SDD334vuMnDm9tr+1sr60uz8Sz92vqa6JZkez87LxkvgXxeE625Lvbe0WJ5P/99P89fuhES13Lwtzyd5/69m///n/qG+ixPt3VeXhne392bv3Tf/65sdFtxsLl1c177rz/X//bf3Pp8vljJw6mVpeQentjv6a2UW4vv/Z6TXXtzFwgqnja6Y5ATpterK3v7bJb5BUk8sBi07Cf0VtMukgNYgh9UBWpURWRwdcsS7u0V/8SBwiui8UJwa3rhRN/IiCs5EIoSH4G+WdmgNCiu0NcqolnYEBJuBJBTK/CkKx44PQmHyHh5WdYeQ8umQe4/KG6lZfIV4r4Xgl36RqXtGoVsGzGIi+CQhXnIayAJoisUMwpJuLI0+Wtu8hgIJ/oH/zPP9b3oTgEC2koKqADBIrUbCHSuNRDSxAF7bwSQjzISwfIS3wl0V4gWyrlqYrGm34jmQjIoU66UKmwG868f+InfuL3fu/36Pf8fLwSH/VFEFmEl19+WXEqY1EW2xgZzIyN3eKrQGi6UQFTZPwTRsBOWEWP88AoLS0hxTGJCshNTLWy4DE2OtHV0VldW2Oam5dPR4kuLQfTRHXApXLWEKTAS08//f2V5dlf+MWff/ONtwcHR6cmZ77/3e9hBtInvbGaa+oV26qsKvnwR5+8dPGtltb6O+86NTM9sbgyE2BxO11eXU4pJAVUictaZDfW2tTefa17bWW9obp2ZSlV31C9HeNcOd/edigSzZmfW/1P//n3Zqd3tzZNX3M3tvarKqp/8qc/deLkkfXNlbxELL2xtbuTs762lZuXT/q0tLTtRyO5OQG8UIwLEFEXjwUyeH11lV9QUUkx+8teZH91ZY0eMTurJtZrKTNozExXOjcXzHDcOXQINyfSNbLSd+6kDKLpd3wCSXofV8hcoH7Ry6IJQV7lajIsyld8l1e6m3CBE8lRVUx8u70TaDIuEQS6RJAhhAhRild+vou6woIi8PWTFgC1ukbm6CkOqHhQDbhXrtK9EkE+HsJM5C9PRctE/QMqZbhCoSosJG4IGRoYYBqAMxiSKdW8r6cHrEWlQ8labDkadRbn59tbW2EayjWbTPBg2i9EPg/efz9B29rcrOXs+jQKfU+iENKgzBxJAuETKFdFiqm3MsmoJVcRVF116onjp9RMTeZmF7hhqsbO9t65s+fhfnFhubGheWF+qbenXz+ZS5SWlPPd397a3UhvxbMgY4MHf3GyOJ4dIxQzA1+M/RbdNQr5DBtF+cnHHjly9dLlmZk5NXz99VcfeOCh8+fPsfE3NbYsLAd+o1U1Re9cuNDQ1HT6jlOf++yffeKTH16YXyktqZqbXYnuZaU39UckSszFstrbm/Yi6xcvvLmyMlVR0Xnz1oV8s93KQKWsr29IrS6ff+383lYkOyu3KL90Ynym4cfbR/onYPHt0XON9bUNbSdW12fqGktWltc4lF65fGNpcTeLeIplbe9EC4uS6a3N7zz17YcevXt+aDKRV4iZs6LJ0ZGpxfnFQ12HwKvr0EF6ps7eMfFLB2uUM8vLaA4TtfTA5aX19EYpM8D8GK/Sltb2+YXZnNyC9fRqYWHSIlJxYfHm+qb79sZ2bjx3ZnLGyENV1t0b62sNdbU6RRfnJ3LjhcFcEYC2ErkGk2Dc3g0cP5GrMD+PY3YAWQr7zj7mKsgL1BKVKUkWhVgMGCMne31tdTszEYXyAF0ZHR1AXQFP/PAKWUIE7drc2tiP7LH1LC4tAAZoMX/t7AZuy7mJHArV2nqgsFheWFicVx/rBiFTCQzz8SAV9sBjrrBcRXkbyAviXBA8aZ56iIottNCYQCRLJp58vcJqYETqo7uUAG3oIDUlp1qw8LCRCxFZVpQcLUcFM+BQHaJQ6T+5easeNGlGTBGo7yIbgtXkwx/+8OuvvU13NEbRJE+cOIWjcCZKvfHGWzqMl9jKSurAgUN33XWPoicmXuFiXVIypHptbR3f/va31YpWQ6lTT7XF+pozMNBviDBijI2N11bUzM8ESjAyPffcM+42tWhabiJ7eUUHs1At9/ZOffNb3/DHt6UwmbXAHLMZ2drc30ijWjQezWauyc7JLiu3xBurazBZn09v7g2Pdhcm8xq6Gtc20kwX2/tbTMBV5RVtzV3RvZzFmeXZ8aXYbuxw1+Gege6p6fEn3/ewfTAFxdEN217SW8nCaGptfXEhcqCrbmhwkoQGRJJibHzT1Kiytow4Hx0Zj+4sbm9FSA1UDbwyZqbyEzkoRnK1t7dZD8lIrqjRbzm1nGQcGxgk98oqTJojqh3K70DMHwwU+rycYKAGrIwQDSRlYVH+3l6AAaIUcUgor/Q4CQVJOpHYMplGcKlC45t8dJC3UKXT4QGKIMSDHAR6hRncg5jB1DQQqS5vXSILUQS4iyOVu0CXB8nDfMJw9zCau2dv1d8lH88CZRXepfWgPuHlp4ewMhK+W3r0//zZ/4VLrdI2CcBXXl7LCDkk0M6Qe6SHV9CBVG9Ja7QOJzrIIZygdbGv4x+CwSCgpJBrZYigKiGhsowJRjQhYXWVojtJF3nm5yWVqzJhV1F7KCpWZK3jKuJDH33y7JuX/vZv/1aGoUkHFPS6nMGdsq6fkN78+Nr1KwoSLvOysmCCCSKYbX9rlzqEGdRheXVFBK/0cXtnh9UD/sN//defNUxpiFfcInPigWkCPXgxsoQyu+mjgsJc+1e6DjbuR1c7DzSk03MVVQV5+fGqmvKZ5VTnwQMs8RNj44O9fV1tB+prm1587tWlwLtz4rf+42+9887ZicnhhcWZ1s6m++6/s3fg2vFjJ595+uW83LKCwrpf/7X/CjD7u4b43LWNwBcrtb5aWVF61913fvRHPry1tZOfUxyLBmuuhAgSIaN7RUUZHrZESHPTOzoFNFW7pr7u3DsXmrkD9g9oLzQHEi2wxwRwcZUkk56l9Up7dTE0IqBsdYH+Fa4OKK8UnaWjFa2nYA4Y3Ik8cXSl3JQosruYooksUE8JDBEVYDon4+6X0YgUpERvxZeJtxrlWU3cPQvRNSEgRXPJ3CU3Cd3lH5YiiZ/qk5uTEMHPMJpqyEFVcaCYIsjkXdYKfv7yL/4riq8EouJ770Kgq5w0LsV7pSRQdsmFSCZCECisNy8DyqJoxgG8ZChQBjEMQyiFE7QE+Ah+8dFabZQYYD2z9o52ykJraU2gqyo558zpSBQ3+HprdVPXgqnk+NNYoYNVySgM/Yr+2Mc+pugXX3zxox/9sOK80rC+/h5VVQeE4Hyv+wUGKwPpwALrWZXaOjvsCsIMKvzpv/jfJj9tHR3Emwi8ylKB3py7ld4qKkhqPjrKnAvn9s4a3/14bPfMnUc3txeSxdn5hbG77jm1H0nbgDKzyB6aVVVeZsPV+mo6N5ZTmqxMr25UVzR03+xdmJ27dPlCdU1ZUTIRz411dDYbeTjf3LwxkBXjOlXx2//9D2OxwrmZtVhWIr2+lV8YAHRucbGrs+0f/eSPs89GdqNlZRX0wMWlebOXnd0t6p8lAs1EZ8ICA/BoCl0Aq2pqrt24ibJlJeULi3NWsrlaNDe28MvAS0RkXg7XZSZLSOJeFFhpNJngQDd9gc5wKduQjPrOuAoeCIsl0Bla0ESJwqUVX/IQP7AkGsJKjto6Dg095xUGO8g8Sw4JHtRcWg9yc/npWcKQDWQieRgimnAEESK5Z1n56UEqV5CKj2LmCl+JGV6KVjGpwqzCyEFH/6/f/aOwJGiDOW1QjAetBVDNECmshMqFzQsVHgV7KxXEAKJMiA2RJVSMOAQtiYuCpDvUohSgB5DKuIVYlwFHOSCuOJR+1cZvGECN0ffpp5+m3ngFlx//+MfBFJOEdgzUlJtoeIbvsQ5DFqXrBvb+jc11BlATZRLd5FP1WDlIPrzERbm+ugor4l6lP/zYoy+++Lzq/dqv/VpWdqAN5uQlwp7gSZWXV1CYV7g0t15SVLK5RQ7tlFeYXewvr82b+9bWlzz62H0NTWVLK9ObWyuV1bg9t7yyYnxq0SaVyO5OSbLQFHZzdWM9tVVX3Xj10o2h/mEDfV//LW4/P/0z/4hB78zdp+mNphPzC6nxsdnc7OLPf/HrNpNG9hLZOQUL86mtHXsIc+YzRh69bZ/XT/7kT5I4dqSoYUVF1awp8+6+PWV6F4kIDj1ovmQGb428MFlSXFqSsfMu2bXW3z9omruzRWHYXbaYUJiHeeobau1CLimhRAWbKyoqq9EhJJfugFF9Cj34gQzSHXpQP6I8Ggr3VkfAhjFHV6IeOhMW5ItwqBBfoC4L84lk/cAK5KceBzYXOCrIg/gCxfc2QHRG2AOM1nmlOCHQGIaIKVDRYSqAlMoe4ncD/ZSVargLFCHkATl4lSk5KDrY5iwXrQ0FNpyR8egoJU7QZrGl1waCX8NEAGiv/KR+aLkINBDFCDQnQyDtMT0FSvCSM4JiEjE9CJQbdR+hSXGpjAbqQLzBvayEUEJ++Zd/WUyFEt70H2R1qZXJic6QuZorXZ8BvbRKpHpRfjQM4nUPxUmJ3qoSZIgpgtx4HHzsYx/hx8bxRiaGFzxjLzkvAYUzRVjK1HYPY+NjDBPqBm25iayl5Vk7V7Z2lkx8H3387snZgcvXz/Fzbmypy08WWqi61derac1NTRl8rGZFsurrGzGSHGxqUbeXXnpHoyBYkxmgvvPNb3GyILtFUP+W1sZ77z6Tkx2JZm0uLc5aQYvHdNlmbXVFY0M9TzDzos9+9q//8A//cHFxXhE2Z2LvQ4cOAByRr1+6u3tQtbqaS89KV9dB/VhWUopcUIhuKBOUmxFqoehBEzCCDK/EcSezdG6oPcpWc1QM5dVDv4QIIX10E2DImdBBKWlFwHgEn7RiYgYtlT8Kyz8EGCR4UIpLzi5vZRVCU0FKdJdcYBjuLk54qWp4+RnWVj4etEW2Xkno8harCHR5G5boreI8hz9/kKNB47/91m9rFVySi2G+miS9OgmUHpqFuKu9VoUFQxLTu7pqpJYDLqSiHXslEginuytPZ0hFustKHM0LSSB/Bk1KvAeSWEypVFcp9XWN4E7YwITGwK60VCb8Y9Ag1+Wgh1SPu9vnP/95qRQnB8K160CHfHQP9FdWVqCdCug8imW4FKomQ339999/r4awkLJI/Mmf/JGyVJ7LgJhLqdXqarpW1uTkDIleWVa1txGtrKjYj2w2t9Td7LlM8G/tcT1Idhxsmp4Z4QCXm5+DN5iGkoVFTc2t+XklQ0PDprUlRcmm2oatje306vaZ2+5+5bnXGF7+7gufX1qeM3suLk00NteSvtGs7OmpOT1QUV6TWk0vLa7NL6595e+/ub7GCSxSWFAyMbVEquXnFW1xqWOQsFDY2UVA6LXf+Z3fQTFCBw5gXdtbmtvsNcNUGkj0jE9NoiG1gBaH25lBKTyryxyhrfsuGxMSOXncqg1B5sdmOGhuBxk66GVkkaF8AFo36QU0V1aIM3e9qQ4g7i1U6QXCUX3CvhZZoAoLd/np2ZWb/wMXCWwDOUL0nforOuSxEL5CvFJ59xCsYbnv5iOVJH6qg9rKTX2I9ux4MItwSSW5SxxpQ6nv+R8GCg84SVNlp+ryUh5OALJ3A6XxTIKS8domDtYnb4BM471VErrQhaRSCXRnhKGamwQr1fiLoO5iqpYQkV1k82OPPWYKBZRIDMfaA9nyYZ1ESpmLjNPwiaJRB+Jlq4ai6ZjPfe5zZLwQ4NYqNVSQMcGcgWSSD9EesoocDDX4kxS8/74HBwdGr1278c47Fz73ub+h1q2uBju+Q161fLm8HFSvoqIUTWbnpizExbI2KfqNzWW5eTul5TnNrVUnbztQXJJY21wZmxxNb24k8opaWw6sre+8/NKbRvXseF5HS2dH68FoJDu1lB7sG33q28/U1TY/9d1n8/OKy8tq7fYqK6muq2tcWlwd6B2sqbFbJaD/yvLi6tpyc2PtB97/ZEkpYvKkiJYkWZyi+xF+Owx8u4y8Pb09Idv/yq/8yh/8wR9wgINgixstzR0E6KGDx0wgMZtBncGqID+ZXt+M7Ech3t0Ssi0olBSApDsVF5dsbnCXKs+KZVdWBmO1ziUO0F9XoqEu0L8GXvT3DOsorzsIPpdnlFdzlPcAG2LqZYiXg/h4QFXBRmR3ycFG/BA2yI7IIkjlklx8IUoM0S8Hl2gSCleEn175GeJbrUBfiDjhBc9+agJQgYGuDNlPQuW6JJFWJUXzHP3t//w73oG49KpCjnpB5KsQMYMiqi6ZBErVKpDVEsW4h2ygZsCHXkoVqEgymA7KggmCwKdhLkWEKhNk00MAVxEWzlSCZg/0DKMEPKnDKqoyypLE1BbKTQOUi3a6RGWMM/RdbKYsMw050Ih0Brsq7b+3t+eee+4B6IxICPz+pKIwmDW+98n3D/dxul5DHEPQpauX9QThx9qTlR0QfWvXsJNZSoSd7OwTxw6lU4slxYVLyzMNzTVZ8Z28glhhSa7JwNTMRGHQp9yf+V0mYlkWfdZXllMHurqQsbKkzFEl66mN1OLq+bcvb67v3n/PQzNTs3wZXn/jlc2d3UcePVVbX1ZTV21VXt006uYtay9Vb7519vixU2+89Y7l3s//7fN2CJSWlJoDLC9xEo5YFl1eSRdmJuXahZI6hZTUCuJgfT1wpxGIH/QjgaJrxiYn1JGfG8UvYcdwcaHlPODPycp1t4hm73JqKYW1ME+yNLkfDRzX1CfsTTTXufAAZ9olQ3gKc/YTiYAS/RXnp17DP6AiAtiECJNQJdVKtiKsb254lrkLuiQXqKOxkGgaEr4Kw+XwDy9vhcvQg+6GY5dnFVBhF5o0NTaL4CGMJrkILpmrmAc5aIWaiyBJ9I9//09VWu01TBXD+7shYkgJqe7SwLHxAbYUDJGABeteSUX/C2PCBKppj8iiySEsiYYqREz1UD+iHf8okVZKoniQRM3kYwyh8BDeGMZ2MJYNgGZWQim1V1Vsg2dC6BP5jzzyiL1dYOQt0PNP1Wy819HRZpxRHEUZ0ZlfTt92piCniDWd8cQKdEGyYHU1tbdPu+Wus2lxq6gk2CZSVJSHUhWV5StLM2XFOQ1NlYbZ4nIOPrmzi1ONTTXzi3Ndh7r0uq0o0E/k9/YNUmOsprW1Ns/NTrc2NafXNm5euTnYN9La0L40Z7ekUa5gcX6ht+96XWPF3n56cnrin//zn93dD4z6iiMvhkbGoNnSVXt7Z3pzt6GxheX0e99/9srl2fqmwsmJ1cg+UUfrDRR3RLbqp8n6hZqQWkt98kf/0Sc+8YmC/CKkA0FKuHVfhil4QBZ0mM2YIsRH55WlQEKjD0mZFQk0hJCe/UMDdinoLOEyd0EnaSW5rtS5IbvqNT+hHBFg0VsqrloRW9qChkL0u7Ik8azfwRQelldTCg1xCTAq5gIMAPBTTCVK6JLEJblneXrlkoOfspJKcX66exsGupeXVbybg/AwjmhK1OqgPf/A7iT/6H/6jf/iHZEc1k97FOlFhoKBL1qQaUZL1jZVh376DDaQnXB34brQcINq2Feb0Y7MEBmaMQ9AK1WGcvOgLHFcclYQaDLXqCI6Iq7SzS5wl5yVgsE0Q4/KnJoL+l/96lcNF+T3/fffjw3CoUZarejv72OE9SyhXkajgDR7wcCtPjrskz/24//7T/7PyRO3/eEf/QE9eGd/1/SX2mN9tL6x9pFHHnrrnTfHxkZmZzfq6vOsJTU1VpSXJ+YXJh559IGrNy6XFOfFc2JEJnsasO/u7FdXs8M63IHpdqGxoQW5V1MLLa1NzEejQ2MVxRWD/SP58eQzT714710Pdt+4pWI3bl5taa05cqzj53/xZ5566tvIoo25ecHa/sXM9mV7f7HK0srq5tbOBz7wwWRx6cDA0J//+d8tpyIN9bmTE5uxaEArZKfnIDigoyodxmACeQwQPPY+8IEPHDl8jIxHk5D+0IPg6MwtD0GQC2Rnp6YtHRIihlMqzrBTAGtrUmurXslfF4SCHNwB1E/JkRRUQhGrXPJID+pHr+Tv0uPu+locyNan+hq7iuPBCEDwiyATP+WgJqKJ4KdKKsWFGuLrMhHEdPcqrENYOrqJ41KuK3x2ZwYNOj1jJ1UBzxKGl7fKEiJ/ZfkpWsAA2mCWCS7IByjaLJICNExhIoltTNB5MtIwGoi3CKQbJBEueZijaJoXcrNKm7ZCrRDhYb0Fgria6QM56Bv5++kZX1G6QF8RKkARorWrjO4Ba+5xstXfaququkTOtH/KPY7CGJaBz5y5naWF1iSHhYU5HMh8acHYrACJsSjt5mtf+ob2Ly0tzC7OWD9aX1/d29+mZK+ub9XVJ4vLkjTklpamomT+Y4898vbZ1+wFt2+d28zy6rJJY3pj7fTpUxibZLUg5fi3ycnZmurGSDS7rroBO2XF+ayvbKTWkgUlt992x4W3Lvf3jHZf6y/MDWKazH/5K1955NE7ampLU+vzH/rw+/r6BvT9rcyJAda5b9xaf/jhzmef623tiFvfYMYEoNRasCz4fz/zt1OTFuMi66uRYC67umrMYaXj84wg9HsMYEqjj3Gmux5x0KKGO8gIJcUnLIRPjk8gOzIyRuXGA+9odgjjT1VlJWYrLC45e+68rg87UWehuT7SI/pRT6ktwOkX2SsXTHFLWJzODVGuu70SWUwVABuACUFcWhH4vIgWvlWKCIpTQ5G9cukg4e6SSCjEgyJEcPfsEu7ZBcfCRVaKBy7lQiQRweUB0uSmtp41RFoPYVYeov/jv/yueLgWlIWCKep4oZ3aILGsMaLGq6UHr2g+wIeCJD2QSRtilHuPYpBMVUQT2bPImoqI5Jy3SlEb9ZatV1hIhWQFylKZpJICqoEcprywqxoOY6PPqAk2wydwjL4yEV97MAYK4ha9+MUvflFaYNW1puDYZmh4QP5YVCd97nOfsZsxmSieW5prqm/Y2FjdtY6054C+dE1tyfZe+sn3PnLxyoWq6rK8/JxAY07klFfY7zJ89tzbd955m8WirFhEOaptOFIBSn92LIfKwaa8tALxycoaM40ZfXSk6/B6Kr00n6oorum+NvD1r3ynsbZtfm65vaX14qVz3X39T7znTEVV0R133P7t7zyl+ZcuXSHxm5vqe/rHf+7nPnX+4vmjJ46/9dZrXQc7G5vq2jpa1ZOl9M8//dnhodTkOKkGBxF7QrjNFRUlqPh5eYn5uQ2E5aZpIVjfQTw566gIvY8CfhXkB3Z32AOk5oZGm/qZwoi8//Zf/qt+1PWLS6s5iaLRsSkyRd/pQWQHVkO9Z3lKjpL6TheAjbe6AP11sVboXz/dvRVTX4ij64FBTLiUlZVgcYS4dI1oKCmmZ9m6K0hNZBJ2sRzCrARKLq1oQvwMc3AP4SQTF11WBA+yCiODrqxEk0Q9ZSgfdxEC/nn++y+SZ4LIGKWimhdABk/Ah9Gl94AcwCrcnfQVrhKahHAu8oNCgg0UCR9yE01WUnnWJOEEvJyp9TIUrktwkXp4lpC1XikuZBEfoKn1hhpVlEpW+sBkwJ4B9STmyXudFLYc44n5+uuvG8dl6LwqxXH0V9CRo4fMNCS3NR6gSdPluSXdT1TfdfeZ85fOkfS5iVhtXfnq+hJ3ziMnDjmkjZ+Cw1nuuutOKsTE1PjK6vLC3Pw999wtlW7OTwRrnLQ+Bugc3r2xLF56RmkCwhrD2Piwddajh49VlVfPTC5Mj86/+drF1aXN2opmHm8ToxOnbjtaXV/+wkvf/bFPWsDui8ZyeN/pgsGBoROnbjND5cRv2joxPba9tzm3OHvX3afqG6vvue+MEXt6ZvXLX3j+5s1heM7KijgO1N2YsLFhZ7reyLI2rG7sp1CBSeiBpOHyyl5jYxJVZ6e32Pna2hr0YFF+MG6YfaH8m2+8gRk++clP8vOamk7lJoJJFEq6sLoeREnZQlWILSWFSAIpUskzLgJxkEB5HarLdBNa+Yn4chMIghijrLKCEBTBK1UCOfzjpzuYylmgS4jiwp/CRVOKCitRQXL2NmQAMUMeUIr4zKDuLvl7JVCtXO+GiBxW3kMQbhKsijpPVFBWgNaqvUjSKEybvVIeQgj3U2OQBoJZeDRJMeAO3/Lxk74uMtOBuwkDmAoRmW6jFCwU1kw+2qwIb61b6RIR3njjjYWFeTQFd0VbEMAkUqmV3JSiJsgnxE/8gJ3CtFSgRx991B6A973vfa+99gpfgNdef8Xk2OyNBPrVX/0VBY2OjTuOITcrNrewdPxY5/zCTGlFMZeEnd31w0c6sxPR7Jz9qzcvxbJYLWLJYhbe3Y6uA9s7+w6HW0+tNjbVa7W1WMyAUNha/TGAtVjWdKuqhjhzg/LKEuFONRkbnigurFyaWR0bnttcjeTFk5YyOV2ev/BWx4GWoZHuJ97z0PT05MFDx3pZQqtrb93qTRaX69qnn3v2vvvuGZ8a6R3ojudGysoLSsryksU5T77/if1IYqgvdTNY/gqm9deu3gB6mzzZP2ygQRU/bV7ijEfJ5+pLFJaUJum2SDc1NbOzRe/PP3LokK4kYsy1NtbTDz30kB756le/btXol37p18oruPMeRDc0D/saHEFQ2w31Euov0NGtAnU3aOoL/UK4QAJOlhB49CB4Cfcsgt70VlbmTsSccJnoGuEaInNvPStRcpe3QlRMiCJkJVDpQkQDUT/1aZiPyGF8dwwQBkruEuLnu1eYm0D5hLUKjJuoo89IbuoEeJEKylM54ZQcpUKhaNKE8kCIfjIUqpkcEQJrMuerEB6AAzFBM7TtCEc44JYbOYET4NvlXCohJgnYSSbqClXE6rFjRxUtB8wG3CogT1oZ2gkXLVOxpBG/vLxCG8rLSk4cP/z3f/+1+bkZxy+/+fobf/O5v/2TP/pT0vq3/9v/0Pfoa90UDuroJ4tzucX5H/jwA5cvvnPgaGthUa7FysIibSnuH+xzNq1ytaWgmu3IZDfLZoCllY3K6rqVpYVYNJ4syt9Is5zQB9Yd39N7qxsptzY2jx0+ury0nJcV+OUnagqmRqf43jTVNa8ubZj4NtZ0Ds1M5SWzttZ3bvV0/8zP/MzZC68mi/NXUrNVtSWrqeU333z9p3/qH2vjO+cuMVDzXnCexne/9x321tHhVDxnm79dbUP51NQY+/7G1nZewW59Y7HhLlmSZUWNWkjSMW2j/9bmzsIsb81x9n4GlSJKT9Sc+ND8Ii6O3HbfCb18oy+gfPFi4sTpLqbyuqbip77z3Z/5xx+71XOzf+ACstfWsddFqiobKUvTU/MkaUNdg3C6ImzrphB5QELMkXFaHV6oZ8qKkaypwyicQDYSeeBj6y3+3Ay4I9iorQ660ltpoS6o/A/Vejm/C/qwLHCXXGQ/xRcTZvS+K4zwgxr4z67qzKxADi7RoF9CKHKXsyuIlRkfPARyHS7hFV9qG1grDJmUgctVURkwQdwCvchUQQeErKwwQTgub9phzvIPziSLGoAcO2yfhFMGTH0sKdigSHjk1NbWeG5oqHcvLy8TcuHCecn9lPC2206dPfv27OxMd/dNIThNj1JpSBeul2waDQ2No6M2f7Tay6La733v+zju9/T02gCwmd4oLsqN7G06u+1gZ8fO1kZXe8fi3MLqcmp3cy8eie9s7rDxcRjmE1hdWRb18YHszfHp7q6jVa1dxbfd1dTcWVRaFV/dmDPr6O2ZHulf2d3I3t+Om9E61fTGzRsMFYw/jz78sBM9gYyXQW1NPQUV7WiF9bX1t586c+n8jfamo1PDqbqyjt2VnI2F6NHW22oKm/Oixe958IPrC7u3H7/n7dcuOeGnsb7tP/z7/+gUidvOHF1aG2/tqG5tq0sW5d24fmV0dNicFXFAzQTGhLWhocmyD0Pm7PxCOr1RXl7t4InmNmdMbMTi8/3D57ILVudWetZ3xta2RlfSA0VlWzux6cqG2KkzDafP1L//g2cefuTo3fcccGJ+ds5GaUVkaPzGwNh4LLFbXJ2IFWzllUWPnGkbm7nx2HtPL6z03HVPe07egkXwP/7DfxvZnRnouZC1v72/vWWfwOzkfFVZja0UhfmFy4vLnZ1dJpYUIt3BGECr4UWbWl8bGB6oqq3a3tteWVtZWF5Y31zf2d/Zj+3nFeaVlJckChKWWYwM9GfUgyVIBTMA01hSEs8AK/i5e4Y3slUcIbBLkGEbd29DBpBJ+Mpbz2ICz75TRdLrztSN7u+5z8/OzM1Mr6VW/OTjIiQrGrFdgWiwFVtI9E//15/jBnVCd/niRfIe69BJcA82BUQP6ueVB+sBaiCCyBIa+ASKbEg1LgsnEtyNFVhN27C7gcWMwk9splWqi7Xo/RoprXrLBwkkVLRoRgkRZDIwMOhtOASHBiJmHEQRQUzZNtTXvHPulScee+zmze4jR4795n/8z0NDIw7SQI5UOlVdUeXgaj3lUE4KpC1iq+mFmobSR564Z2cvxQ6TyAs2bS4urBw/duaN1y5evnSdkDMr8JZwbWwu57DJQyE7h3rDv7NqYHCUhd7+DwLC2T7bG5vBaQK837bj1690W/ptaWzykQsdZ8zm1Tc7NTsyPF1eUr+1Eb18qbu5pYXTxHef+erHf+zxkcmr7//Q/dq4MLX51HdesIRqT3Begg1qZ2N7x2pga3vTMy88XVZZwPHuxOmDR491pbcsO5TysBidGFdtQjKem0ixdy0t64vSkuBo7pGh0Yb6+uhetK+nt7HOnoGa/b2YjTjdvT2Hjx47f/FKVXX1zFxgsEbAosK85qa6qorSeGR3dGRgaXGBUasgp6L7xshaKvLgQx8oL22cn093dhxZW93gIsElajWz56ahqZGqgyd1pSMutEIvqwNAmmgBJVvZga5DBmGyjOjVv+JYnss8BAAAIdjQ++563INXek1fk7Y6nUoCHt7KQeaSyEHMMK34fobol5WEmdKDaYO5jXCB4rjLVpIw/zAQk4iP/bwKSsdSOpGk98IFXsoDZfutKIIYI2yDaMrwFj+ILEdQVkt1VRUEFY5bpJUbLpc7nrFeK5pwVKDPAK5nFZIPW36occlZHLxhkFEzWSnRT66g09NTqGBRwUKYhLJ95ZVXwqIj0T3+veNjw/ffe9/IyOiFC5e6b/ZlmJbA2Mo1708Uzy+MU+W56S+nlqqqSiF+dHyxtKIwNz83trO7uR25fvMmzoxl7X/3e88NDpgtMP9T3CpSazOx+FZFVbVjf5gU7VWfnVvSIsOjGqonVU0zLaJyQ4jtxGenlkXjjLC8tNbUUNPXP3z6ttt85MEGfI4PZrSX+27kFeQQ/Fx+HDLNde/46db6+mJES+etXrveS2v/l//q5y6cv0rDsaWcBWxqlhuPMm3EC/wxjQn1TTWcse2HLMgvtvS2s7cbi2ebouRkc+BJ5uTmO9G0ML/U5qjo3v7hI4nc7MT45BRvCxP0u+++l4HcJsm5mflDBw7pGmeYghgBbQOas4/g+/qNa0XJ0oHhkYJkkdn/337hc3af/Ytf+rWCwuz1jdT2zmo8Oys1i/FKb3VfA2C783i/TkxN63THxI9PjGVgYLHIUMk7ZoUAdL68gRpygFI0F3DqQRhASTAAIQ9YVwTP9GH3EM2YQcMBzBXGRw7PkssfgiX0E1e4PIgsXJ5gLDeXn6AlXLlyAFSXB/kL8dbPYC8YnvNDFgQb0aI20jCQmbASRXInjxUmX3VSRZqSWkoiF2AV3yvgViSgg6n4xLmESgoHFoih7nsFo9KaGDz77LMYTGNCpmeN5uir9l7BuiIwj9xgzpqx+qjkCy+8oOdkq0RV1TZIYm7e3Ym+/dY5diH2j/nFWfYcZ82urs93djXVN5bt7K9U1xSWsmrm7X/sR973Uz/9j/Lys33E5UDn8bqa9rGRxevXBs6f6zFOFiULTAnW08ubW+sqQBG3ukQBU7SaC4FXzSQU3M0prUOJ43gSYvvazZ6P/cgn7rjjrsh+znue+IDzI4ZHRinoKGOpgXkmWZw3OTtmpfnhR++5fPXKwhLJvTY5PceP4Xf+52/VNxb9zef/uris6PvPnrfPa2h0IJadVVNbHrjsZ7ykSNxiDnS5VjPmNjaJ2O3Umr2C8eyc/Egsx4oEi3x+YUlVda0PKNk57ABVTpLW1CKxrNq6ehsF2UYL8gqPHjiSzCvK2c8qKSiuq6q2XtFzs3t8fLKkvOzoyRONrS2VNdWTM9PLayu1DdWOdvwPv/nrf/35v8griGRlb/kCgaOas7J3jJyFhQlMcuPadSYn3YEyyxh32f9W4gwFgaORKQRLMUnBDUkvm7vayaD7QjTreviDOrB2CXQJhAGXB50uRHxCEGbQIcBrZrkNrjCAu4SiCRQNqSUE1BDM0OhZeAhUd5fiMuUE6wByc0X/53//fVHl4m4aoHf1tEjAR70BX90f9n0g8xy5UVUp00BzyExneX1KBaxUIBIde6iH+Aw4XoEyC6mKMl8aVRgQoDncdE/wU7tpPsYTF/UOptVYUxWkPlhCda0AqOVDDz2kFExF+ooZVlhxBvqL75wPCBePjk+NGv4aGuvGJ0buuvv08HA/7+Wq6hK9lZ0TO3nqcHt76150f3tvq6Ss4uaNvv6+ETtUUyvBRwxSqyuJvJjzfEpKCzj32+1+4GAH13nraIx7ZvA7u9Hxsema2gaTSwSvqaokZxx0tTi/1NrY8cz3XoruZfffGvnJH/8Uvxq7Du695y5ubWMjoyJfu3w1N6cgnpWornPUwER1XVlTR934VH/ngSZslU6tE59nz16YmZ43iW9obrl48fLcwuzI2Fhv32JbJ2IWNbXV6J94Qv9F1IGXP999fK9izBwT0zMooLMcpc+fOM53b3N719AQ7PacXkmtO4fLynRuPBGI/N19m2oRihGspb1lbn56a2ctrzjP2XVUdm0syqtamFs/c9s933vquReeP1tUyPll/YMffN+xY0fMSeDS0Rj727HCgrKDB44srqwtLa/uZJyRIDLAUzQw+Tv/MNiYEgtAxWAA3qajGEByfRpKWLIMnMhQIAZHeBAZVMIQ0QJ4ZhYWgEFbvH2XT0KUu4sGjeHb8KezMFRAZLj1CiA9E9PyV0oYU4g8Q34IlvRcau9dKLy9DtGPa1XRM4AS4Uw3gEh3VxK4w7fioRDXw7FUqs6fRPNCfR2TCBRZDvJXIZgm9WmfeNpQ8Au/8AvGH5e3bPnGDbxB1LGuagNHaIMGflAKkxFDPmOOcJqonJ18zGb61tm3zYxxPr/fpnrLtwXjE0NHj3Wev/DG6vos/83N7cVIbO3+B287dKQlnsNGmT+/MPX222/aRlNf19rUcGBuJr0wn07kFhH2Fo9nZsd8qqipuZ4dQ4cli4JlPhyC61BJ96CaNTubdz/z2c/yZF5cWr564/opPkZ33lVcVvq3n//Sa2+c/dhHP8nh9NVX3tK5khw+fGhjZ20/a7un//rOfnppZeFW7y3Suqa2pX9wDFlt7MWuV29cyc6Lf+/p7+QyX+Zk+SbS6TO19grv24cf8/m64ob6psqq2sVlGxJ2C4uK8xJAvGT3HFSxIOEiZFQ9aolVvKLiQqsUtsO3d3Q4jzMnkY/O1ZXV1y9dGR8amxyZaGts3VpPryyS26sOE+gfGrRVJZYTT29vHT998uU3XqluqK5rLo3k7LQeqLrVd/Gzf/tnr7/5TFZ8q7o22XWwuam5Bofb50dpZ1QE3dDyY5gKkLC1Q30wJpiPOf4ZroTrxxD6wAeaulJtwcMdTL2VELlClHsGGNDSujCa1gGkt0JIejmEVxghZBIYFsHlp3B5yj98Dl/JXyYhj3lWn+hv/rvfIp4F+a1B4hHt+lv9/KTVCTcOAKJ6KLKmpjpod2ZtFVLxBh4AcXUSQQiRr/YYRjTQcWekD4W9UuCbli1ViCeNxAme1QGg6f3EP3rhB80gg/1UpdD7aHpm8onHn7xw8Z35ucV/9+//rWMALUXtbe4tphbLksWxrJ219FJVdXEiL2qRdXZu7OixDp73/vYj21nxiDPE+cts7UZu3Rp9+cUL4yPLo8O+I1Zg5ZhFsrouL721FItHGpsSlns5ZuozzWcqsLVgazsyNDjW1NxmBKDQYmA7EXPiuVmR2PEjp5/53vNz0yvf+Pp3P/mJTy3NrDhn4eSJI10H2tPrK1evXbp8+aK+wLTmjj7beL37enZ+blNLvSkjS2tbc7CV+cSxk7ZR9fUOnLjt9NBgsI3u5VdebGlrtqZ2+OjBtvam7t5bRjlOeMXlFc6qDfvFiIryGA991NZPrg16Af0JPKS7cvn6WnrHJNjs9UjHwVrntOCT1Y1oxHHtEw7TOHLy8MFjXTlFueNz42tb6/g2tpefl52cmZmFnLnpwNjAUSrpcJKCPBaInLjJQsnRI6ePHj5z9WK3zOlg+1HG+8CK7RArMMBROprgCNFmjqoydAFwFL6xGcxxiXYA08XieA7lrJ8huEEWTGEDfIEhbBHMaFcwKPxQcQIM8f0U3yuR5Rzb/8EcQ4ifSnEPC5JP+CAhJLuLE2hI0oO4d/rVpSR3ISoRApfw0CXvf//7qToc1xBFelAWM9S63NVDIBCzT8uQpId7ZZhlaj/qmE6oLqyjggghdeSvhRhRIIUew6iPsmQoBFe8/PLLnqmbDh6Uz6uvvcx16Etf/uKXv/IFFpXV1EpxYXk8xRziTAfoL61vqLh569a9Dxw7klPfdaBldGygoIi5umV1bWl7Z31+dmpwZDo7u7ivbzq1xKDEATS7p2esta2kt2+pqibS3px/7PgB5ZKvuztZ/N6cxoMOTqjVhR4y7WV2CI5IAri6mobJmQnqYFlFxW//9m8PD0zUlDUw/oDjq6++nlpZqKuv5LeTm59dXFZAMX7rndefePLx9PaO1eXcRGFqdd7C0Ok7TjvD6PLV6wXFDFDBeVtYpaGpXpzW9lYCZd0Kws4WS/Gjjz82MjkKkcwsKqC3NXxrY31goO/HP/lJGoceUUnkSjjwhvU3L2dxeV1/dbS0L07N9fX1zOYWdrV32f5WkiwemwrWaGednTuymCjOW9tMJwoL5iZW0rGdg0cO9fX1dx1tpzRscxjPzcrJizoLiU2Hwv/W2+tOY+8bGrz7rgcoh6uOwHN+b3SXBZyBGBIyP81KA50bKjLSM3BfxZPFTkrJHNwL32qrAoALiLABLeILcZeJS9rwFRyLBhIhmkNWCRHvLokQl7eWJoWEV5ihfCQHKnfoUpC37p7lH+UdqWYkChQqTBl4l1Sm4ag3ZUaXK4DPmdwFrhsvM6oRTNPa4RiCiTeNMW5IbqiCVEnkFg5tpJS5rCJ4JeAHrKVEQwRC8PbRkcEIXlwsE+F6OuRajtCvvvoqVuTHf//995tUHDjQ+au/+qtczTL7OQJ2peyWlwRfuHC+vsnZ9MzCb/zmz88tjM0vjDW1VNu93tBYy9nTuVeIiUBT03P9AxOXLg0MD0ZyeQpkJRlVHFZYVpFIlu7lFe5UVCUeevheBGpuarPa0dbesrgwZdGNMy+8+i4vNd2UDjUptYgV3XPQWVZ61cFEe8n88u9885ni3LKl+eUzt59yQOPk1JjjCfWIv0R+dklF8Vtvn/3wxz765a9+LVlSNj09++GPvLe+pgSuJsbHnQENE1QSp0bzx1QEAgakLnQaTRXaDgz2JfJzVzdXdvd3vLUIxaUZ9dC2MOnwo8CYhvi6ybf0UF6Hbm5H2WGrKh2iUpdeWttYWXvrtdf3t/bqa+uIrKGx4a4jnUXVJY0djcU1ZReuvAO+6ZW9bE5+yWAeKAeeWevrqf7eWyYDvsFB/FvdKy6qMepUVzbL2VmPaGXuyw7Gr8cowdPFsht06V+uogSWhsjNA7QwJSEvnMAfgGU6cVO/g6lnsPFKQ6T1QNHQEOFhZfQgNEooH8+SiI9oWg3QXgH03nYwFIQlSigrBPFTBKnk6a20QuQjhxiPYnhVjFDFeHBXM9YYSPWscjLKDLLFoaVSYhd1Hz8oXjR5QTl6KUOdlIqLPFAEzX0p92rG0Y3IlD+lyCs5sOo8ltkU9rWvfc1kVwWUYjInH8xghNHrjqnhrAL0zkn59V//NatFDkhiaDfNSm+sL6+kRscGHdG8tZ2em1/40Ifv7b51eXZudH1jcWt7lZuDj2Jxh1YZXwGORuLWNUeGp3gN8BSwPTW/IJuy1NRc3dbeYHNjc3ODqR6uRixnWjG6oxfiOLIKcZHCupsGmhbTd4leejbXG1PJ4BC48tLZhemBgZ62tpb3ve+9tHh9b/ZkKEC07Nx456EOltD7H77nW9/92s/9wj/d2k3ffe9dRcVJK9CRrAhHq8JkAXXfQJc0ESeMEznmuFzH9O7y0mpf72B2Vr6DKoh4Gqil62tXuw8c7GxpbjThdpQcrdTXVK3sWkzc3jKMLINaem2ZOldQwGKzXddYW99Yz8Sxsro6uzi7vrXR2NZSWVdjzqDnLCw6hcV0YGFpfmh0iFZmlAiUNA6mHBRyskxdTGsjWTv5xXkzCxM8Nd659Nb5y29tbC5vbi9ZrIjn7LobZnkZ2r9GEsJGKK10KE5GVUJT14MdgCGpEOiELuFCPLsQHH5EQ3APoSJNvAKMt4BEPkriwT2ErgcIDGGtyzzLDdLElA/EuyR3l4NA2YY5eBvnDq5yZDNBDqnQTPxT041WwkNkG0NlB5oAbSIrL3o/NR1MQ3OnlohAiitAXV1CwnpoLeVHiPwpOXzUlKj28G2pwawXl/vCF94AFITQ9/CqipLw5STepLp+/er/+B//gy4RyzI4xglyh9rLuaamdDON6KtLy6ljJ+rGJweqagoi0bSD+fd9cWg/p7i43LlxrG+7O9NOmxocIJPXKfT5BU4UjHOpImkcGlJZXZidu8XSV1ZR7pys7Z1dQtQJarENM0MLNJmlk60NVSWnnddKfDrib2J0rLGxaWhkgH1mZm7SGvFSaunGrWs1lTUOorpy7aomnz//9vTMXH5RfGSi/4Mfee/U/LQPIv3V5/73oSMntiNbNPuaysLZ+Xn+N+fOn59bnD927DiqVtVVORXPSGlOde7sO3YasLqZLg4PTRSUZCfyc9ZS612drTYcOz1isK8/srs3Mz2H4OQC93wnXBTl5BDz2fHE+tp2LMIqP++Mdh+yf+Q9j5x969z4+MTR06diOVkLqUUnljjDdGdvvyxZrn91nOPdWITy9wsDAUlniAdmvYLCGm6DnGvW13YmJmf304ury1ux7MjAkFPyNpJJH8ksQ1JSNLK/bfHRoV4Gc3hwgbJLzgGyo4H+DXlEiQtqFSEOXGIY0TCGt55DxPupGiKICcHEAYh75WcYLrKc5emn++rOiqykElkcGUorXMKwLM/iu5QuToxoBTjQVw9IFc9PaNZmIR5UWhYYQ0o8YH2ANuIn0S4CRUUnkVXyMS4LceGKcACRVj4KZkGSLQdPg4Y6KQgjgTh8a4BCMQ9uVm92UqXITdFCNPXTn/6z3/iNf29CbCEbNRhmGxur/sN/+HcmtcZVHmzLqcXK6vjI6ISzyHf3mLYXfFMaz5s0Z2bPqZXl9M5WtrXeoYHF7U0mCAjOcoZzXsF+RVVOeVXcZl9zZSosMcHYRzxkONDpn8EyhTqgF6ES1DDBvSTKB5Th+/0feq9J3craYltHy6kzx2lc//TnnFlywLZ3K1Yif+D9H+TQz37mK47v+8D7+QjU1VUdO3Xkox/7QHVd+YHDnTznmloaHWD4/IsvFhQFIubKlcvIqAgrfcZYR9xOTe187rNv/9iP/nhH+6H773t0d8dmgHLnkB/oPDw9PosH+nuHKkrK77jtTFNDc2fbgQQ1hj10c8sCIj+lRC7ZZPk+6gMcTqsuKCksq60oq6lc291MVpa3dXWaVa+nNw1WlBZTf6qO8c1uOCiAJOIDC1heSK2udff1xhO5PQO9HYc6N3bT7QdbC4pyBkdu9g1emZ4dWN+Yt0rA6ByN2Qrs07c5hiBWeMREOlnpd5T0LMRPJNX1IZS98jMENDAABnR6BevihzwQxheON0SQREx6h2c4Bk7RZPtuWdKGDBYyAFgqDhTfLVF4AFbZMTgaaFj3iEM/5UL3kJ0YYbWkMYoBvSkB3V15YB3yiRzMjKk3oAz3kK0ZrKIuCJYtuR7wfSSCYUwuCVEKvazkCeWyNQFwd2EJaJNEJmpvzsAohFj2+6qVIWKJFrvBJSY4b/l//t7vHDzUZT23tKKI0cuZsRXVWUupmcqa0rqGqqmZcZtI1p1Os7Ju+YHZp6dndGJifXEpYknIKhg5ZP0qv3C3vCq7sNg0asVXSndo8sGoLV0gLSyHMWIZCefnFlRVCBwF/Re4qGSL7LzySNTcIHaz+/LgSK/P3W1sr128fPbe++44dAif7/76v/03sqqtrWNjxQ+wPrc4Z+ewY+ZMUllsuaPGsuOk7yGfoqHfpJ0z18F5xRygt6+PHZ48XV13SkrkL//v586/c5ku5ITG/R0Hb9VNjEwDcnY00dVysDRZtZ7atlybLChL5BTlZRc11LbGo3lYglTeSKcSedn1DVW7sZ2B0YH1nY2uE4cSpckt2kE8Njk7YzU3M5MMvoGnaYVmz04n1f0Z886Gw4lizgRov/Oe+3ye/on3PrmaXr3znjuGJwdmlye5jZhxTUz1j4732Dq3F0nbX2kEIDtMa41IVH9qSMDSGUkHPHCpH99FLWq6AAmJdDdY6wU/YToEHmwI8SwHmYYoD7lFJiHzqKuEuklCgeEoIb4r6MrMGoVX4bPchIQJg+255LcaYAOdTS2BV3PTcEZLIQZZReINfe9ZtaRUJ8MliBPtmAEjepaJVDhBNHypPX5S7kHfK2qVn2D99a9/3XoCWNNtWI0sKWAMJn8txBgktwxxo29K+/nCC89Rt2jYVlW2thfxncUpJ3+opPC6uppkSe5PfOoj//E3/3d27m6HIwlrSt96+2p7RzNzW2lJxdWr121WTK/N9/eOV1XUO3cisschmrSJJvJ3i4p5U0by8rf31jaiWUwd2fabG99qaqvIi9IyH3idi+4Hq+4+1WjZlf5ty11m4zzrmSMGd53k4+vwNVWtDqwtrmCBjb/3fY9OTo2efftSV6dtCft8AZwTahyg2JTVFB482HGj9+ZWao9Btr6plh7o/B8bd0ZGhzNSbde5ovavcYIqKjQpDJwg/t3/+7PXrt6yY2Z1eX1yOpnmHrix11jXZLuv9axbN2/atbmztb+6bHNAbHN9OxEv2Mret+w1PTHDJGLD8oZPurIRry3bz1lSkVzf25ldWThQX2OcWCZD0xuJ/ALLCGSCjz3xNUrH0yvLgQxO8DPci/DvsG0ammfmp0i9l199paa6fnRquLy6LM15Mb67ll7YmQ7OznHARFvroZx4MdcmfqmO17MiAOsxxM14tkGObF0hmrVOiGfQhDEgCfEq0ANMh3j11uVnePcA/ciVCQ6sOn561k3Kog2CqDjCZeIKS6RihMmxhxLDTBRqPheY/JXtAnHdTwyAtUiywysCVUim0otMEitPuBwFyh2mYZELvokEHGMVui+4Y0eMRLkK7BWZdVw5GyvUyR2vYwxen17Zy2JgwWxwb+7F4nSz+zp9SUHmvkCP39bTW0eOdFy/3mehiq3M8MgRdXVt5eRtp3klHj2WOzyymV/g+Ccr0O3El8rTZybHx5cWN8dHIXm3qqIkkbuxG4k6Ob+Qj1DBdn5xLJK9YYyP5uyUV3E0KMpLlJZVVFNxCjjg59nhURjd3s/NyY/vBP6JGX2Ap433UcfPmC+q3pHjx9567VxdfVNpsjS/KMFkOjBtOsq46ORxrhC5nQdb4omdgwebrlx/J5bYqaypMB3jqkEq85Iora7hhTczE2yi4NpNrFikO3XytsG+QYLAjkgmeWZcxzyXFFecPfcGn7nqcu5u2ft72X23hq9f7cvJ6j9y5JDOP3j4QH/PcHNrS0VZER+kvd14WTnbxorDHPhHmLYWFpZX1VdvRGPnnnmWBG7raHcgSkW1pd/AZVJvrqU2pS0qLNg3WGxDoU90MaHw29mvra9l1fS5S8feLS4v8iXY24/lF+ZaAjAFT2/sMGo5xzsWzc41ZUiu5ueVFhaUOtHFiKqz9iPBqLtrYWwrEM+Qrb2w6CHEIiCF4hydM7gNeAMA4DgMdw+vd9nDK5nIQV/LRCpNkLlADyKHbBbGFy4OkIfhYbliBioQCIZGfSKZQq9U6eWuTmrDrg/3uhNeJePqJIvJySmwrqqqFkhhxgMcvyQ8cOCgyPxVrAOQm5ILND7gFmUbDai56qFOKmdubZQAekAJG2DB4YEHHlJK8Cmu/CIP+sC8X4nl5Vzr+hxIo50lSd48sdKSpIWU7p7Lt/qv1dSW1TY6L2gyJ4+pZLO2rsNscGxseWsje35hY2RoNxILTFJbbKy50aIShtey8kqTtoSTPrd4Ve0zQvObzqbt1Dc2Bav9kfjkxEw8N39qZn5hOTjKRh24mZrYGdPVH+CouBS2N1/zAb/g7CPcWFlZGk841mF5cmqEL6R21TbUcyB1/C0HG+MYi0pPbzfBYnCTp/nG6lratAeVGPVLymwF4KhRetOn3m3VX+YxtHzq9tscAVpRUzo41nPoWFdg+WlqQb1nvvds9/W+2F6ct+ncxOrRA6cfvOs9iVjSQkRFcTUXPfsTttfNBIIDCnxqO0BVFl1xu7q24tjJo43NdRzPbt66MTExpqOpYbqGMMVvRjt+jtk5CYzKn5nGzlLkGwK6AyPhSj79MIIUpICDrsxeEvl5vsxh99zAYO+VKxfOXzhLgcThZVyokoXO0uYXwUVv19idlnrXmJCTzWWROYafRtLhxUKEW0ozFmUER7C/jFoRohFQQ4S8i37VMByR3QS/BmqmLvBWtDAyxMN2yBvGHz8RQG7hWCTzMFrwLUdZ6A/tD7UakzDji7KZg6CcyNdw0Zjw9Tc5bbrb2tI+PT3jFJDS0rLlpVQyWWwV06aTjnZbKPOcT8ajq7ysUhJeDCa+hDpJodvkeeedZ9Se5Zgd6fHHH3/qqaeISS5IhhofSvnGN77BKsv2SPEjwh0W7UsqyG1wD6zhJSXp9VUb/draOkn0+cWcVHphciZm/61PBxFnvkhbVlx56+bs8mLepctD9uxyHMgBSp6F8e1IfLW6sTi/mP/MUFlV6fHWrjV7tzbWK03yVvZm52ez9rMS28z2ibmFVFf7QUN0aVX90sLcyZMHTXVsVLHOk7Wzv7ayXFpUkpuVqCip7um+5eRCxwM5aygW4cFWesM30Q4081g7cuwYbD3z9HM/+3M/lrOYM7u4Yjls1OnmexFOmr19b7c0tzuQ5fU33pqbn0kU5Mws8szZqqysSm2lkhWlTICDE0MMNfajGUiPFwWfdl1fSZmvv/pyP43ljtN3zU0v+SDZyMhYVUnHU994ZXMr661XLnV2tjVU1ucV58TzI7f6r6z5DP3GDgdD2iP13paRspLCnOzY9lb62NFDwwNDel+PcByC9b1I4dySZYg1hsTV1XmQoiHPznOPje7vRHA5YRcJfMliO9kx1kTMVmqVs294c2vUnGtrs2dxYXVhdvVb3/zuRz/0cX6BRQXFjjrNigXH6vg8EjM9lKrDVnoHCq088EhdXgjMJ97u2Zq9mw6WcwMVSDmBWAIPP1ESLBmAcNFONk4KlHiIchUXFoXjhjjKYabjbGpyFd8PRKcBzIGXpn4KNldUhGs/FvW8uZoKToTFEyEnIQSm8ZpgxjrHjx+XIxlvTVcBOMFbgtliRxgBqzim2Mf1hDMHuctBEpEZwvHcynIwN4Bsyo9XyWSwq93qLxWopKSM7uuME4yHUbHv1SvXf+yTnzgbbI6ZRZpM86wq+DgSDY3ZcdN6EANLJOp881b3lZXFyqoyanI8O1pSFsgDSr+B1Id1mX1u3hyJRXShutHUq6wE8+ktKc3b2F4BgaLSwPlkfWOvOFm1Glu1VQVjY3JCt3hn9/iJk9S5nb242Tan4hyf/p2e9dFjKOFqQJIRH45zsyjuq0ctLR3TU7MkQWBRLalIL6/9yI9+/C//4ounT9134/qN++594Mtf/dvO1+qzC9LFZY7vncDbtIK777z37bevbqzu8MKfGJu57fTxG93XCODiAi4n8frGZpZKanRtbd1AX39LUyPAmHZXVdbmVNUsLyy2tbQmsgqMUXubkeaTnXPTKc7RTmUkNY6dOOGzZZSlO+86ff76uXJb8cp80LsmGs9i5k+tTpoQOEL2yqWLR4+fGF9eYdigrxpp9WZZWXN0M06gks7WKDa2NsHDHAZCtJ3LfDJZBKn6FBZ5XrH4mMwsLqUcQ9HqLKPVDc4UzMjZ8chWev3CxbP6vaWxo6WlnaNeIp6TFZiUOCSjvZSBMZRsDcAaCz7LGw6t9AMaJm5hcqCGKBoYXGAJSGAJ8bAhvrfyAV14o18IFId2lck8GDHCCO6uMAcRFBpeGuIh7gAFlQhGyUC9CWCkba7wpyLD2JQTCUxY+/sGvQqrJTu9LpXC4D6slgr5KRADZGha9vzzz5EiLJLiYAMTDD48cmYqbW1tQ02ZYLMHH3zwL//yL6sqKvoHetdWeR85qjKlgdz78vK1s4g7bkMjP9/kYgpcZ5wEaotFZ2eX80UwJAgGEmN/q6e7b3RkJh7jbZqqqw3I198/kyyOnLrt0MKyaZyjr1ZERhTNBHrtQj6amxrqMFmFayMaLmQzrQ4ReoRVCMMX+cOrXkM2N0ctdeWVBEd9abhRkeNaIqegvaV9dmLp4OEj07NqeGBsYvTJJ5/8xje/9s/+5c/sRR3Wsuy0g/WVrZXljf0dJ2iUFlUn97f208vbBpOqZO36xvrWyu7i0lRNVcOorUUV+Vup3eW59Xhs79CBrq3VLV4fFmySBRWry+fWloNPgtnCX99Y09vfjVC2z6d4g/sMUTRyrfumA0+N0vygmaFMLPmEMo0t2Wq3s2etlzaXE89hKWJb14qSpINbpvnvAZ/uY8nQWegDXkLQCuaoLESVQUB8Yim9tr7G3XQ18PfkgZfO25icmM4r3C5NFtbWNOzvxEcnBwMXxrxgt35WTtTMxzEW5hU6BQYAKQPoYNqKvNCI5iEDZECrZ4IF1sxzoO6jszt0eQiR6cElH/VxD0AYvA8uWYWRw7uCxIRY9xDSP3jLDkMk4yqt1cHhUgBEBgMf75PM6baimteihalCqEuJrzxEUbApBLkO66AvIWx5hVhAymsFVKhA0jL7aAycqaUHiHfuDUKbdquAmhG6cvjOd7/1xhuvGawdRM6DraAoZm0rWRJv66jOyd9pbK0sqczb2FuN5u5v7PJ735ryRb2BYQORk77JP3uiCRgVnplJNTWajlfqvJaWSoMcx0nM9p73vMfcA9AVrdo8bVQAe2sXKaD+CKQmOJyAF8GUFLiTrEUk4a4ZYBYRXlfXoEVkp2hcQ6wQqLmmvfD8S9dv3nK8YV1D462+W7GcqE+JDQz2fOYzf2UowzSlSY4SK5H97IvvXM3JKjBGry6u767vt9Z2nD58Zm8jVl/R1HdjqKm69dnvvtjR1PXS91995L7H58bmFqdTu3zYgr2aTdF9pp2CQwePPvTQQ/lF+YPD/QcOt69vLkXj27UNFVNz4zux7dNnTlZUVx45etyq0eba9tz0wuyMLwDxB2dAsNcg8HJKr2+APjO9w3RtiyOIp8anfbksBJMBX8/CGXS6yAjCUXuRyDPqeaXVgGUuyppixd1Dc0v94cONdY1VhcWJ/GR8cmb4SveFc5ffSG3Op7cXUuk5yy/WiUVmQTbF1TvSGuEp8VBhXhGiUy+E0AqLA2ghulXROtEVli48RD+8hYNDGFNk17tZQRe+FUcvC5ePFoV8Ff2D3/lDaAZKGdFGwFckuNf3oYkTY6CFxitSFqIpQz1kocayk3vAeRk3CmkJDEnEl61nhoxnnvm+7WAqHSpOPu0mQ5wmfxNlyz0vvvgiLcv9u9/+drIw4Wgqrg082+xY7uhsKq8spvnU1lUxP8vw+s0b7W0HVOZWd58NXyWl+ZzawdE1OcFzqeDSxZs+NBT4b2WTMQ40XqutK+YZUWwNqDL/nofuePv8G0Q70iOZVOrJBoUcfrIBhKMfDsEVAaFzfZFq69QJp5FeNWG2y56hzZWZMtpUukedu/vue+wpoe811DXOTSwV5ZcMD05tm1vvBEP8WmrO4YpZuT4pUGbMOHvunfqGLl8lPnTg9sH+4VtXr5YWF964eeWe++9sblONqC2OjkjpuTVEvejtHnSEwh1nOhrqql968fWf/cc/XlPX7FNf1niefvppqgyftsmp8dHRkTN3nOY8Z569uLI4PDpM6HCn6x3o5Q/Ct4KjDpU3wfJl/hGNs0Z/73vPorz5m419fK0JO4q3EXRtg3EtOPIMHQAIxJmqQpGhx1ka0U1364iV1JKFtuxIPOPsQ/oGKGII4m6MFEwX+bmFPKJJeurumdvvLPLx193cipJmBzLRovES5cW0Wt1oK6ClTw37AUvkBv4OkCVDYAMqF5oDrip50GXYw4OfAsPwEO6m+5K4wpghG/gpf12sCfL3EEb2NjjwUbFwD/HaDLvaJms952LWFAlcANr4ICM/3dUAD8gLplVOJuqqTsLlrm3ieDBeMQh+6lOf8pOtUxw5s5kqC4kRnYnp5ZdfeumlF7/0pb+ToZZHuR7sclDb41jS1Fx14lRnaUX+5BS7ZN7+LGtSomrJ+W25JQxTqXLa8PDIQm5OzF4kTvOYPCe7sDxY1N33HaPumyxUTjYOjnQtLbQlsnJxZZLh0oTSIE4kqJVC3dmsIB4/m6yroeEOrE1RmGJrq7hkz9VU1QYTTftnS8vNAazkIBQpSJXt6Oj04QmAC4aCROHzT7+ysrT6oQ/+yPpK+utf/UZDfe0dZ459/+lvP/qe+/STI1WqK+0uLy7M91lBZtui9ubOeFa07O7Sl196fni4oTj45FxhsrD0wftbeROMDdptmW5r7rhy6XxDTeU7Zy/sRq4fPXZiI71mR3BlVanPb+zHtn/mn/yEZWanIFbXV1bul/r4Ul1jA+l+W1kSMa0sMRhnO/bF9z/Y82O+URG3tX97y2SPKC2EWnvNbH5Pb69FNlLYHk3AwEMGW4H41GVoxX6FOHpcF3sVCIjsvPnZOcDSoUBmegNbTpELsmX2WEpXlBavrM1Ozg2sb5d2th7e3FjZjxgF9riQwoNpD60EDxiIdBMI6QWTFKWDDzjBpMp4pQiXzJXuklYF8ElYEzFd3gZz6R+qOh4ylQnu0orvEgjYejm8gqFNXypVKKDLRXlaqwDFYAwQ95aGA+WMQh5EUFE/KTnumu2n6YG6hsUoA7gVgOtKy4qYOCRxYiYXKmNLZ+cB2TpOB1m/+tWv8K0gSySZml6zuGMnE7t+aUWytq6ktb22rCLXUlJVTT63k/R2Fo3o4NFWrpfzS9NlFUU3b12zta/WN3fNYfZiG/a/2IOwuma5NLW8wCEUZfMLEvc/cFf/wM2R0cHq+uAMr/ykJi+onsHXn07UKGSxVuOe8en1Nbglsga99AR12SotMYm8W5vb7HMe/OmzoYEh9IEJU6nXX3vTUvjd993NhP/p//1HTzz6hIPUR0d9RGOz/UBTbXX55k6wzl1RWcOXIthNVjq/u2Ov3JGd7XRvXzddRV/Y6lDWWcXjqH9woLWl89iJ45/4xAEDY1NTXV9vt9NP8ouq2lu7OAUS7bt76dX0ivWpWG6k/1Y394T1nUI9yKNpc2+rzxkNjpNJ+Uj95Fo68CpN7saYLK3lzc8tmV739vbbZMOqMdDbB0k5eblL80uR7FhFZfBFMPQJBLJG5idUW7YQYmIKTKShDsX/NlzbE2d3smh8BlHF5jDLLEU7wZrpxqZpfGpuMTjJZnQiezdSt7JemdiLFubbZVEQmF53bWiGSxZVx747NykL5DLoDBzX8BHVxINwHUHaQpdy/VTZEMqe1UccqUAoiJlx+/XsEjm8xPHTXTQNybwMbkKif/R7fwLEmgqO+pIq5tk7neEnSemZ+s5aL4RcZBpStsjuBCcVAqvIV+XkQw8Wrn70Y4LW7pmJyZHW1uYbN7pF8FXTgC4bGyYAr7zyClOpn6SpA9Vm5wImKWV5SC8nixOHj/DPZJwsovdbXY/ZO7G/kywuvnrDQlt5e9vBy1dvpVY23nrtkoMy77v7uD6GwmDGklvAjdl8dHszxtOCpdlRIiTt3PxKbV2iqa02ntjySQtlaR16eSC6EIIg0YtEmhapPPXXA6J3X79F22mw0NXUyFjFLuTMBxQXHdf5bjsS3bwZnG5EgZDD0MDI4OBwbNee0vWEzZi5sY30alt7Y3FRHmNL2mbFHYuXRa+9eu7YsTvNBAaDMWfH7pmJqZGK6uK9aHAywmOPv2dqYh6z8Wh2fq3PkN53713d3deKCsveOXuT3cmnhR985N7LV87Gc/ftcWtqrt3P2m1sbkDP5tZ2h+kOj4wdP37ime8/WxJ8Z3ej1KHJVVVsO/aI+TABPeDytev0HwOavgtWirOyjE5FJfnr26s8VY2EWo1/CDIjPVqplcuBwSHFyD4nrWMAzumb64H2Igd8QknBMrQmJEU9koUmaYUEkV3Z0aI7jj5eW9nmwx++gEYh0F/8S6z34HzUk4owZQZl16FteCZ3IBDBXR4CyGYucPIWmsOfwiVXjQ2rlcxJGUYSCI0uccSUQ3iXTxiuzoGXvC5Uy4AECwtywdlEPq4VyRRZva3UhCinC1rVY9qnujQ3t5j9OiOI3mwQwDl0egWrhEktIUGjuXr18szshK1tHBvlOZETzDUpr8in9liXadgXtXwtNDehU3jFrBUUxuHMFq3p2XTnoduKywvnlzdosIby/awCe3yNZk6wimdTT2MdB5qGesdoILDl8ydENV1IVUOSaX9VNXtFmrvOqaaqhcWpQKI4N7yUv1eZt+pgLsR4oo0aq5vRwcdSPRSXFGFLh2HZka+2jLxPP/19i1DGLl8m1Tqd7RkFJibG2bEMsHjUhPPkqSNGsM013lplke1dpttnn/lePLueQ/LW9rrdJ5YB+BYeONjuy/KmrX/xV//7meefMcPyKez0xkrv4K22ytZXz71SXlLNcWQ/e/9U8zFcN7NMC+S8OXvoyEFLvBdfuXDvQ3csOnJxYeXI8a6BwVsNzQ1zHMVt58rNspTG+P3qa6/B9ej4hL3+RrBjJ+ptod/c3rKlwfDi1BaeC7pbv6xtrBFwxNbI+FB6K5WVY/dcFwCEVgGwQRwk1Wo8QPbpbsoCYyWe4RASz43vBrKVjTPCegFtpWWB7UgODADVNeV7kw7GWsrPy6mpqpuaHs2NO3zAF7MBjIkve2F+wSEXQA8b6oCqlgthXmdhIfnoqbBDFQHBLg8klG4itoKCM56hKqlDnbMNACopNyJbZA/y8Qzh8vFTDT17FQBA+yXQNtV1l69M4cM8lVTzyiWOlEHJOzuh1FdR+jHEkxASyigUnMI59rCrmPWS8UePHrZGgYLYg0oNo88//7wi+DsEioez+fciPr7CnrixaY2FcSCSLOKEk1XXVFlQbEXD7sLN7NwonXh+ad5pDsWlxQC0HkzFt32wV1WVaNbmhEV1I7EsKFKQOLgotKGhVrUZfw4ebtYlC0uTrPgIFDbeK5RFX+jH80gmB2LP6I9e8O2BUDc/ZiShOFFydLnK6/uhoUFCgRl3Z2sbrYgW4SFKnAt0oLOl59atV158qaujPZ69e+ToAQsXnDJ6+weJocLCssnJicamdis2J28/duXmxb2snVUfhl1fYMHqGbg5MTd54tRJHnvbmzuLqdn8ZM7geH97e/P5q2/bc/PQ3cduXO/9yCc+srgyf/zkEV+pudV/48wdpwLXjIU5J2MNj46QTfFsRpuSyfHJxpqmV15+DaBt5jb2n7r99LnzZ6vr6lXevA0ZCXiDMFG9lfHbKSouyi/KhUJdJhCJAlr/0LOSMNVMbAAStmrEeZnu2ycZbLlCTw6gjsoFtYwSEXy/sry0LD8/r7qqSj60vumpyYLcfSuV+5EmUmlrU85kEPf9BFSzsIEmIUKbVRDZJCvokja8FIHUnkUjtfWjZ73mLoF6wuFqel1l9GCIcoF+qo8KiyO5EA8CpZJDMHcBcf2tp3V5uPQLBxqv2WJ4CxyiyRFQmEYxun2u7DbWPrEykzzQyw5KxsamzBQ7O9tB3L5163WI67veDhy/cePat7/9XUXACvSzqNjJRABQZFdS+DVSUcnuXt3UXFdRWdza1rC8Nrcb2TFy7AfHfMSlwreoFOe1lhvssmNhdFlQYFe2FkJ1MGwx2M8F3wKylJK1bT9HTlaiMDu1vrI7uT41u7a9v9bcVhOSQNNCamqdEK3Tr4Y4BYXqEHLTOjH8fffdd/nShSNHDusbQsEk/sCBLsRBB4vfuILqzNyOOOMOfUnEu29e1T3bO+lDhw+wlPN3u3Xjlp3phnu7hO0qtrErWVZw+dK1xqa2yzfnqXa0kKn5cZ6tVfVcm8ur6sp8MNwIEM21T3azqb1ueKz/9jtPOHNlZWOhqqHMASpOGaIIzy/Pl1WXOxKWqwUoO9wcTSamppDZpBb46FSHjxy0751RKBqLm80xj/JZWFxesLM+4ti2vIQPnFkiC6RJIpuD09ZuoAPrKV0PKyHcwUOTRUY0aAE7ICP1uAEBE+qJvM1MHA1A7K01Mh8j47g4MzXFTERqsMBa0txcT83Mjo+OFedkF+TmoB5lO9sezsxnTawQc3lknGXhsT84YDZGJBmGF4ypWHgpVCmq5Cd1yCupdKWT6sJulVYN9bI4YhLu4uhoV8gAIQCC065p5EZAspwyg++9plKTpqAQDhy4UBbudHqvjDxmAsZBKJQvwvnWJ2TIiipCYVAwN7i77rqLATEYCtO79p0999xz4xPTdbVVGdm/os4+d7KeJvjZ7SNNLdlciJ1lVlpRagftfrYD0tby9my45pgQ55Frph3ZTzmkbdsxD8G029ctAkGRGZB/oINqkhCd5LNUpSWV58/frKwsam6ud+BzQWHOiZMNe5Et5FZttRU56KfMjEqF9V9IUCFopC0aqGk4ifcOV20nN5pPO6CzvrZmeDg4k50SXFzEp2M5IPHulkFc0yzxN/BRTSZ/9qd/xlaRG9dudrR23Lxxiye3MyZa2tqpfNNzs1U1lZT4q9e7Kysbl1MrDuqytm0lp/NQO718dn66otr5U93Hj54YHR26+6476hrKF+amVpfXKhp9KDv32o2ryZJC1kaudZSil19/mdxhQZyZndM0Njln1Dm5CCbgw36u3P1ELM5OxugSI1ZicZtkIonCXLplDieHuE3o68mcfO4Y7DHQhhpgJCuicHk5GA/1PoKwLqIPHvOTyQ4RTKnFFzkkYMAMER/6joyMjnBCSBYWm2AwHOdnF5QW2uOg0202mg328ZVWmzabAGTHC3lGrKdXmSjJfblBnYIYJGSrCfrUFZaCRqjtrmj95cErbQRuP8UXzUOYio6EN0L0qpjI4SWaSxL3QMLhY23TVEbPwDacOQwCM3mlI2UhMYjIzviAVYh/Xv5qIAuRBeIH1QpFqSSK/Imf+Ak8QJmzh4SS8N3vflc+0O/ri51drWvrS0XJwoVFBuFIa1vittNH2zuauKmlt9K7Ed5SG6uLLHdL2YndjZ20LS/OuylOVhjoHOpoars4SzmRd3alDfW2uPhOXfAVsyyL82ixtTXDJPvkk09onuqhOqIHKpMjstYW9iJ55ovM+cjk0sekPvuPTyb6SdtmF2ICwv80Cm1kVNIxTFWsqDYKmtDDCk4g+BEQ+o0DgfU9M5tvrG/YXIubClw8f6mlqfVrX/3Gz/7UP/7Kl7+e77NFkysHOm+zC9nacHlVpWNI+Iuk1pZP337X1Wv2mpsm2m0Tt69SnVWXQ/KRwwfHRoKPgftWn5VgRzOMDo9cuXm+pLj84PGOK9cu3+zpNsxux3ara+qMtDQCpk8i29FAMFRdVVFUULi0sMIFASqD6fU2Aq9EV2PGVT8JF79Bbj8Gq9uITCExpukpyVEDtnSxrjf+MzDoYjoIMKC2Gjr/HDMAnGgewCOSl7FXkmd7+4G6PzF5+cJlH6RhSt5N72OvkbFRo0Qsa4bJONIWM6AZB8rLimz/AUKqDaudYVahAG9EUZBlR/m7BIbQx2kuIfpa6cJVJpMkMELAHrEVcov4oqmw5ngOUJ/hkDCr8GcwlVYMi439AO6M/YSfEECXr/QSQzYO0UjSnQJgK5ZoXhkliUYJ6UuQhEzsJ1jI5MmFjg4TZ7uwMyisClJiVT6bqJzxR4gfPtp27323OzrB56ZZNoKOyonlGRt3Y5GcPaeGTI9PswrDXEV5rV1/m/nBOQ6ceB0P6IuSs7OTmqdcRgN1NmSFO9Y5xnz5y19mF4Lm+fm5ispgkkqVamlpzs5z4Gmw8UIHqxViQXnI4QINg3oCEbXaTxXWrrq6+hvXrmFjQL/Vc6O1qZGehgLibGS2I0nCYQm5NHkxtX78yFHCcW1l7X3v+eBrr54tLak5dvRk9xe+/JnPfOm+++/3ceyK6pLd2PbtZ46vfe0bzig3BSLu0qvredz0ggP1l53+u0vti0Yfe+TR7ls356anKsqL93c2T5w4lt6OrK3TdBeWUosf+diHbZ1BaqeK+rZFaUncthVLvtaR+np7rZEZ1bgu+1Y2lHO9sba+44AtVp19np7k6Kb9jhyUbVnO28u1BGYxYXMpGE41BH3QU9cjHaGGGpnwQO2GdeHeBtjiaMk1Bi1485u0yYWbGlmzuGToa6lrt1l5ZmrGEWZV5WagkYFhu7ojJcX9NJTAXzoYRhI+CV5Syd4Y80FL02hz3YzyYtee8fwHKlAId3cXKKrGu5eqIj7QhwypyzyEwxTcqmQ4FIgjXNPE9IwB5BBMC1QdrMFFbF0O1oQQKCtJ1mK7tJ8aJy8DhfmTVzhHiEHDW7UkR+FAfMm5VesViDEbZpL71je/Lf7M7AJ4HTrUwUENB9tbePTYwXvuudP2RVYgThip1YUdX+UN3EY4I0foQjV1znTgiltdVVlH0eel6rxhVOagFnzgNrU6PjrubFv2ZLOxjS1HKiytpdcJvOLSZN/AJM90iW02N+7bbCUCsqqtJqunKnlWE7LN1mTdGRIFY6OXcHT0bKqDtSiHjz768M2b17Ei2U9plAmpZCKIPw3frEbOFd3d3vR1+JGBMR8Is3u5uLDsycc/MNA/HosW7O8lBvsj3TcHFxbWzGn4vT77/HOjY2OcSadGx+3j3KcF7ew6vqG1ocmus2NHjra3tRnvsyMxn9xLLa9WlVfY9D6/MFlSUTAxM4qL7MofY77TZSurFRUOcow7kQpQDV9FhcHBo4OD/VysJ6YnOLE5unlyZtIZ3YbHEyeP02PRmQFnM3Acsjs0kTE0FyKL9upcxAEXP11QgRQI4tkr3e2VjjbuIRoVbmZuLoSNfieDbNQ+3HV0fmax53rPres9ubFEc13L5urOUP9QkVOZs6krpmzrPGVIQ8XJFgJNLxkAZQiXMEkQA5VWQKOCXPpI6SK/i2O9EF5SubxSt1ByieNSbeFSwTamdZFuYQN/gIFf+aVfBX1pzNukD3emy1RiecEBjtEqdQrnCfLEG+a+LKFUf9NfgLh1s1uNxTeGcFXwfKu71+rB1PSEmffqWsrwDZQTk5OWZsW3FAv9TW31DrFaWJpgEGhrZ6TbNznzHV2mOk2lYTNE9vn2esYjqrrK8SfOZK5ZmLfNctx2b7NJpzz4cN5yat3h15mxK3A0Yt5mCDUmaLwxndLvfFwWpKrqckds8C+iXJL93FHwg7VRupP2Ag3Dt31VjCc+HmrM0xzYmGGUGZ988KH70huytb6w5mh/UzdIwjm2sDhBiFsHIzX/0Ky9WF153asvvdLa3Palv/vqL/7CL09PLUQjiYXFVG//0Ne/+Y2PfOwjDz5279Xu8wyg1bWBxJmdWDn75lmfoLz7njtsJozKIhZ839uahE5hhsJgllrNLniDWuFaXE1X1tQ6PMuRckvLa+RCQVHx2MgIm2ZlRYUjv4uLChZ8jsCJ8JmvvPkck8PhJqanyCMSgR2WAjY7P8e7CREUAbjkGnB7sJ3PhB7xbXUgVvCAyljqDEU+hFiyhCe4FCdovv2pma9gIagZTq5T4zeNBvmOGRjqH0TM2uq6seERZKYIAbuhq7mjbjuya+tmTVXzxPhidD//PY9/xKaJsVH7JSqtgsMo4a1oggzqoDpYKs6AW4fSmdQWJmHaBcQ/RDl3/8DDh/1XozTNRSLrRNFCHnPX0eJIAupyw9hxvjqw4o9JO0Oy/MwEPBhBxGDZUBXElcbwpJHTc5ZgQaXCWglTYGqFGJinDzuVaX9389rlS+9cvMDiFhwUkzHlJosoG9GdbfJ6zVdvnRxz9z3HHnvPo3id8WF2fspWWoaaqcVpZ/vYYbS6smT2X1qYZ+vE4ux0TUWp9bJkQaK2umKKtNhcVbRvM44Ms74nt3cimzubDU0Nly5cKq+s45ZMeAUfIlhb6epqGxwaaC6nyi9oV35eJS08qzZvyTk/iWwmEUYkWoE9/2rS3NRkwmM3IIf+8ZHpB+59aGhw9OKb13zka3XOJ+CT3ecGH3n8vqHhW3NzE7edOBIYs7MiFaUFtdVVkxMTpUXJuenZjaW1wwePXDl/xWFrpqc///O/GNllWXJcvbNTbwwMjTh+oqGxqqf3Rmdnx7WbF7kPkSmJ1uIsZpC9LXo012gOS06arSwt49MyMzNJrdRJlbUOas/xhYup+ZUPf+hjC9zptnN9W2l6dBx/DPVO2o4HjnQVnhH6ODje2Qcw0ys50YRt7Gtk/vbO1Mys028aG5usdWxvblc0V4IXypgBGAuterMO2GVfU10dhDgVLNvuqmC/kLVa+zaNJI5NKSopwieO/+fa7U46WwvLz8kNbNK+MGwmz+67HzGnibGJbicu37yKyds72s6cvpMIv3blndLKQjbV3c303Oyog2kc2H/t0tv26VRW1NNLHKeysbpWaH1NDkanDSaPGJUg8FLSMIspwbE/RgA6EiTzkaahBAeP2oxq/oAf0qtrjgbCA5YYnORlkS7DxtoYoQZyiAqc9nKYzQLD0c7mFv+ZNdxPZmMUQWLLxbhjtxdWY/PxiuhlBffTOrOWchMnANSKLKXV0FCPHjvc39vHibK755Z8vKJZYjJn7a+szGfnRAoLIjUNnBM7mtvqdiN7N3rekS2jWzyxjwEYZwyIpry8YvwZyvG46Q3uIoF4XFXVlDhWFhRChubOnl9YwMNPZ+gNFC8tr+Dc4vMXxgFQQKiFxXmuffZ8VNdUoiD1yen79mo416m0uWRqYrqiqjSvMMf2Gou5hsWMM8+m6XWyqPzcWxcry2uy9vOOH+x66alXikrLeq8O3Lp2496Hbj/QeujaxetOq03Ec4sqCuenZ5wDpyOT+SXPfu/5vTRbeMHT33/2n/2zf/Gdb3+/9+bAamrj2rWbdnlVVlfsV5i3TJRWJ/v7e7u6OkfGBnt6uqtqGn2ueH5mlYEksHRF932d+9atm3ohcDDe3KCs2+abxU8qr6Cypvztt85XVdXaYzjnY0S8fW47pQtmJmfED46x44JZVLIfyUeBtNW4zWDQgNPiklId7SMj6GPKQXaYvRBwQBMJUBd0FjcGr3wp3C4iSBaBr3V2xlXT4aIB3IKjeIwV5gJ5+sK1sxe441NKt7MCVZmNCYQsFVDJOdJs7G4VlRU3FDcwk+SX5sdyIkdPHWVosCl7a90pWbH8nAqT6pWFlZdffuGRh9+rg+DeCoZMYNL2aEzokzz4U/VctFeCGyNoLKZ2zzAAjXk3vhcXgYtRKLI9GwGMGyKHDGAaI9vwp4YQ6J5dwTqA/1CHMJAGLo2VhjysBspWr+g5DkhzLBk9eLBnuLPLeDpmUMYDvVlxJn9Ue+q73+++edNQsLSyDLgcqxzIrPT19CIfnrKq3DvOHD99x4mcxL61RgKgts75aoucsuL2kFpLsdlU8xjoIj7OZa7EmBxJxPOd629DkMPHmQ4c811Y5BT8POqc2av5S0DijFvi+moK7Rx/wN/UOZ5URiam6YlJa5BkWDDSxfOw9PraPEF37EhHabmTQ6etmOxGtza21os2C9HI1+nQqra2nrvB5vq+DT0feO8HCnM53BSMj06UltqEMH3l8o3V9brG5gpctFMccVzEwa4DpcnqyxeuVZZVnThyW21Vk8n3ow898vu/+/us/o8+/EhBIdadfuvsO2sbq89+u88XV6saKo4cO3jjprN7awsKff1grqPjAB8L3elEgonJUd8ZwNfmWrmJPFYyx4n6qFlugUpm0bXy4oFeigDmjj75QYqx/+hBXU4Uy0TzHZbBBQOk7UNkVN3ZnbehUbdmDheKGAHIEfM3SbIsNkW5pulrkp6ncf7acsbgEQ+QHeyecs5zlq/BltBLOe2YN1pUZRfkP8dmj38wrXyM9ha67RkLFJL9QO12uBDKG5TgiJBYWw+29Tmvd2OZyb+Iusthtmdicmudb7fdTNXOjSRFbGe1/QhyifB0aoVgZvvJyGUaC4kb2HwU52LC0GuZV8HqgQGTrqh0es67uNcELXUXLknICZKElxAPwU4cVDPhQHGJ2XlgBf/V1zcgq6kJljAOhMZNwBodFZLFAb6h4WBJYTGJ8s1vfhtDDgz1F+Qn+Irscl/19Yl950w5qHGfncc54G0tdTtROyfWCpJxO9psTKmtr8dg87asb+0mCoh2m3qCMyWD0cOmVMbgzJ4J0nF9c2tpJeVTFGuBp+Aq59mNbScRbJAQpp580U0GMju/WA+iFZVl3hgWiU/Ur69vsvyMBPr7/Ds9zpD1pfKFlVmHyZm6RbKC+SLVzuYHs6OsaM7Q4HBN1V5X+1EmE6eKf+ur316dS7c0tvBucHB0PJHFVHjH6XumHCLtoKDs/bdev3jrVs8jDzy2vJjiuZlaSOfnFl25cuOxR9/jVIie7v6VJb5D+e9/73ufevq7vCqMv/s726+8+uIjTzzoo6smZlQIK4m01YXFWX5C9iKee/uN1LovSjW0d7Y5itaHdeeXV4BJb4F+Cc+81eVEbqGW6tOlZVPDJVLMgOq+sSlaYJK3+hn0fV7+0lKquqreqVU+42fmkJefS5VHDSJP/4YYJRGNwL7EavshDGAhAHA0Rv62E3bnqN9MYsupQC8Ptps4Hc4Z88EqMpXHq8ApmFubxQfWTzNBDOAtOeUzzDu+2DA/u7y8EMsq9oU/uxp9osb2EYdoTIzNLUynVha38nKXG+pjjBnl1fWUt8CgY6q9u8Ow4QsgsextQjC8UICwD+AfYDeYCjPDBoEZcHsORHvsB+7TwqWSGYRraVD5H16qp+Eu6c0BSjyJR3MQj+wXEo4XVg0t2pMcpul8JJFM/zlS264l+7Kx9xe+8Lc+ScRSKTmz99z8lL6xkO5Uto1NxywXHT91sOtgo5nudiSVXl1m0bd844DHyPJGdo695aplsGWQMWwGkxKKD7seZgYLo//23q55mzNFUr6IsbhAotn2Q5cj+D2zWlCiLPUWWPzbjdMmibPAVDI7Y0f2vl1IDN2Z4dIqlfVyR2bgbab3wiJi1Z7eZL51q2igsObOBt3c3lK/ubZXkJ+8eO7i4YNHu6+8bs/U8SPHB/uHfD3AxK6ytmRkgpPlKCVycWPV0VHp1M760s6NS332HrQ1HX7ppZe4fsxOLd66PmjrCFe5yamZX/7lf/Xpv/hzmJkYiyQKNhpbsnyfampihJbhOBISc3hg0EJK8V4xHZKO8dCjj125col57fjJE+Qu1LLu25fDVOUjS8Z5znxsaPNLczY0m3mXbBWb/ID1ulXZ4KNs2Rw/84sK0ttp5vb6+maOp8S2gYXmQ5M0czUI0GOsjaA5wZwxCNvqEIz5zGNg5KIOoB58mwYYkXQx8U9YcOInp+w/gR9LGY4BJV8M3dICmakzHAZpHdUScSp7Tlm0hNMrKWytTFb60Rf/GhvbR4emL5y7tjA/4AQnf6++8ermbuRA19GVVWQpdFaX3QuYAY5DKBPwLlDJwBhygkoCvZ/qFmI7093BZCEEd6ZigdRQN2n9lERkIeL4qXXBQhhLnxEAo3iNOmJkZlSBd2dmz0pwVpwQjG4gK/U58UjB5cuXXnv51Ykx/kJJPuVOA2IfMFFTu2Cb+S4jZuTw8bbTdx7Z21/zsRYStLgsb29/Y2FxWuf5FMXs/IpeIcINdtRfBpbMYY9xnsyQ79gSgg3J7TRjXTITsk2krrZeH9Cq+dn6XBuvNWLGUWc41oY428wJTn6I8s/JLULx2tpKPWEhiVianJhtby+bD84VjdQ113P/qirlHZnNKuJgWUduHuo8ND4+UVJUrvo89Wuraruv9tTYdFxS/vLQKz5s6vMq3Ohtdrl0/tqxk0esQL384kuvvvr6P/6pf0LvH+gbKiutevLxDw2P9Kt2sOIai89MzV6/2v33X/naXXfcPT07kf0hc+zdy9cudx2qJ57LS0rfPPdOe+tx8ytu+f4cdqvy9z/wIJ/N973/g30DvXUNTbrm9Tff4FtFk+4fGODUREJT7VbXyGyECf6c/ssIS/rwQMGWxpNo0m6ZmO9kHD1y/PLVq/TV2toGyieNSD/m5VstDlQFFnd/VCACyB0PJKxMFVRgS8YDkz1rJtyrWDbNG2SIwbAMhx3+UYH4jFtWT1h3Cy0wQCZzNh+Ba6ll2h1wWjRko1sO1hODj1FQNCpKK3e2g+2mdR9oue+utTdeP3/u7atrKw7sKLKrOzfPog2HyHWKVjAlCBQfAt8yTrAYnOGBQN/74XMAd5eWmCBQyZjvvFI3FZGPh/Ci5kC8QJDwLL5M5BYPDBGZT2FTymWE171AYoujgOWgTAMr705GT9KTvt7Tc+Pvv/qVjdXN3JzATG5YoC2IsLG3XllRUsDryJp/QeTwsbb2rrpIfHNled5xeXuRnfnlaYdrNbTUWJ0ZGR/JzyvOiHx1DM7+tV6eFaG3orzPdE/QfNiz+Nc4jFsFwImhoryCerNpZMQwqKMyJaVFdmqQNfNzK8559m2nvMQYohuvNjZS3Dpk7NhfEisgUDzKsSo/ybXIQRBr2Xk+BF/KP76uvh6pMmuoATXGhqccV7E4l8IGCEL9+9mf/dm5xak33nx5em77wOGO7z/zbRYw630Ife+dD60spf/u2988cvDo8UNn/v7vv1ZdF7hRTY7NPPDAAxtre//qX/6qyJ/5q88dPnZgeGykb3CuvsVAF/gL0MsfeOAhO8xspZiYHCeNqmosRI44JIKi4iNQFJju7p7pmZkzZ844YuPVN17n1UOKOcjE+qjNzeY1HGMd4qKz2PX1K7kuH40lzpC3orzyxRdf4jKi1ysrC86ePWv+ykHVjJ9LL2QYTwyPKMbAQeW01FuQY1XOakmgT8tH/2Iw9gpakL80s3iwWmmrCk/eYDKAtvamZtaUIvJCcHZ+dUgGp6dsOZ2X7ZHpmXk3WVpUW12N1wwRDB2+GM/ptiAn2dbSsjCbyonlj48N9ff1nDlzHzNgLpcKJ/2bxERZYykz7/6hemDAMbS7ZRghWIoOIJSZBFNYAobIVIikF4gsLqqNFkkoMk7w7CH46Z0BEfqNofRO2SMWJQgpMQNBZYhwVhmrvJXpz3/+81/8uy9YbhKZxz3CKQCE44l4vTWLtaXxqYXCkuxTtx/qOtyUnRexXT2Stcd3wXSqqsY+0bwFSv9m2nxahRxXYcHfEYY+uZO1n7Auaav4/OyCpeXhwUFGiOqKStVwGXatDZHuPggQGCIKzI2cSRjv6GzRVHNCBnrDVFVV4JgEHFjaMZfYGM9oIEIYBzS4stq4Gsw74V7XkoJ26/F75caF3wx3b791VvPfeOMyzRVKSMHa+ppxnpzj45/66Z9SE/Hvvutes0dYaW5u912j737nmSff834r09/42nft4YrsJ370Ez+5tLg+NDjhy0jPPvMiQ1Vra5uPWvfcmqP3072PHT1hE7XBk96IkXwAz9JKKJ84wIlfUVWTlZ3bPzDc0trR3t4xNjYugrNnaCCGYjXUWG00/dWKnNxsS9RqKFz3u7TXTydVaWBNZtgk7y5cuGTJwrDPEwoniBxo1A4iYevc5oIfceQjya2NTsCXA1HtDGrMrCN0t1mBi51ex6ExUWpcBXQEDwWtOwoHWAvcM0mxWfcMNwbemtb+iX9oqSirsKg30j/EVc63zZgmfT7SgWSk5/L8bH9vNwmoR4Pv22Rnl5UW2yNlTAnFuXuot2j7P5TuYXgYR7tc6u/CwICuwmiibqCibuogE9V2D5jJ3n/DqxdEHfFA3JIxaowlzEAoNsSkLV0XLrzDvTm1uuSMFZsfqB/KMyciLXYiNLwY9x4jYV193hPvvb+6Lrm2tZBfGF1YXrQPKVnmqIVEcE7eJnGC7Rw570yE4HjCvGzbfpxwNmKgX4ysERVFJYm77rizvqGWz8zu9q6ZvdmuIzWhOGuFlS1YvCgpLrLeuL21Pj9t18hmQSKZiq+bHW1v7PTcHLFhUutK+F5lFjW5h1ZU1Y5NjpkFIcTm7rJhJjzayXe4mDycV6GxNnZsV2x3dHX03xo6cLDed75w25MfeGJ8cLqn/yb3hBde3mhpa+PN0t7Z2TfQ39jE57mPRsHyQxxC5EYZm0nk9tN3jo3PfPnp5373N37j1MnjDgagkDXUt0zNTO/up+wFv72rw67Zj3/sR+0NJ0GtBtTV1pSUleoYx5b4rt7QyNjA4LDhC5+0t7UvLC+VlOdb+858fG7fBwTKK6rGAg+uUofA9dwaaKitIe/teLFdiQbLEg0Bju/VlVQXGz99qYe6EYpMiKcQiw/fTqGl9sAoBggYiVNJIReVwC0UbkAC4gkO67DQHGwly3y9VHKsy94qMrYx5Q5xHwDL/iOWkEC1zlaEBhpgiGBnKfnCHVAB5dLsYiK70HLfFl1lb3+wr8+niCtLkzZy1FaWXb9y8Ztf/cqHP/QjvpbJK0LOOTaK5MTZeYLBKuORKR+8FLQx48goTgD5H7r9UIHURBxvVRgPKBT0PWCbALQ/nA3LzavA1cfsSnUpOXw5KYsu2TEaSCOExH3xxeehP5xJ2HMMhQoIizGF9QfciYJ4sixx9ERXdV2pT5zbyc5Elp2IB+4lG9ukiOTKJoSwRFFe0oQ1Oyt3eXFtK72/xQi+FZ+fXF6aX60srdnb3PdJlKLcEtPNghxuZLMnDp+yj7aMKcOsKurz11tZNpY6wDCR31DT1HfLnpvthblUZ3sXb39zrNnZFFBiKlRg5yHJKMdUycmpCTM//cpa5QIXd9HIfu4bRlnylcg/cKhrL7Z79p03z18857u9jzz+8AOP3t/c2vTiay/XN9VPzkw9/uTj/AtsK2HwtUI0Pj7q2BcReByY7zJAfeHTn/74xz/6wosvGve4jlbX1tx93z2/+As//qM/+qivv/hqu8n4+YuXOLsQ0ka8119/nfbFBHert4f7xsGDh9WOb3P/0LCdKwSljVEkmUY5FoY1k0LP98r+PyvxaAvNRLWuxDaag9TOXTMAYmzjmzZCMBMqqant4ptO6HFoIO8FhuFeeXD2GJ9Cinsg6AMxGRzDj711N1ToQT9NbxRHQQcDIJEKsyEmXMpTi9jlgsRGW+jh0QWp2UEmDo7nREuoOUwgnUr7QKXdRQX5uQcPtFkqXVqcyYrurSzO3rx52RFTFc7JK0uyXLsYf3gNmTEqAuI1Qe4hmkM2CMU5TCtRfVQsSJYR+VCusVqHPiKH8UULf8b1veFSJLSbmZmWho4oO34aGYpv8fyxskslUKRofGutQ4WTEEyJnQIn18gu9xHfZWtsqjLfXVtPZeftL68uKcMVSgg2XI63mQoEXq9OhxkfnfIhnysXrt93z4N9vf3lpdWUpae+8YwVg+5r/b6LsVsamCnaGgpfff5NdtJIMtuOwmgwZAe2YR4mHKd3ltNQTCFZ2lw5fOjYxOSMdcaaytJAWqztLiwt6H67ojKSL91YXxvLYTsyqqwjn8HNqg6GZ58tKkg6x299OfhQduGBNoA2vnGjfPn1F+zktLT84IP3dR1pm5yd4LP99PNP/8xPfaq6tsohInnFiUPHu4Ynhn01/u77z9wauvXya8/T2V55/YV7H7gTUKpry9q6WjHeV775pVdff+NDH33s2ImjNXUNlXV2DI/RLsD3Rvct1bDAzqCuwq+/+ZZBMjuz67K2LtjsBn81Fbbm1wwOD/hcAI1I/Sm68Od8RT3IGgOdeprMliFkF0e4ZkVobQSWVxCADRhPAZTSGwijQAvIDm1BeZnjGMyHZRhKOm6Qjokg471KZhetBgcPBsXJGTCUrkp6x9oB9zU0d5RsMB6wwFBYHKVh/d/vwG6aJVefTs21ATLOiBOnmzFq5eXmzS7PEASp5RUOjj5WYiZpLWFwqNuprI6IZF7R3TK0oO4OaQFP5udmvOUCZ5agiMxBuRpoYqnaqoeesBFeqidC+IwrVFgSPz3DoTzFj/6n3/gv/sO+GsYLQxoTf1G7b91oamowOLzwwnN4Q2OwnXBzVZc5eXCHfsuAMX87ufmRrsOt9z90Jqcwmt5eNAHYjWxQGaN7fLv5lOz4QqnjzSJO9I9yI7D/en1teWewN1gKOdh12DenbLxn1pxfmhwc7LWEefjwIQM3o77v/3AKUslgmSb45uYuOGrtzOysVfDVhf1XXn57c2OfuAhcZ+PRmtqKxZVZawsW71o76rFuam0Ln6fXt++44/YrN94hI3AyDdYCH7EkKxWcnZ655657UwvLLEnG7ebGFu6SpihF+eXkLkE2MjZ8/MQRXwq2ssPobpPH66++WltVb6nUQkFfT//40PiZO++wZoe4vACd+2uIv+3M7faFZuXwJMv7oz/9o9N3nfTBUpYr+poO1h90amb1t8+940S3E6dOXb1+E2FHx32i6qD1AVxBLzfWbW5t2IKLLI4ulbnhwtwaCskXbYFIbnB+BpTObOTnrscvy0ecy8pqyGNw0a0cAyoqyvmfQXImrf0iVm0dPUItDjR4UwWHjTLb6Wi4N9ibd8kzEIW7+wDgA4v6tLKymvnbsZ6UExM08o69FZ5kh6VEICvn52Zgw+KVzClanpXoCIn4Tt5Q78jK4kJjQwO+taXO/I0FwrxjezfC53dq2vcS1lvburoOHLvtttutfhpwtBFZQFQpVEFVZehVSaSWLXGMq8XxVtHCXQFAM0sBIrvAxk93V0glxJckzm0wYIjMyh/t2sqXhXqaj9jkBGu0O/JxaZZSDRDaq2DdPJiD+yoOFchRM/wic+zQzSvM8l2VvY2sja21sspkAPxNpysH3kY+XQGCQWsZ7SVR19wExw/7IYCPudoJB5Y9bGG/+/bHVI5e8fqtC4ZxbXPExJk7W4zLzB0azEbEthvYdeJZ9TWNjzxcYq45NbVQXcUfuMGabkNzzcTMiA199B+u9uaURuzs3PzR8RG15iesyVYP2c3nN7dYJAhdkMJglCuHI2/q6N0NC/CVtU4F9gFtH5EoS5RkX7t1+dTpU6upRQvJNVXV9KKL5y+cOnjqi1/4G6dBJ/OKe79806cdgw8Sx1b9odPLr3/vnnvuevaF54i347d1be6soeOpQ8eHR4caWxv4QuNMvpPuOoNcZ3ig/iaLS89fuASUXZ2dVFn+VmEvOmfXMdmOIjx0ONnQ2OJ0eCeWWjYsKLRNYsUJtfoI6QwjVs/JXXYa+NYuOVt/5btlfmhXQ2dXu+KA22yEaoGMmFxvwhOsw4dMABc4zbMVbfuX9RfYIodpPoS6JTy8h2FSq3Ruxw4kKLe6hlS0ogORuYngFCndpP7Oo6fFWL/f4Vq3smpdz1cj80uSWXOzhdacHERgrae41DIwi1bxxGxuIrkfjY/PjiaHi48eOs4r0DyYnMKBKhSinEkmI8gDew5LFMR7wH4okAkP4CqycLVySSXcg0B49lb8QF8yLBL/JB/o04wFsQU1NtWXLhV961vfso8xl1/htq9ybyONxLYjBezl24G4gPgPRoDg2OFYzn5hkUX1Td8UN7Hn6mYM988HSjIVysVkthgy+DCEBR+bCgxt0cqKMus5wewmvWn/qOWkva14ZDNx9o03ug52Zu0sr85b4qkp78xaXdyZnZjhfmzznq/F9Pb2BCPyXiSRWzo8smhV1pLa2HCwWNFoPWtza2rcnsySzDEWR/sGhmBRjxrQHAlH3iCHansAMh/MMC3Mzor5cihHxMJEoaFxfTmlm60WT03O33v/g6++9YpPAXQc6ojm7i1OLhaUFDzxvsf/7E/+1GlF33/uu5/8iY8PD2KtKOHa2FTHPSQS6SorLnnzzTctV1/tzp6aHamqSxrLW7vaEgV5Sytzzv/p7rluvOrtu8Uqklol2httHKtrbnSEG4Ojc4X108jwGMV3ZWkJU40OD/mMl7nPoYPHFhc4Ca+YHpjzYR7l6k4XjYuWDKPEP6LqWR4DlsCQxd5//o5gRF8PJFpGJUAHEwkXaZjBCkwHTrJMFQY6KrQ8xcQDtAPems6CNq0nUzAqa5KTQ8y2aRkZ45K9XYEplv8EEWmWTCijcDC8MKfQehmbs/McsAt6DrLMKy5uPdhRwlkyo44vzC6U1BTbNFkCt9uxnr5B/o6OeCD+G2oaw+mcubX6qCdBbKOSalOxNAGeIVOh6hmAM3NlwjU0uNTq3YZgb69ECceB4PsAxGRlVbA66MR9oVbF+/p7bLEjtEwKfdcyM/QEgl9Gvqxl/qusoJSM7DdQIoGD3Mx2Covst2JzzYtl82reVEX72mhe+8HHnoNNXLY62JMhxMc966qre3eHfFXunbcvnz5+29LiSmVFzXKOk+bnbj95j7PUdzay3v/kJ4xCuoRlltSsKC6L7c51Nh+ZGreklafle5GcI0eqDYi9/f3YemBgvH9wvP0Aj9HqzgMtl66+4+Fmzy2bWhJWsqL2ndjKsUyVLCkvtVOEEOVVj0aqGpzyUZAAR7IQS3seHZksKCk6d+Htx97ziPkGjvV16L7BYF/Y33zxs7fddfKV51/68Z/+R6MDI2vp1PLi0l1335FfwMU6ODLVoaI1DTouOAbv6PH29Y30zPzc9e4rj7/nsemFOQqVD8fvzsyXF5cN9A329g1RgXQSd3TubibNDgnnRGldHJsz/7LSQDNL6OzCKk84cv3atZv8cGqq7dAf0kHeQpJyZRKo9tnZFAwq0kZ6x6fW6GNMfEKI7WDH0uKcDPU1GooPRiYtHlyrNhMnnNVOW0BcI79XzPhkFDTzTgv2D23bRZOZEwdYLMwHPsCQIX1KnvwlIR1GApyxE/IQ4tpiwiAvTJDIi2TbB5a3sb9bXlvNymn9zqzAVvyVzdTE/IxdktYQardrV7c2rvRcpUYtNi4SyhpoWSOjnwdH54YrAOb6njFC8C9j+TEShkB1F6hFquQZNvSyZ/eQSVRPIAPTNnW/pqqqqanRshdDhPZzPPviF78oLduwHI2ekln9NmHzeRLNCtSfwIpsfcogEAwEQM9LIhK1R3aJc4KFw5VJx6Yn9+k7cR9W2LNk6dPqlltsczQQ81AjIMw1p8cX9ByU1FTWA16RoygsnfgmV6LAVpieG70lxaVEWmVF3dTUXCI7ubezkJeTTKe2s6POpN85cvRIT2//5PKkLlpYXMnNizjVw5jp+yvUpyOHDhvxayor7Jusq6mZnmIyY/Lf9Yk9fTZhh952mr6HFlZnFqJZDru3wdLauvYyyVt2zc0vrqyuOXvxbd1fXVuNc+xYyEsWzkxN3erpOXD00MjESGAILsg+c+QMB+/l6dTxE0fPnnuTWam0yjR0a3V7Pb4fn1uez/W1xq391954vb2rUzUW5xY5OFkJev/7Pvz8cy/NTy0e6TzCTJ+z54SpKPtsZXH1VGKauOETQXfMy8m1QldZ1WQ/0PPPPid//loOZQEyy2TUAz5z9ojOzy9YZvGT4Qi197K2Dx472NrVzFWxoDiXjJuYYbBIc7rGnRSXwKHHAVU5lgj4de5nxzbyrYWxbq5vcakOrBUgYsazuz0zP2PVkg3UoEQX/YHxNDfmTMTgO85Zei0QwFk+Sx4LtufylWCQDgL3+K1mFp6dlbazEUvYw5C/vLa0G6HHcpoIXO4Wp3k0OekyzwIrU6+9PW2dDaaJM/PDVj59jHh3ryG/IJ6TW6bCaWdJZNF2WFA30Mcghs8CiGcwrWcNBVidzoIHVMkrBAkf3L11hT9jxUWJzo7mHf6pOxsUkrraSqPSubNvQQ8LOr3BjuDAcdICT0EeD4L1zRSEBd9IN05idKZWo3Lw2blcBkWDkCKhhx88g9fSig9c+cbKrqNXllbXfeMrtbln04exIMHL3uEGVYGne0dXJ28tRfX1DXz1q19KFjvHarK9veXUSY71THnBEvWVi1dOHjtBv2xp7nj2mReaG1udQ5iXnejuvsHkX1KWd98Dp+M5EcdolZTxr06PjPZu72x4tbGaclj72vLClQtvd0h84GhVTfOq0wrmZh3csL+9ubu5kbQjYTd3cmAuNbM9O7JaWdy0tbpfkF3Eo7O0snR0erSkqqywvJhojbNL5/hIa1ZZeVVxeSW/KOycKCkqa6hc3FypbKzNL6l45sU3mjuOpLb2pxYd9RLtPHKE5GETSTkCYH1nbGKOM2lZYVV5UfX+ZvbsDC1rcWpkrrm640MPf/Szf/g3Q5dHDtUd/X8+9UsjveP5OUkrLWaxxNDgUC+7zdTYWEl+fl1VtRMo/ur/fIaHc01N/ej41M5uFpdwM8hoLDEzu5zIK+aKM7ew6Ij8pa35vrGbAxM9y5vT0UR6ZXNqfnm0oqYovcF5NzjYp6igZD21Fd3OXZnbKC+omRyc5cBunTM3K8+pw2YduJF3msVIjl7WdI3tPC9giGBy2t/inC3zNKgsu54qyqt5ZNs3NLuw6CgDujYlkOOBBbbAFXSHvW0xWZpY31r2JZHUmoWK+d3Its1S5nWOxgms6rHNkpLc+vrSvNyd6urc4qrdrdh438jZ4cmrl6+93Nt3YXSkO5hlUs98fWxrh5HRFyrtPsDUnNsNEeQ1fcGDASDYdzbP6DSGO7C9PyKJaudn+BD9s9/7fQgzNJiyWHY0AoyMDn3nO9/h8YZFAkYm8Yn5H15kOYhjPnwF96a2dJtkSeTJD9zXcaDBCkBqfdEmFROfYNM102fmMpgEDiPBdoRAA2IhKkgU72/F5seX5idTPiPd2z38wD0P068M09/5zlM/9amfdmbgt771HSrBw4889uqrr5qkKpJFhQx+4OH7tYqWzPZ14epVUz3t9InSK9f6IjmRpqZka0dTVW3VtWuX2ZHs0MaQa6srZIavJiysbZVX1+TlWOSfN/erriy3O2Jpca0wt7y15eCVSzcNtRcunqtvqMxORE/dcXJ9byuvxJJtk7k4U6Phoq+3BzE62lroHrxP6HV6lV3Iw8LMQmphjRaOUxgA77//3vGJMfNUqWh05FCVD7IWFm5vbLPEj41N2CvMKHft8o2R/tHmmuaTR26rKq/50pe/VlDiC3b01t3trK36pmqYWF6arapIci7aWo862JD04VZpFJ1fXqxraPCNPbMd69ZUGgrtYP+Asde4PzE7UVlX5lMd6sbE7lCWYoe7Oz0rNzEz6TTc7M3VbZ7khXllvE6L8krOn3unMJG7uLjQ2tm8srq4urn63g+/5/vPfC+WS9kNZpPs3sQe08u6nb8ZxzijPV3f8f9wwgoXDDsZZzh2Atq/kZxijBomgIhmujw7N68fzbsM+yYXgaLCC9exQoYD37vOOBM5CURuFssB13yDjJ8cnbaYVpxXeuLo7c11ZOMB9iJftrL0GZjd4j6DgtfI6HyzVWmR2l1B8nf37CFTgeBZCFSGimLguMd0qmx3vs3eMU14LcH/30uT5G6wCSY2Zvf7UQvDNTXU0xKv5B5yimGI/4dGmoEEVQg0QnfVCgYknOEzXqvpNatO+TlFz33/5dPH7/z2d7720EOP2jhi+vvK6y899f2nLFIVFecPj/TyouOJacy1JSVg663Fsoq81fXp3v4+u1Xt57Cf+FbPgB1nm3sRWxUiWf0Ly/MdHcGx7IyGdFKfx1K0lYj64urRqTF6dXW1o2myzHOYJZsa2/PiSYKBO/7a+srRE4dsKPOlIxah4vzc0amJ3ls9Vso1wFnGfO1IPrDW2JoqXvuBYQHDs3vkFfpclt1RWbYdWofib+OrM7Tmmrrq7p6bizMLgRmCf2tx8SjVJRZzrINvn33oAx996ekX99N7FdUVn/3rz3IIa/ORv/3d8bmJD7//QxevvG2WpQmGR/4gBw8eov6aThBipqRHTh60H/ett18lv+ydtk13Y2LN0eSz85Pmb7yMSgpL5+aoMHuLSxg+0t3f09RI1dwrLynPyymgZ1tqNDSnZh29vXbl/FW7aPj59d567vjtx/mcv/LC65vru3GHigafUg+gFDBAhMJtGdu2lSInihKe3KEBSdejIQMfq4nLM72A451GO1AY9YKHDELkgQ65jCKuYFuBOaJZYhZHuiBOZgmBT4svRplywGFqJe2bfwuzyywTM5PTeu3E8dtqa5qTBSW0L8AI8BbMSwM/0CDPjMkfTlVJhrAeVs9Pge/qSF5F/+Yv/o/+Yx5BLOZcs/u//fxfox0zuVwCQa+G+D/DQAFLZLKg9ev4QKrsb9bWlxw70dbUVskHITjvOrZN+NH5WOOsW6CaRHJyy3g+O/w5cCS3eTQ/bkk8x3xsYcoiIO8KHx30VYGl++97gKOI0YNlwMdD77z9DMsy8yxTLKucA6HuvPMOhrxnnvk+kq2tbhaXMQSNsOGU11T4YoBjp6zbU/QdAkcymd5p2tzMvLHF8SErvOR8ynxnrZCKUxT4c2WRTZHsxrrWgrxiubHBnz59YiW1WFtXsR3ZscL5xptvEquUEAtM+k+X2OEhBHvPzwaeOa1tzTRd4sPZOQ5xNGqdOX07Mz8jIB8qMRkY7rrrrj//8z/nRMnkyn/2n/yTn/va33+dFF9Lb+Xn5tsMPDs+G9vNPnHsxLe++VRZVXU0kTUyObod2a6pKz96/IDvddPiRgaHjBhO+STwQGVgaNAxNfZU2B8XfKAh8FYMNs35Rp9eU09TTifpzvrO2fxMWWlRYO9Kp2jZZtWg5hvDOxuEcV5qaXNwYOzU8dM3rt1wEtGbb75+4NCByzcu/cK/+IWRyQEnlaykU4ZzdlWmu8yCcQ4PGqo7ocnmycnZl79QJvQO0r1GS5VhZiVI7SEh6Q3RUARU42MTpJJh1jqDXWEu4URnsKXF4kNOcJJPZpq6v7FmL8G85pCdo4wGgyMrC8tGrZwoZ7CSO07ffeL4aafEcquzAmZ/rS8oMz05/SIU31Au8wxjBGqIbEP066+QAXQf/oz+x3/968pw4QwD6x//8R8HVhse4plPwWGAAL5q9+6FwUh5dgNHmcPy3kZ7Z8OZu4/WNCTZuPYia/vxXWo95cRZzXgv4+yJT4LVFi5v7sGca3cv15Ls5t768qZvKvN6OH/2cl1NQ2ppzQkZNjfeuHa9tb3N99A5DpgkXbtx/Yn3PPalL/0dC2NtXSUjzCuvvkzAYPq8hH2uzW+fO2cCCq8bwUfgqnmj8DvnU0CmLPqEydpWR2sb4WG/csfhQyw2kd20b4BqvkXpIgfkO78pklNX22QER6DFxVlf2wi8qZ3YFMuym5YqRYoYjlHJA4sHepjB0zqZ2HUz4iKoxR3OfNRIowRTl93JNAEaJlu3PvBgrav7Zo/PqBE0Z247k1+Y7B8ePNh5+NqFK60Nbd2Xb/b1DnESMcnG/61d7fMrcz454ctzB9pbbHVnaWBYZCC0idt2fl8xMl2m2Gqpvpsl6glDcMh4BFB20mubxYlKX4caGu47fdsJJ3I31FU5n1AnmObbzEl8cqQtKaqcGJv6yId/JLXk817LOGd8ciyS45zn3Cfe/9iFa+ejgcM/fTvwJKPNw6uTBwxEdqvRr0wJbCdStNFNWi2FH+Dj0O7OIgXiGACVvIVJH/XIcBE1PgCoPAM5bRu+5QbWdLth+BTSl7cdOJmiuPou9rxVz+kZPkw219OTK0oqaqvrT52840DXMQBwvpBtVUSD73nK35w4xLrS381f0VjUFRankuK4YrrWO31mWMdweFcfsySIpxJivHv3EF60eemxAV5nzSDVln35J8taYmCXZTIwMwggkbE90b4CiW+QC5bLkI4YMpU0e46Y9zS11lfWlG3vp+978A5OREdPHfyVf/3PmH3zS3LKqoqqaksGRm594UvfOXio/fnnn/mX/+qfnzx11B4ly5yqzVvTuN/V0Sl3BmJ+DRTf6uoqzOzEIEVwmaAqwIqR8fKNa86i6ujsNAByuw9sdlmWKTYp4gDEMmiSRo/yectIbDsnL+4zkr6+YeCy5t1S37gyv0jR73MKdH6BprGBsEmzyTBeMTUYZAwO1dW1I6PjNBP01FykY2ZBMbX66Ec/msFEYI1mlnXn6HHt5g1yzeA26bPe6VX+AbbMjk+OWPto72w9cfo4WtJGbEk1gSJrMR4hKW2rnTv19Q5NMLDwGpCzjRB6zUnAnp3EoVxoM4zrxMbaBv1y9+33LC+seF5LbVRV1AReNsVl9jzU1dRrDid2mxPmZ6enfPR4dKwwUVBrZl1VV15c/sbLb7Q2tFSXVRUyhzkB3Sn+TKTBtvRgCZY6CmRQRb6qnrsKoK3T5/1ZOnCiBM8Foop0MD+A+4bmH0gZPIOr0Aop5RAIY+trW3b9rcsBroItxj7jSZcgSRP8q4vN6/iCxbLtJlgbmujrG7wxPNbrNN/8omxeQ4HTMHmbWSjAjWHF/JRzKN+RCEGEiBf0X8ZIGowXwKSfVP37X/+au+0mNi1sMDBlLh2JFYJ75gIIyPYj+MuwEd2ATlZckVNeHbg+ZM6t4DBkDwCNOZD7DJTBnCQofddcKFCs9nYmxycOdR0yfXIudlVpdV/vraNHj10+f9URJk2tVUdP/KRZ4+DixD33315bV947cOv+h++/cPnClcvX+K72DYyg5uDwWFYsMTg4+uqrb9MVN1kL+EE01ukGrQP62rrqN958e3RyurmxrqaxaWF2cWF5dmJqxmY/RoKAyltpRyVrx9nzZ30/C1KZOJz4YHCjcNorYQ2E2Zfbox1uFoQIeL6OvpJjpkX0WpWrqq7VhYDIuT8r20zbATAOUZsO+jU4rXZxZ2OH48YLz77AD6ykqGRmYoY6AqAXL13BMPTg0fFx42hDfX15Ydnlqxd+5p/+dEDsePbU3Kxzamfmp2FoYyPv777wxTOnTkEey9vcrG2ra/BoxLcWNj42bdyjyVy9ds16al1tA9MNEz58T084AGXx+vUbjz780OVLV9//vicgo6S2mq6pUzmrMVEHGm6EVcNOnYuFuUW2mF1455yTG31m1dJHQ0ud0wDykont/W1mQDonwUZi+9+KlwOR6D/BvDizWJZBkV0ZZKkjZIz5mT2KGQhigEyU4JhEqxj2zEPDXubjABALhL4BaPtbMKVVHxsbM6+Ey5vh1dFcWNoC3fJKsBl9dnGWFt07eCNqM45FhSLTucwHzHkcOWnCZ81/KOnB3SUXA2Mmtx9YP0X4/7H1H/CN5ud9L0qCANF7BwkS7L0MZ4bT+8wWbdFqq4q77JzEiuPEdhz75Cb5xM6Jr3Ou7SiybEuyqiV5tavtZWZ2eq/ksPdOAASIXgmABHm/f9B2cm4uNOKCIPDiff/v83/q7/k9u7+Wf+u/f31X6zMS6/a9u6RLMVhsA0weFyB8fx64MP/44DzEo0i4LnYRqFVJxabRLK9yG5o73G6PTWWQMQgIK0ARhxkkdPBR2YOaBZ4CxAvgEPqAIBqtE14PaRUak94CF0OVyz02PEYCm3w80oON4e6ajJapqVms7dLCKtZtdnpu375+tjESidRevny5H1dbpX7zZx+98PmT9x7f963lquvkrV3t9iqGxs0VJdu+NT8aF/vGHaJWT77CXVsPyQXtSqSnBUqlWKBBEbgo11xfX8c7iV9xUtGvnAaA5LnJBUJQjVa9tLpEZo2sK9knfI9kJk3gy5ZCJhBl1g2xY1vGolHUM2m4sZFR8htYJ4NRTJil0M45oBAhiEhnSZ1VAHFr62idmptG46Fu/cu+rpZ2LpbXM0yJyoMfE3ysECTOz864bNaVhcUvfvGNDz/6mNnDx04c/+T8ebDHeP9A9NkiGD3qKkTJKDZOgICEMfEWkz22lnz8YLDOA/BmtanBAx1TYM2H4uKduCkU7UmXCy6gRAaW+WfPPTc9OKOhXwzACh0XahmzbJgr/GjoIW0shFhAX3G9yPnjVqYyWUSfieJAC6jUYY25tbulALYZ8oIe4WSQM5EDLHE0IWlodKEdhL4vKWP5rrsCryban/q0CIIRdR5sBrKkO5vAhiuJHldWF8CNRkJrOEI4kyVbRDBgbmnq7u7Yx7RPEDYQJ+tURgwEJ8DJIMBCVEsPtgHrz09e56+8Lr6DrjHOiVPniGRLeCcbBXHHZGwJD1tEr+JnyQLsHg7vjgNRy0Otp0UbmwTuGhCfuFsYLw4l1wrSokQ6Qe1T1P0EGZCohDOGmoQpGwDdzEPQnDAeRCkPRIKNnkZcZ41BVSbdjsUCEpmZu5rOJTYjBXuVBX9LG4mRhXvhxZe5LqfD7V1di0aTNdUd9+6M6EVnb2WVyyOTjhw8XL/sX4IgVm81kp4DPx1NrOe2UjTZEXVxD6h003KAoeRagHwVoIVhsUvU/iQgkpm4y+0gSE3C216hcNus+PcEcyCeEvHY4KPH1Ea+9q++RjANmRIVKJvTmVeiuURIg9ahSoh1unXjNiwpAd96BZmbcilsuHQ5Wfusc7k5uHQEHUhO8I5g4j3u+uHBUTiTOtvbJkcnGaYknGlGHpVvG8268kzF7NwcsjI9O9XX3bs8P+dyOD/9+FMs6q2b99zVdWaDNbtJejQjkeKW63IZH+kGCnPkQxdml2gig4IZJ0L4S9VOVtviMmCVVtZWML/cAT17x2DAz8YtyW5m9EqtW1I1uzhptBvAxZBCoPejs75z2b+S30p0treQ2vaH1siM1beIQjIJR3Be8USSzgrsPHgZqCOQn5IfJJgWkC0yFggSOwHpQvIQenDusDqRjM9lN4CfcXUYIsqiCIwacyRB9gQdGxIM2Bqho6spFcsIJEWF2NXkaMj5ZlLJknmRoHGAXCwuzUt2Kg8dPMWNA/8rMgElRAYng9kpCa+IPfiK3XNADJB57D8HEbuCZ7wJieQJf+C82QBii9DrwmP3AITB//AQssuhyWOWPCCOJiwC8EmqttQjAbGAJyP/w6voZhhoChtYEtJCtH+Jbym5U+KJiKrKKwTGqFiMMdeXSjuwFZIBkiJMQUSQYulzO3aLgxQZDH4WswuFtza/eu/OoKRcERABXEU6UzxwoMtdWyOtVFJVxcsi447rjODSg0BFwmIxMBud8U4GoxpIzKFDR+PRPK0zTCPgLlCZwDpy/1C0QDlYZ9GGsYWXSSVzU9Qjy8DJmSwmM6nhY0cPh6Ohi+c/be/q9IMyAEvDMCK9bn5xdSNTADAHNDq4FoYVwrvs59roaohFY8qKynxqc25yvrmmZXR87I0vfwmUG3C3hqYWbBSD9GSKijVfQKtSM+USV5ubTXPM/cePgYKCuyZbis85NzfjdrqgwRJQwmLZudPnYuH4c88+H00mz188Pzk2RTWVCgMER0yDxDeAIGhpYZmRgXt6uuGhIQTXGUkmEoTtbOcKpB/xxnFCYukYr5ETw2KXFxhGb+L4QJjkigo2jMNtvXztQlMr8LtEdCaoZMyGQYOTibPMxcXiYGzTVAO3aM0QHJ6Q0Qs1ADVKCSmMmSf8FZN+QWniNgm5ITRn5F4qjQIFhY6kEUpxA4qFFBsGURR+BzA+4ALlNCGwc4T+psEGjwr3CbMMoxnDVnCE+OvUxDRMOXyEbSArXzEZJ2trGu0Wl8ZohRmWjyDffJw3IK67os9zbvSuxLLNOA3OUHhv7A+e8Wce/Lq7RThhsQH+twc9bOIKBboDyWaXCN1PHDw9PYPtRrBxjdh5fAE4CTY6tMYUQdgmbANOiONRXINHnpIqsSMUD3KFOp3LczzBgQ5eUFrhFbPE1vCAKRDSxs5oDCwv5J5jk2PEghYbtUaR7WpoBFCw+eEnn0A6Stciacc4g73IwG6RxomEIyE0DepNq1ZT7YpHwp3trXB4ZVLAS4l780TA9BmVMndKwi+sLYUkcqDEjqwD4gjqC/1KuoaMfmt7G9dNkICTRlBGGY5/3B/4kUAoQD8GEzJofRwXxp5adDZZmby7bY9SotpKFx1G18jD0WQoXWP3/Ojbf6dXGHo79t6/9ZAscG97X7OnlfZ86tHz0zPLi0tsAO40pRLOm+IaNpwrJl5jzeH7p7IBGuq9n7/b0dZ55+btr//518mj1NXU79uzF2sTXAtWOapcdidynIonjxw8Qi8HBDaMvkugSHMppbrSYjNjsEgZh+NhauAakwaNs11RTOWScliQTNotSa6+rbau1ZPYiB07fRQ2q0gsRFplbGwIUjGcGe45riAZXkIdIl3uKRKDDUTxEXhSjsU5AnhCipPMBB4goC+khaQTcRTODPBvYmGe4AijgwgJpCWQEC2T7D1ulnCXuB+4ClvFbCoJaFKQR0kluBLkG0QzmkpbCWBxp4I6PZ487UHMpBoZGpqfnUZoAXfixxInIBtI8q6UI+E856+8yM3F/rP9sEiIvXAG+AO7hCvhOQK6+4QXhbyWvCiRCC39lZ84dqI/rZQX5f18kFI3nl1HVwec9CZaobchj9+gY4CCCBw/Ysl4cE1ipUUxandPIXm8TLKV+jp8wJQKM3lMKlYIUjoLtzMeS7BDqtwucgmLc142N6PeC0Vy11nWmIr6TnnB5jS7a9pwEQeHH9AqQNzm0luVOzJvcFUqF7ONic5B+5HsQI4JHDkURV940FgFTgPcRqmJT8NQSqYzsffQF1grOs4luS2gi2p2lVQxNDJMVzSLCKCSdvvbt2/Sh1VSzHPNDU3r4Ti3v6aqJhNPM8ldrzI8vv+EbuZN41ZHc/eTRw+5zajzn3zvb77znT90mlwbycKTe0NGtRkabJVCSz2K6X1wFXV19MCUB8RodHwEjQ7idWZulkQFsSIRFH6X217FUGu5VOFz1/z3v/izZ5599l9+7V9cvnJFp1VPjk9ALcHmh0uPdCFSB5kcex7blc7G1DqVTmNCWMF6Ib6oRqhacRWo0FGlIjXHVQtoFjnkfBGGsYXAIoQqPf29HMrldipAhBBaMsNeoyTtm/HniN1BuDurXKSPKYoxfoC0OXBfZk2hGvFoqDji81JjIawl9Q3IkC9F+EQGqUgTOSInol4cYhmBFGxncjCISZI+6H5Bg4hXR/ihKhex8lbRbBQIP1puOFUgM4yeDIfWBCq5nPlrmxSMszu5HdR9UVLloGTfwjfz4CPIN7Zl96sRPfYAr7MlEDx+5U/oQeGvIw2Yhl0R5ywxcLwP0eR9/7gf+OP/8hCxsfB8EAKwDsgOp8ZBStaGuFKYDiHmop+Ib2VHs4NoBhOsMUDRRKGb9ohKpt9gITbZJFRkVEogh1Jwyo2N7T4/TkWMgBKGOIhA2EeOKuu923eqHNUjYw9oNm9tajOaK6MJ7xdee+aDD98yWvR6i9qs0Ks0jIEoZ8CKxiRQ09ylHO6tDHrOssa61vff/+jMmdPRyAx+mtFIokEwuWKHCQsk0mLFtiDFR5dx1exqtu+u6mFXtHV0RGIxHJLgmo+NRA6H7Af7inZRRITR4EqZijQBrJoDj554XI1qme7Jw6Hkesy3tPJrv/JLf/Fnf97U2PD5Z7rf/sk7UzMzzz73fDgBWoSZdnX9B/d/9unVpubavd37YtHwyPhoX18vncdTizNL3hVGQZqsFkpp2ViaCQPcM/YeimPvnj2QJmXSqYuffMIgu/np6UaP5+L58/7AmlFvePrpp7ltlKgX5udaWprgpOFXJI+1JiNJ0yb72GKysqq08oQZHk4PR1lFtaMav5Gro4aAJUTyEhsp9HRlsZIqCfEjI+ahkOHagWmgI4TzUdyB+avKXgexNLkgknvYLkQG9U/6D08IHQjYs9Ig+IMRMBJlmKZsGrNcGj4J8R1tfpUKwh7aYhB6/BFuAYIjkodC4UoQEs6OnlpA1gibqJDI1TkFsyV1xc0wZSIYFRLxMkUF0hrZ2ZpmsJrdVisqDyXnhxVDnsUBS+4Moo/iF3uptBt5kVeknITQ4mTalEoyG2wLiiS8ifsvZBhxECcjxKL0RPCJc/RyDBdyzUrAZEIRu3xzeprxo2USeY0GIIwCECL5f4QIv0dYIuLfkmjRRoDwkyBlCogildogAbcB/5XIjJFVNKrUzD332y12nXaTPAa6kxyO8I+z+da2engLqZQJqufKMnC+3rUAhLPPvnB6cmYM7m+aWBqaaoExF2ObVMEIGMCQ7d93UJAjbOwEvPHD/Sfu33mMTpcoaJ4SnPGFik1RuNgSvB2EQNgkahsE8vFESipjDKmGwB0PrK21yetb4cLxhRgyTx8ZLiYdHHhqOEXrQHm1ho6OromJ6TV4s4aXaV8+uO/Q+NDIC8+8eOfGgypb9ciAyN7ilL/60hs3bt6EyE6hVV+9dJ+ZRK+/9Pr3vv8tUutGg86sY3zYWoVCtrq07K53L60sI5HtLa1sABKyID6QOotR2VDnXvF56Yhvam0ZHhlhDOGhg/so233vhz+wmQ0jQ485vfW1Vbw1SG1NWj2xdRYvNZWiNOYwi5I2HT/0GTL8hvRRTgREG04ntOWk6vWspNkK3FU18HDwheef9y57ERpkhUR2OJqE8W97PcJtJyvP3gMlAT1lmVxJZhsxIfPLNkDdoVKQ+GxGDkwdYcfR2NokJSZJJ5MGnRH5IeyViKQNsw+Z7ZolH4V/j5u8G+8KP4Wh9ri5SFnZdjwaJnckPB+5DNdUlLdrm70LwQTDCDJQryBNZIny6/kg2JPunoMWS9WuS48Y77o6yDa3Dznk8b/uB2EQeCsuO8LNT/4srnZHYKbJivCicH1Kzo8Q/9K2xI3hREsv/4MzI3R8hYSyFH09tMYxJ5xhbxVKeosYEa6HoZfDEOJwmsAkOMjuGdDuSQkRGgoKuHxLMs1mqGBIMCPu1oJRnA2Txc7+JWVBbAWTIY30lNZNZtVGThGPxtz11vpGh8YomVkYKmxvNLUwwzTHuFygiyBb2LhUuEirNdd3wjNNVLTqDbzyymufnb9BiZpQm8k1hFJl2xV5OnTyYmQQa8G5oSNYBHYo0CaSmxxBo6x8+PiR8AE0crvLAW1vcHWNESFDg8OYQDQopJKkbvFB0VsQi9g95uUFv2/Jn8tABRf4+L3LnW2eYwePYtCOHjy26l+DRLGxuQX8Qk9XJ5xzv/+7v08Ou7mpzu9dw4qTeTRZTcD3zVW2QCgwu0D6dHFzo8je8zjdTSfqw+vrjDPXaeQb2cTYyABTOg8f2X/z1hWi/y+98TJeOJQnL774zPpawOEAPa9d9a3hdmOvskmRmydepxbG5ZL/YRmoJaDv4WMM7qyLepFCg7ckxFCufO6lF6emZmura+D1Dvh8iAmDpzBEKAgGzUMAQbkFTEOFpsJuFlgy2PhoC6Pii9Ai86g/RnQXZZXoy0ySlI6EDxPbkLnlWuCe4AgINyl/djVSx7YEN0o8CQ8pElfS3MLn8a/DlBrFPpRXVKIlZVIVtJCwQDY1dkiKikoJQX8wmxDuOg+mVpaUlIfAiTNC0ribu/qdzbBrB3iFx64jxEegRYkBVuHPux4MewWljgoRQe7/FH1xdB6ICF4amRPOjN/Y7jgLmAMcfXA7BDYCGmcgspZQACLjwKBY0u0g9HH9SsZEZIc4LWwSmXiAymadGfwCfmEskkKMsrQBMOdTrsQQc9n4xPTqANaJxMLklKh04ohHY+vumhb2LUQmgnZAX4a3IyrNsQLNpJzOqi8h/DgJCKqyS5cvwtHJFGcABecvfPSVX3rj3Q/ewv8HxKSmdUeMKS/lsyokuAbCsyP9tLGTKaaNmnx5oQgho9Nhl0vkRDmB1TXazUlB4LaOD49HAlFyV05HDVgD4ovZyXnWp7O9F2Ld+dz8/qNH//bx4OMHD3/t17584+qV7Eauvq4B/UTW/KmnniExXru1ubzq28wWmD9w7syJocHH8wvRvr2O9s6WkUeDh04e+fTdD4w2y5F9h0ZGxhpqGngnhb6VRR9TtanHzczOSiWVsQQwt+K963dbO9ojaxGrnbG+669/4TXahY16Ex4OAmbRW5D7QqYg25GDXKiqdo0lxtYY1iaIUrbxS0nBie6tTfB8MtJcoBQgoGd74O5jZOjywTv31NdxNHQfbpIoaJBI2lRws3GR8sz2xNeHi53qBkN64rF4LEJEW1cvhudC2oyaxk0nmoKnmirh3OQsgQrhilpl02u0+MdZhqJUCCZW0oeICRAg3KS1NTEqioiCYVRkuqEsIMlE57DSSMMRXN+p1vYG8kpayC2LDEBch3UC7UO0fOPGDXwlqawLCREPXIVSop+nXG/J0UL42Qy7lIlZKT4Gdw6J5wnAAb61hHKrIFcgJLXkP+G0lNS/kGGOyPtZIGIddjBOngIksIJWaHjtbGzPXJbehW1qh7wqwoQipLPlarkGuJKYBaymnVxgY+ivqat2QBW0lU6EAgmGnyqhmmPo0HaWaVxUbTjF5o5WejJ7e7rDQeJ6AarhGhgDAYI8vZFzVTvAk9Ks2uppJMC1uxnKvb4wv+J2Wyh1IfeClkOlFEZUUC0lFYb82NSjvb0HJifm8YsKGUF8RGRrNJgMeiUZwvmp+braanQPOMS1yYUGQ7Vqs0yxpQCpPzc3pjMoySHijsrFlL6ddDjnsHiKaXlgMfPBB5+QwcDlWJxeDq4F3FW2sdFBBl1azOZwImx0WrekZZ9cvkDlCMQEKAQkA4NT56kn26hX6aPBWDG7ZVGXybclqUBUTdInX7Srjb4F38rmypmT577/nR9RLK9oknOSTFEI+RO0KwzMjJJ2I/bNhbdmBhaEKysvdxtq3aZapaCA0DARDL0wODNEhjoD0DDJvC39g/uPyegbzcYdOl1kFByMDUqKdMu0ELd0t2Ym0/ASbJIgJoIsGUNKhJgRFjAlppiR7NWcPHWcTIvdaqEp0eJ0DgWmqEKfPn5idX5esSMZXLtfsYElLwSLAXo15+cXGBBNK71ck2S0GV57Z1PT0twsI9QhxYjDc0ZvsUzhrLbCeLm8vEIrPZ0zqViKDhoSPsw4w0lhfE5FecFVTTiuSuczm2Vxcg0kHtp6PWtGaKd0mxtDgiGbbkWFhs0PApeBQ8ePHydjGIPMYlt4NyRVsTMU5fDruRxcEiAswuYD68Ve8Iwl467gGaPRsUeEGwj6//6ggrPrWokMEkcVvc5UgUTvJuxoWo1yJ0e5l5Ke6JimrmnQCUIsso5YNzYokT7Va6yL1SjIajbSefIwerVmaX0tLGhrtb39nWQj1AoNpnl9DSOgXV30r/nD7moXjmE4DIMVgEodQ0rQKaSE2jt6FhYENy050I30lkKuJUn1+Rdfoa7HyZfKD+SLQYZi7UQMtLUhAg78TYAMGC6IKoC4Qc9OFNvR2jE3PWc3WWSFXJqK7GpwcmoOYEFDU8Oezj0Tk4PFPMQ7IZRrOBB32xs0Kuu1K/dph7JoXYE1f4NHYTXYPnf23L37d65evdrd3c164qMTGkIkUlNft3fvPlQXXj4mmGWcnpoA9sekSdhsnzn3ubnZcamYsJ1rYc5XMFLjdEOgRMPNwzsPmuoax0emuxp7rl+/bneYuro7tgvbbrtnO1s+N7Z47tw5mIUgjUTmsABXzl9pbG0BZQSpB4VzvdKEM0YKDDKOgD/grqudmp1A38uLWxjtRDbNfa9pYFhLYHZ+Bj566YaESBfeAE4StUj8AOyOtnV2Dw+QVISZSAteO/SsxBX0x1Gc4rqAeMl2pCcOnx64fW9hZm7k/ohMIaPO43BXMRAVxxikmdNq3Ulnab4kjQgOADoanclYIVeQuBSAjlweRJXVYMmn86B3GbJGBwsVBqhXWSW4U2Hn3qT8xgCMHYEjYloKQ8mgG9Qa9NEA/K4AS5k/nwKhtrA4b7NbO6Vi8g1JPwI8MXW8JPq7ng57AC8GZ0eUSHnTbkoIA8e1lRrelMSq/7v08wrmlA2A8SNA4c0oe9aC5Cadu4XtjNmmZbStWlu5JVHp9Rq4oEVYL8iZBSCIlBGeCTkH9iC2hRtMkwZ0iPyJ+KFSImL2hZllZ7XzwIFjkNLhyKrlFQHfmrRcszgbXF5Z5FMH9+9TVZoXZwPepQgnYjI44+FNWqVUFRabQZ6MLE9NTkcjogJQ1OGrYRrB6WFp6XMFxUdCpJIpvNAWYdv4Olw6VkQUUySygD/0xVdev3rx2rnTJ3F7pidmTh17enhiYvjJ8J6+dpPJurw0+5WvfOnB3Ufyimg6gVO0dGD/4dGhMfRFg6eOhPfqyhIuCk7O4oIgtCKE7ejo5EzQMk1NTRRegBscPXqU9z96OIBiRm5IIjNDwB8IVVW5R4Ye9e7rXPH6KA/LdGpPQ30gGmvtaJkcm4VGD9IksjrPPHV2fn4uEos8uPfo3Jmn3nnnHUWF8vDhw2NjIyODY4RJJI6nhyed1S670T4xPE7/8Z6+Ppr3s5sbdx/cbuttJQ8P+p1kABhShUqyvLQqtAnjdhhEYnWQAsGDF2mKcgEWwh3lppO7Q0uCQSSW4JyxNsAH+TUKNlNSzjw8TBb0IIvzqxFfcDuTO37kFMgaYIvYkcbmZpPDksjChBJNREPGSgX4lAyRmKyC6qfGbGCCPP0IWB4yoqKfy6jbQvpKZM4ILmIGoSMEZEhakdwZW7CIucoQVyK0yDEnQ7QZkyR2AafkWwi/sQOcMARKbGNQHWxdHCGOKVKTpQdeEPqQn+V/8xf/HUWFWFNCf/+jD3GBEBN+xTsUMlJy2bEJyDqf56eYmVBKqyF8wrlg8B+vy8oam1xkrCpV5XJVBZBBIkysXEOTWy54y0ndaHGBqPRB7M35ocupN+GLQfCzvhYhD6aQGhRSTG0ZxIMA0JsaW9iHOKDw2DBkirO/e+cW5wYolqZnAgkwrBBCsbc0esqTFQyQZIvTfQRslrE+C0tLZGBNFgPelN4ErkLASdAc6F264dESlNfQxGA3MKA0MHNTY5GErKwyGij86i+8fv3qLbPOePzoCWwU5aHcZkrYEAXxifAjSdZdvHAtndhqbuyqctQMPH5CVrR/3961gBc3FagIOHPghihmMpJf//rX+/sPwv7JofgsyQ1kiDu3d+9elMK777+H6J86foI2h2w6RistQ8KpQDnd9vGF6b7+/dSroQqFqwfrXueqffft9/f19JEXgLYoGUv+7Gdvw84yObnc0erhQmiywMRNTI2fffos7S8Mtbw/8PC5l19YXF36+bvXvvSL58CBg+zv2dP9aGiAnAHcH43NrRTLsFF6vQH/G9FHX5TaBUVbLbof2UDmRIibQ8soE9EYwoTogDvAZz5/8dIGY7XxftV677zXDCIjtgGIbqdQ5Hwoi4F01xjURqdFppEtrC6sB/wkHybHx+jdMZhNbACnuxojQOWosIXfkYZombsFbwg+tox5wwgseTpw01SM2IZlm6TTxX2kNYFG20J5Lo0F33l0d4TOclRSCeUp5nqA8zh58uSzzzyPjEHuRJTLreeK8HxAK5VcmF00q0zQpaOoEEriSzYN9waubeEz/U/4AxL+Px8EE3yERJDwrSkobQNxJv9FU7xCo5Nv7mSpwtKFKlNxZPZKobbWKpJc4AilClBHjIFByrkCVhwRpAmGTJlSxk6gtAYHv31yZBY5nXqyCBMyZXPUJ4aYY+ZTZSFfUqexdexx8wq0KHMTU/hroITcbgW0IuXlS/BxsGONZk0svE2oQhkkq8uDN1aV6A9w6khBhUMxitfsUoEOqNgGXst95Tab9KI//X5oAHerrqbJZa+enFgghoKWE8YqKm+PHz9sqKtdmJmfGJ05eODYZ59eX5z13rry4Ktf/Srh9eDA49a2xkgkU1PjQU+TQSIk+OEP/w4nEbYLuOX69uxDa/7xH/9fglJKqZydnW9qagHU1NndR10T5JzNDD9mTGfQTU3PBWMhGmLuP3zQ0duNRmfyDqmESqXk+ImD6egGE2uCXkEAc/TwkZnJ6XyagnQUYDOUfoRJDD54cOc+VGJul/v44SOPH9//+QeTTz1TPTQyiMqnD3vgyRMW31WlSWZSCERjYxMyhq6lLoQgcitRbZz2bhZF6FcUW4Xog2EPd7R3Ii2QoiAQTwaHSZYLuq5kZmbRl4lmDCCdlYaKYkU8HcskAL3qy4vMHPHNri453ValTkn2TEC6JUX434mk4XYRzEUINEEltWLGM9HmSK8ZMGhyTnQNA1mTIi10X6bxokFJibw7o6ApXm0WtSoT5aewnxYxH4RpqGeiXDJMBH7oGiQZfY2DQw0KicJF5ypQ+WwDYmtRlsMK0fSPrKPvUa4oAfpuEW4x5AKWOHi7//89+GI8a9x4wEycMBVkpl4S7ppthrqmGqqzC8sz6Y0UnhnrCE6Yai/FPZ3WQlhFbbuc/K7IIElQhGKX7yRgfawog264LJ0oAN/NxHJM4+Z+wBaajuWD3iibmBGrWBqPs5kqOohiTr6nrZ87QVfu3s5adq+r3sCIEdiaWKH5mTibia/hCre2VhhzZ0zqrA7W3ECzGH38EHOSybY5LYIEBdcReEm5wmF3gt7BXYcH8pXPv4bf3Nbc8d77P5drRYXo4f0HTFG4fvUeS9zZsX9yYunXv/o1igkfvPchSvPIocPHjvYHg7533/v5b/7zf3Hz9q3zn15kJfkIKFcKGlQJbty4+f77H+LnPPPM5xghjs0JhyL19Y0kQKCE6Ghtmpoc6e1unZ6eO3L4xNjsiFqpXIutM4cBiDAZsFdffgUqr9s3553GqhOnjlMYAQwb9AUO9B8Cgw2vK/Lx4MGDqWn/v/6dXxsaGnz1jVdv37790WcX/sf3/swf/c+MNgR5euaZp65cvQqsg4QMOUfLFnQZwg3DEtIiazJp8aAcdhNqi83AzRdGoIQnQ5hsFiu+IpEVRXG4J3CiEBvc+va2NpCD3unFWmd92B9WkAaUabo6+4afDIEkz4Zi2c1cdjtFO3xNQ7VOb9OoFW2aTswI1UBmv5A5EYPrmEugUnCl4L6E64EDhpvMwFzARXQWUmeDoAXwlSilCgpEHjIpUwhU0EJwl9OkXTaRKkqwBcwGEo7GJB3MZFHMMJQ/sNPuXhEXhdeA4sYYs0l4LupZ7BIuhrtFbyFGgKZ4ROofc/3/v5uAj1Ei4/9EjXiKEDGAhXY4zUYLw3vUDEzIbzlDsQqo0kFkiGaIYp76S12DBIJjlhTVwjeyF0nZMo0UqtNwkGQAUTSd6dmQP3Zk/zF3VQ1O8/LMMtdsNzmQ2UwkvVNJrYPIgiKbhsavih25QWPpbjdrNUZuRiwIURTssJUwa5i0cbKtlZoyMoEGG0UqOiSx7KgVelJJ2m7xnNPApdPoxByhbCofWY+C5Dlz9tTwkxGYW2cXJjVyDZwcFjuxl6gPEJx9+ulnL7/42sqyf2hwkh5iUOg0MfV270F3tDY337x+Y2R08A/+z39HPgqcCDobhfL44cAbb7xx9/Y9mpgmx6f+5b/8lx9++BFTo+tq61jnhfml7t49g8MTjQ0trc0N8HEQA4BvA1mMGVFbNZmdPOoXGLbBoHnz7Z/s6egyMfEb0rHtrK3KJqks/9V/9ivhUDSZS0bTjF1xmZ1mR41taPyJrcr62bXPuFO9+zve+vlbVoe1zWpNphOMsTLbzFRIIjEBq/TUewjOfP51VoHWOUDmfISsKAKHxON2EheRmkcZkZBwV9dEmXC9vUPASnrDaneyjQmXGUNT53al1xMQ4ym2lQ1VLZlYnkmbatLhcmk8GzFCuVqp3ywXW4gaMBQTVOBAz5BHpCMKYv1saoP8EkUIEDZAGxj8A34RZc/0Yjqw6bFAs4uMlBSU1z/gF8TmLDlI3Brst0pdlkMWAelJdugzRjSJFFZX/RcuXCD1cvjw0eqqGqSOB4oRh52P80EUNHBM4QLxO6qai6dixHOe8GAj8vx/f+Df8hE8GQIEqls0SFW7nfXNNZXKclqZuFUQwdo3zARqTIBjStTMxDjgRNEyrtCAn2fTiKbNcsatgYnMMVkWfKw/Td4Kmkgpdvzxw0f2p610IdEQQ4uwulK1I6P0JvX5fTD70d07OjqOv15uQUXsAGT3r4bRBPgACqmS8gR9W/We2mDMCzk8sg7SWUyfyeWjEVC0dBkwP1hT6u/eBkRFiZ7YNA3/QTiy6p1/MqL50le+INmqYA5kMLCCDkY7llXmZ+enDQbzwQNHLl+9ia1QKHVklG7fvgsA7uCB/SwrEQXHeeHFp7///e+7qmpv3r77yiuvsMl/9rOfsYBHjx4nEnj11dfu3r3Hr6TnmBlz8sRpHA+cQMSRGtbN6zcnxkfklTue2gbMOwaWQauHDh5Bjun6XfOvdLW1M3mtprF6amQuFI/MLc/WtVT/1Xe/2dbc8rXf+c23335bka7EUuHk0De8EoSYTAIi+sm9QUWWhZHZZXZuLi1y555+6sJnl5paaEUSBWA0Om52e2s7Ee3y8iqjY1ETNpsZ+4yWBU+L1mcno7BJcuDUQZVDBM87RezENC2NVlMpozGaiSPpTalKqpucnLIZXEaTZTscJgDbCYuEezwRKZRl8dl4bGW2U7Ek8k36HG0FZp4OMDocGCGDC0RWscSfjI4EYkC/IRPhoBwShFLkbMh9oalZQ9QW7y3QiFwkwFXCChvZgmYcIGZZZoNk4xYNYsgYY0c+/vhjtuvZM0/hlCL0qHyMBTEGe4vjoAUFwhHfDpYlyLfAeF29ehV54m94WrsPnu8++DwPgjzwFGyTjRz3qQwAfW1DFVPLqbpIZDsVck4CGZFjd/AacUmB71M7mpiYgiaR4InYF8WJTSdxjubGI6M8zhOIkdHBlA/h3aSYQDplcmIMXKGdoswWs69jBr1uk365VNKo14HkrHY5QWL07elBTKemJjklm92EMuvsaKKm9+zTp93Vhj29HXodmh/qTNJAkJxxr2nYY2JziJDOXVVtt9koOHi9q1YbtHbl8wu0Ij8uk2aPn+577cvPvPqlZw4c7aLFZ8++bngcwtFI7569NZ7G4eFxkjxkObGzLCkzWlgx5Ofyxct0J6MUv/TGG5+d/4yxBof6DwElSMYSB/cfoOhjNZnra+u/8zffISP219/85tDgIHkEyMhx5NgGhw4doq0bZM7RI8ebmtp6e/cGAuuwVBJrwqHiD/gfPH4QjYdPP3sqnos0dtT54z6NVZXYjH//Z9/1RtdVZmVVo2s1smqttbb2tWZ3slKtdP/x/e76mj379wKqZfwMTHjvvv8BIoYLhACQG8VdQJdPzcxC2I6mJ8ADdk9b2cICIGq65YwUGNnxTqcLhgGwRgA3AbE5q6qxU9SqsBLIj1at6u/fz2fxYfQmgy/gHxodYsXITpKgodcGXUBNANlj58ApD+EW+CJyPqhd5GHXYyHbw/YogeXwshmjGKe5WpBIVdLzVcHWZf05FCpbJKbYKCVXglgc/6W1tRmqRbrnS+k+4ZMTl2IHKPLQl4ylItDHpvHY3T98EWdbEuYtKToA54ftTi5ZBOYbG5wTsisQbmwQEYYLe7G7BwT6DfWNWgVdIC2D4YgSBu61QgVTFqIGMhBVDzhfVdw24malkzATbRlUGpI/uOyVMILo9DxBXpPxKLRt/mUvKSAkw+/12cw1VrMlV5X+6IP3PJ56WlX6ert//KMfoE3bWhrszip0D8h4Fr2+oe7HP/np4cMHbt+5AQABOmhsK4x0nV21NPUmU5HFpRkA6riWZG8E5LuCsEnU3OiV02msqWQOlJEv5bU7XawIREOprS2DSQdhN9tvZGLAaqaMKjPSF0YZbUcOqmnJu+hbC4CxJVam6Z6ecRB4fft7now8onT9wx/fr3I6Xnz+cz/92ZuNTS0gbblG3AaykxyfMan9/f0MwMOuEgQTwHzta19DfaL+nwyPVtc0dLS21FS5jHrNx++/A9bVG/RWNTinlqd7DnQjZFQh6utqpyfHPO7qi5c/o+O9usF16dZn3LK6FjfgYk+TuH1GWFbjcV1G13tQjPOpafPgS2xndzRWPc5PlbuaCgwFEWeVmwwKMzjAYi3MzkIwj6XtbG9HINBKhEN0OZPp53azzpwwYsX9RpGxPXD2Dh88wk+TifmzmyRCHE4nSHWz3pBN5nGu5OXq8SezdfVNkfWYxWn2+r1ag+ZgfX8owciolV5TlywnBXpEAAqurgK+IDhTQNohrRWSEpiaoRkbiBs4OtCIpZp7GflxdC6+kbwoAJ7A8IQ0UtuqIL24lYkDDCmQCtMe1JEup8JtswlSCaSCoi5NVLUM4amrEy4NTo0QY0gsqFMJ3Y7phv5eYIHw6kiD8PPj858S1mAKlpe9zBnaFfrdn3xYfJ4qM8ZIOFJQ4Zahnjx1VYzdpQKgUNDvuEUlmymDVMqBoaszlZt5qgAVcB/wZUDTuA3sV+/qEsgj6mhoUNKaFqNLalBuJEUKb2lpoa6mdnZyCn3Q2Fj/8OF9NjcNu6hY+r65hvnFGVTOTvlWQ1NVpaJcrpTOzCy2tjaIyt+po8ve+epapyYu0RqUSTjrc2lQSYLvX1tZmSO0KioAQYisGkPI5UQUDMCjxo6JR1jZXaDuCpsbpPPjmYgAaRXiZrMdMUrECs2tDbJKZbWj8cGdwa7eNnA73/r2XyrlFd1dnU8GH/Z0ddG9fufegzpPw6NHAyB5aEeG9ZYZ3Wj3lua2Dz54n8j+13/913/7t3+LpX711VfZDySXaFBeXvEODjzcSDZeOP8J98JqtlUoyqYn5pq6Ws5/fLm22U1HL4BZaiSBbArRnJgeZazSibPHPvvs8o50ez0WxMaiVuZX5xl21mHvcjfXzM3NWh32lcUFnNWujs7VR35PbR1Ev2g3eKfBKC57vTg5BBsIGSLOredkFuZm6dTKb6ZpsaPZhdYIkOrIHOUonKvmhmZsAu4V559Or7AlKEIDq15bWwX4QAezyWZcmV+Ta6RwfdiqzCAbQbeQuASwBvuzIikmwTEOR65VgIsRwkRCc4u5AXlOgJEp4II525KYCrQNgknZhP9RTQMGIiidSm035F8QYlwJGu5AaOO1k9ZLFpIsHUgmlC8nRmrS5XSTc6utaert2e+urrdanKgSUQcSuU38IJDOBISiSVJkgdBGw8PD9+7dC4SwR2K7WyxGmuI5YyH04iHsAA8+RuiQL+Q5FGwOEHTrTSqg3bk8EzHInKJ0y3N5RA0EWwHXDaj4zraUrCV5Wa6N2JpKBysI2oKwfXFhbntTwpBM6Y7GYjKt+dYplfNoam6mq3psbJQIxu1xd3V1gqIJBNZ0Bi1ENpVKUywZwUaNT43iodbUWXObaQPZBX2lNFT26MnDff09kzOjWqMCqj2ARWDNsdF4ZVCZYQdM5K/Noj0PtkFKihSxiSPZ9thohBU/AQdsYmwE62l22EB6QrnhdHiYY927t2fw4ZhMKXk4cJdjfu6pM3RpaNVKre7w8aPH/+L/8xeopV/+5V9lGMeJEydwhDi3K1cERg039Dd+4zc++OADFhZXk3W4e/f2iy++9Oabb1IUGxx8fObMmUP7+20m/eTEOGlBaEZ7D+wlEXTgQH+2kIYNzm41keyg1jcyPv+lX3yBsJiiz6/8yi+9+/Z70BsAhbKq7a+88dq9B/epy/pDgdbuTghgPM2NKGl4ZVa9PnwehE4Hg6RKY7bZmPBOrhC0JT4YOfKYmCYofGIwf8D1wWtw/twION+xYLyBLNP4yDhav7urF9Tjwvw83jIyg6msddesB9d69++5/tkt8DCRTHijsKFWaLkprOHU9AxqsaWzmfMMkvag7xE2HTEoT1SRCKDZcUQJdCNgk9kAhIdYKpwcUoWigY15jckktPrgl8W2oLizg0+EAyMv3xIJFRD1gbW1hdlF1GtRzATb9NRVI2+0Pnd29JlNDp0GVNwGvhaRAI0AiDdSLHI4LI2INqiFSaU4P/fv38f2YRzZD6RudpNfJZX//3CBWCOiB1jXGZXqdNkodXFKtMyhNqC6Zeg4GPr8FpyKAoRNT0K5ToOULS/7rFZBRIycEdETtUBuZHS5SAsEvaFwIFFlbYiuM/Arc+DU2Q/f+4BT+tznPjc1O1tjNtF7MfDkMVkCbjOdYoT8uc3c4WOHf/azD+vr7dykXDHDtXDl5ZXbOpO66C9DDVisBpIE+XwGghPUDP4acAOmwpNrjkeipHSkZZJqR1UCcI7JApElqSIG+vb07l1cWPD6V3r3HhJj0YYn9+/fy8rqjEr6bwaHH+W3dvYf7PX5lylCDY4+sFuNbHmGAf/XP/njE8fPpmIbf/vd7588cezh/Xt40pwzKw147qu/9iv0oTMeD4C+1WJmp/3HD96nVeXs6VNYnle+8CINlj/87nc6O9u/8NKLk9MTk3NTP/ju93sO9LS0tkXTkWRad/LU0WBgdWJk2GZWvfP2R65qk0KmIAEAjD6bTf3O7/769es3L178rLO7i+YSegwuX79W7fFQeMev8PnXuJsMmc3mCjR6+5eWIO/Bk7bZHOgXNhICBE/26OgIyCUaZZH++bkFJAadyqnSNEMiCPe7tb0dOzw9Mc0baBYtbC7UUIxLRcnlV8grZ5YWIPyYnBiG6guYILXb/A7aR1as2KSNBuVFWjMQ2Gnv6cht5yNJGFOyosRbIv5HUxAvkT0ruT1g3eXUqKgYsvdEt3AuS1JHgNikiCL+DzLMWD1ZlAnD80tz07OhYIyMPbuIqfL0kzHNDfVqtsCuTes9m4kkPNVqWTYjthD/hCJnF2AHBAFjWfnv/9a/euutt3AAsAOoQvwB1DaSSl5WiLt4O3tG+E88aHGAGREF7yxx+NTU26CXzG8ltytA2FDtItsoBhaI0X/wVldAE1QZXEvOzS7jtwCAI5trthDNAostEMsS2C/PreaS9MbJZydXogE6MPS5bKGu1oM5EgOIIGOzWXCNOrs7kPWBoQFo8h8PDrA9Lly6gP6mrQuerKaWxpGhJ0dPHKZpfWZuMp3JWR2AC5lckoRs0Agi3qgzm004tfTrQYkDzz0erVpvml9Y0upNoP8hsyY5zBuQWrYfOoIWZVxqiMGZ8UqKSa20fPLBZ6+89BXAI1MTE8E1/1Y++89+41cHHzyaGp9qb+mdmVyo87QDiAiseQl+0JqoFdxlvB0y0Fw8V4SbgbXHmvErK0zTCHPeyZuBN2NgFuqLscSXr109+8zZa/dvORuqtyTMf0r09XfLKyuWl+Z6utoDFMAiQRgr4HB/7bU3HmPvHg1wzHNPPU09IxpLUKHEGwG8SajQ1dXxySefdDQ3UeoGfA7WElsP8KGuoZHLR/jIccG3h1WvstspZmO4KaTg8rHgyDrng50U7oDJilfMr3hKNrMNPwr0KHaMOj19qvliFqoYmsLnphcaqj2JSPLYoWOxUJRpxawnK4BbQ1/evgP7kFzaDCTKCkAZPFDMyAPwHOQKQWOaN3ZA+AaVzI0WLCYQM/IeMYkDRwhxYngKcPXyimKBOeybA/cfLy4uhddo4i1TK1Hngj0Sx1urruTCjx45rZDrd7YrTYYqmMiRfsby4u+xkVDN3KBS0wvp+HLJpUuX+DIuD7bkXWRoIBgW2usfnJ/dHfAPP3kRRe52V3k8Ncg6WTOcZnxqwl+SqFvoXKhiuJkbEBtxTOQTnbuJG4CsAq9FqQirI7h1S7lX7wrz5PgH7IfX0QS70fri8opWbwgGKSWaXVXVBqMJqO345GQ4EsE3Ja+57F0+ffYMxAS45vAm+QNeg1n38PED9oyahTfhC4IY1xuNjD5wKBXanS06StUmg8Vms4fWgwvzMxSnSN7hY3I6wNxJ6qOsy8oh/FBJJODnLWq1DTIKpcYMM3Yg5Lv38La9yvpk5OHc4tRaYEWjk20VM3/zrW+MTQ7VNriHR5+8/sU3kKqBgSd9fX3oCagKCJaOHT/yzrtvU5S9f/8umS7uEOBWXE/0Ky449/7ZZ5+GtBjUGhiEnq4OyJGIJUDm2Nn3Rgs9RiRiJsYmL1z4jKwAi4sEECAmIykKo+c/PH9w/+HXXnqN51NjM3t79oNYppR+5uRZO93JhS1yS+3tnaJDo9TthPyR3uAWoFaIQSNYNtI9RiPGig3J5uRmQS7GSQKVo/meqR3UZtGRXBeiz8mgOVk3jkYgh5sBFwHkpEA2zcDjZNI9e3vh+m7vbsEOu+urlDogCXmZXEJZicwjW4j7Di0NXEk8oQxSspBitDD/8E9E6Zd0RKWAHqH7uViSQcI7Ek6RUNvCIAi+wU2QvOPjkxMTc5nMFsxjTqfOBO2jlkEblSRoQuE4dS5U9m66ktXms+xkfGZ+crRdUd4Vb5FKAgIdiscY1gC5uX9tjf40JnljeEo4SkbakFUt4K1VlMHcm2d6BrMJmV7urDaTZiGBztdwp/HYSHhx9lSy6VYmA0+HELQqVPAEHtBl54vBAoHfVGsN9NrSEz8zNy/47O2WVf9qKpPUG9TetSh6AifPaLLyT0MrU2GL6bbofrQmIyE8dTXJTJLkT3NrI8zaMKYwhenA4Z76BraJxVPnDIX97a2NKFSx62x2hkdU2athCqXnmElkRCXlRblBby8T1RI1lpGEDjeDsIoLAcaDegkGA5NTY6hntCMdTSSP2T+wO3JAMIZJ2gtl+UMn9lTVWavrbWa7rrbRzZjoI6cOf/2vvv70c0998Re/ODj0pLWlnSgOfcM/kv1gs/GjCAwwC6TkkDDUB9seOX/w4B5BKn2VyCUW2FXlxhOgOtvV1dO//8Dzzz7/1t9fm5ma3te3l1NC+ARYYHvrxIljKAtq2JAnm8xGBldCnULlqspVAyAKtwoOCw5Ls200lDSBo5bIXfYq2H7o2a91uwHlE70IFt9CAV49aNbRPiwyJ0a1nGS/m8Z6i5U8AXqXKQ1M/SKTUVfXAGcWgSkrwxAtTiMUXtMB5mZkbTQM+gO8ndNt0xg14USwWFEw2U2MBCP3NrewQKfA1as3f/x3P1sHmhcOY1VIRiOCaAEK8Ngi9iQSwoOtgM7nK9B0pOqQLupf4nVGjjIgLUeJehPc8NzUPPh5JoVSmBdvzW5QB0Oy2Zw6IyjmHcHKCGMVE5lgOtws0lCOGGBIaN2FzRYXhvfg0IiolqiUUyGxhGngQXKdChgxLmaBv5M6o8GS4kMhDxdAmcVe2dbbXO1xcvR0Nm00k/4nJ0r2V8u5EfWKMJn2FnaWaEmma6gykyzEYvRabra1dgaCIdwjp8MKJiURDyQTUWaemnWW6ZHFhVn/5Niiw+zxLoveAKwUe3cjk+zb2838n6Zmz/LKPMVmCiLZzSzzhZj7qzdAlC+tq7FPTo7CBk8OhF4NRJZ7iYIDToflIdAh0YZhYZXBXfMrZNX+YABUM36R0Wak/W9kYgSuhI0NIQFIISwQgCIJjmhNSieSQghUqps3r6NXOCWUDfU1fClidwwpbYyMeFLLjfnMNiLtcdQd6D2kkMopgZHlRLAokCH3165dQ/2Q4yJvjaLiizjJ4Pra4QMHobkkoiAZT5kvsL5+/sIFndmw/3B/ciOx4J374JMb//YPf4Gk1uTsWDwePn7ikNc/j+jPzfgZv4x+PXXqJF0PH314oaa202qtBhroW1+lhRqp6D9wJuANTgwNr/kxBe0MwsG/BSbN+TwZGe7p6SLoJ3PPvWd9iM5XvXiqGpmUKWDQADsY6IarExcdIiL/xvmzhLTmoRdwd5n5h5CQfWYn8GCJgEZzdeRD+B4SlCIfXqkOBWLJWPr6ldtdnXvw3ZkNVdtqVeggexOuphglz8bNs6sBZSmxPKg8CnaoG+gQeRHpBzrBW8SkOSktZCq29PiTScrq1CKBtSNxeCLcF0JtGChQvPghRn1l316ywUdtFk+lxKSssJKtwJgIdhImRJdBOQYJHYaHeoJUSoGDb+I3+EoQXRASuC7sBhXZKuplwJTKy1z2Slxt7lu6kID/GTT2jqgriXySCCi2y3EFYfMrYWhFvkqgnpF0AmQIQDXMmIHbw4QLRIOCL7BW2NxeWPYW8kmbWQ80PBxPsElxWzOp7VAwTRxCm5VaKU+lEqTPHj58dPbc8UQi8swzT0/NjZVXVlQZ7F7/ckXlDvuQXmQBW9AyrSTn9S1TpS5196YIMQFkgjXayG8sLa6yH0Nr0YMHD1Px8fnDz73wea1BRePn6OQTVJTb7WIzkMLigcjyhMEi1Im2t5jsUIhF09XV6s7ObtAsK6vz0eQ6+oNYvK27LRFjhHSKIQ3hZKhip3I1kLt08aoUKEVuG2z9a6+99u1vf5sawvDoEDS6SBtTFTt7Wqi5nj59ClPAMq6tY7LaQB+RvUlmk03tLWuR9c6ezg8//dDqotuEKL8MOJDBompqrXPXHpmeHa6tq56anDOYzCajLZEOLSzP9u7tferZp27dHFFqLG2dbZXqismpIVoDt7cY1ZiEtGzPnr1kKskjg89pbG6gi6q7sx1gaiweRfUxpZXuMIQYDxzalWgkQLWHZPTSoheXA8nGm8KTxKoAttNqq4zAlZkgWLaVTEZT6QKpEKCiJL63FdTdJdQOhNLd2oFSBgRAGUTJKiVMR+PjExyE6dEIFZVNXAwcE75dLDjzzNGvMnSTKD1hDEu+ObQRAI0F9oFIFGMEEC4eS/lWAvCHk+mHUI57hHXguyRMRMECCKmjurDFUNDFxQV4opjwaXa6qU5kEqKJhR2yDXV5OV3FFAEqpUUF24f0kyBux3ywIyuBzlN2Rq6387QjUpRx1Vo7u5rNRh05e5BSFrWVgdgZQWSUFcQJOxKdRIvVoPEF/4RWI0HRXOo+Rq9wcgSTBJfgLThUirmJOsJ4htWkwpGAzSo8+1huC46neGJDJZPniztUGZlLBEGsBoyoWun3hXt6G+49vEeg09LR2NXTRRz8ZHga4we66dHjB1VOSGwZ4puCoiMWT4yPLh45Zu/q7hsbm/jgwxttrbXMo/3t3/7tixcvYY4ePxogUhwenkLTLCzNVuFsu617+vdQR1v1LZNjRetsCDLXLaqiNGewsXGgW1u68D4hSJEUJHqdkaiBPgyMaRB8nqBWKcfhjobjEDxC1UaRIb+d+etv/aSrq2ZsZvDFV5/58Y9/jE8/OOZ9+eWXMWXHTx4mN7rgnVlem2fsdyi09o1vfaOx0ZMvSwVjvmv3rlIfNa5r9x7ac/vezQcDw6efqpWrpA3NDUxS2VktNjQ2RqLrTletpBxO1Tjt4VB/hoPrdocH3pTaupa1gA9GPdIYfXv3JKLFZ555avDRfb1Rg2FOkLGJRwrF6ompSVLudocN68Sep+uY20lAhd9P4A5iBJVGkyeeGNI/NjaOZzs3NwUJFZ26aElkpYSBF3UbAaWC36lctJUD3mQ1UgVBrAABgqzUdgx3BZKFiplMz4jx8hoZwSE9x7g67BO+ka8mVYUswbgoTAkJWpHtFGgxsT+AUsJRiysJCQoZ9hyIL0FszOssPQ+OIzIhdMKQIIUgrryciJm0DG4nc+4sOofZWFOpoHFqQ1GmJiCFYqYMBpBSIIryJ0lTTqBZSvbg7wAmpsTMyXDIbchYzp471b+/Z2szF/Cv4LRRJUlkozWNLmYkUtiH/BCuBLILqE84iklubuLwl4bOIiVUKkpnSfOC4J9aWQ4ya1QE42py+Xm0O14EKGSnzQGoVVWph45xaGBiZWFtemwadBOXSWsQEZ/XmzCaypBGrY7CsxJHC3Ynb6Bgc5SZrMx7zFFX6Chl6MDPYT7BXeJlAhJ+/rkXf/jDt3De+PaXX37qypVre/bsOX/+YZm0rKbBDG7PgP1Ry4plWxQ0gCfhCsKyIfCj6CGyEODciyIOoqAPBADkhc6oIdmKDzYzPbVbLGcbUO5z2V1rPuaXVBKeMgc36A2vLq6wxMDgSDCgNcmBAMvBPaO0R/g4vzBLxIaXyzCL2lpPMprEoH/u+efu3LlHUaKts3NobLTGU/P2O58dOtZSLi02tTacOH2ELTo69sRoMbY0NiwtBlKJHYju8ptxuUJy+Eg/41JisR0mur7yxue/9bff/MKrz959+Ag3m8geOh+kxWY1Ly4vsZNJQXA+7MlqdxVJBRxdonwcPwQRREyVw9nd1bXmFY0vxF0INA4boCluLqKGswFlE9KPx4ANxMOGYro8D4CThnct4SoXRWcZ8St+YyqZBtSIsJbqVlJiGPKnMDttSwtqLXdeyfdyp/ALSFUSobIDmQRIpytiXSpQifY9HjQckuAX6J3NsvW1+OzUgnd5bSPNVDKw+JB67JBrpM9RINzEeJkyFRkhwEKqMhr3mjzd+3tP1zp7mO4HHpG+hm1Jhp1MpRZyOkmZHho3umLkeCukF4Tep5BFaaqMV2C5qY5GEpDwaHXKVV9odPQJMXpre3MklPX5wuh2isoIhKRSEg7EiGLZ5SDcCJwQUEZ3keXFKcOzAjOKIqFoKjjCoHwocTCyLtgTXFKYNhbnA2YDree15MCIyxioDU96Ng9mcNPmshNowsKnAgZFW2pmQ62t6Nu/tyrs5+M6o4EGOhoLF1e9aKLNbUldfR3hMAG0y1kbjsXdtS54iLgBeGq/8OVfREcCF4HqbGUlcrjGQewOGy5NShgrbGM8mcaisZAVMoUgjWPWG9O2VHIMMZ4obLiUZ6C+FDhqe7VWB9pvnkG6O2oJZ1VFF7DFCq+bzWzBW+s71IUwXb1z8e7AfN/eRH4nb3RqTK5ucEf5aNpRayEjRHxSqTX7Iyski5v3NNx6fO3s80//7d9+f/XWit5k/uizzzxt+vVY4Hf/7e/AbThEzWl86Ny5M3fv36Hu+2hgpNrZ2tQCQ+Osf22RnZBJF3p6Tty991YweICpOjdvXaMGqdbopyZny6uruBd02NL8zx2hFKjRafr29dH/RGTGjSDEJP2CxkITk72+efXW6VMnEGVadQl78JfglKbDEBAKbgJEhji4ND+KtngeG5vb2U25RJbO0s9RTlE2gz+LWGmk81NLUPOSiyNOEBVJjY3ToKMcdg1gnqBQsQDcU0Sce8eDjA8PpF/8FFpdeCXoUE6YJDwp41RCFKThfSMRhLeCbHHmvI3tLewBeEm6aYAM7+zAa0FrLi5SiipKKlK05yGD5N4Kl0UcXxQN+Cc0PiUxm9XFgehuFN+HBaBETNdABW59qqHRY9Cro7FQPpc24waRXSkWYNXzBXyhUJleX9bdU0dChh2yyXhg0SjPfGlIqIlLZKINhZqqoiIUhm9DvpFhhGNKazBRb8L+kAcglUFPdwo+hdlFGtNpqAcgCAp/dGDARpWebtTChtVkfP2NV3/0gx8oVTK+moGqgLqUGjE2eXFlMZmm28Z+/PjRazeuQwhFdp91pHpP2pu4janDXB18RJTfQS7g5kKXiYfGuDvww/v69wLYouMvU8iCZsHsUl1ko7KepIpht6diwhqp5IoNRtKkU3DykRbkRe68XqvDT0WbogCySfpaU7TQtjY1YuuobFQ7qwkBceuxSOgU0n8keUsTqnFx8Zvj3FSbzcbBkQC+UavT3bhxg66xlRVvfV3T/OIyUDAsTEdX58jIUHUt4BFBGQhtJKVx5s5rVYDPLFsFJbObXS7t6Nhj/9ryiRMnjx3+3N98+7u/+Vv/7Jvf+bpctUOTYWfbwSgDL8LrnB62hbA7FBHM1aH1CHVcgjGEjy9iqZmzzevUPSLBMINLAAU1NdbDTklIhX5FP7AY4AYAB/AnRETMgiCnmc2D1ZXBI7UlAfBHPTEaSbJApD/A2xL8Mk4AwmPqMJmNBOiebDZJIl5jMJPzgYgSv1943YLCjU4HlKWIptlFyOHuc4QVgBzqH6wCuf+VxdWx4UnvyrpUTOPTCSgoiB/qMoDGpBQToFqju1jC4EPUv1YD7bKi2tl4sO9sc90hyZamuMUNZW/CaC1yq9DYkQACLFRO9xNfzL1kOUSqBEwP6aHyYn1tDbEOMQH8z+wVDB9d5FjGH/7gJ0azifwUVSciTmZoNTXX7dnbs+pd2GZMrESA5PgIviHT2BgMSJs2/iHOdCK14XC5QL+w3VA8iB0LQSaajjW1Sgd1AAVvWt7KNgtWg5F6O63lpMNLo6erCBwZ6Iu3yTng9JL+w4vA73/8+BF1ABrPqL8RYb/80iuYlrmZWRI8oh1tW8zrZj/j06GtqGKWwQWlkUOIQ6QB6w4OlYz0mEbDMWkTwRsk9Sz2ZzhGghsBJTkGIT06jGiN+hpJRmGFFCqEhjUiqMqk47D6iJHAdstzzzztXV0l7kRFMRMAI0BLFN4FCC5MPO4iarW2po5XkEXOkxcxBc2tzSwIo1Coa/b07KX6Q15PqzOg7XgdTB3FGaZZjE6M7dnTgzmCevrE8ace3hkdGR4+e+ZAKhO6fevyF7/4JaCTk1OzUAo8HLyzVZ7RGIzh9bynvgmdL2bdJkjqE1MKrl/KujxnkDK+EKlVMDNsZs4KMQCLqpHqQIbEIsGu3o56j3t6fqK5sYaMC/NBBapHqRGEhjBRSSopFugQzRhGYMu7skYElc3mLTYXWR16XNy17pnFyYbmOnweMdJieyO9EafUJZNqwCBRwSf7jx5hD6B4yfyIiBEtLHIngnxN2AdmijGQFI+9rJKyN9ZsYW45m87Tri0IR/At0Pvg6KQYeJHCwTtlA6BYyFuqtWXAtWurGvt7TzfU9GPJJOR8+CaCYDKhBKiC0RTINAlhdgP8cCotfiFREchbNJxIg26IiZNEKQsLsyTIOC1ZBWTWin/z23+IHEAgA+KfwuT0zMTtm6NTk0u4VjaHpa4eUnErZFIgt+mUi4ZTCoUR8pE13zRLzHRrktNcDCnyNW+4qsYFegygueDxVOmI55hF9+9/5999dvHi/kN7mCzBfCGzE3ALECs5o1rI8SFDdP3SV0W/BtlAmi2gLEaU2b1kowcGHpHHaGio9y6vUhXq7e6NRxPkKBBWoiIyUSt+n9mgBgq3srRqtJoo2jEY2OFwkukMrUe5C9BMkMJnNOu2oQyhpMxH7o29moGxPwZFA9s+SauHXKltb8UbXIeFq6uzbWx0YGZqnDTR7bu3enr7CbUWJpfb2lqQsJ59e9gJ3FBPYwMnT5KeNl8gjUaGGsEVZTCCwmMiQTKfx91eo4tcIu3Z2zc5PVPX0AR9tKA+1xmZdO+qoh8lLVIZiq0rV69vbyqOHD1OfwxcArCfr66unDrx3OzcAr4AoYXZoSGXCFccBoeSRzyewRWhAQ20NuvQ0twMTxHRJEVygCFkJ3AOyZPCvwBTQ3wrSRbGZnbmUhs0LVWWixepqZPvRzapIcBPSKhKL/8GDhBZGmjIssVkJEmGhTwkw4Jph1wDRIXmi64dPnYQKGh55Q57Q6ogvVRGIC6rBJ6oJagg8CASEJUuQViCnhXJePYhkYkIV5BL+q0o/CVgG/D7VgOF3BbTlQQreDqNWcRVQixJgKLZ8akERhkKYeQcQ0ySSEZOJZvIRNPZBGG6FGJFeogEmBRrw4bBv8LeyKRM6Eb0Ozs7MYJEAuIkmLIrck87a/4QeMZaTwPTf5AzvkwPd99qDLYi0jDtzXuffeYl8higeUAg/dEf/6cnj1aTsZxBZ9cr9HmQMRkIjDYlFtPc1KpSZaJtmYw1RWII7nSkU6hM70jHRsacVc5S0CzxNFJgtq3455lw+NGnH5Dm54oS6eTS6jIqMMvg5u0CJpuF27f/AOOJWCN2Qi6foPQNXxpzPxn9gnHANGMfE7Hku2+fP3FsP64RvWo4bmQV8WGVeu349BRuxlYxfPTEiVv3b2s0BtaFnlipNIV3SxMjC4+FoT4K7KcMVhcQRPE4qAro2olikUJ8LTruIED2eWGBW2FkBC7ihx++j4kDDGcxOzx1DYkUdRITsY5oRN0WnGGETVabEwtT6sMEgKS3OqtDkXVfIBRLAFtSR6IJmiRHRidxTmnPpXBNozUZ/ZaWLp2RelOUZB9nVV/XMjO+TJ0hnljZ09u0vLzI6IDr1664nCC1rdUuRzjp15nMeF8LS162PVDz9UDw2LHjkxPTaDd4Edn2WEUR38Mv6Q8i1kRrwfWAQqKIRWIOs72ls+nDj96xOwzdPe00b2XiGYbJ8tWKCgVZUQQP5Dujx8DWRrzr+SQgq7Kujq4rl2/giURiCZol1sJ+xImTLGNaWnmBhd0A8UOGdJuE5jbamlVRkLgUeX/h76MdOD5LjV7nFhMJ6GDHZfWLkng4KeZGomJ5r0SgVMiws09ERlVUjAolXIPA1xEJ4N6TkoGph8OIMSOFlEYLn5AhD0csgNNN8B1iCAdXIUwiBgC0/alTp+i0wiIj4mxEXHbgJTgnDCJnRwrb4wABAABJREFU/7ndddh0Zndy2yiOkP+k11NSrgQguR5I2G01+/YesVs9//k//elXf/lXEfpLF+689ebHY8MLQV/KYqwLenNmQ/2Du+NDg7P3bg3BgSWXaidH5+amV/xLwUqJCg5+Zurg+DHPmLrbsnehvtlz896NtZAvm89Cn2S0mRKZdAwUP2lpDRW01OjYZDxBI1GeyYGcKtB7CpbPfe7p4No6TcP1Hg90xDOTs+gU2sdWlpb/9L/+FCgv/SWsINwhtdV1kAsxnfazi1dA4vAisQc9ndBMwEWDW8IGglUBcgC0OK4p6yvajoxGfCEyDwgcEE6KMYSG3AbyIWwY1AdryG1Tqhk9qaiu9TC3B+D50uqq4FstFKpra+FwghrRYLK1tnfpjbYPPrqQL+wQT0sqlHUNzQzFsljtwfUw3GwQfzNujDTh1es3Ghqa/IHg40dD9K9BDU89lPhHpEWk+HWFe3dvGvRwqlG0thF0cdfX15lgaUGnQkVx9tQZ9HcvDEVS2ZrXV6C3PJZiPMfK/DK+/roviBOvqJC1QulhsxuUmmQ0RtNAMbd14/JViImcFuf40NhWFtSYtKu1x2F2SXfk6Wi2SPWbiedkfOPZdCLHrFKr0TY3tQBEj01F6fb61Ws3r99AT+O/oV6F4ofFDkQec8HI9xcFGTP8vuxztAkih9CjcVg9fGPkkvXkRZYtTqM3Q71X/CvLvmQsQxSPdsYd51O7m0QEsrhO3GnAhrhPFLoKZRsEK5tlxBiEfCnSupDDp8R0Qxys3dCOSA8zwSucRvmf/dc/R+7J9fL1JLB2pR8Xv3QqecIvfDOQUtxmkEnwn8rK1amkGLbBK6IHmVSqnFOgzYGAME5rldPpuHrt8nPPPcvJ/ejHb54+8zlGwur0ih//5PtXr12kfEbnLmhVSpLI1nMvPr3sW2hu80QSAdGAq1YFV0NUjlG0w6OjeIpkighrRfEceuKNXG11LRgsfDAMN0JPlz1xMNA/iuR8ZHVplRiUHNz62jq4fPotq11uLoRsHVlIQf6jUKKD1wKBR4OR+pYKjUGbhufZZiYTCmU6VDlEpSQrKYVy80SlHDtIAgr00dIqmjsSS+IwAgjkhmFImcgG7KKluYEB1Ewf0moUoyOTO+Ua8kjApXDJ4BLB4hG9sND4uxQl4PelmkO4QsKP+QMAh0bGRsXFDg8TGbOqzFyCRhe4C24J1VnK2FgbpIGrIGTCq4HMIrQeow9Eq1KuB+Z8q7BrGV0Oh15ThRkJx4LZzaS7yTE+DfK0npIi2EUggBQBb9683d3eQ4UEDjYkbHlpiUyUEIvyHcBI4xOjPZ2dd27dUUq0Nc4aOjG6ezqYB0VM2d7exo7Cg2U5OH9Whuwt54k3BSqpmAAJABxNMze/iCGFlhgIW5lsB1qQMsXOkdOHtyooem0otDIBviwvo80VMSO0LWEFQO/AESZ8HlYe0acjGkXM7sVW8LOYL1tbSj24O7AeCAMfA9bDEtHWBGYIwg4cddEJT+qG3D1NHkgqX7FdVOtABO9oRCZU21DTfWjP81p5bXlRhwMPtEeAIOgN3CknMSPMPkci8KXuxFpAeIFKw9xjj7Dp+Bh0DAGjp9bDT8QuncoWcuwibA9JKOoIAF3oi8sSm2Jq6U8XY8HyOzXVDUsLa2RUz555jlpmMs1MWX1bUzdj27733e9UtVQX0vBBqG0uq28p3NAo5lZA6kGdlaw5vXCd3d18NRmD9XBMrlaODy69+urnHz8ewEEFUG6SyHFvCCIB8xBlP7gz8NS5ExaDjfG/BpUpGcuCaafRXiXXhYJhslYE7sNDE0ND8a98+RhTSh88GixaJPt6pY+fBE32uNbIMsrILte3eOhGgM+RBGs8FgWoSPIkEomOj4+x6NhkejZVCjGPDYWDqkGmicXwagUoMhUL0FxPJju1YXdRkkuThmJhwapgl7knONxsUcinXM6q9eAYNSaLSQJR59joFM4DmEiTHhaTGuSAG4GLSnAIKg6zgwdPrhneWI527NiR23dvqo01cjVbV9XT0bE0z8yVTCi0vL5eVu/pHJ2YhMEXT2lnaROf3mSsM2gttF7DAYIixxGYGptkJD1NZCC3Du49ePnyJcALVothC1D5Ro4GGo+reuDuk41o8typ0x9//FEJBEo/qSG8FldUa+bnFmn4QkwNL1hIq8P3E/XGGDHFTs4qKe7m0Z6YR3J0Hb2diVySwQJCt0IDDmwmmtqR7qi1Ktx6tDiSw3ba9XY4IFLHT17hMnmwYrzCltCr9WEvxXqq9Ch6AfeBd3MzVybV05dL7khof+Gzk6zggSclaghwG+Muifw3VUWir1Jhi+7AgmD1FD2OGGY2ErcOYH9Ourq0hHGvsIM0JYlfwZoTBWqUCqp06B58OIvVRBnfYNRxF/EWyHK4az0Qpi77gth9GlbYAPyV66cflPMmMq+vb2ZYNCqwxqMnbIjGM0wMg9S3pcnc3NCISh0bmha6Z1u2Mu9VKXVao76iqNQrzZsbwsdd9Yn8RLXbHQQ3lUjVNdaMT04RY1H/p5rmo1XJF6DyQtnKR6eB3jh4f4yGGzhdUJwUXGBqMOrsly4M6kjA7ICUHDt+rD+VmHgyOBFez5AGqbaZ+vcfXV39aziFgH7Qm+6pr4F+o7rWBdU44yqqnFYKZLmMYGSpqXZROaYWST2fkrXFjH+Ck6IhCUOijSbxBC2X5ZJEXHCOUwwmKKPujc9NjZoOffQC0qyHJSofogFgdmYB9wxOaQqgZMWPHTl+4cIFqCiOHTsBULTW48YXh0ENmjSapOEsRZ7wrPQGMGf6kdGBg4f6JmdHRMlepQ5FKNEodHqlbzUDb/DK8oLdYrY6LbRxFivy5CXX/JNqhVFXId9IUZNyh9aBoFqoBbV0NFPkWpqaP7Lv8Nz8dCaSfDw3Bwjf2Wz57rfeLObKFHUy6DhrXe5QMHLkyJH79x4iXYUU3DYmo9PIvRl+NE5+glZD9u3C9IpEKicHiseCphD2M5NMJKNVde6Z5Znz589b3Dab26G3QoOFPaSOgvxJ5EqhhJEBBAa554M8duWe4/A6P9HwDFzCWUeSmbWE7WUIDbeL/cO+ItHEHiK9AZm3oEcXOSRUEyhMih7bIKrxhfgKxBJB5y+7X0HFizwjITd3dkclvCApu3x3z1GWwwJgdyiNYXCb21o5OZQQn7RYrNRcYXeCO5J8VpHix3aGQjI3gNdpJLXaTH6/jy2LDqCxhp4G8GQ4f8srAYNRyfOGetf83CQY+9/9N783PSW0yHvvfBD2k1dJv/Xj91798guzs7MHD/cUdrLsZqb3sNf9wSCY58nJ6bnZRRx9xIUkzNKylxotkRIlkYqyKBgPk0rT2dV79cr1gXtA28vOnj2ST+9cuXLVoNbML8DiHwED++DeyHPPPXf16tXpqYWKcu++fX3My8imUL3CqiK1ZO4hGkOXU6vBySMLDFu9VqcmlcEO1m4zE7uaJkMUAdEZ6Y1w2K8nsNJrIK5x2qw4AOgTggW2KHSbKA7AghgxfELwklDFkA9FHVCcX1hYsdlcZNvo0MMVuXX91p7unngsFvT5UXrQi+OFtbS3MoWOO3TtxtUjRw6xGYj4t4qOmdkJFQMIC6RwskAQP7t8u7e9dmx8aKeYY6Qxfb2rXvAZ4Rq4o1dmAn7vnr7TQW/k6JnTd67dePJgiJv7zpP3SAQ9yN7nDPH+Bx8+Ymq82qiF783lsi/Pzr/60tmbV25T5WRcFPV4k27HuxyoczfWNzSNDI0WIJaLEkhuqyrhNLCS/odslIwk/A4AHMAy4CQDqIaKT6VVLC7PARw0Av+pcSZzWSBVlDgtNmMmEynJn3AjkXiknytFAhEz5A27yk9Ojwd/BRgWDDLSiomrGFsmUUBmzPRJ0amcE3No2AHgzYhIcX/YIETdqDxEPI9dKG0tqO8Fvovjg/PC9xFbR2B9ODY1OCnaFuXFqHuRddr9YhwGNNxuwo5dyJ0jv0K+csW7QlvdZnQT5AwJynIZg2v0dAAHQn7eDKaA+0Q738zsFCdna2ggaRPyRro6e9cCMXh9oWoCuYmvRSR3/OhxYtP/46tfQ8Q//vTjwPrqB2+ftzg0kIt07W2215qhhCcbS+feo8eDre2dc/Or8OZBX46Q4ncy59npqJ6bmU+li3T7MM5mfnqVzvqD+/sI3FdXVnMba8WCFCqYsmLg0JGjn332WX1D2zs//5hrxOulhDkEm2dqQ6OS0Swwt5ykJabOUK3UyZnRotHjBFUwYYzqXmNjTSGf5YQJTEGPwmNDygsgO2SqLFFkPYJzwiIK55Ua6g4jWPKh0GylkiCY+0k1LQJt6vqaH2vLquPLhwJrII3JFc5MTfp9QWrtBKz1NW56kccgwCpuzUxPEstCF8AX4ZycOHkU+mgqjwSIk+NPaL/eyCV9gRXMUWVZinw29cFYLIqhW1lZqtjWnr9wfU//XoVGuBCdHd0YGcK+G9duQlfM2ba2tj995nNXrtz48he/BLLtGjrCqCtKNo8cPHT00F6g4AD3R56MfPVXfwWK5LXVoN5ouXH1tkalD3jXUxZmoacNJhOdW1SUfStruMF2oG3VpnV/jOwCUSuo/cI2I+OTJqveWWWvb6+Ta9WBaBjJYvK72qDPMfU1R+qGUrLQzUIGSxsARwXoD+xY/7QTdrU1UknYgx9LSEu6n9XmwtFK4BWIWyopAFOPgByH7FrpIWQb6ZYoAHqKFFCuDC4JYQFK/e+0EdOniCtLIUxwK25RNyD7rSz/5v/9DXJJKDA+RK6Afin8KX8gQI8CHWW8j9WnPY0DcevB8BS2wfHhbon+KVqS+SvpPL6YX8laACWlj44yO7VPdAMJLmLFpWVUOPP9EmaDFoPBKWvUhra2ztmZ+Ru3bl66en496hPDVOXbJ58+XFVnFv340GQWd8JRsfspwCws4JZUCwahFTDGwnpS32Vnhtdy0Cn1tLmPHj2KhwaWi7P4za99DaFn9yInnD8PGmGp+JCbm5udBd9LJHDr1g2ZSjE7H66ug9CiTKmRwXBhsKiLZflMPgGhjRBBME6VlSaznZoUzh6tCzSyUBshO04iHK3PUDAQtB53AzeJhl3MyNj4JF4bnRWYRBI1nka3aIuoKIdsD9Ai5CLgb/t69ibiG4CEH90fQN0gOtjMX/nVX/rGN74OYptoyh9k/1cDT2Kd0SPoIHIh7Z3tkXAUeuQ8Tn2hsDTjbaitbW2qvs9oDKuejJZaYcdB8QUDGoOOqC6Z3dTpqzVy48++86Mj+/rJF9IMBFn0zOQUYvTxJx821NXH4mEyGYx+Io1Oo7R/zYsYxOm22aDo3kSzE/xfJpPt8sWrQ0MjIHm4s+RVEBpaoEAEavRUUsuL+QqIRZBLhI1OVDnMZSoZjWyw/Pf279uprMCkJnM5o8OGliWhur2dJneP+ONOkw5iDwjxZwMItkzsA4x1Qth4ILy+ldDKTCIcTCLh7AecSapMzCIANCRXg/sX4e+ui09SgoNgBASSpZDQ64qgkDy1Uk2l6fUXf8Oqb1HLqjZzBGS4W9TQcmAXSJrB/CIB2UR7OMgvzgYLEk1EsCkAxYDI20lBWgz04OH2cULEnQTM5WCwi7JEJOO0ugF5k5glIUClHWVDzwTtheuhSIW0UogCHM0bWcFQUr4Jww8qmRkg66FEJM5sex3sMVqjtqWt+T//8f9Fu5pe69wuaD5889YP/sf784NrkoR6O1a5GS7PrhVUG8ojLQfVWdnw1YcGKdA5LcNOyEX7wjmVuaxQUTa7vPrhhY9Xgiv1bXVNXZ6bDz7ztForDTmnR1bXqs1JfN7Yk+Ofa1FYEsaqnUJF3NPscDc4oXLB3UrGsySO8LzptsBXxp/UyOQbyazLWgWxOPxziDuGC5kjmaaWK5dmFqhybCbyxdSmTWNVlqnc5up6R6NWqt9Olau2NX11e57qPxtaDFUUKsho4Tdj4FMk/XaKGPTAevD7P/zh6PAI+qaruaOxrt5gNrhqnd/4m2+88NKL+/v3/tZvfa27vY15HGhLp9WmV+kaPA3ku3LZHLxJ4UCEZnAIxPfu6ZxfmPzZW+8h69tlAgSJssRDc1jcxw8+a1DUSTZMdy+NPrw6tpWQ728/WZHX5GPlP/nO26FVZuXF9nX1U6kP+sKdHXsWF9cGB6YvX31cLNM1dxzE3w6FY23t3dFEEkOB7x0NB586eyKVCMciAcbSRGMBeuLAZ4JupiWQRp2aGuyWQaWTR9OxSr1cYdaly7baD/TlYHuXMHijINdUJFMhppXlNuIKBrJBYShcTpp0aU0S3Kw80Hc+P6CmDeHK4JkWy7LwKW5u0+UHchEkCGPrIfgAQ0iAIfJGZMFpPKSZcXOLDJAU2ATUGRDBbCToYqWOpdWUxUIC480mYQJiKhPGXUIjM4tI4BwryrL5eCi+Wv4nf/SnaE2iOvxyzoOf2HS8Gn6iO/HpcctwlZAA1CHvpH7Bm8lLEizwVxGsyNDuG3yQRB46EneZ/corfJCEEnCG3RQeShpVR9hB9x2xEfuV4+CToJvJrD1+/FikAi3griFLC9V6zK+89jI5b+/KEldIhnVhbh69SAXaXuPcUVWWq2Tr8Kf7gtJscQsMYV7s7KZme0dnq1FPXVupUEpQpWg4erMWlxdWVpYPHjw0O7U0Puiro3nMVjUyNhmLMjkUp3JTrUcZyAhsYBsQ9qechHQac0laoLrOTeRT5XThruDtNjU04u0wwsSo1cOpmAinzp1+Bob0mzfuBtdCBq2BBAMJHGeNM74RNVaZEoUE9IwpWnuSyYmJSbp/2lu6dZW6SDBGch3+izn/AqS0hIdkI0Bt1NXWEIxRzAJpghlk/OvMnP9zL56EowoThzfR3NY4Pj567Ohh8rMP794lUiQI16m1dbXN87NeT03b4kJAr3c47fWQ429mN4fuPLp97cYf/OHvf/Ob3zh14uTwyOBv/uY//9Hf/WDv3j6vf5W6OUaDmu7S8vLk9NS+vXsia/4N+MisDiaM4OS8/+57jXWNCAA3lL2aTCbWwtTdK6o91WQdh4aGTWoTuA4JjqO8gimTcgakMZsZjK3LJqG7XbTykp0sE+pePLbgCSkNghRgYaJXwYRI5lLMGgX+wNxy1oB5MwIKQd9zOJScGV+BOZNAE/CiUirYrChyo8PxfxAzfsX5F55QKQgWfEIUMmQwRgDBLFPJyknpHjnwdKOnRyFxKKTm7S05NofORTo988U400FFxUGkQUuAWL4b74LjCgNU8pP4KxfPcz6GmPIG/sqviC+nyE1lV7AN2B67G4Zf8Uw4LX7lbfyJrcKLcMgQyfFxXrlx4wYeBUdG9PF0Sdjt7jHiVJVC+sF7b1otyyAWX3zx5X/+m78ZXg/EYxs6ZZlGrQSASThBR/yHly5QjmF+LaECOd91GlUpeaQypJex0YnVEHEO1Qm2AarEabbjaiL9xNO9XXvr3C3Li8GaupoLl2/TkzC3GHW5KjU6M8OOgZSwXdACdGZTC8TPoWCJA4aJI+lESYcEBjcpFAiiklEpa94gJNIzCzOk64YnvBaTDMoOCGtXoHmr6Mvt5NR2LYtGUhzJAMbY3NwaDyX8q96pUMqgNrfUt3z84ceHTxxN7lTEAgmbydnW3PTo4X3SWaANUZIolFp33fQUXNDBvt59cwti1jx4WbpzguQAdso0Cj1bsdpTBwZ33ZegN81XFoiuJ5ZnIwOFcaXaEFuPNlRV9XS3v/vOW4cO7ifDBy/yrRtXDxzYh4M3uzCxsDhD8EdXKiS1zS11sDSksnEI83CU79y9ASB0eXWRKTILy/MEeG36Dgb/ROZDJDBdDS6YsE6eO8m5UY7E7dbgTxeKMD5sVW4D48WPQNeTBSbnSOaA//OP30g9oqvIwuD4IAP07iJyuw9kjLlEQsRLJFZIC5IDyQo8bhUaERNjOUTSGgZCjAiDSUob4B9+inyoaIrhI3CU8BsxADmZbI6WfG+TZ59wXgT+R9A10LtA49hWGbRIHLAUIyOXIv1DpFB68ITXSb3xrXwG24oCYFfwCvLBc95QqoyKRmNeITTEaCDxZH74IPsB68Gv6HjkG2Qbf+XC+BWh5xQ5LMek4kO5B9Qk2EmsBGk1PPsXX/jCv/29P/ztf/V7Dx8MjI4uYhBf+vwzVF7Qx6QuAJD+4Hs/fPH5F+iZO9C3j9R1PBWHmUNr0tc118JshwsZikUJKPE3mG1KAgpnjJ8435QEqR4Pj43oTJqLVy/s7W9PpGMOF2BeAe4CDUoPETxkwIFAvHG2XAJ5VbQDog/kmDQURxgdmyALtVNezrwjqifMzxM9p+Vl//LffKXvYB89lv1HDlR5bN6gjwI2pAm7a8jY45deeIlmAxptmxtb2to6WKVbN++ALeto7kCGvvoLv/bM6c85zFV0X5PFZDYH+cq52YX7tx9azZpnnnoOEXr0YACgBOV+p91x6sQZkEtUYWGqC/oTSqlhcc7X5GkffDDa2drz8O4jh8UR9q1TQb1y6RIQMfpsLSZdNBYkOMF9f3j/9vCTR/Bn19ZUGYzq9XV/KhmGnRfngZZr+Ictdpo0rblCxlnjmFuaqqp3Ivobm/TJJ2E6sdVa61pq9Dado9bW0NFS195krbarTTq93WSvdljJi7lssGsBJgeVIOBtop7IIoluW84fhxPXBSlChwJewgsCeij2CH44xe2S8LAlWCJhaqqrdQRjQj5J8oi9wduQdf66+xAQCLGVQBSIh+BVFJlVIO4AHegBIHEfR/rZTAgthxWSKcSTyBeoJ0l/Ekelx+5x+XruPS+g+Ln3PDhLBJe3Ee1yXAwxCpv7yjE4G6SZk+bBE/7KfuAIHIqDsDEI8lD8AI2wFWToKXxyZD7OeAg2GhodFQ40l2oDLhCXOvxkgB0XDISpk7d1tOFZMnPt3t2HL7/44pPBh48fTrR2OGeX1r75P77haWsmVoK/Ad4/GjwJsADuEmNQEZTSoiStAFVPQXd+cREQBGU/+Pi7u3spbEFTYzBpjWYg0Nu19bUTk0v19U7vmp9OX4NRwQQu1oqQDloKg1Gmt5joxzDqjSBkUOHkH0jPsxoUI1Mb2c62ThwQb8AXiSSsFltLd1sV/YHpQmtPy/zSfP+h/rnVOYYyMk2avBBVbQgrevb3TAxPaRS61155/d//2/8AIuP73/7B2bNn/93v/AGW7fq1K6BfGf73f//pn1+8dOH2vds9Pb3MX+MWPBkdcVfX3rt9t7m9bn527urFy4LWTmUyaKx1rfVv/f27504+ffXSjXyqeOfy3adPntUrNF947nPwgQ0O3stlUwf6e6enxgFNUWYltb29s0F9KxOJX7l6AcKlw4f7GtuauIPcGiJ+xl2US7eOnz2SjKcY9FIsWp219tRMYrM8h9Zr7Wq2VdlB/INUZQq2n2GH0q1oPpkIx6lbEzrKVJUUvniCvCKRoDaF5yOULxhIKehpxIY7IupWorpFDCyQcDyQH/7ET0Jk5AeJR/zoXCMYxsITNePmbOVF1gcMNcfjPbwbzY+XL/5LSLFTlkmRkBUdL1Dk4p0A2gvSRh8MtDXW4KVhI0rN9TneLpJphDLf+9YPdkWci+e7Mdl8K/p4Fx+LFSYCxijj2OCu8BPfHtlleyDTCDrJAaSf5/yV47CIvJ/nvIGL4SfgarT+gQMHgDTj3fJ+fnK1bEe+hZ/ki/CIAK4QMJw6foImurt379JlRo+ixqAB8Pzmj3+4vLT2/DPHyLQvLc2PzazvPVIfjIdEqWV+Dv4CdjT7k7Eb9NxY7WbIYYDE2W2CjDuViLGvwMPwFXwX3xtLRLV688iTcVBZfh9MME4SO9ytUMgH+TYqkJw6OoUVh4GPPYwvB0kWy4Um47t4gKog0U2mi6wFewOjBPkw54+HE4LO1lHNvQ1GAs3tzeAsxqcnKHKjFFhbCI0T4SRdNEqpyqgx/vxn75EQe/nlVyihcGLDI0/YWvQ8uGurUZ++wOqBQ/3lsvKBJwOkmKV4ZfiTKTGKk3q+UW9ZXfQy4vVo/wkG7jKzo72p6+Inl0neg44PB6JcNWCQo8cOdnQ2w144NjpKlZ2cKfcXunJYAwubeQIqAEUWh8VgNuI60oGNoRZ0KTodJp3bYTaaqc/w66pvFfEAQ2532fG3ASkCD6HRyGZ1hiKQ80u46URcZoultr4GkAJ+C5KASItMpdD+6GQ8IqGyOQFylcgu8sqrgKLBWiEq9EUiRWgWFgp0MzcLQYf3MxreYIxIwOfHBdn9Yrg5MQfsqt0NIN4vqmsiHmBLwaJILUJOg3pZQa2qDAcjuUzZ4f3Hf/krv2k318nKNYk40V0RJD84aoBxwmfik5wZd5oHd4IHNx6xxudhRXjO+aG5ec5PtgTYFV7kI9gEPsIJ7O4NloyP8FeoNbhb2Dh0POKOubh27Rp/QtkT9eL5cBAOhTBhIkii/fCHP+QIaBfsAA2dmDjgx4A0wcGCVQZCQ17gxtVbREj7+vb98i88OzywQFNjPpOFWlk4V3gNO9s0iMF+TBAF0wPmTRQ9KiQ2hyuRyoC+pQwk6L83NrQGHYAZZ7VjPQIuTT9HV/n83KPBAShh8JroeiHypnoC6h0XlAIzYFIMOY4euWIiAyrTDMXRGU31tEE0NjAqVa5WjM9MFHY2M8Bm+jqDTDaLBsh5g7XHoWSJyEHQi0TRjebJcDDktLsAad++dZdyGAsF7fP1mzcGngy++tprf/lX37C5bEuw60fXLU4rh300+Li2wZPIJJ01Lq1JBw3EwvwELDiry/NgvYAEL8zCUbIw+Gjom1//K1yE3o4euUTqtFpcFktLvTsRWl9cgCd4p6bW2dxCuta3kUns6+t+MjSIdqB5zb8GULcyXCoqt3c01Hhc/Yf2WO0mWu8rFcCHd6xOE8q+qb3+qRfO1rfXg+cB4IAPiUfE+KPl4CqMM7ntQrFiB5gtFF9b4FiZSw79SOkhBqDDJ4uSpxUDFHK+IESVDD57AN1P+p3Ai71YytYjZnxIuBOYXdKb6HYqvlsbdsZx1tVqtMx1E02PYMnYfgi4SLL/w4OnBBrCJaEfCm6LEryIbCnNTOyisidDDx8+uuULLAJ4FwTmlaVhUGI8NjPCvvFtvBqET+y58nIsIMKNTHNkND2bkpuEHCPoKGxMAaELMs0pctJINh/Bt8GT4ScvchBOHfUjECmkVzY3IXxm0+/uK97MxsAUPP/886TY+F4UM39lEyLHBMqDjwY0Cg12Biq4YDTk88NDr/rTP/kvdHVoKiuaGuvC4cAbX3pjZGb84rXbGrMovWF24esAdlbf5KFzPxIPAeGEgAQ3BgJe6mVf/4s/+9a3vkXnuMvpZEhMLBPiJnmXgpC0pxmNwagBprgKbrEigEhAB5w1cRuRMEdnQSkGQ3bLGXJv0Isr3lWcpPVQkN3GVueqIX8h8iGMQSOIPcO0PmGWRd6DReNT6E760cACE++h+MFLXvr0MsVUWnYIe0bHxyj3Eiat+FbouUMr053z+Vc+/+EnHxLKs6sZNZJMi/JTPBkrbm00e6yzExP0A7pdjalYTrajbK7ryCULMEzCR+Jf9nW3dSFzN25eo65MP7E/sqbSyhktTrjlqanmrlGgdbldgCygdvUFvH39vclsAnoYEgbU2CtpENILYw6ZLmeOI6CAJW57M7i+jqvCPSUfxZkgGCarBRYqxpNDOcmbcRxYB+QZR5GSEQUf4MmIvpw6ICAd0RzO4Tdx7YVkC/HFgaE2hdii8XbQPIx5/geKBnI5JZedlAPECPAdwRxKkW5lKcIEbrjjoHAkvcdBuHccjYCb57sbBitqhih/dZGboNfB+bBFKLy9WeF2Nj177vN7eo4yO6Vihz5MwQbE+QjJRAR31TxrxF1ETXIliDIanT3Am/grvyINpHQwdnyE51wwb+YnSp0dwuF4Mw9ynZwNOp5FRNxZKVx85JuNwROEm7uOZ8kmYdvwBvbeyMgIxoGfbDbeibiEw1GaIkpfSqlc0C8CYaK6+dTZpwcfD7odroZau2+JXbhFzphrRtSGh0cZ9WM2WdHWjF2AZwY3q76x/ic//Xs0R319A7xADEgk85hlaB89ozQaQVzEBW5tt7V3UpwiFNvt6UZKOAGaOtAzhMVzs/NAfejyXl5Z5SB8i516uM0uiF5wtPQ6PDGQ6mxFWnaoxFeq5dFUjPuBTwaYmffHwgmnvSrBMBfuqD9AExb00fsP7FtaWZRrZBa35fKdyza3/f7QA7VFuyMv+/DSJ0uBFdIpw9Mj6+nIUnC1nAKMtJjJJRnEdPr0UarCcF8SsSSSoQuffXL+s09Qk4GAl/xGJLp28bOPoLjO5Qig1nmFG0G296lnnnZWVTW1tJAqQJGB8wXlAaHVyurykycDDx7cxb28wzSbR/eoPSOcTFVCQftDvmgyrKJYbdDQP81MFzpawFPh/pEUxiazVlSCIdmmS1KlUGKTUXmoceDWxXxRUSFH90swAyxQblNPYk6qoIbIUnObUDHcvo1MDlpzcKBktNhyqAyQclAGEe6isABTBYI+OJSoW2k0SBYPIIagnckr0cAt0jbIIX6XwaCHr5YWqVQ6ho4XtD1lxHWVFCi0hspw3Hvz7kV/YJbqKA0vzEOhnsZMbynijvux66RyLJ7sev/sAU6Fy+MVNgDv4a9CHygQWqEa+Ss2gTPmV7YBDzYG8k2an02CuPMKEk+3Lq+AjePjbBW2EFuF1/ns7mbgzeh+irhsCdQC34vTefX6tV//F7/xwYfv4iPhJJKgiqVz5z/9tKm+TqEWvLBrK8H2JtPccnS7KPjcSWDxdUQ/xMRws9HCS6wDiwG9D1OzMy67A0AblAfAeAJzXvjPmGIf88WzGfrtUAbShw8fV1c7yRWgU1hNwOpanQbID5ePrOxqcRQBrKhKZR4mJRij2OdCIyRSBw7up4JDixN9hJ6a2gQTT3Ib/QcPeFeEZw8G22wwnztz7uKnF6GqF4nF5WVapidnJqFMO3z0sNFuGJ8cddQ4gvGgvdZRKN8ER1nY2OR5c2dbgInBiUiFQrqwushStzfVdnhsd+/ezG9sNzYompsbnn/28599fJUui4mZkY1k7sTh4+PDI+DoiAeJbcgfBmMRdimLjKIB7MRPUEmkvFrbOrCWkzPjzAukZDm3PPei5/mnnjp779ET5BDzRa+pWWnSSnQkDOm5Q093dNHX72uoayShDGtYKp6lDZ12FE9VLRKCcaD/hHCfKR64BtCC5Oia3tiE9MGg1oHTiW4xnHyTUCCXExP50A74qzhESGAum8W9ZFlZfFYVUUGoyB+x8mxgVV5BHSCRSWRo09pCIYI/UJeiZbEZUP/MfQReIQrNUDKR3sQfgwpTAzqJMFzk9EFok/CJpQOLq5MGeLMkWtrWCQmR5/I//L1/j3CzuHwroolcYn0QX17kzLDyiCBamTPDIHBatK/veixcMKqF96CAOWl+RWFjTLDmhIm7bhUnyOR05J734BTxcY6M24DI8oSv4+AcluskGcqvsK20N7awByBbX1nzNjU3PPXUaWyIgiJXjfuZp854IYmdnyEDncllmX3y2bVrmXyZ0YqvroQOLQ1N5lZ+LRhqbHFTE4FrlrmLTIJhahC5MX4F1DQ2M4RAhEOpinJNOrm5vOQnqY/LyKwDpmnQrYHHjENJQzPnyXXV1ntIZ+PHsy3xcLheoj+UAmfLOogmVxlNGBvEM+xSltFqcbB0DIZhaZCSSChi1plIg3Kl46MToIRwIPl4jasGh0oMidBKmbpIXpXxJyhWYgksCVSHxHPBCNMf0iQUCPIABaFHAitzqp2MWlpmNNiVCp1/JXRg37G11TBdq9DCBlaCxw4fHR0apWAUCYUhcuDk+g71M1uElQex8oPvfq8UgFkokmTF0MUto0XL1OTsZjqaCNPDANzrxp17tXUN4u7nc1RhcatxlBFrZGVpcYXxrEF/gEMxQga3ymGvejwwWuXGMRaAMzY8/PIoGfpgGAuMRQQLxy2g8ZJqJuVtOfkvi5HxePS1opKYVoVNxhEibCARh/wgCcgroojAIDyIE/afdA3DmsLrsRjYmHCSxkhUFfaHZeR24wTxQTYATSzgQNkL6P5KOV6+IDbmSvkr0TjQY9qGe1r7z5x8Tqu0KmUGiguQRvJX4frzZXw3csllcIeQOZ4jmmxKbjnnxBbnFiIE09NTvIiMcIoIMafIefBxloDrRw7o8cXJ4T18nAQo8od25yt4MxEhb+MNLBCKkFfOnDmD98JuefXVV7/73e+2NDZNTk5UVbkWlxY++PTDzy5fpJfH7bQB/yA/jFOLudy3Zz9zR0gw0y35xVdeu3D50sxivKNLSziAK4JRZUwhX03ymBE9ALw4bcR03/69G5kNig8sLkjM8Hpaq95JJTf9/rRGRWwDWjjCjLb9/d2wYFjMehat2lUFZCuSJN2X4GzBGtPIwpZQa0QGDCGAaIq9yjpUZMqZswLSe8++vffuP2SOECYOTRlcw3Svy3cq+SCjz3knagedwupVamTTi1M2h7XOVtda2wZRHCWkcCJUqVYy2yQSjR47eaJXJvvZW2+y63AP9FrT0sKqSla5b0/7xPBj7BJLElElxZhXjeIP//3vR0KJKxeuDo0Oq9QClcR8diIHOOHwpu/ee/Dyy6+QPH3p5ddY/HsPHu/d1zs5PS2RbZ+tOw0GAXx7p7GTWU/UT2o8HrYBqwRwGZNHHp1qBpAE8nbVrurJsSmarRl+Kt2SQTu1POetc9RS8qIjhVq30A4A7wjeFrylfPsmWpwhljQZE5hSMKZS6Wmrp62RziOjyoybSnUATxL5Y5Ii1gBZQoqQSeQE8eA5vr3w1hAdtc5htS9DC0TdrZAjmMYmM8dIvAUBJ3SDKaWIg089QVTBkMrsBoqsCH0JxLVSiXwzt0MpQwCiSzEDrim9rLA0ik5IBBcNzfcRlXKPEVB2PLgGtCBqnuesCE94D5K9u9dREruKn9vJ5kEm+DgPPoUF5ORYDvwE/EIOzoVxz3g/r6DJOCAFMlQgwQBHxmg8ePAAJqnVpWVIRGBdnZ+fxtCXsqkqny9gUMv1TiebjUSk3Wpdj6wbpBRBs1a7zaQ1mdRxh9nBGHGdUiuRS0x2IywGGHGwFfBwki9mR925cwuJbG1vWfEv67Z3dGrI7BfiEQA2eor0NBiCZkOvcHfh8iCQQ4wEaYxEwoiaWCpBwAAVByVJZJH6AxK2FFrq7OwA8U/OdGlxGc3K8+HBYbjdyZAS4JCErpTBYWJ68GDg5PETcNxy1YQfREd0WtN9limk9x3ax14lRcZisvJsG2p2uH+o/InRKV6sdtQyQ81uhPA0Df/Xzlbm+uWLXa31C/PLUIDZDrgp1enMpoGRQXZIZ2/X5PRsJOCfHltqa2nMFopDYxPg8vr29v/Ff//L11559e/f/DkUXf/md37//sN7FcxnlJeFIwl5TqKzGjZCYbw/Wn3ASwNcYvA43qPgbNFp8VfYvR5P3ciTMSbWaU2GbBxqBvWDew/39PSFg2HSrCgCMi6IwbZqs97h4UJgTwNeBV5BCbsSXpDBwE6A1xXBZZlxmkX0hZslOKCLRFZbauBrYjIvxgopQueyAdgJuP7497B7EFyjj1Dw7A20PpBA3sw7eV6SQxEHkyPC8ZdXSkhtQbYCGQheK99KUzf+sVqhR3g5AkltkkwFEaIAWyvVZblQ8j/EskgzoszN4GLQzahP/B/UP28TvlSJyoZvRaDFdi+BWvmVM+C8EWUOQgMHmRM+iw1B3Inf+SzH53nJoolkPB/nFSwDG5t0EF/Br/gPvXu63Q6rF9p0m5nukPsPHoOnV4DPUSura6qY0pyOx58MPoamipYrrAF5FbvJhmMdD8fnvcuepuoyuchRM9yUvhRaH4C1PB4crHG7qmF52d5kmzmFr6+sAFhPF1S2qDRKmUHC+Rj0KotVOzE6YbHqogUcjxYm85GAT9MOXmoaxAtIpzNMnsplklw4V8fwL2xXfX2dUWdaXfZi6ms8blI2jMKGVhQ//uSRU/hXjTUNZNPJ57Iml65cWlpeYPb10RNHATDevHmdqnDQv06xLJWI80HmK77+6hvAP5mDy944dug4SoeyNzquvbHz4Z0rNjNUGs3UcIae4Os7AZ5ykpvbW1Mz0yBMSQT3dO+rci0NPBgEz8Ms7o8++Vim0LzxpV98eO/+gYNHqEVCNUslhI6pnk6qbAIHzFKsBCgI1kxNTNY3tHCjcdAZLsnt5sSgaJdXUNXV1FR5lmaXTVqrd8V/7/ZDGuSTwaSckeTbMpPSQJ8ImKI8zWtU6Co1AM3QlYA38yo9yB6aB+QyFaensam5R9hk0hriBqCuS9T+pILE/tneRuj5yVezyMgU8oq+50+kkJAT+mIRdH4l5yKcDuDQRKPIAZuBvQHPCUgHoaPpEyiWA28h+yQ6YzgINFOkLqyiGa00ex56C0GLwl3hmzgWIkiEynIjykgqYsrG4a/sB+4Ewo1ex1wQnPyT14Tp4A08OCGEno/sekpcwK79Qr6ZZs6fOCDGhCZX5Aa5R+BwtMQFSCTHjh0jMcpHyCRGQsGVuZmGRnwoDwEroHyMwE5RQ2MPFWW3zQmvCNePMWFkIqZT0diIhNGoOr0wQ8s6TDVZCnk0ciqlDLHLbQos8YbgP0tFJeXgGLFspYWSQtBbU11rVIO13sS2snbe5Tgcw2KRk2G7w0STislgUGqV+Z0CL7GsxAmsDNsbK2G3O65cukrOClzDwsIcOT4yJDCHITmLq4uMkiYoSzH+OJWiT7+jpW3g4eClC5df/PzzbHKjWUd2JZECFRthHZi+Ae0t7VeAOPB3wc9AuADLCA5cW2M7WRkaXOYmFr7w+ZduXr5d5bBrpEVm2eNAd3fv6ejsvkT3em19LJyGZ6Wqur61RfLgzuPc1nZ3336Xo3pidAy358HDh0aTvamlnY4w8rRLKz4m4oDkRbgL2xsUraVKKUlEhIvJMdwRkjxqLQGPVKDit0A0My9DQ79og6dJrzDDXfnZx5ePHj6xPLcyNTZXKfpUykIra5S5HEYbFUzJtqS+2vNg7WE6noJRAsoJailEd1x7majWx8u3ykmdkR3hJ/5eMLSeiIThCsFCqku9EwgP8oZI4N6QhNks34Tyh3vEeiJIiCv6m3ZUJIHn/EQOqbiJ2harJ1WAugACBOaZgBheFeJdlRK2L1VTSzMDEzDjgtklJzoH2Bvlf/Hfvs4huGwumFNk96D12QZ8PZoACDjSj1hzTkh5NCrYJDlP9gZ6ne/ls1g3/kpKhzcgYRgy8pvEwVgDvB1QnMg9Pi67v7O9gzEc+Na8gW9Epp8MPOI5XjbWl8OSmTp57OCVzy4CsPnk4oVoPMZm5rZRCfXOL/b19EyNjgMJmZ5bJRHmrrXPLwZZs5OnT9kdDuoyl25ciqRinT3t9S11IBQSmTjNX++9905bewuym89urPp9bIaa2gaahlOM+dkoTyezsnIZY8I6u2hNsdM18fDx/a7uxpmZuYOH9pD5trtdqwEv7bx0lKJccIsYaYpfxwG5Sd4Vr8dTyyKQb+EaSX1i2XGHHISWNNBFRWHNZXMCQsK6Qm6FHf+93//dn7/38+oaV0dn2+NHgxoo+BUK1OAiYGZKFdVVd+7eBxdIVgAr193ZlUlBiex3V1cDiM9mI5KyOEOxDh86TqFQpzd9+smFvt5++vQdFufP/v5d0jJmvU2vNtPNmIikUF5ytcio7O0T5KRUUuvr6ylaN7bW0wX61rs/dbltC8tTx04fkSnL55eme/fsQba4NdxfhUqDkqIZkM2vhARVqvAt+XE4L52/YlSbx4cm9u7Zt7ywhDtjNtAsGodhgFAKP2NsbAQ1hzDywPtFP3MadMGj7xxue74sG4wGxWAlmUShUwEfpBRAA+qK38t+YCkQMASJNyOBXDKLjKuPB09Pz8jQJMAvGsEx8sS/u9KPQw8XG24RcFEe8HMRNRHCCTJ0JvYqpTrBK6BkEsL+vkM9bfsTobyszJSKFisrdIVssfw//uF/Iu+O1IpPSySoebYBmhuZxpvnhLi7bAPUPOJOqp5Loj1q97vxlPAB+BTv4bxZaPyc3V+5Bt7Jocgh8BPd1rdv3+z0tMli4Y7iOkGyB56b6aK3bl5NxmNvvP4qt/z8Jx+sLM5WkjTBCm3kjhw7xjRtIrDjx4/TXocC+JM/+i+/9Mu/YLOAd1CEg8GPPvoIj3pxZZkzmZ2fxUp+8StfvHLtKjlsT2P9/oP7B0eGYSrHpTZazJSpoJy2uSzYsXt37vu96yatmVw14Fsyeho1dZtirceFga2pdxcKotOfqXpKZu5g/jVQIya7ejsFbHhqnBQ6F4tOaqhv4lYx9YFMdlNjIxLwwXvvv/DCc2NjU3S+46fS9APhHH4/QxwQC/oeGF9HLhIOL2gH2Py99HNevcodqqpxL6+ukHAgNELPkXAsqSsZhoUEAKO84XwHpj06fvP0ySM6NbwY2/PTK9nk1ukT50BV0I/2+iuvzU4v1FTVDDx8wq+Tk7PcBVjrXS4nadBz554afDJM3pA2X8C2w+MDOosmFAvsVORrm9zZAi0Whb37+ibGJ0v3ugKsMloR3D53kAmEEEDYTI5133o0EB58MFDjrCbp2dTSpVAZGeayHliDIoTMJZPfkolIVTUDKRSoVOZmN7e20+eztLQajyUZlSLmYSmli94lUFI2t42JSZF0HBZU4dHgt5OSoQANUxphAP2yyQ270RGNJmg5gjctGqUARxOSKNFSnkeb4IejhCGjpYKMLcBBgbhfhAoM2ubsJRXMg9vb29fdscfhqKK7o1KiI/lTtiUvwrsFokKqKP/Gn/8lEQw7GHOM0KP+WX3OA2lD+rnNhHSIPjePB+uIBiWtyQMlQazDYvGEJMluwhQnCrXBx/mVHQzHDpgeJPv4yVOYCBBBt2/fBvwzNTF+9syp61cuVzmsp04cn5sa/w//r/+TawCQWFbM4faga13VNXS/Lq2sHj1+kr5AjsxxopEQQdGJY0crodgrTTEbHhr96le/ypncu3ePaZtIKh4X5VVXjfveg9FX3njOXu0iT3/v8cOV1dCzL55+PPr4yPEjVGeuX73hdtRkE2mtUjVBsKjVYhGYutPc4jxwaD8Ta1Z8q+0dHY+Hn5CGx+qCbif3lsbJzYg6Gh3ru7qqvq5hzReglEF/HKdnpnXaaPzk/EWCVGJKKGlMRkswDHLbMzY+jq6ZnJnGMJI8hX+ONQcoKfSIUNZJjU6H0cP88jb2DD5hS1MzgrE4v8B1QXQWj/trajVWozboT8XDua7W/UvzfnojKP+v+9cQ/aWFxf59B+7du3/m5Jm333qPVsk9fZ0Hj/ZDDHPpyhVE2e50cCMePr5nc1rKKrcBrpodxtx2BooPYlX4b5i6g87hnYyYqgRlvR7OZgoGaAu0ptmJWavOfPXiFZ1MhW5GsDLZotHuwUIwKJ5J90a9qh1QnawccAMQIMSGVj7+qtNbGUoByhOdyIxF6vfQZi35lnZoA1TLMltZvj23VaDCw4PKDB8kTwMuKJ8ppumrYH8E1lG1lBHJt1OJ54HUIWYMcBAoIwbeEFBvbpP9hP1b4C6o98rkDquro61rX+8BT21zZYUqn93ZYrAB3ZSQc5WTLxRdvOV/+l/+GxuAsxNfur2NckLU+BWZxrdBRXGbuTfsB8wCGoUNQCGT92AE2DBsAJx7LoyPiF0r6oI0ZOjx4rmRmN0f/J0gyFcqVF/4whcwvsAKcMq55RDuNnhq52Ymodp652c/ZVATg6DBsSkVTBDbPHLs+KOBJ4Jauqz88tX79fUuOPvxufGR9vTgFSSjkbBBpyHNSt4Dj/zmzZt8C4S8c4sLfAV+CHugqbXl1r27kUQMpAhxM0ZgaHTBVW8ShbAiQ93mTVqDbyXeWGfHH42F1rGhVOgh9AUuCsfyF7/4OqCuDFwGWzkoG+qaPdFohMKtUM8BH8MK2HKAQFkBejXRILRupVMJYvbV5WVppYIAFKZYEEEEkZRBCQ9wYMHVoUfIxnZ3dxL5iFVV63iFeIYjwDbBCpOAR31wOzCnwAdIedCUjo1dmJ6tqbH4vCP7+rrYAMMD03u6DrQ09Ny6eg+MsdtVBbaipqr6+tVrTz31zOL88k9/8ma128VQGQb5AETl2/Gppqcnyb/NLM4SI6kNBLqS/M5GfistRlHT80cJb+9+gKuUEeFQ0qgZ/FMEgEmXC+IIbLuYFQwr25mC0+pwu9wwN5rstcH1EDUQ7+oiDBoupw2irlQ8BjcES05mE49RriDOZFfQ9AhNb5bGyHQ+OzE7DheswW5KFlLM2qYfRmBHhStOrpgJ01vREFn/RNAfxRSweggn25KfRLE84nGaM0VHOxuATBHTiZBGMj8UoAkTaHxobW081H+so32PxWAXVAcSVZYEXgYcDFaGoi13my+SlX/rL7/N4iLEmHJkGieeo2ORuTf/5Bch3ETliDXbY3V1GSnHUGCpuYWEzlgJdiev8Cuf5VMYJrYBQomyMVqs7B+QM7yHLcvcnLOnTjc21IEreXD/biYRCwfWXA7r6tKiXqfhfJifVaLUjdAID9GX179GSoJjmi02pv1C3NLU1NDW3HL//j2UEmHc3OIid7Srs2dsfIQg+NatG337+qFyoTmTkaPHT55+MPgwlkiOTUwBZlxdi9Eozpqhq2iPYir2owePw4G4x21vbmx4MvQYUPSXvvT6xcufMryR4Ik2vPY9HaB/b96+cersKSpW0H1TFmUGHgeh7YokHheLcOBb4+aGQyGSctyUV9/44rWrN0g/81d49VDw2GLsBvcPvYF2X1pZIp4mCqqproH7hQsk7YhiQ20SSLCMLCDbgOZPVB2IeaAi1LMvf/YB1NENddWMDmKkwdJ88NjBM/dvPU7Gk/T4ApL57MLF5559dgorMznz1FOfI/t+9971c0+fm56cFk6DXAXTuqvKUV3rliqJGMsym8lULgGNmhhyLhGhJ8oenAIBMXy6GsZqG/G7KtgDs9Nzbofbv+iFE25ufLqvsxsWvZaWjjKZEupSBIYOFVxTh90GPSEGGUYw1GJNnQe3GdcUnja2NARbmzs5OtEo3y6uLlXqlNX1NYL7VS0nAUTBUewTliuewuMPBUPJeBoWIIJsVHVJPkXun7icZUTqGIEKJQ8hg2B3l4q4hZsiA7UI8qXWdeL4mb29h+i2zaXZw+VqJZ5kmUQkmUiNSwk7KB2QDxVpUGSdk0OCcdYRdJQQX8CWQOIRfTQT9wPR5/nCwgI5IYJa3gO3DLuFG8yt4ghoNYYNo/U5yK5xQO4xIDhvnFkylSiNzBDtBB9++D4IKD0gK2Zrb+ZogcXaPfP0maDPB8KWpTz39FN//VffqoUsvLnlzbfe5pR5saW5ERfIbjWDHmU+F2fLnPm21g67s5pBhW+//Q6QMr1b/8ILL3zrb74DR8id2w9Onjw++HCAmsuT2eGv/R//7Nvf+e5Xf+krP3775/BGb2a3V+b9DLSym13kCRin92RwNJoodHd5vv3tN1XqMofNiiFiBbBaz9c+hweCcCCgqH8uUKwV+bidcrg1eU//3n4i+BvXr6MCnnnqadYEv5EloqRAh2Q6yfgMacDvY6wiUGSIbOnMgu9jeitnMpqJf1hePCKY3dEpRM3LKxR6CrRMsNqgnVhtEqxQtVEAAS5QVhSsRBB/W801Ctkcd4qIf/DR8MZmDvhSbjvX1N704Scf2JzWyZkhbPjZp06PTY5QNw3HQjDnYYtSc/FcMbvv0P6RsSGLy4hTNDY9Quusy13FrSQutNspYSi0WoYOKwn6cyAJshRfK7m55N9I/nDf8fupdbAUMNkwPgtMFSdJUaLK5dpgqHKUqbsqzAB8p4gBCWhKYBxBzOfahDw3xG4skxUBnALj0ubUuCxbzJkup7ekGAslFuYW1nwMvoYnS0g/AoCaz5H5gqRPJPsrALmQAeLaefBHxENEvQRxZYVUumz//roTR0/VeVqpMjAAEqefkamlYWh4BqL0K9hxgXCUsAvlf/X1v+amctzdiJYnKHjOlV/ZZMTBeDsYF3Yz94lv4ox3g2N2CK9wm/krzgBVJ7YKH+e4u97Ubiyh1Gi5nbubqhTak2CuYK5ZMhFvb26or63SqhR2swkqkMMH+le93ut3bj0YWnK74Hpy0HWFZqUSj2QIOwPYMxKp99TiL5XEIkLRHqYgajcUWci1Yxn4Us6fW3XowMF333+vpb3tk/Of7t23j49/+MnHhZ3ySIbyYZnJaCBTq6xUsmZ4q2R0UkkQVOUUUI4dP3Dz1hWS5WarwlZllesqX3rt88Njo3UNdagcarSgNVl3kAvcCXLt7Ir62vqf/vSnXPm5c+egcMRXpLZ1/MgxsoeICKeEgqCw+uUvf/GP/uiPXnn9C7w2ODSAq0YvQWdH79zcPN4OzhLRS1dPN+Vkcn+4oE6GaFRIqd3CaIs1WFpYAISlU21WOUUEvDBH1awWxoTGhpbFuUX4tpCSJ48ecT4bKYGzOnniNFuRisrU1CR8NLiI9XWNDKwnYfXqG68Rcc4uTtO8wuSilbWV7FZGo1MxGKqijElrYvQRLUGwv7CYJA3x8YA8jw6OttW3LEwvLk7N2UzWzpYOajgGqCBMRvBt4BB8q35cX9q6WG00KTOEoACikEztOL8F3ifNDCGZumwtvMagIFiy6fNioDduEnDpFa8Pyke/H4bsGKg4FD9IaQJcbgpHQ2pRo8iRyGKXsufA0HBlEDYovZBJ7CrxAG+0OfTooN6e/XDXpmObZmO1Se8QwwGYs0HZGdFHsTE2dBtKGwHlLP/2N7/DHeI+8TXIDcuESuM5Gh33BtOMvuF+I8HYNT7Al3EGiDjv4SckyYD42eUcAR3J+3kzG4P3iDsBvykkyUYjL3IchIeP0KBkxPPVaNqa69UyKaPySLhCMg6G5KdvvgVBHnNfuQE9e+D5IbOeF2y1+Ty7DtefhWAzHOjfzw3eu6fn/MVLL7/yOt4OJTrycfMzs5zDgf39bJsP33//+Rdf/PM///Ojx49du3lDoE3HRskujS+urq1HORkqKIBMqGpQZsLvN5q42ASYK5hGoRSGtvYrv/DiW+996Glx9O7vjYKtYMCqw0rVDFEOhYIEFagJwl88+MIGBSMNLLwk730rXmYxIb6kQcnksDmp5WBGzj59lqFmJqaxZ5NgzuiVwVyQnrLb3DTLo1+wx0+GhxuaGvcd6Gfxdy8c2ghuWDKewM1j0VdWpov5dZMep9dc5Wxsauz+2ZvvEqSSCm8AWT02TB4KLvuJ4fHa2jqgxSxa3749vJvQFmtMR8TVa9cImaemp5957hl6a7NQhcjKmG0KTQg9iYQrcEvSUsgd1FMNIN9d3NJrjPWehhDDWfwhal3RtejK7GJ7cxsoZAh3XbVVuBMAQ/Cv6G9HhaPkMRRgEClEMjlGq1eh+HckYAViK2vLUGgkN0BwwBeG21OGl4Wjmcnmhp6MrawwQycOmA1wemVFJfqb0Q8KtagcM8AEWUf6kR/0KYuDlmHD01xZqgRvpTPbmAtXlf7VVz7fVN+g19lh8JHsqOzWWrnMQMobLkdODFceTBKBOL4uW4ssT/l/+IP/iKFE1pE59BDuKVsN8UJEMALcSCwAdxq0AvoJTYYQQ7CDD4C5fPvttzHTbBvewI7nCLyZD3KWvJPlY2PA4scBeWyxlDqsQU5GckRCGlSVTkS+9NorcLBJtgq4HMNDg5Qza5rbmF/1/R+957KLWjIH5GaA3oEGmHMkHxoOcXbrhJ5sALjiHM7qzq6eqUmUnIIwETzFT374I76diyJo5hKQKlJPAB4x3FGsM+SxdMWm0tAVEuYcOnQAdB1tbuDLg5FUZ7tjxR/gBhitpFlzZoeks7/H01QHyjqTS+O/M1iFDNiu7HJ1te4agVBi5mkwiKfOwBuX033z+o0zZ86RHY8Aqo5GET4CG1xhzG9//z56Y8DrXrt5rWdPLwkitVoPYmg3BiC+I1kCPkxA7UMhlM7cNH1nevBU7HzqDn7/vGQLgv96ZgwoFAaIaMslqlRSoIiz6STI4TWfSF20NjSBMgMVh0HmDwIuT6ZdqLAgOVAysGSlgK9CGuqEtJAJLoUNClgACnmDUWclpyTa2cFPKgW5Jx4zMJCp0emmusbVuRV2V4un2agRgD+WV6MrtUapDaQp62rqiVaBUYimorw4ZiDkNVi0tDQYrTrI6NbWV+UGGZsfUVZp9JhZgmyYzOcXVu7ffwTxP0lQ9hUzT+iyoeBDVUGmlhagamZgUMkjgpWo5KSIpm28eH4ILBskENtlNTXOvX29Rw4dgLxWqTAoK/Xw+BdyFdtFyotgCUQlDrZiNgwNVGKSSwVYo7LyH3//J8gTq4MEc2vZXqh2NDebjBfZdhQBuNNoVvKb/BVQ0q1bt5CtTz/9lF+RTgwIPzkhPsIe4Di7T7ipiCndVbvHYUF5GyVtOoMI2dFnKjltCo7enk5YkZYX54ANhiMxuBHhUTUaZIkENVpaw0RKi2oExTxSDXzL/r3kdEUHAgvx/Isv+fxBpkQEAwH2WzQYQpW+9PwLuGQgcxhuh6ROz86iPoH+40vMLi55Wttmlpbo6MgXOaZAHeJn0zISDMSqaxiEkXj9iy+OjDwGw9/b00XlUoZvoWemS45CHv4PokkXJb7kg/v3yWbSZ4NIfefbf4PZWV8LAJMmZGRGE11awGgZNopniHsQ8Hn/4A/+4Ec/+ZG7pgrmU+BroJKYds6mXQ/HG5ub6hoa7t6/pwIdqdNS1GPbQxLMstMtxRkyeAaXD10DXalVv0PBrrgJMqXC7qhfWvbrobSgbAEMO5tu9NSwROQoMbmWUkOjRqNmL1FO5b7AWDo+PtPe3gSMnq4AEAQwDgJySGRRyaIAuri41Ne7n4m8TNTjCEzN4SZictkDigrlwtxi2BfaSueLG0WTxnTk4JHz5z85eLj/8uXLra1tQIfWfOzkLLURRM1TXysIEr1z4Xiwts6tN6kiiXW67KPZECBQnBnQrOUVLHt0Znpp4PEw8DVBj0intqBhYzx7OdVGyqDprSRYN9FSJ/IHwrtGF4jdCZN2PGM0VjI/HtvAzOjGpvrXX32NsgmXBSHiNhPcK/SVMj3UbExhZdJCyT8H3Uc6KivoE0FLsIW+963vo704HJoGKcfPYQMgRuh+vpKMJ+uOymdL4IaCXcMb+vjjjxEs/oriZ+l5wkPIOrzYZWWsI03AvJm/4oo8HHjMe7AA/IkHHyfXSMcyU1sJhbXKSphwtje5N76Kne3URplMq6CNU6viGph4DCgjDwRcQWhfpMwhq3KC5Kk8ePAg30hMTLXyX/3278zMzd6/+wBIQk97dyIZO3fy7O3bN+tq69G4qOCR8RFcHQZM+LxrsXSSPpFgOMxKCqskRrgyV0fmcju7utsY1bMe8tU3VC+vzOUL6YOH9hGUz60smWx2ahfkMYAFsxpOVzV63aDXsybJWJylI11EdWzfnj6GDGiVhpmpWcp2IPlhQFmcX3zhuedpAMGrAZ/HgHgAYOvU8MLre/b1CldDVmlzOmiGomLAHgN2H0smQAtjcscmJ7idpJKJLLH4WOlwcMmk2TIJSIptcma5q+uAPxAjTiWDhKfEfqa0w1hMsCvUGVOJDDqH6JARG7u3hp4VEupYQmExSHXmMmq9Dm7P9WiY7AeFP2ikNrNbTLF2OOxiN6rVcAGSvwLMzNGaPI0b8Y3FmXn/YoBunP17+5noU9zZBK3JfgX8BwsD5Y65uQWyT/ReMwADskS5Wmqy6cixUkJj3sUWuAaVAsJnigzxWBZI4sry2vJSECtFMhcYBfpcgPKEmIu4dncDkG9A+nc3AGvGO0o7AQUOYg3gerq+wf6rv/rLVrNNKVUTxmwXYVGHDFRJbx8jWMn/EO8hfoQKtP4RK+Oe0YdMv74ENYOPzuJyRHQ5gssG4EWesB/4DFEBAs3EzytXriDK3Ht2BUuD9uKvaAicSxQ/cskHwVo9++yz//pf/2sUHqM38AVpLSR3iRYnO8bX/9M17ACyLyuPp/OMVFla9Ybi2/BGMpoRKKJOJ2MXYdQSCTFyj7OAA8akV1tMJvIqB/bv4/Zxbsgi33v37m1mVeBZ1dXVgjOjTEHOnhfPX/x0dnaayismi5RvOLyOEsT+QH8NsxIzFGCG4Ss2ctvhWJ6BcNxIZjjQWT89O4nJxmkgeiPvabNZCZFpvMWtwlSyLCwU3w46mkThoUOHWQds49Ejx1kNjABuj2/JC0VCKpro6ehug/zdFwx51w/uOdDg9NBukEvmXn3p9Yaaho9+/qFSquzt6SGicDns1MUJ48j2AN/o6e0CeoQPQCKfFm8wdrgGtEch+IDCZmanYfXhe8migiJR6TTQveAeU7ROgm1inSskBouZyilVFbwM2KvZdbQK0edFTQAgqpU5AwYtECRmGZHPwcEjPQIJZBLon0KB/WFXs2dAJcI6Q6qRkNFsNhA14mz07iE664GbFmQhfg6C2tzSAsgMexII+SLxQCC0DD211qyMpyNMKCqv3Gac0nosSExMwhhMHIlIql1oTnC+01NzAd86fj/+DypP6CTo+7H1JUgc5REEhoUVhOYCpiQcDZG/LHXb0vWCHuQ83TWm/fv30s/Ar7MzywFvZCPFHFWoouEkEkkO6gUoCP4qDkU1oYLNhecNQxe17i2R4UKOeQfyTQxAMgejyZdxaISMs0HOgKwJoxOL4UwdPnwY7xwYAsfCF3r99ddJTaJPeZ2fJbWRAh9PcZRBdyWhL7X68+WlB2fBbocDiW3OdiR5C1GdTLEFLyY8vbHohtOla2ptpeoVCQOTWk8m6JCAiVpNINva3IQqJROAzLEPOclPz39y7PhxbBnjsjkwpRZwacdPHHv08HEgHGztaGdWoVWlBofDJYN7Ju0GGwaZ3h2aKCpgKKRxkSKonD6yrbIcMDhewB8wGLR0u+GgWvR2Ciax9ZiOgQlZ5uSZ4C9gKTGbYH5YNED/IJb79+07/8nHHa0dYV/MYbEyrZOeQDgM8y7YBFOUJocfPUF31NbVxNeT8UA8E9144wtfnpmYTmRTxfLizNQU6wbhz4H+/sW5efpux1fHuS8sGKaAVUXc8WFwCWgZRuOgyzRaErzm7XIFWRQGzZMfS/uYdJyGTAPAL9dHRlW6HoSnGudelLFBiVWUb0L7Xsi7quEeFaCDFz//hYuXPiMDA7D8xq271U7XU6cOUHgmDiHfTYcnZgFALjFuIsL8bYo8CegdI/5wdbWLCTHchWgytnE3xynZ7VZ2YyS+7nRb4NijVWU1sJCFKkCe122qYQzYYVSuKFxJqRFDNxaNpCD7ACe5A0c3rQnsAdILCCgNXVCOMtRXxLqbDDgtiazQ+fwZnb0rRMgOOoKdwHtOgSY4fpQeEkbD+1fXt81oXSPdgIi6KPqU9g+ywQEwHWyof9wMVA/YChUVrB0bAN22K+LoV2wCnh83DMcGtYcWxSYQXbFbBOiCzmi9Hr8IhcRP9oAwqUzBLBkTNg+3CjedFAQ3FTg0ZRD8t9IF7CL4uD0iXYBl4OI2RYxGPYKmRtXOdqajs4llZUfR8wwsgNWxmJUH+/f19e7Bmt+5cwcyhenZOTQEXengLqF8YZtBnYs2Qj9QPGxraYdX8OTZU/OLczdu3ZianULSYb8Bo2Cymunrzedx3hCFnUyOrVim0pdbXTA0LtM9lId+CwMN7bNcwVh5NgZ+FB4zUUQ0keBy5hcXGOwHohAvlrQ31ADgO9Z8Psge2RsDjx+31LYLWGg2x+Cahak5PFq6vhanFixmczQQJZfy1d/4je//8Hstna0QBFldzBMQ7fMkjmwOB1EBC7tGb+8apI60zBIIiQojeofbwSsquSUTVeDrc4HE0/cfjjur7VqD9fqtm6KROhLAT8KP4E4HKeOYLfTiLvu88CkYDaZd75G7gya277gIcGfnFydm5lCHXV09OFFqrREhBtSEHuRW4uDZq6xIJSUpDlkiLilQB4Q41etbLbfjsmP6QmS4qb7HU4iHxr/u1VvVOoMB3o3xyfH1WAjiqUhSBVxaTOMk6QzaAFOb28H1X5j3epfWNjdwTuQCsbyF3RLz1bnLJMRobsH/FDPyxNSLkhQLQeaX3V/JXFO/YtBqWWtbXV9fr8VqXlqeRzFVuTwWbbVObeK6cLTAJYs9AOEcbgAGjC6fTcJdnB/0PgssF+Q8yPFuppIr5zXEnVeA/aB4+JXMLh4/GT1+RQfPzEyh/FigU6dO8Qq+E3EemhhPibexZ3GEuFWcyjvvvBMI+tnGyJMoXxOLowB23SCAVlR9BYcc7XAFNrYWsB1s0tsbE1OzeH60wckryjmRtqZ6AN1s0UePHvT395M7J9+P7mdzwl32d3/3d5hTeJupO5IDqXZUgX65desGY4Ah9MQUJBPp+sY66M3pkgmsrUs2KmgTEw0ScACh31kcSVkmveP1BzBIqY3cxqoPOIaop2SBQsncNXSiZJlrAmMxV4ruZw9RP+fR2NLEtfiWVoC7QtQsduzONnDXe1fud7V2xpPZrfI8Haog/9ZW/XDCuUr8O2ykCx99CjeEp6puddmP9bj+0aOjZ3px9B8NDIAGhZyZG02Qw8ZGBFElfMuug8oix2MJov9nnzmDDkMFqCE+SqVW/SEqVgIhUCGM9UY2A10XI8YYD4XTwiijZComYSakxcKR0XGgw0NwT4DXVylPnDn9zb/+Vnxq7su/+Eup8XGShNIidQzcf7KaMnRiNAoR4jbCwzTFtcDqZrqIKsHhZOqrvEJJ0xldiqh/3KRsDi2TZFTuzPwEzZYak8JY1UA2CbDnBpXYIiVXKWRx7B9GXq8s++npiYYIeZBOGfEIeU/knwc4XwHwRFkj3RBp5QV7HOLE5mEpSg/hyaCJyQvp9ZXofkwl3lpzc2PYn652eColeuCxZAhRsnyKgS9C83MZUCviaJWYVzgOJbad0qQM0RSGhUVhCyUtEbBkJIQl5vr5Jm4DnwF1g3BT4GQ/IBNsG96MuiI8QOJxnERPYHMzB+EInO5/+2//DYvBOylvc4mYHb6xtHvFbub/3AmGU+Pz8E0C/qFQSSoVwhei7VjPmCDyADtOh+3QoUPpFCTxa7wyNTHGHoO3cG5hkTM0+pmkC0Y8wYg4yuM0EE+OjhFlBqGnWg8AYIYZjjuUmCVCgxqIDa8QQyBtFoZj4uxulSUq1eWwuvIeppLpDJqNzA5jd+CQJFsfAn1pYcJzjhkFzMDU6ExHjx4jPoH7xufzA6qhH3JtzVfjrKKFjaXARYRGgiCKLMKhvgPbxuLEyKjNaE9GaYCNvvHqG4AUCCtHcyMmm5UulisXruw/eCCUDrY2+dnPiHV3by8uL5ooFo+TxaqucbNCLCbLy2HRONStI+tBk4mudsKwLiyDaFsBc0lVNZ0JhcNE80JP0XDsdKPpDTqzVqvERM8tzIjgq7yMOBtZYRHYVxz5wYOHDx4O1NTVe+oUtNdQE+G7iNa40VvxzUqVdB1ijMi6ychE5zgeBNIC8cyD+w+0Ug3QV2YuIxurTOvRaSEdclTZahtcsAtHE34Zm8dQpTPB6ZIJxeMAYKgqk1gUScsKemXXoVVNRIkacHiEtItWFjxyMiPoR7RSBUMh2QO0qdChIESFs2WRd8Uf+eEpP6mO0pSHQBIhoGKQYaDTjK0rgsSDbEX4FagEfH1YoYUpANGPJ8Lz0tGEo4X7JMF0sr67cQ8iSwCAB8KF4fxwL9kDfA5nlxwi9oGTePDgEfaANDOco/Ch81fmJBEqcD/QzV/+8pe5lxyHPNLS8hIHKUUbwoHbPXt+lryxcu4TnxUXwzt4MI+3QkZVGTuPI0mLT29XN1EEew/PEvNK7n52YUahlkMcTu8SuJrMRhKsKOofHd/UWo/ct3W3NrU3Aw2Qa1RSFZ1JpnOfe8pV6+7q64glCwyFHx2fHx2fgKMcDxUNgoaFcI/sBY1/bCEKQNg+i9ne1trFxFncaPoEmHYMkzNUfLjmILTISAJLZiwpO1Cn1uEDg5K3W5zLTNqIZccGJzoa20BNYn3oIIEsmuIrTV60iTW2tr3xpa907emdXZgHtQHT8oNH91kB5m7CyUPo6fX7QM6gR8SNhG6EMdQaPc1u0GuT0iWBQ8Ghvq4O5zQWS0GiSl+RzWKtJoMUod4fwcWi53OrsAMTCaMEGZrGIF/ATtv5TdlOuU6lQsFSlMYlI7VKowJ7AOSap66GTbK9kyMbVOWybOZTJrO2uA2DTw61yG0h60AmA4kBasDmISd+4sSJl199hd0C7h9L8vIXXwJVWpRuJbJho00TTq2bnUa2HoRfEOtH41E8GcYEophwF9cDIZqwsslCXIx8JBGEXBOJVuxSpCAMJfUs8u/cHVaYHkREWGSyhA3CZYAJW4aO5MRUajmKaX//HrYKipik35ovhB8H1o0dA8Wx1kAiAJYUM9AmNhdLjQBz1QT02BmuBZlkq5f/2f/7L5B+KhoUthBiNgPuO/4Pf+ZNKCS0AoqcM2IVOCeOgtOPyWafAOfCGNCmA9c2fhGbB2a/t956C0PxTx5UKVIRyZ8S0xfXWHoQoIO5hRkMHS42NJZHQD5w03bygkvLYqRDMtnUWKOCFUNJX2IMmmhq2OwTQDgkEc1MbdoSEDR43Uii44aRfSJcwfvCEKGkUXhkro4cPUohGf9vZGTu0KGeaCT54udfffed97/8lS9+9wffXVjyK5QMx96hv4UzIfQk81NVY49EA7CrwxoLlw1swEgYfSqo/4NHDv/qr/06t0SvMr7/8YfcI9j9WO+NVJYSxDpAmlSumCmQAtJrdKgPo8HKrUJ3VrmrEWuiFAZe4F3ML85z38ntnL9x4fTLp1Nbmd7ePuYq4Hxya1D2EM2wYhhSNBGJfH7yKwzknmrHvZufMJFSrtTU1rVcuHRdY7CwkFhFZIj9xgjU65evED/ShZyMxKuqmYCp8AaWKTzR9Q+pOCBGsJncWWphpIbIgXLJWoMaFwKlgDbcFoElyLgicg/bBdkOdgKBHCqJ3h1C2Ugg5DK7QAQxH6lAY60kt6dfFJupcMOvyFRJDDxFDHKsCFVmAyhjERie0OQ7khhTJbOVAw9HF+aXEpFN3B3aU0GeQlNVMkrobMHpgBdEdgadCT5PzOjENrDM/Id4vwzLIAiECYgNRsm/+q1/gdBKKxhJKd/Ibm+kyvWqWlhPMBrIFUK/hdPDFsRE0B78D6NidilyhU8lXC6cGU4UL5MDkWDhJ6fC3UJ5I+uIPj95K9uAg/KgeEmpj8FBLc1WrBfSy3Hv3r0HfwqHAsLOLUcK8aO4bXycOy1YJEnkigF9wnKJTADeF+374iGqG9zrkjGA532bmJPcVS6XfvH5Z3P5FNCk6Zkxh9N8vOswH+HGkDina4mdvbC8Eo3Efu3sL4OhZ7rwwuoMBcvlwPLQ2GBtfQO2q66lHh6/tu4OTp4nWJLkBuzQw9AM/uTNn9Q3eoIhPxBRwBo0uhlNapEyg02FgAw2BNpDxETozWAk2d7Wysbb2gw/uv8I3xr0GFfKXOiVpdUqmws2niZPQ+W2bOTxiG9+pd5V47K6kP6err6PPznf0tLGYl6+dp1l7IdByLeqUFeSwCFpi1oSCvXUqU+vnacJGOlHiHU6fdAfqnbWYEi5Owf2H7x1+8a+vr2PHj1k8vWjBw+DgQj1NYifUEnMVwZHoNaYOM7DewMRf4iWAJfV0d3RSYGi0VOX4+RS+WpLNUGO3eQsl8hWfWtOp3pobKyto1WjV6/6luhiod56+NA+uAigEM6kC+xbTgbp58Zwpeh+nkQi0XI9M+vYldssOOlRujphfpcaJIGoN7+W5yaTdAZxKjT3doFBMelcHhg9tQWdlmqx8Jdymfy6N7y66EsnUMP4PcI14MHi8MDhwfCKSFfIPgIq+A9BasAvxwbYKcpwmPDb6ZqUSPMUf5mZSGKKryP6Qn0iVoCX8KOEpIvTFE4PT3F/0G67ryFwrBvP+cn3iu3Efzgz3krli5/4l2JbSKVYB/QE24APsyWwDBwRW8NzXiei4nUcTcSdIhFeLLcZOWMLkbjAmHAcvoMD8pXiEsWX/T8euy/uvs4J8bfSKQLqSHN3mdWl1ErnlyeHRh9C6Wi1G0bGB8EwSlUSoiuVvpKfDS1u+jmqax1UD1974ws1dVXpXKKju+XAEeAGhUQq4nTb9GbNvoO9ksptIO+UY773w7+FtqnGU027xfjUCHToUdF/UnC7zXw7l8yKQTYBVioHgUEK1FKO86DYHAyuV9fUwiYdi0PYuMxo3KGRQQ6ysDQbT0ZQMFOzE1abDfA8xyklAzYHB4a6O3sW5hdBVna2dnz59S9BjquUayxG2+LsUk1V7f1bD00ay0c//9gOYH1TQlP59MhUiJkDNufi7AKoYFhEnwwMgSkaGhgkCf5kYID2NxQzi4aTyY0gQGKFM1lQ/tOsNvYQ69HV3bmwtBCP09SRh/qh3tMxPLiwvBj++MNr5z+5PjvtfXBviNlHjHzGG6ly1nS0duLLMS8eyMaZU6fp4aYEztD5SGg9TXE+EibK4qJ4kEROZZL0XTOwIFugQol/IgEiReggsF+lKXe0C1FhojZPfwp3FevBGyh5Enkj13T84PLSdYAqhyCOtCcamp/0XSCmglYR750UEJVf9KpwDvDXhaRQ8SIOYLsgdbsP9k+Vy43Eo6dw97kWgHN4O9gZThVZ5SfvRJKF+iN/XHrwK+cpjlh6iDfg5CCypFn4ib1jM/ButuOucPOOXdFEODgiH+Y46HV2C28T8Uc5yLAQrzQ3N7H6eCkIFO/km9AiPGLJGL+KSynthNJ/RUqUO8dPtuDu6zznu2hJMFigzaSmwxzfewyFtthr9lk6oGsNxpV2NzaHqmdFyLeeXU+DJTY4dY+G7zFcBLHQJBVtnQ2M6OI0+g500YyL8VxcmUlvxLjMw0f7we392X//k4uXBmHuHxha6eg22SwmVlmmSFM/Rjty7ZwMMHdK8QRRhE7krwqZGLFBTZ1tanLa3eA+fPRQMpNi2+NZNTTWFrJwsVBMlWzSWVkUo8lJL1qMlpnpOXwi0c525Njdu3fJKVy4cN1mMzS3NeOx0+n36UeXmILxn/74P3946yPfgh/ZRatWbFU4LYIW0mqwsc7epVXuDuDMwZlHeIdoGTAOgI2Hh32k3y12R0NTezL5eCMfZRAvEAzoPpGdjTy5yzLKyRa7zW6xfe+7P9ZqdEsrYaO+CrfaZrLh56gYUbMewezX1VTNzI7TO2ukIVepXfOv0QZDXwHxBnKPYSEFzO0jpgTKT6i6lkkyERDQBbPAIOslK0rtskTvLBIbiTQ8pjHRdwBRRYFYQ7ADYtZwctIbGyBESMjwpcgG0SqiSOcIMQC/gZ9EtBBwGnlFfUJKlhDxoJYl5Fh4CahHxFwk05F1XuF2iandRIx02GAjyBqi1inGbkFSxK0rbYBd0eInB+GWIXK7oshPhG1X5IQF4RTI3iBDvAMXCAWGdkHH8DrCxHNOml/5K34/NoGYYRfrxhvYNpw6uXl0P1Yb54f9wNdzdP7E+/n63UdJ3MXTf3ryD3/4X/9DRkC23dLuOX3uOK09mXx82T+fyMZml6fd9VVFSS4Y8zGXqFC+Ec2EltYXV9eXtsoLUkVZaiOWysfJOoajAVAO1CCn5scvXPo4FF3TmTX2aiv0B1gDboHDXXb3wfVv/PXv19Q51yMBxtexPrBocNMwu5BdovvJTkCnSrp6K19ms7tjiTKvb51AIp5IXLl+9cnQI+jz9/Z3+4IriXTk2u0rV29dIfhO5zOtXW00tDLYNRgJ0kATSxYhRW5saf7FX/nFL7z6AjEGPFlMvujr3hvwBn/pK7/y19/8zvLMilVn34jnTSozg5ouf3IFBv9SKmOrvqqu2u6cm5puaWqC1xHqKEYHwLGFVHEvoH8kORSNRVDN9M4DTOJ1Vl6np4aV5C5852//9kc/ftNT01LlbN7MS08ef3Z7szIayVy9cqewsV1X08QMnUxig64rCPWclmpo1q0GaxmKuwhUUQmPA4ygdOyjAsHM0l2O1k+mk7nNnKSyTG/RGx0mhU6N+icZhVJHzTMqlIIOpWXa9+RKFZFJKJJgJhelRmwRmpr0A+FBBpYzCnJ4KBgFJr4QtqtkeIb0CtMLVSq8CF2IzkdUeODbiAZL3KPdf/+oT00Qf4I5lilJmxNC4hyR/dztqETEWSKs4m7UivrmOQ9e3N0b/OTBr8IiYCMwVWh93oerg3CjfvB2kGae8yJv4Dz4iWdPoInEIvHsIXQqGwNDzMcjDOKIx/kUz9ExfJbbgE7Fj+azfIRz2n3CU37le3cln/PY3Ze7J0TqCi9ldo6h56q6+iqjiTaxnVA0INfIGTxYztLb9BX0JeYBf2UqSUDkytKJNHGsWtBnl+8/vJ+Q5vHjAXpeLU5zd1cvJwzGQalT7envnRif6d7b4vHUf/TJe6CCO3uoFHe99ea71VV1AX98uxCTy1U0drAN6AlHB3FKcJC0d9SCasTnhVcMxvC2Tsgxx5AzupFctqq6xlqLzkLeQ6GRzywulem2aSFQb2o+ufyJ06MeGB3Y17f/3uMHnIZJb6Ty4nJXA2oYGh155733Y+nYl3/tjfmVObTbUmEZmpO2+rZIIEpZAyIjuliuX7oGZhPOqf0H9pGCJAu0kQ3NLkw3NltQLiaLbXpiur2zi7HVmXTO5azmfqNgYLc9fPDInVu3wSGarY5Ln904eODo3TsPT548TT8AbZxmk+1nP36TJhiGZPX0thudZo1c5/evVNVUO+wwkouiB5LA91ZA/FhiRhPLGEsg/Qy5geGwnPlfO5UUlemdoRwBtgv3HF0JilLIoFzOzRa9V6RuJFJqBPg3eCIAHajGcLGkBvAt+Illw7zgCODDI+lISukfDpAQGH6AgcAc4KsjNQST7EaEiQKv6PqFy3UHVKyKvCeizwdw7yESB/ePZCNsnAk6mp88R7w5HkLLA8HjJy/yYPKwCiHG+eGCec5LZIGQY37lk7zCTy6MncDisgF4zk7guByOD/LAYoAMxQvis7shNaqIJ0g/7+HFXUH/X3/yIn/affD67nv4yWmJtBdml8YfeSUY5hWqrOuBMmlFdhM9tUEpJVvMRzPx1EZqPRqihhoujbWEBgKCja493QBooVzed6hfbzFWVEohSDQ7LIxtow0vEguTFjtz7uTk9Fh3X/uR44diSVgIA3V1dDZlLCYDFyvaSjCvArgEIRMjlCUACb1+5mSyoBVcLJoFtQKxEoVahj9RgHQ6rfQTwubZu7fXVuVo39su01cuBEKOevtLb7zQe7AL/OO2rHDqmVM6q7ajr31pbfFv/+7vErl0ILL+zOee7e7oOth7IOoPV1mrqJXOjE+p5aqD+w7CRfHhOx8wiQynhQysb9Xb3dXFqtKeTfuGgO6YTDhOe/fugbsOnQ18hiRBa1szo5r/v439d5xeV3Uv/k/vvTdpNJJGvfdiNVsuYBuwMS0BEgg1hfTc3CQ3kELazQ0JCTeQEMgloRPABhtX9WJZvUsjjaaPpveqmdH83vs5ssLN/f7xOy/58Zlz9tll7c9ae+2111575ZrVJvfvePqprQ9sF7jtXe9+u1GLY963vvUNgZKw37EjR9/+xJNPP/mU3XBH9h273dRz5VxdRlJee2MX86uNnabXHDp4yTsqSf+NDY9gAFYEug30OfjVcrI5wOgEncfRfVO0TQAw7HT39jP80Dlxgem5TQVUIDHYTAywBUVlYGDQrnkQIlxACw7DxvbgoGb6FDghZlmJgQXwKfTkYzhkJojr2E0w6cfamxoW0aemMSC0O4JDdAhLv7AtZxcecJH6JDjQYgD3nocUsQveXEm0ecqlOQB9HcopQpEfKAaAcq3ycTQ+eOsDZgq56AmLX6Vla9n+kYZL8MsvvwQfhg4DAlbxXCk4wZJqrDX/9UcaucW4MTCAxHiVYWTFqtWFfG0FuR52gFe5ySu/7f7B/qxcquSIIAqj007GGMsRvlOAmJyseNpdQtq8OXMbW5r3HTykFXDMpp6Zlc0HQzj/hqZmq9RZDjwSGojOPjv1xJOPXa9zcEtJRWWp8+EKiwqeeedj3//Oj9gZmdvxbJiFcaAPx0wJK2l1PnFRbYZJRVziVHG5eLc9d+M5qozbDbNq+RrOJyIO5GQXsQ4tW7003+aK7syHntiA7t/+0beWLFm2ZPWSHTt20vgdnSS85rd++N11W1cwSlpNvHD1Io+VJYtr7SyzoXmgu9/eq4vnzh8+fFgPLlu1zOqp9eQNGzYVFxSaVQ8O9XR1NvPMuV5X9573ve/C2XMYoLX1NnlC3+/ouH329Bn+mHiGTmKpQ/QfXd8/1Pm+9z9FlBq3rTMc3HeQL4WtQtu2buYZJX7J2hWb/vhPPvPRj/6Co8HKi0qbGxtv9NbZEm9/S82CjBnnB3LpsUUoRJzOHhkdh3hgMLXgvSbcLWiZ+EEb3zuDPylJ4U5Lz/CcGOT0aHkzM8MpW8n9A0JhDJLTjDEsDnofxvCAOar2koTBL4z0CRgNEjYSN2yEMbXeNCAkYRLSPwYiYAZpZ0eK/oYH+Brou6yMLJQnfOEWxiK9xg24wpiKRUDEDHKH5HBCDAT7hXjp2DtwJ37wvXEQgmn82CACFtxH02UsoRjNjgmGAfM8R1wRSMoAfblxbsEPPoxx+ZsTjti4o2DFK0Uy7Vcnv5KF5s7Mnj1zScDhc+euMLKPjtkYkWBrT2aGPWK5NfOXJafy0eiwiXxocILzbUvz7dS0LBA/cPjI4LDDf4qsD1RUVvEpsaOPKLp89Rr7rwAT+YXWyxYJdslb7tKVS84L4h8qNAPrNRPXs8/9hxDGjmHlg8AOO9g/QmhMT045IbS3c6i1qZ9bipMY7RThVi7m4QIn8lXWcOwhjK0SWibnW1IEgtbMJvrnLpu7dMOiourCnY89ULOsOqMobf+JfcfOHz597Y2x2eGf+YVnlm1Y2jnScTc9Lrso21zREKpXyB2htb7//e8jNceKyCCBdS0y8kCJltiRaPW69bqbNquDDAJeIR5CMqJcvnTBEw4jbNgiSYZthcm21yWVVGXcTRqZTRy5ePXEpi0r3/rEQ7/9O7/627/1a7pg04bNM5Ozf/+5//2h938s7k5KX8fI88++KAZEX/eAuYrj+lob2y3GQVtFmYCOc5i/QUJnpaWnM4bqOK6ypiKRghF1KJCom99IBQAqCgUZB6wUJKHXY31N/6GiBKd0vxanCH4jmAyBEuf4x3LAknRnclYc69HhO4N9kwM2nA85ksbB8SGOKV4QHrOro8tGPEuWWem5Nu/DJBDCnkKxoipRxSMxDeG4FA1VJrBo7Ir/g//2hxEKgdILFPQNbd69S10l9QrHq5kcURv0WSewSn5BLgbgXy6ljadM7/y05ICyFgTY5sgbe0+V6tuoYD0NK+7f/POeFcjzoCuZ6cxM5uTaeZxOpDnKygZF7iU89e3CILzFMigpLxGpyhI921lJYYlQ2FZklKjNdnjRSlVAQA6Ovh7auW/F+hOf/CQAwVn13LkO7bE/6+qVS2GtcRL8ZsQL6Osaab7VmZGaf/L4uU0bhRJIR4HXjx6ZmIlLz0mi8t6ZGl28rKZmfsXxk0d279mUkZ1y4+Z1TE6sOts5P6/E7E6wBduFk9KcddXHPYaMYFg8e/Z8fk4eHYGstU1xZHD02NHXbSenuf7w+z/ctW3nxZPnTBmcSMBuqPK+mjOv2sZ5jjp0cScePPG2J+puXNmxe8eRo4fWrVv98qs/unHjqm24ds2vXLWGPLSL6NDRY3yzZUsH2LVrt/OgxMsgRttbG/Pz0/u6u2ClpKSCaQvct2zaPtQ3/Mef+ey73vmekYEx4xi6U3KcceYEoSMnXyosy3nggQeMjZWV5QYBAUs4h4M7A6VFNCMDtaehsQkqRHIPcbtilykkNuBngf76gsw2SXO0JkWess4zx44Z/n9HXj3JL4hHeohITCnnUIGDTWJNcEEaKxh3w0F4IS4QvZ0+Gs8+6hnlaNayAPXJIhKPlbj/8Ye/ZfONNTc7v0aHZwtzq3u6B8NaRMyLVqWCgI8FoiWI3cODqWn0NhoH4DbJmBWhE79G44VfvEICWc0hjTTGfAvo9Q0GoAlgGH9GIx2XBxzG8G95WNYmNJDtVeQdpEiVVwkPYxAPTMXy5U/1iz0M7Bi9jdVJPN+40bHp4J7TPwQ3NfPnpGckz8Td4fY4OjHAXW2wbzSLTYDl626SA3DaOm8LD5pXUIhRexpbGaNMgtdvKiFCiOeqOdULFi4+zY4eYnUV0bHSsjIuXbhsb9nw4JCtBZyQzp6+wAtSsER7yVesWHbl6iU+bWacop7MWzDv+Mk3BntGnnrnWw4efkUkizXL1wx028s5XZJX0dcx2NzcQiIsWJC8fevW4YFRB6Dc7m5Yv2kt+UcX7envWL5qEaBcvnTVPPn1s8eKC8u27N5y7dqNlub2Z37mXedOna2YW5YZjAvZqNTW3kHknzpz2pr9ivWr3jh14hMf+uiJ0yfsEOAoan380JHDJsqCqpM7GLu0rMIZSgQQ2yj3ScuxjOoO1XO40bp1G4Iulxwv9n9cypQIG+L+5uUUzK2suVZ38dCB45Vzypw5kJaUZTAR1UJwX9BymtCi2uXza6tu3Wi2obGxvpkxdN3GdSZjCTGNXfwV3GL9kTeUtSCizEQZMCkLNjmSkhAWWIK0p5dzOWTvJvCm7zph1lwSkMKZGmAZOzbNvJXU46xv6htbt40nnug5tmp54aglY5jJLux4HQv7IC3e8cKEO2hDBJCwz9N3kgvysnUEuUyNAE7oQnbAjiR4NARBmj/9RuiHOgm4N/X7G3a98wtGbqjRxDbo6xVjSoR+D31MBYJ1yNZ+h/fhE7kYds+fP4cNhPtTsA9R5FvfEtuefhYGneiKyvYb3UT1uP8rDYIISWBqxGw1NDjd0tzhmfV8JxINiJ8/2NfdyxyUMn9RDUuGqPG0Jw5u6M4vDX/aPmLbgOV3Z4RFhl0bX7CtZEjDfYP6zjskLydv5apl+159sbGxidsFoncPdAjS2DLV9ciDbzl65MSuHbsPHTo0WVpk+LLHlMm/tal5dHC6r3MwoWdmxcqlJiQHDux74m2PN9+8vWFL2MP+vW9+58Mf/khmXnr7azfJFABFBAu3RAmqctRz0vC8mjlcIDlUl5dVXr7aUl0z79EnHhnrG2ZuQrQx55+kxC1asmQqYSqvoMD5aAIQfecH3zUqJqY6oJsPRebcedWW13WEDtZqYyxRbb6C7OJDGtFEC0XvjNl0KxK07bDtNWm2oLQwuyDbqXvx0+GQzJam28888/RQ3+hX//n/DPePVRRXOcyGLrF0wdKuAbtIu9o72hhCnGoymTiZW57f2tBu+ulojKQ0cb5aCGNerpCXl104MNinK3m7cLY05aWW2EgARF3NXbm5eTFxmzbJwzS4NVNXBHjst8AXN22f7lRwD/ABrDvryMWOYzhIlNJYgHd5H9GJ+BHHGIBPJ6Up2JTC4owv8vJCrFwyOjMjLzHBeS+8p+yUL7AMHVxmYrF14dYVyXeIdQPVKgzVEQJB7l50aOoQsOoGvSUpErPiU2n8EvDQ4xvjiDRc8HmAUlgJOQddaSQlVXiMJ598ggsQgUF5wAmeK0yf3RkK+4YDuIOSE65omh9uwnWPHWP34UcdcDvbLMuV8BgG6KLCgvKSKp45zmAXPMsRhXmFjFSDY5NjuXk5Yk5hNica+ZBWE5tWCN9iwUVPhAlG/c26pcuXtd9uNcHi64+sTms8dvgYWcg2MjowUruo9vKF66Iq8ED9j+9/Z8Xy1QeP7DNPsFczLTnbubMVgvYXFt+Ij2u+0TZnXvmhV4/fvDVRWBT3ja/8B5NIe3OXg00N+1/58r+sXb86NyPn1NETpENrfdM7n3qnbVOIICqEQHG329qXL7V0NXLp4rX3vOvdoyKPhnFw0mJRgmnd9F3HhKXnpW3YvhH9O3pv/9Jv/LIB9vz5s7Y7ARl6Hj58wKlCfMXzeaxYmjS6hpjJg9TFrl6BbIsuXb7mBAWaBR99U2fTG6Fp9eiRo68XF5cvXlTb1dZtSyeiXb1y/eDBcyuX1syfX/PSSz9551Pv/trXvrZg8fyMtGw+scuXrrJPrbSo4vrNa7R8Gz4dCJtlwhjP+SEBxjpbOlPpo8w6Ag2y8VDaJxMcjBfoz54ZP2trTnpGJpWWA5ro05SHuKn4cW0enzJuhDUuu6FE8AQK4IBoJ0DanmIiKyTu5J1pT0xQk9JQCLOFnYwmx2FxjMHVFGAmM+PeidQSjN8ZUSzPDMF/iHhadgxoQd5H2FOCaYlflyeeQ3KEQAcizKHz+MMvTJNYsCsFLEqN6HgDA3juLd4g7XAVh7PolT91sCXhH/zgBwYaVGNTAjvOcPLBoGZNUW2iX9kaEvGierh3KeWnbyJOidUv0SJff/9Ib1cP78X+3s7M3LTy4nL7tiZGRlkjw1EHTrLgHse9MLY9PzffNLgYo+LA2kXzLcxVVlatXbfyytWr6sx1j+iaVz7vnBhYfV1kvw1cyFdWUjpQOcKC5/QoWm9t7cL29oOLFy+km9KCtm7caJsLYfPed70Hb7NBps5LfeTBvJdfeaGndyInN67XMQV3mu/WzOj7G3V11kmXLFuksytLquouXLUvzMmNDE7zq+c55Ep4YEukA7394i/wqiJBzt5uKhXtM7dgNjkYzgdG+606tnQ0ZxVmE7Uv73vFegUbq5jeqIqTM1KJ0hFBWXQHCeWXQKPCPf/88xahRTY38ojEkZVt98IUF6P4hOnBwZGFi1eRvnae9nf32t5OJdv36r5Fi3iaFhrG16xZhQcqip11eWn5uhXVtVX11xsZysJRXLN3nnr7261IhI0K4ZB3+2A4O9M6QsjE1RtWXLx0Kis7DQYoYCHqDikUzOVWkEYTnaB9ZxbROIhwiRBVKTM9M+4ulR0G9H9s+hcTiwEGpizBwkrFCWEk7XSPTINhNTjMH9lI/M8fzD1BbA4NieQ4qrFAz1+NFQBQPYkYwAeRvJcz4MEq6t3HoYeeqIEnSRQDf9Mf/B0Zj3wZ8YDs3GOGaEnLDbgY34EJP9GFDNMSEFe+3bhxo9pcvnwRtzBiGBYMJmRSLAbGvXWH0M43a+aTGPRDrWI3oar+ixmELOlRnEKM7Ok700zgQjCsWbssL7tEuMK+oS5H4KRnZgk2ZiOFQ3mst0CSb2lr01PjbM9w3Nt9OzvTkayNtilv2rhOcWfPn4ufTsxIzOYR/6EPfujQ4X3ikJJAZvPw7QzpxATnDaWcPHOSKkW1E0aTcLEts7H+Fk3j/LkLDQ1NzEQvvfSSVaoHNu/Zd/DVOaXl3X2dPCnTM3osITpobPsDWxqu16fMJl/tvLZnz+6rN64CotxOv37GmRen3jjtVG0RO9qaBQEIe4+cvpiUmZSelz7R09EvkiTDQnKBY7Gp4E6+4DFKzJt9ZmZnI/XQQE9yfKYlUvJF7xifdVmhmGVJwcRJ6xOUhVtHxt3ZBQtrub4WsfRWlr/68st2s5rxp6ck5ueXtTe3rVi60jZrBzYePRD2rL5x8sSeXXvqr93ctHlDYnpqY0Nrb1f3pYtX01KSN2xc+/xzL1AFu3q6nPjNujok9Bc/5dEJwRI56ga1R+TXtFTDcARB2OJVLhYGlNO6sQ211qggDjwje9v1QWpIGNBIV9NBUsxIEPaQUG1MGjipm/zq/IBc44JJpUzCTMGfeAADCACaFEeHarrVwGE+JQnvBWtPZnre0OA4FZ5oxYZQCj+eAwbcEqkuT4AtxqT3ojSEjb+KJ7wpfaZTQIybMYCHxKoPkJiYJ1b1lsR0CTuyvRV0XwJ0VwD2MkTYjeGGKGV7YXLBWgHcMU8RGI/+6UU6txoE4Mcun/t/9OsG+aLam8Va7rEpcXjkzqXL9d/85o8+/3df+tq/f7uhvl1QkIHu8dst/eMjs+lxmf0dA92t3bYaTYn7MmZH1LBzvgYGe8UMy8vJOH3y+LSRpLezpCC3mnFwYigtK+HylXN5uTki+YjT19Zwmy9a683m9PjkE4eO9TqXezb+/GkxQzvHh0dsgbXqf/3S1YGeXm7GVKb3vOu9rDcZqRkffv+H2aAe2/uWj3/4meyUnJqq+RtWbe5o7li7asO1y/Upcen/+PkvPfbgEwOdw+MDd2aGZ1Nm00QFcWBM9+2Op598e342r1Cr1/wEiPBSAVfCkW9JCRw0HN9bUJx/8cqFwZEBZ0IZCjp7u5vbmuyOuXD9+tDYxMmz57hmdPXwtg+uimaiiGad5MbNOl2u1xzkaE8wjj20/8gjD7/VAWoOazJzZRgY0lXjwxu3buLMs3Xn1vj0hPVb1zd3iNiT2tp1+3Ld1TdOnj587LhTynfufLCvazAnM7+7vYfbWkk+b6YiJz0WZxcvr119Z2jm2IGT8yrnOehCWG1hTOnpLKY8NHMsKGY6aDtYGy2Z86QY5f80NiQmZNgDQKMJOpOdN3b7GcutdpHsCcZGIXVYP4GBU3RMl7KRKuyNNDsIrGRp/p7zmONrk/lUO7fPQge4Bg/UEO1Q9JfYqTOyCMI0aPjUFvdqgjLuPcQDWALdXPF/8oef9doL7AvWIA6CEZfQ9cl71CTUJXBF31jwrq1d1NTUaBDwMIy5MdUbnxB1ekJhoEz/ef75H4n7LU8ZEldGSdE4yAz73OjrvjW3URXcr2ifYA83ErvMWNjGPMTQkQd10J5i7eeJZTMHlaaqomjThmU3b1yyHsy25PyFnsGejNx04cmMDzZ022xhtGImcqi6Udu2KRRBZfFn7oxOp8dncoC5eObyzSsN4yNTTN1O+jWeGEnKK0suX7vKGcaCfYdwUZzS0tJoVqId/s7v/A4jrygsGms4Pv7664sWLzQHME6u2rDi1MXjF66ef+rtT1M5LEU13LzFaZG65fPv/Me3121cf6vp1oJFC7hkj04Ml1WVZ+blOCvSVIeRh8gghiilzjzGFT4hfZg7kZdMYXU9cuSIZE2Nt2oX1JCKz/7wP0RJElFi2/atRw4f5VtRUTWvuKT0jlXXlPSaBbXsob0dPfyIWMbOnD0leC1LYkUssNfcqjmVZZWk+Pr1G77xb9+28HTjWp2otIKaELoGhw3r11eWlOvIxoYbo8P9W7ZsFBK47uZNbj0LFi+dmk3iJMtFZdPWRes2LBXxMy3L2ksGrxObTrnQ1je08PWHRt7x7DlBI4pPEKf21LFrxw7eEHiU+76lIL2vi/liUevD2lSQhvST4BpqzSqdT96YpbRw/qR3IGESbNOZf6YJDp16yyOPPvzwY92dYtCXcnOyIcbeABwmPVT7hd4InOAXAUyJET94BW/xX/uXfzd06jyYQ31PpSPvjQO+N8SYxrFpYDLPmXghk+GI65VRWA/JF5OQ/dH4QJcwzAGQCTHdQz60GZlbiXCRcF55iEOYKeQvNIkKkYLKVS33XrlxqU9MM0SSoCxGCUzwowaoT7A3Z6c9sHH54kXVheWFLbcbZpLF3Joi0ppa6o2K4n9YxCFtrOOIsiS6Jff0gbF+288FZm1v6r4zNN3Z1NfZ1DOvcj5t9eBrR3gKGOidW2uVnVGQU9dDex4hHIx1WhpTMROxAX5QOg7XFoZLnIBQjEUlFYV9Dn8a6nJc+5ULVx0qwf/H3lxbc+wEqF1ce/LMiaGJmW9+959eOfDyjt0PXLhygbwyJZQhMWGF2yUrZZHfFEghffi6UlDt/wojs3M6BgdN+g3wC2vm/OD7362sKFm7YkVBoR3Pnc/+6MeE6JyaBXYIWJzr7LaVvqSysKyH+tLVOX/BvFgUk4TBgb5Q3FgI4iTIl4CBbS23uaBa0BAv7Ojho4U5vCCKxIlcs3z1jatXdm3f3tnRmpw4awszxDi62i7k2kUrWm53n71w4t3ve6S9q14og4KyHCac/OJc4ViMNBmZNldZ97prbwOuMx+zrXNidLqpvvfaxYaW5mGz5zCNnw3uoHagUVVIEwH++VZDmnGA8HLKqYlybGIQsOGhmB3GEMms/wuJNTUZt33bml/48CetlyXGp/KGEMAWWGLgCZoF2LggDd1AKxL/EWNIQ1gnhJqNhPCd6Isi0nmtdyMFBo6lM0DLxeyWsAd0LIUl5B60vexsCPAL37KjShkllBTWI2OWJUVChs3gH//4xzdv3mp9UCk6256ZYB2LXUp0RfdR1d3L3+WGbzh5AILyp0lZmvOcaIQ/YWW/9/3nfvT8i8LLWBgWujfElhm37l1mpYmdmAqJf6yuqJVxxrgsNoQVGOeQ22PH5Cwfzceiav7Wtz4SYiaMDht8P/CBD5jZUyqiFT1rtNZcsTQiGAEI6VBYVtajjz76G7/xG3ZEfO5znzNPID6NNuVF5Teu3qQj3bpRf+XSVQEjDuw7Y28uqSHW2lNPP/rpP/6044df27+P7YcXgFhG7e2tjDkEENCrjCrBbn19g7bfuTPV3d1TXT2v2Iy1wEkTIfQsAkozdWeafR1Je3v6Fi5c5CHKI6At0eiJT/Qav2iLV1FfGLEhGCWljG1FDFQXUq6rpwNRxSTn5vnIww9u2byOrbiistx2Z+sJJ0+esq3HeLxp01ZrKZcvXyVW5GxF9u1PvuPKlWtOFhBUlJzmCRQiZUyZA7BQC7HrOJYU1liH/zloQx34CsASD0RRqsRcwfkmXbwxTHJMgHk4YyFL7lwqLGanZqRraQQM1ZYtUlCZprgHTt4dHLwjmBybbEdHz5/8yZ/aqRsa298vJZxApgspoj81+R6WPHrzijAWFo1hVGp/61Hg1gEgy8KAB2JsJyhSoTHUvFYyHc82h5R0CcZQCfAMgordBzFAaREUIHAIK7VIcqYExm5SU1Wwyp/+6Z/6E4OphhJVOuJL9dNU9268ktilOL9RyuhPb6VRB6W7IT+sOL1+/Mb+fYfbxfPgnzU+3ds7wD+Wag308G3qRFuY5dnvsEFCg0Pj8IRD00RLFcpvsN/aYVg2fznMFBPf+953rFy2XHwBAaoqy0uFPEIQ9fy5n/s5pl7WTBX41Kc+ZcavXZic+EB0Aaqw97/8y78IUs2Jn8MRC8l3v/HdX/7FX7GphZqxfPnchx9+1JipR01Sb9y4TbIsW7ZEZ6kkXU5zUE970RNtY6O3U+b7ubTgeRA3HbL6I66bFUaQR0DjNpoQC2rCcGQqb+9VWVkFsugCmRhXI5M0Apqq6Sal6Ck97t5XSrd+YljgE87bmXAziSdz8wuy9+7dffnyeZkg9Y4du6ysnTlz4eaNxuISNuEKzbe9WGPZI1mHli522MftBge3JaTwIpkan+nvHbp++QZ/XXq4JeqhwVE9ZnneWq/S2azmL6i0FTscX2fVPRivBIXiPURjof+gQQhbQuP1zwmF2mtghH5yMDZbcG65aX+SYCrVc8vOnmm13rxwYW3DrSYMhk8wgCuCjf7Sfe4VgzIohgJQgSXcexvim8M9aYENoBbJcCoE+zOKBAHukGHTrSdUHZ2NdrotQqcblzJ8Jf6rfPzqXTKStrNjxw6rue1tHQL5E2Y+1E979jy0YEGtVspBDWTuRzf7vT8mRHCPwI8xpLHNgozREl+FdUYrhuGaZYZITo0TJvLCxbrWls6qqmrWa1ihLnJs5K+oIDkQdWhqqlSQbR9NSV93f+PNJjGqly5aWrtgIfEM1rzi8vNyLSqBlyFx2bKlM1OTDz64WzHIghoEgXZ9+tOflh32xv8f/ehH2R+9UrHNmzdv2bKtvLA8JyVr+cJlv/Ubv2159XbrbXXgKPV7v/d7PqEELjB1mZNv6UCE9O7ebmjgmGQQ0PHO9YAPjSWAhodGbBSGbNJUJCJbnzS5oqKKWwGCgzI0CEcAh6a2qMd0qBRda+IbJiex8XnlyuUcCoXLggrjwLz5NZHnJoMpo4SlpsnpO32DvXmFOb0D3RWVJTbIr9+wsn+g6/kXfhirTO6BAwdy8orOX7jy8x/+aFNjK7v/+vUb9+87cPbM+WVLFhMoZk32ArChjXP7vxM/PDDufnhoIj01257K7g4H9IzYCjOnvJrzJBalx1nfsn1Ke8M2W8Pw7B0HRlIXTAlEx2XoCRwQO4eXLOYNwTgURn7rYs5yTs4KWn48MHCOjLt2taOwIPnP/uwvrLrSvc1CI9zHejyoUv6M4SRmcvV37PL2zdv4BMSSAsWRVQcLvAPEJIRKAKsnUIsxrP7iIeKHDAN3ej/xgDewprz0h55QA0zmiZmARW/54BZjuofe4rT3vOc9/lScQYBkVQ+96HLjV13vX/crCg3RJRM3EshH3VzyCZtDTf0dizk61djQVnf9FqIbzITTcqKb2Pf02s7bVlQ7GUx9T9wYBqS/cPbyhXMXy4rLqirnApDLMbpaFDwgykqE4y4uKrh88ZIBTd0+8YlPaI6xW9Hk/dGjR5Hrn/7pn+BeaHhK0f79+xkM1AcgcjPzrbDaidtyq/XsqbPSRHFtv/rVr9YsrEEQ3f/Hf/IZzICGYSrV0jQ8MkTiyBzZCRqSgbZDlxD6gVTjQGYua6KUnZUnoBrycsfB+YZTiqUx0P41o4Eh2pHDxCTCMsERfFztCQviE9HQH/VkGGR/V6+3pB49h/4j2hYnWUacju7bTGd9/Z1Vc0qEOWlra1ZzhkkS7drVGxcuXl22dBUnDqHitm7eVlVZeXD/ASYBldm/76iThlMTM7puC2RmmWJK0OGCnCJVYMV3wiDgklkGezTMLxR1PZ3Hjm4Ti4C2iWzW2sKiXtghQAiGrfEuMwTHKqhq7B8FIcSPCDNCC+dTTomcEY0uPy9DdJEPvP/nP/6xTxINYfc9037Mw1J79UgEFbRFN/cegjG4RsoV+gRXCEjVzbDuXqJIvzclkA4pEVRq4DBSk3n6m5ghIIGD5oC+bvCrxCZq+IT41LUgJRnukgO2wcoa/+1vfRf07RVTD+4AHDBhT/foKleE6eDzBNdco8MVCBFdGuYr9iqVRiwP/ck1xBa+CauOdqKO3Ym/2XL92q3xO4PZ+WliComITYl3VjbbHznAMVXM1Fs3Ox0pomRrKwLzx08lOYMtNyv3mWeeAWLOfAYuq04UHnVwTKX6cxzUqG9+85t/+Id/aBEAphH0xRdfdCIOvZ92R1NiKqAOQeRPnvvxZz/953Dc29XfdKvFOI/nydEly2qJks/80ad//MpzE3ETokPbiEiNQBwDJm9hzS8trzCI80BHfHHvhJ8xApgMtLa0FRbwQ0l0xotWk2u6Vug/kgCFhcAOcqqwl/MZPUqoyaAdGTVTkp2VJNx57cJFtGojf5t1yfRk6wpscTqIeZFnBCnG182yg1GuuDD3/KUzqxavcOjLWx5/TKSZyrmV+/YfcMr8gdf2mXJyod20cYtjv6BC0c0NjRmZOWJd0H+wVk5BRlV2haybe9oSkzhTzamqcChOMYhjcrP5kWEuxlk2Ul6vu8mmaX4L8SLjcbkLTtDB0oOjzYbDxtcUBlIBLO30Yv8JAz7BFhIFW6CofhA9NpaVkVpaUm4EEO2i8VZjYUHp0PA4XMSgElYDUBVyIMm9hzFQKSZcMVViOoGiD/HwLQU0SyEdltAHoECxgXJoI0KQ1Tf0YD0NFlJ6i+LQj+eUZJroK9XS00SmP30IEwrTzb568sknFYQxQM2EjxdrVCcjo0smUga5HmPi8CjmMi2NJ0YAfyoR6RUtZax5M8wkd6Zm9YFFsJHhO9kZ+eFA8LzSrvY+TjTlxQJMzS8qcJhXXEND86kTZ6qr5l04d8npPTzvHfsuT1Nbwun5F38i9r/SFy1donomwTY5KEgTdC2x8b73ve/P//zPKYFYXRP8/sEf/IHGUoiPHz9OIuzZs8cQ/uCuB//77/z3D/zMBwRosLOWymQazWv/r/76CwKjc/DcbLNObrYttgQW27+wstHw6AQ2lORcrb8XLlgkQAO1x0NTTLLNsMD7jQpkMwDsYobOzi59x8P01q0OxA+TzoxMnxu3bTEhXLTFsaQFxQUcDJSlayzdCOVUWlEeREd8vM+NG+SXYDbYgylb7IXly5dM3Bmnb3b2tLPY8tN8z/vec+LkG2auO/fs5hkdhftub21rDf/aefU9uOcxRxq0NXc23Gg5fuRkZ7vDmkfvTsVbcrZziwji4FBZUSXKdKQt0/7x/JSVgDuUZyND/PjESFjAChOAsD5AxAGDCuflhhUuijEM6whXMA3ZpZaYyB4Qmz8KylbGatDY0BTilXQFr03AAI/7VwQn+HHjlb7Ta34VD89hqzUQyFFJkXSHfjD1vV43ZKMpGQbBvIDgz6jtOXxLTxPAFSQHJlFd1CQVcBFF1p8gQrqkpaUPDg6VlZULHyS9bz/20U9wrnnb296GT3StotGFccMkIUTRsjQQi5QVqzFX6nssIYnxXQP0q5QIISU/WqeMWGhkAgqnc07OXrxwXcgV54bYZOdwqGlha0bv2gI7Yv9AfDo/n9sCNW/Y1tM1XFZabrQxv3Jcj3N/59XUUOHtWOXvZbblOJlvfvtbIrBTFbCBcuk5jzzyCCI8++yzBLzBkHmHkZ6BiN6oVl/84hc10PN3P/MeEwDpH3roId/+4i9+4uFH96ZmxP3ab/7asePHYaikrPRWU6P+MC1G4diBXLlI5yRdmo8prLE00riWL1vBtIL4OluYJ9DHLQZYNKdw2gNpGaiiojArK9tpdkwxyAjQKE/A0S7QEH4yczLFs+BrzZ5ws74eRTnbcbq2OdPJxAVFhSEIM/faFFvAByw/O72H4VTsx5GJoVstjUJ8iv9z/vK5G/XXBPc1XCCO6SzTX+iR4Jg51d3d39TU1d87KLzD+Midgd4R3nfjI0LZ9efmFJipO8EEKSCENNFwioxxLDYfHQV9Yg0HqrMJcex8olTCH8+TxmF1+N7escADBn8fio4VRc6CHCqieTazkUmIWSIpIH8SIfoqkqqw7k+fRzgHQvgEZm+Ds6fXIBt1RiRioV/lfKBryTyf4QF8gqBGfPT1ilaDN/QTWW5AkEzf0xcVjyt0FTToJ+l9BTHUXNWCJAE9lfXZz34WtiQDaaWriiIU5KHSZe6Vm1gtUyLc49fo0hg30a8x0U5TLM9F2k6MxoaW82euvPH6+bQkg20x7wkb2wcH7J7JKsgvT0rMXLxwCW1y8+Z1xIbRybZafQn0Q6Mj//KvX83Ozztz7gLzPzCtWbNWpFiyFhuo3uOPP47tqUYicOlL0CdFNBkFuJFZqKIxQ6cLNahJ2j5vYY3gU8ffOH7x8sVf+dVPOMqba/HixYsoHqXlpUYe4BZmnRTH547vUCXhd/iNhsluMs8WIcA65V9YWKws9EdwB3SwBSGmzbU9vJHGhTFKeO21/fiQ2NJraMheF3qkvYVJF1D8SQcTkQ4Z5UZ29A0MdnZ03brVWDmn2kNDgQaSi7ahcl/g+r90xfJr9dcZ/kU8r2++YW3R1vORyZGSsqLm1kZBjWCAZUkXbNm8/VZ988YNW5zR7Kya+rrbVp3FE0hJSMUPYtRdvXzNwdem8ihD5OlTBSnUDbEOEpNiPorBIyijgZ2yQ8Ml6cOW+LD8q7M0UGJvY3Z8zOOjceYbuwJgWJxqOSPdxPhUgYN9YjqC5qBDdPk2Ap5Co5sIRZ4rKJhBVUh78IRHmiQRkeNJUCVjS7PuMYmhHAfLNAIfNKC4HrJwQ2gZPYwDOgmOZaUGqoLcEpuckRY0Zt7z7HqGDiOD3RsUXOkNOMSeeR4qYGj8ozgmM3qRcBoEhr5HK3VVPXWOVdtf4U9aIfiyCUG/s9yMAG3NHSa4J18/97d//Y8HXjsm+HBGSn7SbGZxvhCJi/NySp2opTI6r3bREisLHIytyvDLhA/L9GfPX1i2Yvkjj73Vbta4hJS1GzaqKgZ+9dVX1crMleGfePYk6kKcTB6bIVDwKOJ0PAalJ9/+BOONM+vFkbUdoqGlgeNqsznl6hV8e4RLwR7ktDzRE3EM8VrK1Gi0NLKjic5GFiQlOJQLweQ94kTTLYRlWPOLRIZW0UHMRO2zMSU1PtPE9CDxgZ4CEhaaztse7ZjcrHRrHKMTk47ftfump3dwxco1N+sb+wbAusrhvQXFxZZXr16rS83MENjirU++lbvn+z/0s5fqznf1tyVnxi9ZVVtcCWO5V65dMrKogJAClnh5PLx+9OTQwKhFFy5Gly5cmRi903m758a1G0cOHRVdAmZgjPIMDI4CaW1rA1dDd+zYiDDJNViLv8Lzx4oYO1XYFCBCOuDq2hCyMmCS1cixLnG27IsWMhVCIkzeicvMSqNe0jMBxvjpEDRR28h0sEGB+3qOcqFFl0WXP12wDUWB7VCK3gIWOAmsYVcHE2B4A9HNECRAZppx9D2hrj+AW6ZRMcrTT+bQmuoeaKKBAocYbWTLPkUf4KMrh7a2Vi5lGoxz6urr9LGvVAMb63KlQIAnUY2DmSgMl9Sd2AgYkwTA74na+zXBwZyxOqdyp7IOEGh1N86y3je+dujUidOPPvrInLnz6ZpOYk5OzJgzpxjT2ox6+dJ5+oMZh6V7cSKaGpq1iH9V/8DQseMnVixfXlE5R/BNewbU6oknnmDGYehEXByuXSbB5LHyrXUYUtVZM4nhsJfJYRYl+dR9AUzHp8QZGqyo3rRu09qyqpKDxw6lZ6ZWzS13NDdmEIGdenD1Sl0I3Z4f1n0N5fn5cSTCug2bRhw2PTyCINZrDYnWwZCLv4iB69YNEW9vbN286crly/PnLyBZ0V9lVE+vuVIzHV9y15YXNpOCghI1NLSKWCqNC88U5hXeqr9Jt6WIG4gUQbXoH+meO38hqcKdlDb4i5/6RZ7O7/qZd3KLSklMEKTMxMmhYDv37CRoBBUuKCq71Ww2mHTufP3atfO4YM2mjbH/jI6Nnzl11oYHsfSQJecKg1yigCEYeHxsGja4I/CEjuRIVCWIhA3GLj3Om9oapZ2fkQE01tFB+eFsyhXCAqZzsIuKCeUJx/k40lwOmEQ4UHNlD8VYiSAU5ewXloBEPrGs7tlGoz+DpYwcksINGEXiGeJ9RgipPd7wMX5QP+CWgKjDLaZ9EvjW6K9hWNwrpAcjtMYDfn2CQ2JMxYQfzDixNPldXd14gJZsJ9THP/7JD33oQxaSNm7crOM90RgdqcvVh3CVT2wgYhsLQ2GsDfjFzDg2ndf4mEbkleAcnrOk8fK8O5VQkBvffXv0K//8g6995TvDA1OVZQscmENtDTr04OCOXTsd3FteUdHR1elIw9Kqilh42ppbTU0f/8VffGjvw2IaDA2HI4FB8Nvf/vbDDz9M8aAtIAjhp0paTf0jflQ1ooZ9mBN3Jn7/M78/ND549tKZz//vvy2fW/noE48tWrbYnkaOfQsXLTQJPnvhLMIaJ20IoPAY6+GPrDbPJ1DJVuYBwy/qQbbpsohX7LO9YdGgVFlWUcg2MojA45dun25+ftjIqjskIKo4hOFbaTwRycdAZFcH7dMcwNmMNglhcsES8wtL7ZAjBErLKie4LTW25hWUiJct8Ghv/4BDN+g8OYUCfyVt3L7W6Y4LllTnFqQL3Sz8v3Vcu8JQ49zZ8yKplxZmjo+M20KdOJvY3dmTL6RZahpuoebpKlTyy2OXTQEMaAFpMV8G/YuM0BUpRcQ0oRwzeobODU6jdzhNhuhuWMVzqq4+z8yKKyxOzM1PWb12yVsff6iktMDeMBgzFbTnETfqHeLAV8YNmSMjzKCPJxDoUhloiUYAZ4T9qxSEIlh7oXdVV4W8RkE3siPzzNWAWwJciugASsv0irJE7FF/ZeKt5/LB4gCBZwieqtIqerNXnheXFdMZWPokFuJX/eobGxiL+Ml4br7huX0Ffh0AoUnGn1DppDB51wZVCuPgmzqQG5cG04MNZLEGTyIxazB21k6rYxaLbVQaG5uxerFjx9aH9u5sb7thGxIzCB16xYo1r77yGvHf3Nhmwc6YYu7Fic3JBj9+7keHDh3JSEuximz3PoY3SQU+VcLbxjpQe+211xS6c+dOyiH1zyvLlo899gh9Q3TlF158vqC06B3vfNvVG1eo/k0tt24116dlpS1ettiBSw67cS5TWkZ2w632VKcyJiSQFNanGPUjBdJBZshr4o8TohHAQGSfrmki431ZcdHIwCBEsPHSkU3AuOiuXb+Wu2Fadvorr7184vQpAdoc9L5o0UpqklHRpGJoYJiqcft2WJX3LRLROmvmVw84eLmn0xFDpm2V5RUDfX21CxdzT7Pb0ND2+vHDgjsbAaoqKpzv1Nc9+uNnX1m7Ysv5M1dFEhsYGm5obFw4v6p6XoVo68uXLwCh0L/JIWYH7Ss5IykljTNq8vidobz8wsGBO+fPXaGomD1T+WDMfiBetno5ppYQ/8b6dGu9kxNWbaeoucEUF8/BwfKws3ziCvId4Zph7WzlylWPPPjWxPis6TtpbS2DyfG54aiyjLtWsglN6CLHETYaDfSU/AHGDeEeKytoFiG+J6gBOgmDXbxAcWjT2YQfu75+lQag9bGULl0lJRxIbExQmPTwLTuCzUOleqgjsZ3xgVpskiA3mqtIVWpAdqIRvchKqhxk+OEPf1iNqVvMLHv37n3LWx7fsIG5MFdBHLwYBOUp/+hyH/2pXE/CcoDmBXYIyyVWy5nCBJd3GjHdcmr8LruSQ7Refun4n332f4oouHrd2uqaGsFzqLHFZaUd3V1tmpwQv2HjpoqqOUzmz7z7vV/4xy/mMEHemWZg1iISCEGwgcUQtFI6KjGMvv3tbycX4AmJXIzCwHfh0vlTZ06WVZavXLPcKTVbH9gqJBGXT/YWXKTCBKcDYbn66GDnDAA9QDhmNMwEhhkE+c8MKIuM9xtb3p9cvFjkScjsg1oIQzO6pT9JGfnIU+nmIWqCaCqJpLpfnR0bLI0EWpGemWEnDQFH3bKzSujCoqLiG3X1rAgLFy1pamxjUvQvOzefDzt9LCktKT0nTRRhm5DuzI6/+MoLs4l3q6rLP/GJjzsShu1IngRBaUmJjlAi45/puzhlQrNwMBGrxvx2sK9fsBaFEqPSW2vU37zcYv4/CUFbEQE81W7m4PPoX/CPDJq/3QTBM0CfBm4NQ0NwlWN/ycpOzcxOWbR4nr2yA4OUCcc1BDs1zhGzJ7IrSg8N4AeHRgM38AZgKuC52krg3pVE9BItepFpVr9CPHGCsr6JFB5KDlsHaUTkw/TcuXMkkAsziKAP0IDc0CBHWSE0rJjkSaCrBgYG84vEHA8LZ4YlHhfMETzSdK2+US7/GUtjLjoGOYc4HGyUoo/VUhdSPzAVZmYb9SSqvVJcah+2TMRcvb1VARcJZ6lE1/ZMDhXSpsNS6IRTnPMygs/Z0PDM//yrfxSsuK/fyCaAwvb582tICFH2X375VQdNUJer51UV5dnpP3L1yhXj2/6DB3btesBBju515NVr12rmzbMAbAJAXoKdrsW05y9csDRjv++HfuGDZ86fae9s//BHP/wHn/6DDZvWpmem302c4QRBChw+emhuzdy3PvG408cEMoqsT2mZIyXlxZyimHc8r12y2LwCGfUCrzBeGbpOgEQSilB3mtjGLRs5GJ90nN7qteSRE/Ucwxqwbn8SSRk/ZepSBIw5mYOjY92dXabI7KREQ1FhGYdSFBuw0W5odG51lRGVPGppbHHeq2AZE5Njdp9VVVXWN9TxEBEC2i7cwhJHhjaoQ1FxeXoYstrOvH6xtam7u2+gtCTFWuxEWZ5TmOzDLq8oO3LkECw5U4fnhelrQkrCiqUrVq0Pk357Wevrr3Nh4PkcpD5P0dlgrHSBZhDyLKzB24d2wrQVujte1HM+jbYQivtp/TIjPjc/jXqVmZXqBCCgF4M6v7jCESV3p7L6RwUryRvk9jEzY2CJxD/ARPcS4wEIj0YAz5UbxOjf/fXfQzZF1rAuEVJ5B3PQjGXhzBODgI/1NCp7RZZHGcnaK3jVAIJAYn2mqZaQHKW6e/du97Qj9h8HShMYUqocvlI22KmiYYR8wmzqQ22NLNx+79fb1AjOcJQi/s//+arad3aF+QYt5Vd+5VcYKzIzMmMmIuQKV5iDvnnJBFXDb2ygiH5ZTibGQgBq23JMlL37lV9+rx0b9n85kKK3qy83p3h0kAxKZM+2OyMjL6Wx5daWzdsgoFjwibz8a1euPfbYY//8pS/jcCeEOgzT+cEsGFevXhkZH/tv/+23v/6NfyPjP/rRD125fsXAbU68ceuG428craqZYw9/S0erDVYtt1ucOSCYZlNju160lRGrW/ZiVO7r6Q/D6d249rY2q7aClvLlhgIbankeDI6P9o+Qv2EdQJc5t3zBgpre7g4S6tXXXty0YeOqlct0Fue/r3zlyxk5+fOXrRyfnBGQywxq4YIl5qYMfk50PXLkmPHWGq190s5U5WeAGTIykzNzOYH38xBxqJczPipKK5NmU9hz3Pd29ArucuzgMQ5O8+fV2owiCtiCedXM47reEZ0GH4Rjs3JsoaU3ESscTZlflNfc2sTO09V9mxxUYbYHJi+bpC9cutbS3MMBKS01iyixzkl+BZjeBdOw3Cnyn/hXvLoofsFraHo8LT0lrI4lJgnIsmnDtiUL16Qk5SfMZNhdMjEajKp3nfdwN2g+QKVWngCAnoI3AJA5ncKTiA3gMImshX4o9wdgucAUKInn6EuvpDHAAS7I+hKfeGJ0hm9tlq8CwNRYgz2MGIcPH+YjYGOkSRhFWZ4echYwP8NUklF+oJxM9Ypg05G6nAnP5IHB2I5VMtVqFwbjuMHKUV6OJe7+2799fd++Vw30kr3z6XdpJC8xrr8qcP/6aWaI8QLTcuz/sf2W5MrAIGETDMrUIlsvvEOUtNT4woIc4Qxqqlc33+pIznH8+p3l69bVNdTfbKnbuGnTpcsX3vXOdz/+yGPf+vo3DdrtrbdXLl+uer598Scvo3VLW6uxmhTYv/+gKebqVWvJF8v5tvxZPHr+2RcuX7+U/Hrill3bhJVldd28cVtbZzsvfApAHreHcGx18O9AEE1A6rFhcXCLJkbHFs1feMuKSl//HeulI8P5ZU6GzOnvCwuRpKBoshSErPxc0czTMjMamxpysjMW1y5wHldxfkEHxaqzq7SqWmKy61b9DeqifCzX4CsH0FswLijIN9qYdAVBNk27S2M8DXvMhwfHBicbR3hzcFguvN3UV3+zted296MPPyLCyvlzZ8wQMjK5ZI5oKTyIKKOv16xfZ0nRQciOL2k73ioGOpcKmCurmANO7bfbOGWK527E6O3rsgRWPa+0v2+4s6tbj2BR9HSFuFexybBjMiZm7KK3+jXFypVKJUsPbjOmBsX29SU4A9gmelOEyEIoQmPwVhaKTlnQj54Su4AWvD3EDyrjXikSEMdh2uq1BgC6p2S8F0YxvUvzISSg03P5yg7cXZAtmecYGinxhlf6fseOHTIhimhHkb5ESlEV6EhKotvoBvngdXDnuogNfOUTKpAnOMGATk9gOjApx2DeUgZ8xddAJalPslKlN954Q2MwEmVMbf8/L1XyPPq9f+PPImGzsnNVUg50qMyMJEuV8+cvqqyoFrnJ0XEWg+rqbw4MDw6PDfBczEpNd9ijnZDH9x/+4t//76G+oSULFjsnwg7MRTWCLHQ6D+bqhStrV6wRJFBsxaz0TOxx7vS5n/z4J4N9w1WV1c/98EfNDc27H9jDLWz1ktXtDW1F2QVtDW3unQmQkZAq3ktne6ejxAQot23NNJSzcX5BXmuriXP9tesijhX09fU6y8tMFwER36+2m1HoXb2AvJpjtoB/0EffEVUmJGhLJKGCjiekfBj1oLdEqck0kaRz9T5RZe+emBszEOdUjb7h7va+llvtwghkpWZ1tnUcPXj07BsXtfql519sb2kvKynfvGGzffRGrcKCIr5M5iPGMSxNeLPmnTl9mV4qEO/Jk6d5rdopwW9CZAc6uqUYkt7JhX5VXtEmCDwH2Gm4RQTHF7zgQLnEMCPgt5bl/ESR74JhNG5yQqy4MB0Q9douMIs/nkO7od6qQnCqswHqTf1ed0eQQwfNR6sIKhFLQBTOD5FEkczlqUS+8YSFHjXpJ+rniecIJy+XtxaRwDrCvQku+KIyIpJbJDcQ8xgzqpAoIO5zupMPVUK3RbNhf9rdpxskpkTxr2QLUjm5mVdYeSXj3YA4T5uYbpBL7TaGcFqmUIGv3HyoAVGTol9l3b88uX9//4YRjWAboUIMD9shY000N7cw1daxnCImI/MXkxYEtebAkjA2aR4y8+DOneys61esmRwbP7z/QKZQjOkZPOiXLl4i/PKShUu6b3fxqbbYydF68fwlf/3Xf0PWGLVYJJgpT79xuvlWi4M2rly8dvHslWe/92xJfnn9lfrLZy+//NzLGYkZs3xmEtKLsosWVi9wFHtaUnJuZlZfTy8jTHXVnO1bt9k3r7YOBkgStDEpiUeDpukX/YeebJvmzWakVhJNpu2MYfeLFo9YcnhH0ld1jRykRzTyjyuOe8xghDGG4xwC0Y0uE5fYRrrZ8QTHDlYWVdXOWxQ/HX/uxLlv/Os3hvuGli+qXbNqrW2qRbkFpIAjBbqMYZ09t27cys3K5169avnazFTqf6YNukVCbJRXWQlmGz16+Nhg/5AEjLyckphZUwQLSQ2gtK+XJGXnoeWbEjDQ2cltc0Jyis4J3nKaTqEzR3DO93D/FF/rsZEZ6/rLl62rLKvRd9yNYFIXG0+si1kQhS7A0Eb5+w0oj13oFkEffkALPl0JoIxGZK1cggrlrO0bNwhg6JQp0YJSNCJCxQ25LoGL4EcvuEdED+XorWk01Ppwz5490EkpImBUQmJ9gPRU+WPHjhkBFEzwYCoPMYl4usBNSyPv1YR2ZC5OMPjKvaJVXaE+VyVjBU4zXPhc8+63TZro+k+4x/6O/rz/ivmMcM3Oyxbpk/H72rXOL/7T1z7z6b90HHdaiCpScvHyVUZuEbgmpobFY5xfU714Ye3RgwdJpfWrV7/8wvNHjxwSzva5Z38QAkbcuim8XHlJqSnF00++w0nXOx/YtXvH7ldffu3B3Q8W5hXPrar52Ec+ubC6drh3+LEHH9u5dU/y3ZTkmbTMuKyS7LLy3LLpoSk2vdtN7aN9Iy8895PGG7cmR8YcEGh7PyFNsb5Wd/Xb3/v2vPnV4lVdunpJHxEiLB4GQ9o2oiE74qBY1Nl4g19QzNslu13QyOQ0Z+yxZ5tCIKlu0jXdPV2i/zuOct68ahlacKqprhZ7RoyKzOTcOcXV/beH/CvMKW6ubzt1/FReZv7mdVu2bdp+82qdjcI2TF44fW5iZKJ2/sIli5byuuBva3JldxibnKKt6y1bZtomfjge6168aBmfxeKiMsGvWto6ExLtCrLpVJ/YqRg2k6gVpywdbas6PcVy1uTUmNCX/BzZKvg/0iTzc7LWrF7zjre/52Mf/dXf++0/ys0sTUnOdrSD8QKvBC6OOVQzBONzF0xG0Ic0TQ6ojV2KCwXHLvdJ9BlEhCqM6AOAoxS5AVOyQVJgxVJ+3XsFfOa1siK8gVt6tccwFPpoEKC6RGzDmnno0CGZWDeQP76SErP5itUI44E+SY+RZKgOpt3q6ldx0sC3rpW/4QifcAw1keBC9/Wvf13+pih1N+vEp7boE6n3EdCjOvuN/oxae//e8NbV3SFEB4cRPtjJyVkiune09/emxA/0H1q+bJHnCxYsdFCudftr1y/WLlj0r//6lQ9/8EMFeTm08NIi1qEBxw2eOvP6e97zzBe+8L8/8IGf5YHY19+/atWaZ3/07PJVK0kEFne6H/tpQkLDC8//xLqE5Ul2mFvXGzraul599eX1mzZ+6td+xVDW58CPzg4nPTkRY/P6TcSkQy8b6huo9Xxj+GaXlxNMFvqmxX+3AMyi6mQ0oe9QEolYh0XCY06xB5CO0dLSZD5180Z9RWl5rp2ryanLli3HJFyrRdAzp8IA9lGXFDlnsh9JUb6vt8c4H8ddeXhYH9mbX5ZX0n67IyMhe3Jk6utf+UZSfNK2jdtfP3bi4pnzA129i+bXMistWDn/4tlztibIZ/78bdiGqbru+iUHtjr/1ARX/FALNsUFRRyBnIFJM4l2xlVWV3b39ebm5XFDAiST+6ysEFQB2PQ5zYV3kPHLVi/iVx/SSMj+gqqsivlzcNTmTduzM/OH+kY6bw/xIjWfFUoo8hdC4aDmOT7etvCYIgMk+v3+fXRz/xf+gUSacEwqiWIwRREQB2XEBdboe/duaJZwqbUqLSVnGCMmklGTQBwLAT3UksqsH3jDr2ScBcDdt3I2MpBLWBy5saPnsgVxEwOMxCtGAhUyMNFcvdLZWAJpjCFq5aF7mpIBBLaIOiw0t8pelkFvo+unUB5uPbz/e//GQy4HAjeCF+623m5/5bTF9cT0pJTMhsa2n7x4hDPMG6dOOqdEYNAH9+567PG9t7ta5i2oql0ybybxDj3f78r1y1ZsWLZwRc1rR15dt3XtXdHaMhPbuptrFs1DHHOVRx59y5//5V8gNx9gKNyxYzcD255de3Xe9s071q9Y/76nfzY/o3CsZ3TXtl2182rnz5knwsoqR3FUVllwYf0ERwGRENkCzDvf9bTxip/m5StX5AkuWmSARUwiA6z9WkbkrPrII48RwBjDJg4+kksWL6OiMCVZQQhbaWLhCBy/4JBWDpU9vd06TndQmcpLKhwrzihw4fTltSvWC5lx8cwlgV6chv36odfHBkdyMrIdHrN5/ea+zt5LZy+WFJbmZecLQvOD7z83aWk5Fi10xfI11r/E/HLQrTHK/iSeQyaprS0dFhn4XzTdas3IzBX/Mqa5TQkfEJpju9LYXRIpNagqOi7g3nJvSXnigoX5v//7v/6Jj/3i7p0PlRXPmZ1OHh+anhyn5pgsJdsTbLHM9knRVfyDZwqBgCuRpIciN/dFYQQSBQAPrBLxivZn/N/85d+CGuz6ANroM5QQT3yA+p4TaTLCCciNyTyXkuQ2A8M8FkHBmpCmuKOm3H0L2dLv2rXrhRdeMHSQNObTvsIVMsdL+EclXFjFbhKw1oUR6OtvNsA6fMvKcQ9WoNVVyosXLxgo/u7vPidloFNc2PJL5AQBGZYHgsgP/4td7qM/7/+qtvtQ+enA51Eyp7IqxSKDqAoiapmPOa5qeKjHmRc5dnblZdkUJkCIPY0BKJNjKs9Yzq9Ao2xbMWPhuFFWWgFtNiLyMjhx4uSa1etv3grRuChn5qnafu7MWV6VFlznVlZZFkQEa+ePPPKweVNpRVmLkypLC4tLS0QQW7xicWNzvaMP7kyboPAHu4vDUWN8YpT4MPU6cPBwoigjMWUVhe1B1CPemidw0C8uKXJeRWtL06d+6ZdtRTn9xkkON//01X+bUzNfTeyNnFNVbY+8DbD6niWR44DzT5nJmEE5r6PPQPfA/NIFVy9cO37smO6GyYHevoK8EP9iqHeQoHReMge45374LFsCqdRkL3BPhwPAGxoaRaUXNw9ajIcBobk5HA35AloEDANgrtMnBrstOQ8OOX+HkcdpDC6RdO2QLq9It22AIq9jk1Lj6H6cu+dUVwvInpqcaUcHd3dCqqSgkr/j2Og0bco6Btlvizfc60+7CzjEq7NdgqbayILbQUVfR+SCGTcuT2hHUAqQIBT/p5/+M4/ckdNmq5BBzwFu+r2ZsVfQrP0apsGwS7uCSAOF9BAAmjpVJ+EWKgq8Uk7khivIMPwT8ZI8pZctIyaXMvJeWUZn2j8WUiG/7EJwz/dV16qGGospK0Ot8lz4dVUSKNMogXASmGxgAKcJxbYMhGlQYOgY0L1141eD/br8GV3h6Iuw4BhYKLbDKPyfDYFrpcMx5laXL126ICFxurHJYddd9C7+aChlyGpq6l27tsYwyGSuDppMuvuUMCsrraQBGuX/5cv/Jzs97/r1eiZdwQ2UK4zCogUL7Rx462NvuSmu+aWrKHlg337RCJ2dsWHT+pSsjL/63F87r7d8TnlbV+sX//kfv/Gdf0/PCYH4RY7RhXzpTGchWG6K47kpLsPSpYtRj5OP3gmtS5htJ2Y7OpYtWmzGZtf3ow/vLS0u7uzu5nb5xX/+Ml87KjYW0kftnR34GUTEmxIdSEyr4oKSDps/Z+PNgA+9eMRYdLu9XYvwBk0V95KMjgdWentzS9ijMxb2A4kumleQz42cDaajs5Nvr3CJLEK6wzqugxgo8SLscQg/e+606A/W1wQwFe2WxaqrY3DeXBG5uzOYcdkkZ+6WFOW2tA1Wz8sXctjK6aIltcL9VpbNcWxAVlquABMsP3Z3OJI7jW01LZvc025rF1PTIcaU2TOZDplmNCLwuXQ36kGd30Ci4E8ZZowg4YkbyAS8cESS6ZTXSOkzkPU0Ung0GxtJ4Ab36wMkAEcARUGyDRF5CIP77t27aSYSGBPIKvVQGN2GtJMGbwAQxGAbuId1xYEva+n+/fvBS+Y6hrQDd2oVQUvYy5A6Yf4tN+WqrqHfwyhzTVKuJxFPe6jyCpVz1EKf3L88jO5Ji/sPYzeRCZmLVsI49507PBp6r12va227baffgtqltYuXWAOmC80mz27aseRGc0PFggqHdVQtmhOXEZ9VkjlncVVpTcnwzJCDjybix9ZtWz05O/7QY7sfenTXxWsXsguyfvj8D/0TRb+4orSzp+tmY/3BIwcJ4117HmTdYiKkba5csYrvwPGjx9atWfvBD37QKpsmuJBISCik1imaZrJh9PZczQ3UNB/mRb2DFDzqTDmIHlRqaeHU52Cp2xaAcSVJJEybeG0V5eXe6gtPfGIQs4KGZ1CbxiWBYAAN9bd0n2iha9evcR5GYUmhEw+aWhrr6q6xMzU0169et6ah+RZHV+dQ9fT3cvPGAzwLmVW4InLGtJdgYGikZv5CoYHGJ+9wWrY4aFZr1nu7o3NwMJiqHMu3bMk8AVKzs6y13WHwFFSxvWXwX770vz74sx+0jcaeDXak/OyihlvNHa3dZrq22E9N8meOy8nJtzG/3Uw66DLBwmPGpesjZAObpvmFWzNSLYUuvU9iRggBSBSDcA/xBpEalh7QNIKIG5lKJDWUe83/kfhHLPYZsp/0gnhdAnlRAihE92gmIBMkJt0pPNCsHoqHe7VRFZUAX4vE0mMe5ZLrqK9CXjGD6maDA9BDxg9/+ENu0ipAq9XTLK04xzZF8+nHH388arBvDUq+VWe/Stf4CB/+dA8oHrp+GvSekljhN7pxH/sXnCXj7JEduVbnbN8WcZmEGs/OKdj54N7SyqrFK1ZUzJ2z8YENS1Yv27hza15pXu2KhSnZyWMzo2m5KUX09tKs2RQLUumPPP6Q4zPK55U9/MRe4QvuJk93DXZdv3XtO89+Z9m6lXHJCelZGU+96+l//OcvWtB97cBr9BDudAj1/g9+QD1JkFdfewUBIVUPiSp39foN0dHsT5g3f+HI2AQBrGnsPBIbV+GAGons3Ch4FoEbLdwywKVLlzs7uzgXCf/m5AvdhJgMAMypvGNMJ8zm9RHS6VbTCU5BBhbjM9/7xUsXOa1v5+7tw2N907PjpZWFC5bOu1Z/tbOv4/L1i3bGDE4M1S5fMnf+HDub627ccFY3cexUnpy8fK6nzuZxmoHjycorKzCYkYph1sqWcIB6R03MalRGv7c0OYU7rrf7LuPyt/79yz1dvVnpWbyku7v6f/yjl3ghrl21ec3KTZbhbOubuZMg2Aw7wdTkVGFBAfy4kAL0EYHaQzJ4orsRk+xQkOK8gxb0cR9d6AYeHrrgPP4zv//HcvEIuSPowyug+9Nw75V04Itp9A0ZD9aygDwJPI+ISGwYNILwiJ2pYdyk5mIbQ4c0eFFryXJPVEs+fkl9uhMuUlakDukJ9Radz435AJazhxUFdZKcu7o6dY95hzzZTyjZX/nKV7gfk/uAq20xgoT2a4tPonqqv9pGv25iF/ubL2IqUKQIxZ4aLVmRDRGjYyOpafFVjkssKWaNrqgs5q67bcfWW403PW/vbl+4eL4ZpGahCeKYBtwJ606TYrhzCR4fviO0p0MeeIOhJIOgMJ3Mri+99PJjj7xFmOhXX36FCCRunQUGdrsf3Hv56qXsgtzKuWXVC+e+cfaN0orCsanR0soKG8fsVVi5cjUiZ2XmOGxGTVFGBxtLDapcDDRTHzP0W+HUnbxwSooLDx84SLl/1zvfmVdQ5PyYq3XXj584Rim3P3j+olrgu93ZwfDOTWzH9p0mtb3dfSaSA70D165cL8wvsv6gsxigrl+7hlsqSsvMcFhswgrD1Iw1OxZPHnjkoAiXudkFzS1tBQWF1+rbCvMybHEeHReuOIU7EIeo7u5hOj3nTQEi7NXg6QM+K1cuOf3GtYryTBMyQf0f2/sgnzkLPj4U+PGNM2cZdJ58x1OUq7zcovTEHNssQZy3s+U+m84oPfewG4Qb6aaPaVUOWQp9jRPQx4UsCOKKpQkzxlg/hx9PgMQrOGHdDj5nMAedYITW8KoA+KbEozISkxD0GbKcMKYpyQs66YjUIc8Jb1D2rUygkyCXIfOOZC+//LJNUj6HYwlkKAdlwz3Dv1/d6Rey1VhlSHoBZ+AGI7k/d/4M9UyH4Uyf20Kgr6wKC68iT6V4Drhhl1hMyZNz1Lz7iI8aHxr902xwD/2eBXUiXPbcJPqDuzzHxFThD5pbOp2GbLS0yzYrO+XggeMZWakFhdlzqua1tnbk5JFZKXF2rM7cJdj4b2mXsmxpTklPyCnM5GLR1HIT/goq8h+qeVABNUsWHDpw2LlduWV5c+fPE0Bl685tP/7xCz98/tlFAuzY1BYX97Wv/1tKRtLuh3fGJQddglu1TVMHDx6kAWNqAVY4lqOGwQHx/TL4rFlTy2IbNlEE7/Ipy2FVFUKYNcq/rfW2Qa2ktNxmf2NFV0+3AwsLSooF/LFhzfC7asVqjFReVCaAu8avXrnKvMU5kHPnzsnOXn7u3Bn2KrKmpHrVdPL0QM9AXm7YqlFYWtTS3JqclZySnebo5Y62HkZPu2c2bVxhXHr9jRPOTepobxl1uAsKhUMA4saI42E+uXGC64KWXUcFuYmpCUk2kX3yEx859Nr+PXv2DA8MNzS3OECksKTcKTgJM6mL58/r6uTsNJyfU2BRmZMp3LJHU6hiwjQDJFzQrx/hOWZBCgZ+D3WpGxckIAvhCO4wFg0a3krjz9DzJsEwjUDUEpBiegd0bEDBAGjkNsKaqkYCXo7wGslvuopcYA4bAKLuh2l8LF/wJdSVjRnICYMAMY/BPKfcK4sWhGfkQ/WnMkljFvGNb3zDUhcdEZjkLEMMgF7GL9C3N8HN8eNH9b1uwzPWGb7wxX8UqANwQ0tiV9RI7bzPDF6pSXS5j11v4t4fMX9SSUDQJyZSnqmYeVk4ZSM7c3JscPnyJWlZKemZKXdmxorK8kcmBzdt3eAgMBwbmDM1TdMseVoiJTWC34oT067Wbd665UfP/0RIQyFADHKmyD0dvZwxmdL50ui1jta2mnm1t9s6Dx4+NDE1+fiTj9Tdul5369quvbv40NOzCT0y713PvOf48Tes9RoGEd/yxaJFteSOeopuol/FmEBYIt8w6+BsrqA/+I/vpqWkPv7YW8JZ6pnZ5gRHjh8ZGBlg+sm0d7Agl6DVy2Re/bVb8yqr6y5fXzy/NjM9h7nG+HPq7CnjKrPeju1bFYTTUF5o/rD/+G48EXD00NH8/KLDh44W5pck3k1ub+sy93WMktqa/g6PTJZVFpMLYV+EKIwUl+DiySshhECdNjOYnEgwU56Zfe8zTzH1Lpg7D04MLO2dnb/9u3/ABdTB2UJCd/f01dTUxt0JBmuE1SlwC2kMBnCo+XrZc78Iru88dCPokFfRBUXQD9V+Ddcw4LlkErv30BWGCX/LBVcpQxXJaV8yAcElye1P6rhkaknA+1OOFDu4J+YB1KuIMWg10AnuP60pSeCtfGDF2CJbKj5Jxp8HgMwo5KMzkJtNKUrjCQ0K0Y0tNH7F0Yl9SPabe2BOLPSud72LhqZE3BLNadRZqyIqvEmBe/+PsUaYCUQkuGcC8ndAP/L6h9+8ZFMI/wgugdnjE9Om7sSL5X/lfN3V8zdeP3yyu7Ovvfk2v4bXj77RUN9shyERbT3N6WA9Xf1ElC24hv6s/Iy1m1cPjg38wR/93vD4UHFlcUJqfN9QTyJnx7QEx8qXVpbZtmIO8Or+V69ev/rww3t/+7d/UxgfHnWPvOURMAVozdQpTALga4IvqNvGjVuJfJ2lp9AZM4Amalv8srORRNd9/rQsUz23hhAUWAWJdKJMWKWsBxMcstVOgY/QRBdgXYYH4zAoeNvR2X6zqf52T7s4ufMWzL1cdzklM4VLyJx5VaIFt3e2pKQnXrh8bs78uTMJM2wDrY4ebG0tKipw/GlQCynFQZtIbW21yWRYX5H9dvlIYMeb3RcdHSS6eIl3jTMrli7ijbdowfycrCwhZJx5u3f3I7/xq79pWHAUJ/sP5So9LYuZf3Ro3LbjOVVzbTaA5/7ebv68OosJyD/NcelT28NZjo1RXoR3b/q9wadmgpMbkPMbSdXoT6siwbrCExHhxCHDAGZOsCHeEIpQPX3JnoC4lleMtrZu+HLunHlGBpuqzEqlwYiCloHjhfNhWFi7Zj3JEc61HRzkjkKNsccP7/L05NIj4AIlh2kv7BQLtimSLh2+OXG0NLcZdtwTZngDV3AZMhbpcszjhq3DQ2FM5GCgt+XCk9jp1sEoRJVUugzvs3sA+b1J8E9JfU//64VxzKSDuck2PAZBJjJWQm42SYlpI8NOa5tJmE1pqhcqypEB07ebehNm0jvbBm7VNQkDGOIpFhaqQEwSi7E84GhrOzP/6i/+EjM/8tBey9U79+zu6e8OgSG2bGrqbH3upedLqitrVy2pqV3Ii9M8wYpVeUl5ZmruxLATIuLnlNc4YSApLsW0wZaAdWtXi4CQk8vmo4kC1PVCtrmWrtVlqMHEHAbtcETayNoNa2nCbR0tbKnsRcz8S2oXBfGZyt21qqgof2igv+76Nc58F06ff9c7nslIznDqa297d2drR3NjExdUnV5RUcZoIbTGitVLbV5zxvievbuZ5xfUzreMiMIMJMJH0VTNgO2eYUuxI1UFbANYUFtZXMpkkulzUOzp7RseCVsLxIYpLtHctIUL5zs3wIQbx16/cUMo7OLSsh//5MUv/tNXCgpLevqGuIhOTcc3N3Ww5fCs1oloS4zCLrUcAj0hC9wEfHITD1f4BUUXoU9uYgb9Sj/0id0mfkkQH5IOOITY093xf/HZvzVqMPkYTyz1ClWJmRhMyRXRW9koWlvDGQTme4qz6i6Ctn34nP7s65OdrjVL82tW5DASsyXPd+3a41grCi7W921DQ/2KFavOnj0tKhNBK38pwVf+qmjBX4UY2vA3wxye+cmLz1tEc4MH3vve9z7//PPm3CiF0XX+wEC/SKj01Oeff2HZMgfotv7DP/yD7ufaNjzYT8ygC5aOeToAYZjkhKFuejJEE6Kmx0ZPD2Nig/J0zzAqZ6/CFaJxhGkyt8KwaDB9JyfLRvV8luzJqTuDI2H5Sa6lFcUJwSY5tXPPNtEtOXc769xG7wxGmLExgkA4Bqc9YPC58xcsW77y6vW6ixcuV8+fb1Lh9GLKHhGem5YzMzjdfCNshFAyR7dLly7aMXO7s33V6hXtHa1Oum9sqd+yfTNHIPrF9p070OpWQ4P6WIWI9VfptStXCRd+EHYa5WRmaOmlCxf8drS3LaxZ9ORb38lQeGdmlPly38GXHLYixJWYVr2dg3PK5j3x6NsarzcWZBe8fujYxLBzmcfiM+I2btvoxIORscG6G1dTM5KdusSba+tm6lBfZ1u33abdHf2jg5NDAyPzqhfebu+73d5FVpK8lk2MYzjN9jqGpqCh3BVowum6SaK/DQ7G7X1wbXpicnZm1rrVaw/s21+UX+RwvoL8kiVLlosrYQq1fsPWopIq0ez5HIoQD996QZeEbgmdF0b4mMdoImVBJ7pikuueA1yky1CXaEaqwfMUkgFdTYJ6ZlNlzNMxtnUYKoSbngixQVnWMAQhRKLgK2XQgzAQ+uokKIcV35MlXF7dB++XEH0AP6XzgqKfSOm5qhCE27fvcL9v3wHKif118jdAE4QCF8N0MInk5fnVHP6xhD0Tshmtb6EUoV3WawzuqkTMmIT93M/9HK0JAwCN/FlOTD9MCm1HJBXOnj73mU9/Wn0cZW70sGuB5kA6EgyKkEnQERNmkRJLuImodv/XunuwCKl7zKfKjcq7GEmiND4kUfT97fburs6BUVG5x2YpsRfONu3d9db6mx3Xr94wEp4+d9Yiq9mUozeKC4pjS5hpZSVlxqi7k1P7X3nVVIECSXUUH27zts0JQrBcvHCtvo6uvGPXjqyc7Gt1N77//R9u3fpA3eWbbY23xaeqKAvelG974kkSpKOz1ckrhqVzF04DtyGRQHGkFxzohUgommgZBFR4zbrVrPhcIgZHAjUYyMQjfHD3TqF7HF00NT7WdPOWqQgHpOuX6pputnzjq98oyS/m8l1ZWL5z8864ydn0xIzk+GQaP0TzTVq1YiV3FYEQHZOqgXcnZ1puNcU7uObOjCUIJ5E5jwRsDOUmD/zJCWiiQaQeVoT588vHxqdtrX7v+x56+9sfLyrJX7t29eT0xOq1qy0dvPVtb+eZ2ds38NQz796999Hi8qr4JDuleN9MJtoT46CPlNBx3EK5i+oIYx2XUjtCwReyLYzoaDgx7Os1jYUxmITeIOKlCBGXjVd8Q1zBPc6Y4Ylff+OE+N/97c8AisemrX6N4xRHT+gwsXGwAi4jxjIAAZbNeMQPESu9EUdJksGZb6HZPIFU9BwUdAbF1BM8QKf3Fc1VzjJBLA+hlmIjc56MFBs35iPCTr340gtkv9yeeuopeqqhVlbmFcSMnjYayA13HTt2bNWqlV0dnbzk9x84oCxFSMNtGCE0Mgj+mRAMI2wajhkH1DO27eQe/gPQY5cbpbu9/yS6F4iA8jhNtYqd20OwBZpyEEsx9S+YXztn1brlZ84eZ+mrrCpu72wrE71N1LU8h1WNOE5rztxqbgK+vVF/y/ZiOyG/+a3v5MVsa0YXzU9PypjrlNL6VmOjaADZ2TnyLysuMc7w/xGc8Pylc86XKSovOP7GkVVrV4rz2N83ZC5kFfnmjVvC81MjDfEQ4BRBo7Qg8KKnXLlyecFCVDrRKGJ4+SLOJj297Tn52d/5wbevX69jiFy8aHFl6byutr6bVxu2rN/a1do+0Nn9Cx/6cN3N6+09rQuXLhge1YKB0fGhOTVVZjVm5JSKzttdJYUVE+Kfj0xzHGq81ZKfX3rqzMUg5MUqhauwNSyYE4R6AL/K6tK6us7iUtEJZj7xS+8TTuvkiePrVq42DzBCFOQVctHLzSx0bGvNvIWVFTWa1ts35Khj6KXQZ+cEZ2G9Av26z6VT4EdPuVdi9Kf7GHKCfu/mvqYggQs9XVICDDgEafjmknAkHBMimeFL8kOXeIqaEEy5JP4xHHuL1pM0gO4iy13S4xAYdY+TSGhZ+9x8S6kq4SFwE9gM9sQ5uBNUKgGmRgB+oJHaiqk8+c53voNPMN62bdtYh7CWvTXveMc76JfufU7kK06GqoQHlK4mv/u7v7t378MRJ2Ah7cSWMtdalVGNiEAa7Caigvvo8sTl/v4NOkavAsFiV/RKVv5CXC3C5G4k88Tgw+T1/e9/3+YP7Hr06PEQ33Hizq3GpstXr/eK0sRO1NfXeKuByW3dmtWJ8bNnTp0mgCdHRtuam2enJhnsnQcezjYuyKxvutHYeusXPvoLqekOAEoUMujg4QMvvfrS9h3bxH8TS+vBvXv5NCuImsHvLY8GnZn+3e99W5OhJD0l9AupRg82iD3++BP87FuabxuI6KtDg/1OoHO66KIFS0qLyhbOWxA/k1JdVbtiybqBHrHLsx7c+dCi2iVf+scv8nFwHnPjjaaDrx1uqGvITstpvNFoJ2RnWzjgWtzVU6+fuVnX0N8z0NbayTB/+PBJgpboRx672jkxG9CgxY6tzNx0XVZSxg46+4GfFwazk7Jq0ba+uX5wdLhqbiW9X5hcJn8nmaemZHd19lroBU4hVVzQYp04nKBtQhYDvU53RSh3ows892fUKTpLTymZBHcTfRKqJTJ1RgaZKz1IgDdySQN+LkANve4Ddd23bx9mkM4HRLUZLTQrSVWk81BJUWJYkaOvDMTSRzXAP1Buvms1l63TK0JdhfQZFlKkT0A8YgzKjNkwES49foNpOSvdnjqLyupthm36+8orr8A32a906JetTCxB4Ct6l8S0MurTu9/1XqIe2yolxtY2HAcXDESJ6kb7F/WEz2NQeGKX4v7LTfTn//tLL2drkF6rvY2EinvEef31N5x5wxjDF4j1Vjg0C0OjI2MDFvxtLhyfwN7Mx2iLhnt27bx1s+5tb31LdWXFwpp505MT7Y1NjmE8evzwbNJsV19H+ZzSP//LP926fRNXeIeCm78Kn/it//h2OEcsJ/vq9Wsi+Tywc+eo4GXCWLQ0LV+y1MFn69asMrW9dvXyhbMXOSqfPHHq3JnzX/7SV3ft2POBn/25gtyil1588fTJN8rLypy3WVnCH7NjeOBOXmZRw/W2o4dOWmRNDWf45m7YsHH37gdtHqDepCem79yyc7hvxA7ETWu2lhVU5qXmT43e7b3dX1NdOzY0zrWzrHSOWKNc7jhCkzbBHzNcYbxlbnHQCnRRh4aGGbLmWTTcsWO7wdmEuKm9mU1sfHpi5bo19og49tmUl+VUfG9Q4uSTkRHsLmFl3+HJ8aJyBCcayi3k6AXwjeQg+OmFSKp6q6O9IiuBxwW3Ekegj0QhbEQjQCT4/XqrtvGf++t/JKuiP5QB6zIi780H5A5emIEkY7An5oGViQP+VDEqz3PFYyaCPKoEmQ3Wel15qqJgifn/8Pzh9wI3RnAODn7BWtGeMC7hN6WYOkvvWGb1idbXDAIGB9U12mAGk2N8FTGkIrSNEY0rwb989SsmD0ivwnSPWLljfpl22Ezuj31IJmdXBPT7N4EQPzVQ3H9LBaK8hsM2rJMlhBkFsgUbSEbqQw/tPnP+pA0cSWlxXd09pRXZeXmOihi2tyk3O4c4MLk3lSLMLMESzz4lKKmxY+GE2X6SW+ni5BQUlf6P3/r0R37lYzmZOWKhKcAckYGf9ixChL2wmY7ezsvEHtdvXJ++M1kkotsNCwsiilZfvnTdThFxspTCH17vkAsG5qryCuTSTUsWLvj85/7GEcXbH9jKEX/b9l3/868+V3e9YfnSdU23eL8l79iy80c/+MG61SvystJtH85M50Q9QofU3LTM5AWLForvIjKXuYhQo4x4zc1tglnKgdacnpJ+/cYtURZJaXNc6oWvBG5IC6IySUAKRrU9D26dXzuPH6ie4n1dUuZEVxI2Kz0l+7GH33b9cmN2emFnS39VRY0THsxxUF4fjUwMm3WKog4MPFKpxh56JRMEinoHeNxEvebmflcignvJfOuKRgOfR/zglfsAjNiTkMOnful35IvPEJT6AXDudQ+wErcISlpLB3OuUAMn1dy9q0ehCp/IUZFK0mimDE8USRQoA+7dm/kdPXrUKpsEknkOx0SjBihRWZ6QDazR3n7sYx/5/Oc//8ijew8ePEjXlwxPR153KqNEzKAUOUQ7yCghzjxUyfaO23jMxANf2TsSVeCeHQcx/u9wWj9Nr/uE0yg0un95Hl6JVxw7ydDbe30Qm1GYAwBoRlba9MyECdtHPvrzBw/uc6IW6xFdnFXNZezmfsyYQ68gkAiXHbt2/tMXvyRkeZguCqJaUCiMSkFZZWNTS15ePsc4On0IDTQwlFuQL/2Jk8cXLlpQWV3x0isvTMfded/Pvu+Vl14mbKvKytGZ1sdnxs5Mfm8IyOeHGNJrRmAshGjU/XNnTpfmZ9+ou7Z3714Tyq6uvqPHTp06ebkwt6SivGb1ig3d7Z1mxlcunM1KT1qxfFHX7Q4RX3fv3l1Xd32OI4rj716+dqGmZh4HUodPtnV0zkzHFxaVnnj9LL+KcxcuQj8XIHNZtgae2REDJKcyNtx1jNjWBzbzp8BOjPcVVRUMAOL1Ll+zjDnEEZjOZOrvGlu8YFV6Qm5P51BWRh77GLoJknVnSkw75yUFET7QT6jfUz4j1OojN0hKBMMMVHiCXL6NJHhAacz4EfUagEkMSFHnunf9JwP899/5I3gCLwIVrKX2sboSKm6UQTbjAdqIGzoM92C/hgX8EA09sqOKGKfgVa/gB38Sgf6MPlEPuRlAvFUKyeRbdQVEw5lfapLNxIQW6EjABieBwQG+dSpNyUoNfGMhS8jmA9jg4YcfpiZpv/3jxhxaMmLJgep1s+Gmb7UIGwh1rxWxlgdAq4lfJbqim/t/RkMqukSkuZ84OSmB3PWhChMdgSZBUE+lpIpfm10931S+u3bpgrobVyxDLVmyyFnWsXDH4lmkY34quDkfbkFk1RB9TXOgs/7WzZrqGurD8TNnnnrmXQT/gf2HaubMd56c+LjKoq5BDynoPJTO7nYa0aEjB9/+trfdbmzmsJCXk49Q27Y+cMJAmh62/33ve9+3gRg2UIlBjFt8XnaOcC/jg33nz560QMtkWVJSQc34vf/2j3Pn5G3asKOrvddZkeLtPPbo3vbW+tOnXt+6ZbNjsVctX22PoZrbi1tYlO8MAAHqWm938PPkLLjjgT0vv7LvzvSskwGYfUbHJjiAIKe13RCuOZMlI8FJhWJXLVu+dM68SvbZd77rmb/5m/8FRdt3bhudGBXnZeZO4oLqJXVXWotzKxLuZgj5I3gc846AFLY33J2dLCjIcVyNTikqtCMqKK66ABrB3UO94x7wNBZiEfZ+fwGDV/AT8YavItz7ys39/o0y9FWSFHIhRD3Su74klQHXJM+NLqRURAVTZ721NxyC8ZM0MK0SPpTApWxGKFU0gSbg8YCRxK8pr5IAQobqoSyiWg4+NG2ADG/Bmr/DqVNvhDYXFRk05G+KuWPHDsISYnxrVuCtzDXDTcQ8q1evMcfYuXOX6snZcnJTa4sJkvarbcw4HWgUIxxRYSh8U5a/OZ5qQtQKBFIllfnpC32sC+thys9MOKwqWi4IGufo6FhzUytR5kA4gTzSkjKbbjXbjMW7Pawmh5FSmNtepi2r+miLzpcvXVq4YEGI3zTQy2in47Y9sGVyepz+8973PXP25PnaWoG6Mp1iZHg8f/Ecx8xT506Jp8v0ZEP6hbMX8tKzcjNzBeqR27UrV1gHL128iBplJaVvvP76hvUbGS4dzMqxzMgzPXHnyqVLAHThzLUNa7akJCZ39wxXlCYODwweO3xs/ryFiJ+fm2nYfGTvjsuXzplWWQDF4R2tHfJnRS0pKebQj4wJSSn2Oppnm26J5/7avkNmpCbceseuF6ZWcoV6Mj09E9ggNamyimN8Lh8C0RVlu3btOuoe9ySrqsGLJD7jVn2LA11SEzPj76bHz5Ass1lZZFYwOTr2zRBnCoGxdRw90386JZLl3rtXc2nce6iv0Zo4VhkS0L0E6h8h0z3AkCm6zCvIDHWOCXe/wZxEUiqJUDcNBT6Zki5Sk/REqdSylgDyQFx5pLKyeQ3BpexA04cu6Ado7CFlNHNVM2XT5vWQt2zJ6iETpUivaHJdPrR/K8qqa4ig4RhAoF/OWEIdfGiIwCFOMWL1I0jkYCqMBIYI/OkJ3lANT/yKHGE40grVUHNiQjtlDt9uXCoT3US//nRJ8P/fFc2e2fF52BrBxp2oPsIJdMxauCOA7tjePTgwyoXd+k5Kcrow/MxEepfaoyGMa0zxGJWC1zvQW1FV7gj14cG++ls3GkXtuXF9sL9/QoxoAULi4x3c3dzYsnr56i3rt2zdsMV+Yjb4vh72yTHH+/HCsOOW9xtvzdutbbSBeXOr2Rbnz+Ooy+6eAJOnT58VQEMFRENEZ916u82hAWHr4IL5c81NhWrr6RFZOu3b3/tueWX59h0PTMxMiRW5dsP6yjl2ks1va79NA9nxwC7cLogqyF66fGXuvBrbJMYs88WC+MeEgkCf8azqaMjcEPwS4uLaBKxTsempaH3JHh9LZhnpuRmpeclJmXhqPFBswnHiAkYAhi4jEcj6qCMAVwdBGnxGPeUmuo9kuU9cAAnrUAppQBtjmHs/vpKJ3LySTGIw9it99Ik/4//bb31awdKBi9+IRZTqY1iEQhg101UAEW6ma+eE7CWQGPIMAlJiCUKdBgWm8pG7fDCPqOJ2BtNGFB8l86tUUMA8slUzb1mEsI0xxwo5zmHiw8eKVpA5CW85yWBaAtnC9P79+z/5yU9KaYS5G0IPcDfOIu9xCyg7gvczn/mMHFSDFisTX8khRk/lB5URUTx0uYmoGd1HpPerdS43Powehj/vxZkLz2HISUSK814kD2TVeWGJPd55jMk80igPshHz3WSAardoYY0Ag4ye86qrmIaZf+XAtrNi/dqLly+J6m6p1V4QwbKys20yKbJWSG9k+G9obhC1iteACX2To+QdGdbcUlMdDkJFc228eP4CEUOz+tVf+dRIcA6i9c2SIAIeHj16uKW58cHdO5BOT9lzx6kmIT71t37zLwzcJcUlixbaWXZzw7rVtYtqWlsaxR1773s+YDYinJb1BL7Quok+7CgnZrSXXnlt+cpVomEVlZR//Vvfd2A1fh6bdDrktMEghKwSpWp22qqIuCeQyVnIKK3agLFl63bSUEwUDKkCKYnpQndx+UyYRS2RVLKY0SwxIanAibGAKIGYOsXRPtEkONYh92S53IFWX8KV7tPF0RM4JAR1ilcu/IBhZCKx0mO9FmZf+tRbGfrW6bB50feeRqCBYJesKRUS+UAuPIUAF0zFBmRvgVrsAYi4gjgns8FdMg3G7nQSupN6KBWO/cpNStmarhlqvJKbh0w6spLART4ZNPEbBiD7daQGOHeI9TMaFvS3GmqMt4YC4t+3Vy5e3bdvX/X8ucYQRRhDvvXdb0fM43PtlD5iSItg7iMBo13aq/0RFSKI+/XE7/2Hbu6/+i83yMq66j0mclzzjM2swbaQODQypf6JCek93UPW3kN8mzjuu7d5cGRmpWv+unWOpai3MYV3efDESk4sLy3ha2R7APev3u5ek8BjB4+zvmrFgdf2b962xU5FhpALly+UFpZyvFu9Yi1o5mTnLqrl3D/Mxo/4SxYtpskIBL1t8zabFeuuXuPewvnUqaYMLJs2bYZjAyl8zKma/6u/9oGvffWbg8NdzS2WUhONRTsqt16+bgtbHgvsqvV8WybKS4oR+XZ319DYaEF8sUABXOK2bt/W2NQsbMy8mgoL+b0Dw86oFdEw4DCJF1aCwzUgWp78mRC/oanpPe9+LzZmKnXKpYWl/u7+3GznuOWJOWZNcXrS2t1EOC2AOX72zoyooMG32S6x0AuIDNnEt86K+sKN3pRA50bd5NcVPdRH0RDhQ5c0UARsuhUxfRXro6D1+MRDuSWAHTkKuNGFlCaXbDLABPo+w75whk/gj/SlrliIURKWoHCTEEaDRx99FGtILyW1D0cROTInpaT3kMYPxCjCRqEPVEXO9CXM4y11CLIV5JUGKEiVOEH4xS123GM535oY+EovKogWZJKttkpXt86O7lhApBS8Z0vEY4++BSfImZLqecQA9EuZxChz7ydGujDOopEWRej/6Rv3Yb9t+Bc2jv305SvpKUIy5zIQnE2E8LubYLu1aYKDBfoHbORiIgw7761rGqQ7bIHNyrl64+brp0/2DPRfvn4tLT1dHbhv3G5rD9vwTFFmRIVNsly6YfX6N46eyEzNLMotGukf6WztFKPh2pUbu3fsoS6VFJW3NLW/+PxLE2MTLKG29m7fspXbBRPFCz/+UbeT4uPjjUG/+qu/unvXQ00t7Zeu1IVNW4nxeflZs3F3VqysFWc8IzOxsaV945Y1Igv/5OXnTXHnLZzXPzbUKt7VUN+d+JnFK5bWNzcIu885zWYaR5uRGB2dt//93/+9oaHdtCQjK8mxk2GfSJ7V/bBky/vNccv4025kvf/zP/9zhnfTZcYc7jlYMW7K0JmWPJuePJuWeDdxdmrWksjkxGjwN8QNM5MGav/QNlxx4bxGnY42Oj0mmUOQnuilX9SL0OxG74AcPOBeD+/LXJ+7CNzo13MfBujHJGASPQSMvPZNNAGARdnBHCBiA0ILPgzHUEuK2C7EE4EKi2GiyQAeIMiNsIz0nqgr8KkHLwacIE88AJd4ERsoRcHS4BMF0alYeDCS0UZikVM3bdoEb3LDHorAxGw7eICW75Xa32fUaNTzuZy5reEWoWvlgz+NBsJQ+taZcn6tqETloihVMEbie6JdSyOuCNR+kwciat7/86dxf/9eGgRxyZmflakhE2HidEL53Aoe8LRWHiiQz0kWLBRqJysIClE13NhgX9vt7p7KijJBbo8cOlyUX9DS1NCV3JmVnrdz2+7uzv5TJ8+eOXnO7qO55XMe2vngl+u/snb1utdeeyU7LXP/awcEnDt+7HU6KXPn8WMnhAbSQUZmdVu+dJlxwLL0Qw89xOPk85//+4HBURsSe7pDQKeDh/aL4Cls6/W6Szt2brp0sS4tbbTu5jXKpNOLhZaw+sqxrWbBfDEmcq23dXZakciNy7PnnW9AT183GwhXU5u2uB5ykejttdiPc5PuxtMzRcBmJqBy8MKKW7GixnLHD77/LOhy1uBMZY/1cO9k9dwlmSm5AMlp6I5pSpLQnoJ+UlEEi2a7mnVSJQNooDPHvcQgqoP/yj1TXkC8excU+Y26Q/OhAjbQPYK1fomA7jdKI3HENmDmCtnHejyYR3wjCwTyCDThCdsBLpXaEzIYh0A2/oP7nMwsPMMcqUgs5bkcFMxqAamYj2w2OHBoo+n6HOOqhK3APjeAyFwypVgsI7ldeM+MFnDdBMVx3jybsq2O0YXg3kP8Y1DiFkqWyMqsQJ6RBmz4ki0WtUoVccuypSsEFNGj0bIxmJslqyROxjAMx3JgGYsgrnpu/KJO9CQi1n3q/JeHYVxGuFgippUwg4hmEWEEN0azgVgnmQ1jUZpFfF1FsZ0h0ZLjZi9dubVi9YKm1raNm9c1Njc5xwZwC/Jyc4oKJ60Z2Td1d5ZHw4VzF5y5e/bMud/89d/5y7/6a/aP5/7jWTu2OtrEy+A/Md3RZtoTFugEqNu4nj61hkmiuLhoMBzhc+fCxfOayZsoOyPTOjGsj0/cJYmCRfRWans7D6WRjs627JzslWuWnjx9SigLcRlMAAyTem0qIW7BoqXL16zgMOb4HJ6BK1Ytb2lyvOyp4dFRo7dh+fK1GxpdVJRue0cmuZ+UMDYxOhs3hc8NklQyG8EEzb51q6G8vMLeLiOhWfjmTVvR2DaajNTsuOmkiVEnYAjhE2yatgUjmtlTgoNSDVKxI6IjeFIpIUoXRf0Sgfh+p/hWeu0lg4i5qBOhUQK/ulWCIIpi3MI6ouu9ktgr9/IMYpEi4Y6wBzWvfeApbcSv3GUEf3CGSaShVHhuguUXlOFSGeAF7m7kKwEomxz7EDSlNIWFV+iUidUrI0mkt+AB44aLScTIIAdVtEYIzWS5KZe5hFVJfOj+Yx/7mHhB+GfXzj24hVODGnI5FrX8VmMDJxmLwZ7I/Cc/+YlyMc/mTVuYUG0EUSUk0OAYpUKbXTojuol+JUAE9Y8Iff8m9meA+Zs30fvwK42vIrrrpxQRN2Mbg+rrGxlhRE5m3Jgcv5OemukU7oTZpDlzKhpuNgvf9NorBziTedLeIkrI0PnTV/p6RxYvWtHd1cdxnyzZ++Ced1gRG50oKypfUL3w/NmLixYsYtuhXXd33q6otEPXwUTG50KFToxOLV64wrasuRU1FcVVyXHJAnraOT46PCFSb2tjU+ONhuWLlolbun3TtsLclDeO1lfPCeuPNNIdu3f2DnTf7hHgt7uipvLp972zZsn8ivmVHX1dCenJTR0tOcV58YK6zalavm7V1h3beXdevXljJl7IqgK7qW0GYM9FVZjR3dz8M7N4BNGvp238nz+/pqik0HQebAzm/IgtetshzXUCfaaDOmoIRTNTZzI/wZACY+FvT4Lhn3AiFdwEAw4IKSiwR0xGw6p7l+f61+XGpet9Lr1X0VeeELL0c/hUSZcbnR71IMAHUyt5qWwAkrtHEQQhj9QkaOVrQCD7Id6r3i4BtQt8Lx9DgU9MGCwPMAhak1cwfnXwg3ooSVP5txkKWIJ9JT32UCcOntCjZgHNsYBZCgImxOJG2NM3sPvBRQcO7Fu3boMmDwyNObqUnfn6jXrDaXnlHEcd3hma+P0//LQp8ic+8Qk8Zi+FoYO15C1PPC4gpgaTVcYKbi620C6cH/YQOiCI1ocRKPxIQBbEVEHehRphafAebwTS8DsPpCBzw0NPYlekNUW/obd8dtcmJPLGyH83uKZ4YoLW29VNFw9zqLQ0Ou3dqUm67FgIaDg1mxY/PTxbU1ZrX1+nqJkzo+Wl1TZ/CPBfWVlNIezv7tu0ekNfd09ueuFb9r71wKtHxcyW8+T0cFp64lNPP3H+wjWucrnZeQz8YnRu37Dj3IlLtrCUFhuqizITCl59fn9BZnFve4/JNOlWUmg5Lee1Hz3Hs39J9bJTvedOH7+w5YHtCnWqc/m8SqfjMJkOTbHGjibnpXUNds/FIZkF4yOj3f29Q0NNFp4zCnKJoSOnTwxNhNMHZ+JnTOgJstlxbZ8pKCju6u0c6B/LzIrPK8y2fmfr9qZNWyjaQfdOzSR7Fi9dVld3KyslL1sAB+KeDJqaEJwLrGOWTFuxLYQ59mAY3gBP12AlXeFPDAZ7aOteagQHLb/A5lVsiLhn0vDECZNUJhQL7hOJsW1ixocw+5t11pBnsvfrbxCwOh7/m7/2+5AHiwS5MggGWet1GCKJPYwM9tQhGMUtpUWlxgSyVjKiiGjHOfQfCPNVxHxuTFXNDeAGsCDeWpgiFCQBXlJRjfStEqn7VCmKE+7CNvNrF5p+wDSdx1fSmE4oTk2Ic9MG2X7hC18wYqgAXd9sW1YmJ0xDDimBIeM+tYdFQum5eTnPPfccE7hMGKb8Ei5RA/1Gol1t3QO8m3v3MQ9ED10xrSfgP3Z/7zf8/X8/0RBPot9YylgfpCRS60CAhk37cqysrXlMoiDChVtb+E46j6iz87Yo7Xa6lhbmOvlLZMLC3PK+3nGrCps2bv7Lv/mfm7etpUdUL6gYHR8dHp8pK68aHRpzDHZmUtr+1/bv3fWQAUeAQYoRctmE5GC8lauWU5v4rbQ0tb7rnc/oSoEhnNf915/766zszCeffkJAjYVLa/cdOXTq/JnB0ZnaZXM2bNo4PDpePXch0SZym/469capsJEqt+CN108YT+zxSEtOGRoQE3cOKSNOBLRxDUE7y37Z2RkzZrljIwUl2RzYFi9dYm2kuan9mXe9tyC/rLW9u9iyV1J23GiijUMRqQERoIFKv6shbERU9SesIyN8k+5+IcefnksPPJJBsBs5yIpcl8avh5lZYX8iDvFWhnpEGveSuY/wKZnE0Z/xv/zJ35IvuOMkn7mROkrhBuzwJVr4wMeGgr7uPs8R2p+eq72ymUH5MkAwnSdydcYPNHjJKFAQD+K+ksBF/GueWhIhuOvgwYMKjfLxa15oxMTxGozrlKh6UG7W4VvDiF/8oHSDCULgB9WAe3UWLw0zICXvOv63rOMsEkwWaqh10B8mLROB61xRH/g1rYqw6z6YcjBDbB3HjSeq7UYC1/0b9175lU94Ebuit5ZZYtRjzRAqRxQ+PipptsCSc1xcXIx48FF/q9U5mrWLF9XdvKUCNv013RpaUJ20bMmS7LS8tz3+9OjwXb6l7R32WHSeu3Bqy84N03HjnGIq5s6rqpznnA7LvQKXf/jnPnz6xKmZienaBQuofPtefQ3nDwwNwgZSmHod3H8QaAzy586fnb+w5tDRA6jx9Huezi3MnU2Km794wZf+5Z9HMWd/H2N/ZdWctMwsp3s4RFUPLlti71hrd0f3pQuXb4gXJsD/XRvbC8LJfElhJzRrT3xisomyPXF3pkwMkpcsXeAoRHLHlLKyYi6/0Ucfe9LRqC2tHWtXr7eXKJ7XWHywxKNPREMUdkkP657DDHLqd/fgp/KSuaSP9VsAtBtQiVAawd1DOIEKU+cIyf50eR59GN2HBDHHBUTwCg7tmAz7rL0mICEJKEmmiOFAHxHhmA7jA8/hL6oE4Bpxo/kDe7xBQHZBvsbHq7TczGJlpd7UHo1BRyCOWmXJhtcdmS099Uk+LDmENKVL1VVG6QqNjD+KUA0fKt0QZOqsLDSSLdvrRz7yESmtvikIX0lgUiFnHIXr0E5r2Y7UTQKNxxue+DOQ/Kd2wHgStSv6lQbV7l/+jJ7cv4leRX/e/yRKE43OylK6X2zCLcVkxidC9g0NhShJzst0tJZQH0ePnjG8C4UZ9KX0uJExMROmrt+ou3z16nPP/7C1s80+9Dnz59ihwie/rKostyjv2OtH+cat3bBGNKG6huuvn3x9YGhgz0O7+ZwxE7+2f9/J0/LkVZZRWlr2ox/9mHbHwdgGmrVr1uXnFfHksZfyX//1+1bErD35xw9vZHjUcpYuQpOAiRjygOH5F34cG/m7WUibW9s10D6e7Jz0/gGHDCSy8ZL+7D+cQSorywoLU3Jys8EJkW/U3SwpLtXMnTv3sPQM9o/U1iwyd3eIqlULFFMKaPl1r7thxgQPbO5TGBnhW00AL5DuzbVeDz0JguTNK0qA1KQbnGgCyrsPM4PsbHyiCLkBACEOYNK78cSvosNCrNSe6hhQ86tU2UEnkKmlmatL/chgedF/JKCigCx5j3Gt9folMHzCBocEYCoHiJeh/DWPhFYeTCtYJVT0/e9/v69AH3xdPqG3iL8C0IjuCDApVQxbYjY5axhC8HbEJ6ohB1r+gQMHbKYh6eVPyKktFlW0ghBXF0pvbkBTUn9P3JsFRLsf6eXyiV1uwj3q3/v16s1/EawV/dM3Ucro4//yq9o6ibSK0kftFRBD0MWqqrlLl9TaMP3yyyKcZtkF5uCTktIilpP2dise1ivitN3xcjkFOY898VhpVWlnX+erB1/JK83Pys+MS46/cuNyzaIaZ/cmi2mZk/qLv/IJm9/5Lf/F3/zF1/7t364IzFpbi6+ELyDTnn32R/l5xRcvXTv++sk3Tp4VcSUnu+DKlevxog7djTt25MS6NRvaWzv37nkkIxV0ssqKC3lThZi8CbPbdmwTQXrXHkd9peQW5pnNVc1xQlr2/Noqq2ZZOXF2y+YXIqSdo3e6+8bsZxgZv9PS3nf2wnkRfpYtXpaZlt1wo7GtyUEDw5mp9srn8b2bmaK6BBPNfSDGaBVoi4ywByq6D2rRDcKlBLaIwrrA5U/MoKOlhGkI0eM6OvoE3vSyCw9EAk6a6ENZyR/kyGVoV64nMglbIoHD35Kqlo+JTxnRNGTqkpcE2FpGNHXHgSiPGPZKb/lQhQh4aQhdk1p8IgH2kI/GWP+XRi2Bm4hSpOJh2rTB576Ce9niK/mrNBVINVjcLB3QrIwPlBzi31sUkRKD4QEQlxv2kAMq4BApjx07Esl+LHHhwrndu3d/4X//A2KphubQiwwRDoZAbo1VK05rbt6kb6CAK9KIIvgq9E33Bw/+UwUKz2OXb6Ob+2+VFRvbA93DHCN2zL0JBrmzes0yJsumpuZdux54bR/npQwTszk1lXYHsIQ6pIwEKiksKi+t3LBh07GjJ3LzCoQVEVNfdPGissLm1voNm9fb4S7az+Xzl2WcEp9Su2BJakJyf9dAYlxKcWHxt77+LT7VDGvMoEhBGW5saEFnZN+4aX1FRfmR40c46hw7cex25+0P/sIH5tVWO8bz0LHDL772kn2Pdv+s3bjh0bc+jtS+svdTTx07cjQNw3EU6Bug/OjZtmYLR2hoATDM8dAgLy+4f8eEK+8Tf2auXbOhtLhi9m7SovnL0tNyLMCIMZOVlcsyRuWM0TmgGblc+t23QA9LRBvIwYBLMk9Q0o3uQmR/6m7YAxgf3gd61Au6wxn3PiTaoyKir+TvQ0Tw3L2vpI8ShP0AbC/KABSp1QnCCG/CkvDGLqDvS4iXBl0Y9RSAQ4h81CFcVQVYAdGA4B7hZI3byHJMZjMEsEKnDTGyUkXSmmIjDT4BZWVpicm3zDWeKxUjJr3FSpmKaa3uVBnfYk5i3hPPTQPQCyEoURjPE9xiQ4zJ8f79+73lDCk3y5bahX+wpeY4XIME8KGKaawWBQS/eZKkrTMRveA1IqhKRjd+Jb7/G9389JOIE4Dgfofptdi3YXFHhhJYKnNa+q/92qf+/u//PqybBtsOKTeczb1TNAehZIcHRZZyjKIQw48/8TbKjDBsDrPpH+lz0OrY5MjGzRvqrl233WDTxi0iVQ1091+/dH1kaHzj6o35uU5tOd/a3G7pgFHqIx/52Pe/+733vOe9R4+fRGSjJQo7kJzD9uDw4De/+62UtIT8wtyP/dJH+4f6k9ITf/TCj8Q+sUugct7cgsJCtjt9BKwoIEL6+fMXd+7cadndmoAuuH61sbKSDOoZHw8MkJJm8hvampdtGlDgJMmBgUF7uz76oU8YbXKzC7EBdyFu2+yZTqiCQnCXMyzqepRBSZ0Cl5HwRpnoiW6SrZT6xa/n0kRCWQ5eSea5HCJmQHxzAF8p4n4ve+UTOUeMIRPlhurGlOEwAkjtHWnqUSSV4Z7c9dxFkPjz/qAjlAUNnuqiMEsnoAaRJCtO2LdvH8ujuSk4qhOp7Hfu3LCgK4FMcJHE6ofH1E+evjICGEBY/alVVq8OHD5kN7B7XGeU8KuFH//4x//1X//VMOJz+hLeU1XWnmeffdYngK6eWmhYw06qZKDgWampQubjK33GYKWBin79xAmJkS/CujQYwCXD8L+793wiYp2CvPc4wdv799GNpG6iX2+1VFZ+LYVGJPYbS6AcB1GH3jW2jI5OZeeE2Bmop1fsfkzO4DXYbxQT2k3kCPrDQN/0M888Shg3tDY7MKa4omhgZCg1O4VZ3bbaDRvWg4MzYE6+cbq2ZjGrtD27N67fGukTlqusMKfAyoMYa6L4W8flqSHUJekjscUp0yThZwQOWrFi+XMv/NCZR4tXLKpZOPd2T2dza8Oho0c6erpoX1t2bHdQX0zi2KGYWXf9pg4FPKOok2Q5CBUVFOk+jdV3hAkOHx+LwxLsbm2tPZnpWupg5Lsf/cgvFeQ5L4fJ1GFWafa8iyQCjugfIRuJUEcHuSK5BppgI3MIQSLJpLlPXjfRFXVBxD+eyMQnfnWH4829VTf3CnLJAfGj3CST3iuXzz2/N8nAABFAYZS8RDLi3DcwFxLFJrgkKNlM2DM4eh6pPeoN39L7hUgFRLoNmY2XSB25eYVhHAqPpj6UjzEBiP1pPJUAFCjrjD/4hMeiBEo0K/BcSg378pe/DN9KNyy4wZwgzr6pJlIin3LVXNs8VyiB54lBSeaea4hPVMmgBKsIZY4YLM2zs2puHscnzbc+MTC8Sb6w0GGQULpuQEdv3Ud/4h8kdiHi/St6IitaOB8kJI6yCgN1cjihiMRxJq7ZJyjYNG/zl7MqvBI2hrG8vGxuS3M/t1AH2qobU/DqlSv6errtqmxrbWaK4TMmKyusjIKmkFrd0dORnJGSmpU2NDYcnxpvrvzqwdeu1197YM+O5198vnbxwtz83Lc+8Zajx4/Q5m3jpI7yOqFeku4lxWWHDh0Wkq2hvnHj+g27duzMdZg2ApYWT9maNTluQmt2aL7JimtrhQFKPGl7/J9+x1NaGhPEGUiNyCWFJc7oZZnt6x6g5TvnjqPbo3ufsNJdkFvC8XN22rmPyVx2w9pCzPEMZXScfHQNRUA+fmHJnzoCtSN1RRp/orDnEYjd+1YvSBP9Rr0vAXkKGzpL74AcSMtfnlDkBl/5RG76RQJv3fgq/utf+w8oQRHv5OiRnpZXxHzw4UYC38AWG4sRgCiNypAjuOMEBWBZlZOPSiAK9JtDa0C0T5dtFKCVStIbIlRLe3yinTQiEpHupCBPVq5ZbR1Adcly2FWWbDEn3oBg9ZEypuIHj1TZ+sQrUl8dOJOqDAL501hPd2KWloNJPBlmfVrRNmBTljCexlp40RDptddKvgpEHYPCmhb9aZnMQ8TRFpdSIiL69Tx65d7llQtZoz/v/Yboi67QZ4gfcggrPEH8qH92Ttrd+DE+EVSn/t4BJxSIGt3c0qQC3GOeeNtjw+ODW3ds6x0cqG9q3LJtq8Xlc+dPCShmSo0ODqz+wAd+7vrl661i+Ne3tDW1Ll+ykr6ek5W/pHbxj58L8cXk/PDDj/zd33zO4Nzf28dBnQfEhQvn625cE8nwIx//+Yk7o3bll1WWiJvyB3/4Bybcy1cuizVFJFonu9Vz5rAa8Npr+/HwZz/72b/4i7+EeHF/bV8gkkBUiAqNtnHDKu/k2F1RtU30PvM//sSpUDbkcU5DA0YFJMQ2zq+PyIgIaOKKaAh4kONP2PUqQrNX7mOVCT/Rn564gR80jDKRIZTLwXN+hzouYg9vowSylSbShSTzEMijP+P/7E/+BgpBE2rRFC9K6olcwIgAJjPo2Z4bAeFybHgMJ0isisS2gQJ7+FNtPFFL2NIGslmp0iMQjMrfpXrUFQnUz3BMmSGSo3w0nhObDLnVeOuhCTvsKhfXyd/QYcDFA7LFMCpJE2Ns3bFjh41jcvbJwEDf3r178Y9qW4z01Zq1q+k/nkSDiRmCMH3Ll6+0rMdpArti1MWM8XV1EiMKXUXOclOKH41SmUDVn1Jy3McIG7ohQPvNt1Eav29eMejfY4CIW6K+jJghTpUys1Kr55dxjWZTb6hvy0pN4znAQyYpOW5ktL9mUfUTb390Nik+Nz+vesGCN06dYUwRtdP2SL0YZEdbB90JYR3XZZYxNjRaf73BcV3Xr97kiEGuL5i3QDR9i/RPvf0dL734Sqmlh8wc1nJVb21r7h/qfWXfS3/0J3+4ZPniU2dP2E1/4eqFhtZbov6js1m7BX6jmch/ly5e5cvARuiYJfMB69Bnz13gzRZpBzYJEut8eUdHJj/4/g86cbnK0dyJ6UZNI2p6mnO2s5ERRfV+S3sbCiMsKiFdRD33CA6RCAt4EuhNadx74i1c3U8ffSL9/Uy8RZCIQ5JTglunt36jr6IPUcmfioj4RM6eyyH+r//yH3Q8ahKuEgE95cQcV/fAsRSQQTlhXCe2NcPmPQnUDyIJZsxAALvkixwype3AHPktjWxJZSCTLe6Sm69ULpgpskOEbqOEgmRLEksDkbse3GOhwJ9Gah96C/dmF/7EiqpEmSF4jJgqGbHWyy+//DM/8zP405Kq/M2J0Qjj4UyRCMh7n2iCfHz17+wkb3+7jaqS/fM//7Oevnr1isqrrWqEDRlvYtqKlRYZYSNqeh5dMo+I68b15uN7I8BPP8Ep997GbEFe6VpdqXdorQjGu2FotL96TvnMVEJLQ1tqQirH5smJkYG+7m27NjY0X3N2+jve+Y7hiTEhdMbuzKxeu+rc5bNzqucYTp97/sdYVJuZIgRXKswrQsyu9g5hqPlftDS1mNKfOXlm7co18+ctOH/23MMPP3rjah31mFwn0URJc0zTd3/wnd0P7li2ckmKMKRxdw8cfrWlo1m0YMNFrJIc+RIdWnH67AXbNUX6zMnIKywuN+AkpqTWXa8vLigYtrQxPj2/unrv3ke4cT32lif6up0mNq+nu197KYn6SKBDUNF3Kensm8HF34XmqBHRBzRBBTp9gtoeuvfrPiJajG5S/ScbeBJBDqikgWGYAesQZj52SSATb/36UGL9G3WcP6Mbb+P/9n990ZfmiFqHBzyCGJUGCH+iL6T6jXIHL+Qg16kT8CelVjEyyE4NgJ4Uxwx4BomJW2WbYJP0ZLla0UOogH6VJSsz3Qj6ETnIdQVt3rYV7j2h3hglpMEYvlWK58ys0CxbjCcNdGI2VVWlWKvvPvzww9JwxHCanVHF6bj4VpW0mWWJCiSoheppJm43DkjzyiuvKKWgIB/5tEI+xoGoGwKBYi4SEQ/c7wDtRV90lzj6jV75jXKIVeanf4I0ktKv5WF7BllgCdfUtKTSsrDK3lDXlJddND0+I1TEzJ2xwqKsO1PDhPVs0p2aBfNu3Ly1dfuO5avX9gpxlXiXd/7I6JD98v2mEv29amIxQUews10+dyk9NaPh5q0Hdz/U39M7p3LuN/71a0+//enGW41Wcx958DH+Wv/w+X/QvyLTdHYzDb/R2Xv7oYf3TE6PweToxPC5K6eEVRTT8tSpMw89+IjjBb777e8PDo2KjM3xTJjn2x3dzY29c6tLUcuZLtjJjodf/7XfsieAkiMkVlpyquOWASbEJHUqRnDjCbCGEV3GRBlTdgQ7uafNoxh6IoK+0LNSuiJaoaBXUnru0lJPvHLpcc/B2nN/Ks4lK5FmYu+DkHIjPZq73HvrN/okehiYBOY8VUtYJEvQ0VMYpUzLkcikPxDqlAqaNwntS78oqAZwrBLqDfrErfnra6+9pmBp4PJDH/qQP5lBmSDBF/SJYZIgyoSGo0IkDRlvKABHhQKoocYIow7UG368zswiuaVUDXQxDuhmA4LiDCO7d+/GupqEnagxLE7+lCfQRye4bNu+FftFA45MyP7v/ccPtSsSSGT8zp07FecJn7OIWFoU7+SLmB6JJsiu3IiaauXSOr+eSP//Xvrj/33oCdGGzuHb4OYe44TgypLY1WWaK8B1dkVpVdPN1t4uQeoHEoVjyYwTevqB3esTZuIXzp0fNxXX2dRxu6drPG6SDw8LPHPnyKCTahey6yMy3VQ8w9bOFuFEa5csnL470TPYc/rMG/ZnnTp9bPPGLRzuX3r5Rw/ueeSpp95x9OjRhoZbpBy6Xbt+6UZd3Uc+9qHGxobBkZ7+4UpxZfj4iYY04RSc1NTB/oHMrPzJzOmGxr6Otn4DV052KvOOqfLY8FR6olNAq/Nyis3+xU/KyrUmM9bb2Sc6k8xRySp4QuLdVGc4Ou46SOTgwIMUXiGsTong7iaibUReCfzp0hGeuNDw/o17mfvQjTR+YYBcQ3zreFHmMvTt/W6C2CgZvEXZ6tzQI3/155/3sadwQKz6jcS/7/ErHPvFFbIm8rGBaHv+JJv9qUIqgQ2UBMTmA9L7lcxbQwfZbFIuGXwbE7imqDdOMHSorgmAe4Yd2ghAK9HIfvnaVXzC+QL6JcCH6qaG+syUjqjmdPTqq68aLjCVgjhiEPkGUFW6du2KTMzLDVDXr4cTr5YuW6JF8peJVWqtWLlqLR7DtDhQDmoFPUrXHX5d2sIwGvUN8kXSK+qk0CFvjtpeIR+aRr/3e4hM8fDN6z+ZxIdRh0GAtz73xIZJARSMWq23Os6fvGhmu3TekrmVxSNWWfqblyyt6e5rtYWmomJOelbexi3bDx45nJSdVj6vPLcgFx+xoja3N/EyNjnmeMF0Y9C2ucxuRP53E6xM9mtNz/KFtmHt1q2m6gqhhHpWrVh76eIVw6ldy0uXL7lx89qxE0fe/8GfNTBfrbvwlif3/smf/RFTx5Zt2+n0vf0jz33/xU1btl6/7PTX7vKy0paWzrLS8j//s/957tx540lpbjCjdXcTHwmNDa0bNm2mCOUXFDkzxkkctosODQ3yFNLiYDBlLEnPNgpGFIho6KELHBFEB+nrIINiiJcsIlpAauwKDBRjIeldERklk8Bz3RoWsmN95JXLq9gXQaLJAJhdnpP4pF7I9td+5XcVSdySoFJ4QYJKQZRCre+Jf2gGI5WDWofmEp/A7WMl4RZ/wg38SQ/fFHRKi7f4xBTWKjrecEPwy00PwS4Igj78qRYgKlF6YxFAc8mSlRUG2jnVxRPJVEwdZMgupD3aEDFYNJgoTgWoTLY7RWqbisUa7+cuTczcGjsJu8t1gtph8UFV5W9aokpcS6CBa7uBAs8o0Vsqin5lsUHTmCE0jOD6WEf6Jc5jvYgHSKbwxG/Ur1GHWUnzJvZr942VsLuiDoZIvbFUnthEZuuHvhZai6fc8OCEYFVOpRZIIT9HRF0Hn41a4I9PnDEtSUlNZ0HnJb7pgW1Xmq8uXbOM5488WW+o8mKJ29jOlIRc+Tk5qHfm1Jm8nBySOzUhZaCrZ2rsjmmrbVm2IDpFb/XKtT/5yUtckXUKir1mI/x73338+NGFixfa2z4w3HWt7ip1Oju3oK93qLSk6icvvFpWXp2Wmr33occyLctl5dshK54zAFkWiJ8Wd+Cu8LicO6wkM9R6RZKOT40jnbhMRp6AZ7vyEuI5kNLQKDi+del9HaRDI9wTXjraVy43KOnyynOXe53lT73v17eu6AnwuPcbEk8FyRIAwOvaOBYc4MMVw0NkUaV6ydy3ZhGJCT6YVz3f0XQW6kRI3bP7ofPnLvb3DToPR4Sm/LzC2+2dI8NjFFaWrKZGm6hTyiut3vfrdq6KfTZ7c+lZscKfjqWsc94gpxYr1QMD3b29LW1tWbk5tUsWNzQ32fdQVFoiQhPZMDF1Jyc/D9Y9LCwpHh4bPXP+HPuA+2g8wWnYhiaj6rhF47FotAueRwOuw2lhRaaoCDuBLPWJ/mYsdpLclSvXWAmRl4q4cOEiuDQnW7ZshRMJnCv6cx/4YEtTo33oF8+fsyFrw7q1Ijjs2P4AGG9cv3HnAzs/8bFPFDqD8W58fm6+05htvkEvZvsAIAZ+6Le2ax8U0zbcB3s/ZYFEdwyQ6YIBQwhpNlWdHo4oENkv1T/rAPIR69JqwN0QXpozszSgMz0RNz42k5GZLdrJxPRweXXx8NRge+/t8anp7oHhc+eb7Qu3nmqXWVY6aszsfmhLUsZ0YVnWnAWlov4PjvSzfQ0OD+BF66j5RUW9vX0LFpqUzh2fHM8uyCmqKJtKms0vL1q7dYO9itmluT986fuZBWkbtq8fHOMZM0AcfOsb305Nzji+//Xxwcm4OymtDb2zUxnLF27q75huutGfl+EYgZ9937s/mZs1p7SoNiWlcGqKzlkh7oywiLNOcjVdrKi0USYjN2tsaryorGBqdpI+ZsVNuBj4RpzJiRkB393ERO84aUJMowLS+AfSoEwQu9xAc+APqxETU8QreQS+MA0MfvUHPPg1qhPEkcLiXkHGBAqQfzhOrrF3GSLMiFvn8OJY/FJ0tYQcXFSI5rHxkcBexB7pSxuGOfniP/IV4NRVSWpDkyGwSV/ylcCWIKqNaeVLL71E59m/fz+BCpSemxuYEsgHiNkl2ODVjBj2SjOMJ4SxertMKrxVFtBrgFKiolUDl0M2BqC9aKEPKVdGIVnRi2hQSlHhyOKpFMJbBUj6Bx98kBHp6aefJtRNHpwQ+q1vfUvrlOUTflN0qmi4k8C95httEJ3IQWjViChbEDshobSkDNQVysItrE0M6MGkoC2IA/3GXpxA3BtpZZlbs4AAABk2SURBVOLyijO9G8lc3oT/6RQGeV5ohs0QnCte9H33kjNnS6y9AJGYmjgxMz45M0kJGAadidmlKxatXLn86uWL9germ7NClm5ftnTdEmp685nGzVu38QZFKIUivhFArawdv/LSq6wRBfnF3PFXLFsZjpyIT3ht/0Hxung32IxVXFLG7XTDxk3OpHnphZ+0t3UnzqZwf1i7cvXpi6cXL1hx8VLdS70HVy7ftHLFOot+s+GsgFQRpifGOXgYdgAsWdR5OByLqbgJiaOcopk97ViIKeEUEnRTr3BpKVgGI/PsDBQGgryp4dy/R/yIaNEnIQGSxUI1xz4PPxL4jWS5ZG6wiZQeAmr0XHdFyTz10L2txtErfR0clSYdth2eh9mY81U//zdfVjYAoS9kgLKREUxRk8qhY/zCPcwBMQYFMuLW3hQqB96QICjOAwMUd1UBejClk0SqC2QvX7H0SCxqlQ+hWRdyXgApHGWG7SHLPf2emUgX2vXL1un+0KFDJLpygRiylaKG2onZVExV1RkreqVVlC519qf0/vQh3QYUlA7lxg0crv4m0BYHlMKhQFvgXkOkNKu2JmAw8aGGqJWvLDP704ftHe0403M4kycKaCaC6gBEvH+pW3QF7P9/XZosgTc+j/rYfeiZ2IXzCUW6kJ3loouK+Gv4mDd3zvWrVzk1FRbk01VUPi0vtetO785Hd4iVcubMKceklpSXOAYbMVGACaGqvMpIbuC6fv1GmVOHSsqdNq/T586Zg4BNt5ocuMK6K5lYnlcvXe2mr+cWMBNdEuhzfPzIsYPTM+Of+vVf4ylydzqRY54gnknJmUMj40nJ6fa0hZOjkhLTBdFNTbXTg8Q1u9A0Qso9CS0Tr7RRR6AbgKIYIOovadyMjQ5L75IGQbQ+otY9eoateGF9XVYuD2mA0kT4lt7b6NJ3inBFD2XiRrKU2AQj6J8xOnvubFY5qEaorfBKscvbqIj4//abf2QQJJUJyAjikfYPEMpQFWjwcaR/SwPZECwT4tm0wStAIUpBn0auQgYKFymOPYAmK5tjeimgqwSKAJw1MiwhEwmMFb5iJnID3EBsoowJzQqkZM3UrwZBH8pZERKQ99qps7ETsuI3uDcJjmqoIVgIw6iASkqsCUpn9cNUGmWjjDFXhrhIl1hNwyfyUecI5V6psFpBvwSHjhwmjIw/2hvZqtHRTdTNUWdEUP7p7rw3NfYI4oMQslPewBDkXnSvh6Wh2Oocn+sM0MmyaJSZNjYyDGCUBxgVNw7H3gmOfVnoQEFZvXN1TnG2cIUlFSLKiCM9zMayZfs23h9EgxWAdz71zOVLdfYt2UGfk5WXn1188sRJaqRoBjfr6pF6dHhMDH4e2vJ3NnBxYcnv/e5/l7mjtr/whb9btKT613/9V9mbnNVls7LdznYpOApAPF8+lrCpqg4xAGCerUEAO1o2tooSa2vwYoi1MviVoKQE+kLXu/Gnh6IAycEn+sUnnngbXegQBtQYA/gKhSUTKlQyl5dRziFVpO7H7Dz+lFWUm3zMrlyGKYkjrGMAaWSlbtGBKSFBZIQgzr77zecJYO/IXfDyAs5IzX379hHqUb3xALjI0Z/QBhzaQBVRe1CGKp2nefL1Cv6IbRWCJ/n09Hb5lhKCzeQPuL6VIRVIoXLTbZQZMgxrmTzBvWTADdA40Ldmrj7xCkzB2uDj25g+E/yRlC4B5oFawtsTwxdY4y6ZsIECEFKqnpzlqedkazGBUUgChbr3XMOxqzW1Bx54QEGapgl22Z44+YYPZagOHiKOlNqrsQjiQlxXRFO/kkXT32gSFnoiNiG2LEV2ugd5w7QTerCCmGqkljZG5MrOyhAiZXCon5x2WNvUxGS/EKIzd7kwJCY5tyq/ZknNkXNHHED/qU/94vlLZ53hbqWssekma7i2i23JM5St5dGHHj9x7KQJ2o3L9c7xXb1iNdOkGCosH/mO7x4etZdIzJIFNQvhjOecrhdIVOCc/oFOwYIcGH6j7lZujo3ks1Vzanr7h0xCrBGyr2gOJFELqcaGLD2Y5hzJmFcCtEV0AxIEQXOXJ9KjmBvNlH58dMwTrxBKMq9c6Ka/7tNTVtJIL2fL5CS7lBGa3eiFaECIvvWVrLz1Sj6JpmQunBRbbw6M4ZiNmDUpfBhmaWEAd++ht/Gf+MhvoCzQUMd9AyihhbGDTYlGWOS9A51qo1RU9orpMMIQZJAcME2uEIrAAW3aL3cqB5iS3ziYXi6UUDQxQAgbAygt+IEG7095kvRYBSJZMIxCmk0X8m2kozvhBzd6qBrgHgkSFSCh0VGJMvGWCZWRVF/iyT179qgDJoFU1aDkeKi1knGHpOmptlbzofiFX/gF9dcoH2qOzA0pEdb1Fq2J1ijbH//4xz7B0sjnuTbKFgXvX0jv8ieURzc//eu5PxHWjYrJX83dy4oUU6gZm/zd4AHhPsWaQxYRhi3nsaOofEReR6/Gpc0MTkz9+m9+OCF5xlbJ5Axb3tax8YiX2Ntjy17JyiXrDh04Jr4/L/zXXjqwbMHK8rI58O1cLeRFVRNx7SUf4YBnBBdU00sdrVHFhbkTd/qdgjZ3Tk1Xd6+RKT6RVpYg1K6oVwHBobZpDAESQx3Kx2xZ9Le73kYdoVEa6In2qjayu9cRmuyVlnriQhCIgnsEcY+wauU5srjc6yxHMVjP8bkEnrjcRJ8oQjJfRVd0b5AlXKTBALFCYgXFGMBXnjMKRUX70ycySQJ9fW8QACnVBSNgpQ+YNWoA8YwNoiKVpMaQTQZLD+7kvVxwiAS+dRGiJrUs8fQon+tU+/2QBs8AE6BrLcM/1QKY/AK0TBwGrJFkPBqx7eyKXapLrsuBoiV/OaOvOmC2w4cPG0NUFc9YFuAspJJSyk3p1hC8BSadBOXwDdmKM9oAN01GfYwkoGBHpY6Hb0fPk/1KVyU1xFS+woqYtu12q2FEzX2lSn7lrGm4S9s9cUXUVzc3QTj5X+yKXkX3Og/tw73ulDSmBOMGhSpR15OKHhqkRReprCgnILZu2kxRaWpoFKlHGw10vOqT4xO/9I9/9eqBl6rmli5ftqStwzEzia++/JJIqxNjw9lVNU6LYTI6cfxUbc0S22UunL2csblg04YNsK4Oeo2kR3Mx6pBCZZ0JAJ3uk5LTrtTVz6ko5BIpmtDAkLCWmbN3mCbZYu86vTgGgLBcFYw2d2fFDgJo0UA1WQ7eIjgCIo5fNI8IIr1LM5HOTWlxaWzHdRAEPg/Qiu3DBh5aIqaKUQjiTULEkrsrVhK7jSJMGYygCCWYpD9dcotVyWpaADdkGwus4ocuYWzzo2vC/CH2ILbpz/c+CcNAbD9gsG3+6i/9d8qDvADCihJlIPpThQghmANNl2rhFjAiRUhiT2g1oEaF8ErLNQbHuqG+Qz+KuKdOHD12WM6qAKBuJFaKG3Ckr+M09JIbqaxmsOheEXRWGXoiAYOG53JQGcj2XALo58IA8eioREtjKgMlSvEKLWSrnqpkUgE6oIxRZW4EYLzC2BLIXxuj2YKKeWLMwfmYUKEYT0ECN1y9ehmnEfka5VIN+ctZlWQYqHtfHUoIw+t9BpCnIvy61BMI3OhynwOce1nxfmNJjmZ98vSKWXbbtgccM4PCmWnpjpmJCGvYfOHlH/UOtFfMK37bU2+5cOV0eYVg6YmTUyOWe2OCHDIzHTbhEMvh/onE2fS4maT2pt73v/cD6EGC4HaFUn7Wrl9/5Yrp9QRQEnzGIXxeu2DR5OTYYF+HFTHnPnFk0BLuSqz7YYI0PKT+4k3IxyY8nSvaHTLa9K/14O4toSAlLKEVSQQwUOS5RqEK3jPrsHqNJhFZAuFiHrI+UTfzAl0Q0crYEJsLBM+RiE98IquIRNL4xOXGWw3BD165HGioW4iY+wngX+nULr8YI+Q/dc/lTvoEcAcjWVOB/E0t1gww0kP4WDvDWJyZSeNXA/XTDO2RXkoIQwJgJVk9xwwaDN/aj7Iwt2/fPrLZoAE30kisrr4CAuMA5ZsogmkjhoKQAHZJPuyhUORTos+/973vRe1EZWYf4498lALxEX0NLz60OZhsftvb3iYgppyBmOajRdYNFOEe99K+uIJSBnikEISUDY6wIg3SAZxwzIWPa/6//dvXrTq5FwXfijJj0dat25cuNeFx3q1+JSDKrcb41hndoEPAgJfnJhrcAeDGE6tC0ruxi0riGE/oLaotyqUrzlnf6oAsCGVOqEucPc6i+vhbn3ziibext3LCmVezIDUjs39QVM276ZnZi5cuf+97fvYf/uEfnNb02iv7KsvKbaE0c1pcu8hGLc76bS2t4iAJsD4yOETjX750aVZG1oa166jd5pOMSHoW5QtLCpuaG6DCzrHe/l57I63KcbDrG+gVy72ktDIxKTUrOz/RNsik5Am+U/FxnT3BwOpbI2okOMBDwCWuSC4d50/Ej0ZpXakguHTjoS4ImIuFHpSDP9NSUMlCCvPALI3FvMjmfMelWU+5I8DE9JR7qqCzechxcyc2sXI7/EtKbP7NNfEX4N8gE/TGMJX26wmTv+UxgxENjeJkbFY+Q4JlODXBHoYH/BJYLjZPA9dosIr/sz/+W7VXP20jckhi9k3Ii1Cue6DNn4DrIiypHNQDTfInOAK9lD5Uhm+xE/HvK6D3Z1gHeOO4NhPSmMrnZCpzHAK5YVpRaAxhW0FZVkCPRmBqoz2u8KeHjPrMlDCNp7ENljBMIbo8iXyIN5LI2Z+wToQTabt37yazqXaSqR4c4wc5q5hxQAKZ02rwvOaQVYYjBZn003ZUiaigj8lWBcory2iJ+/fvlw8poLa4Gs+TGsgSo2wQB6isgT5kvHDuC/roHQ/9upcMkVHMn6jhHpEJS+O7ItQH6ilShmcVXrxoKXpiKvcFeaFTamsXaaBvW9saapfMud3ZyCFtZKI/1fFkva1FxTnTcWEGGWLLpeWlp+TCz8TIjCA8a1dt7OsacZwRIKoMduVt7lIf9fBLeNM6rI7TzLyFP9tuUMOkUoA+8jlqJuFFKhnMzAHkYqDRBMqGyKfykI82RtTw1o02IpdLnTUQuhBfGhOAIAZie/B8JSVQIhoh7pOwTPifM4GQrUttzRqIhvtr84QFHzvaS4ivZQkynMvK0OO/kDHRKUOLAoAOxT43e5GtCnhuKUI1fBuoEBtA4v/gd/9MB0RmPvjwvaGW+kuKAzrYaQDAARA8IQeE0cIBgqiWKR4gxYESgFg2LUKBEfR7rvbAdPbcaU5yyoZdFJEJG5HMPcGCstLNZh16SEH+ND6omZr4U2WwExlDwGNZ6DQrMP2QIdSqNkiZLlNyQBm/qZuqmk+Di0woMzhHd0rsLfkkQzWXs/biAdXWQ6rqcz2HXX2ohlH1dJvKCAerngqCAC3S8fQxN4YjbCArDScdZY4a6DNmgSwuTqMiRlVJjOGJPBUqgSe43fiJvJi2duFCsUksaJsM6i7VkFICJ9IhkSLUn61Y/ZVSVJx7/cY5oRlaW4ULbZi7oKx/sNtRQlZO9ffevY/84D+ezcstdrp7ckJmeXlVTmaR+ECiVQe59+Yl22CbiulmtOEQGWAWZGE6HIPCrm+aw9efhUplpJXScKEro06hnMgJBZBa0wxoJL22eyix524CuGLaNlgjkeYjpt6XrUythrmk9Ar7uY8Fi8+zcObv2Ea9kBW4yspbFQBlLGosJcjVHsMYRcM8QUtiv94CfOw3QDwY4lwxdrcurzIehRxj8y/spDJykDL+Lz/790AGDf5QJ21WCZgDtWjE1E71IPxAkPzTr96CFBnpBlHMbqnLcIBGYKEY5bnR0zpP24BGDtBpMEERydzQScg2+GMj+tKXvgSFVBpiW80MIxBA6sicmCRxgW/Pnj0egjs4ys0rRIczmFZDvOdG/UEWr6o8uHiI2Tz0i7XUX8WMP3ZFYXLNhCr6lfEBLllapJGY9q9dbmSuhmTU3OrgZOpbRWBvuhbgSqCGPtRSIgC1sb17pfiEesDWrRtN/cZZQmyJFeosLq6woACHPPLww9IsX7YMDxQVFKuqavtQu9AHcdxUzw2xKDGeekbwMv/Lyk4dGuZqluUkOeelC68/myjMzNjZ82eOHjnuuABAmVM+b3714qWLl1+7enP5sjUD/davYC5YadAWnmBGnjo3Es8BFrHNJbrJEQ5QR3pK4ELwoaFBDceT3mojTlMrmXgrN/Uk5WFGDb310C/KyNMTHyrC8Chl9JZ2wjPaTEAmsvLWECg9twd5utd8WHWPzQBSDiAuNwXJXBN8EmXuTw/dR5d76V1ao6wQqd29UUGa2NI7E4SCRLLzJGKAGFPFxf/e7/yp51LrDEJdzeQIdv7U2ewh0BNNB2kCOB6OyUgdg+9Vl4EcYhAIXCjZetEvbvEnGKnl2nVhi6MmoQKWgCSjijRyxkLsOShrVgqX6AhAO3bsgDBNpSOpFX7zSk3koM8wnnvJfKXaphlRrbxyr1b4hCLkq+i5Ohhb1BmHywfvZWZkmxNb9gdutMBOeE8DLV+YV4C4e2OIVuM650zMra7GkBHzqK0Psbq6YTOEVg2ZuMHq6EZgR1gxWRM82dmDA4ODegkz5OdxIOurqqx0Ogbhs3PXrgP792sgPyu7flED5dFTKyBGNezPQmHalBoio4ei/QhKNTLU7/TcaeN+3LQl7ey8DG58dfV1ApKaugjKUVE6R+grx2zxNXJqU3p27mTsxKQIwfJUYbmhHsrYrw5SaIt0LtrF5FRYylQiPlQlLtNQG3UN6hno7udjvRmHMPsGXMWMMLL1odygX9NcUc393mOG5JRZOtREWLXkgxh7G2wJ7DyW1UxU9LsRQIbGEp+YHaWmcCgOQ0bszyCzZe5P1fbh/cvzgHuapxCTrKFhfDB6BO6wfhF0oRgDBG+MMFKEMeEeA3zh775KH9VtagP01ADt9JmqUFoUI1O9C0kar8ESuIEVws89bPlKYognd2EFuDUPBCMWctIOnQEyFEm5By95+lZx0Ozec5+40R/6ANG9JRFlJX9jDkxTfvxyTwBNkSC8kgwf+pZG5JXPVRtjWPTFkG7AXRHQoyZyM+BQfiCsqnIuPQcXgbj5gAk0gsI65tQENaf+eQKRyKKGYjF4S7WTv3INU9hAVekzOAdl1NlQECh9966CsrOy0EehAOQXw+st5epUudHl1JBuJnMlCoILVCAVlodSgw0NhjCz/Ddv3qgaV65f0zVWPCory82ziwvyB/r6+T509XSlcxlNSuANai4tZ6OZYW3ZkuX19Q3OkFy8sLa9td2es/7hEb1O+qiDcQDd1NOHFB6qDQIyswAETTp25PV0ijiOaRmeQ6TEep/e4lK3WBODkuMh2rL/+B0aCVYdT6IiPNFeiaMme+VJNAKEBMmJjhaciQ0jJqnhiTOJYwNLMAE53y+MAEFXoc17y54bAgrZ5hUL7Cel0pHFn6E5b0r9qAJ+tYgnlRJZlb2NMSbbf2C/cIqP7QcxBjACeHKPAX75E7/jBaZHaPUGAujRhRDgT43xxCvlQbm+IQx0M88CzykkcLZz507drAMk1pdwT6kgyWSLYR7auwdivNK1ZCdJLHM9Kj3cgD4MSYx59Lr8ZaV5gKIgMKWZIATLj+eRZFIxmMNR8vc5RGJU2osnykUD1TMuATfISqx0UDPaaLM8DYt+SXRSVhq2VFWSQJXUEJI0ViYYHr49eeHF5+nraMJnyYeYUxptlEbFZEIEaCasy181rl296tQ6gNAWn/tQbTVZSsyGD3EOSrrwtiKCW6htSbdvl5aXD48M4Xm7GnwlPpwudJSG5qhAV3eI4yDPjDSesEUtba1ZMQ9Ca/tNLc1GZtUOLJeVvXzpChYSM3haMfEshlnkC6B6DPCI5mK7d5JRwIP1aed3QCbt2rRSuOukRM65ZKj1Eu3SR75Tf2NawCsBG0RvMPlbXINFM9CQceyCvNhbFhgbAIImoyt9JUHEIcH244TUoKiEy3Pl+os6hAMllBj0JQZl95R+EXYpMe5RTHp5KsqNP93IJPr1SXS9yQBBBQoaT1j6ChPxwYERicMDvMoJOWhrQTGL//vP/Qti6Tmt9ZRkAgtQw/0RzkATFUAElaEW5qBH5+ldyTzxuQqBvj+hUFYALZnc6CHaA3y+1Xm0DhoOqEVzUOIWkiTzoZsnn3zSWKFcxI3KgkKdqj4yVAG1BWgppUcIOjct3406g5eGeUI50Svg+MILL9CsVINuQ+iS4pQWKMnLLZBbxDDQ7HM113acrCCZa5E6qKQPtZF8BdPXwkGfa1UYKcgCbUEWdiRN09lYCLPhNA/7urqBWM1j/RfCCSvCqKLJxjHVUxl/ykEbpRHdTSnUQs9T0gMHLloUmF+AWxKB8uwJGirUaEZUN95q4aOqI+Xc3OaQ1mBntFghGT4ZGw4HBEUHGQKb56R9TBMOegBnOwClJcvfnMSHYVEw5uTiCSJIz8soIzsrNeleqLYAlIQwE42F6g+s4qL3BzABP13f4tz/HZ0hgqlqRKJaDhIo3S8GGO7vCTwUG/nxXmxSiw1D4jCQ3IshEGbeXvnCQRrMOwq9X0+IlycQKl3FXL6NGNurWfFHY5wUext4KUHgbSGGwnw+jCyqFxg+WFDDQtD/Dyo4Dmktn4MxAAAAAElFTkSuQmCC\n",
            "image/jpeg": "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\n"
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfHGgzKhZbVN",
        "outputId": "cd59bc71-e3b7-4b5d-8bca-906ab3348be5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del(potato_dataset)"
      ],
      "metadata": {
        "id": "4DrWpYtHaBd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_dataset = datasets.ImageFolder(target_path, transform = transforms.ToTensor())"
      ],
      "metadata": {
        "id": "ACs-ePPvaAra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = full_dataset[0]\n",
        "print(image)\n",
        "print(\"---\"*5)\n",
        "print(image.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKi-Sf-RaApL",
        "outputId": "630f1312-9373-467f-9a69-a11d06550075"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.4824, 0.6314, 0.5804,  ..., 0.6824, 0.6706, 0.6627],\n",
            "         [0.5137, 0.5804, 0.5569,  ..., 0.7216, 0.7059, 0.6902],\n",
            "         [0.5882, 0.5255, 0.5176,  ..., 0.7020, 0.6863, 0.6745],\n",
            "         ...,\n",
            "         [0.5843, 0.4588, 0.5098,  ..., 0.6275, 0.6314, 0.6314],\n",
            "         [0.4235, 0.4118, 0.4941,  ..., 0.6353, 0.6392, 0.6431],\n",
            "         [0.5765, 0.3647, 0.5020,  ..., 0.6627, 0.6745, 0.6784]],\n",
            "\n",
            "        [[0.4706, 0.6196, 0.5686,  ..., 0.6706, 0.6588, 0.6510],\n",
            "         [0.5020, 0.5686, 0.5451,  ..., 0.7098, 0.6941, 0.6784],\n",
            "         [0.5765, 0.5137, 0.5059,  ..., 0.6902, 0.6745, 0.6627],\n",
            "         ...,\n",
            "         [0.5686, 0.4431, 0.4941,  ..., 0.6196, 0.6235, 0.6235],\n",
            "         [0.4078, 0.3961, 0.4784,  ..., 0.6275, 0.6314, 0.6353],\n",
            "         [0.5608, 0.3490, 0.4863,  ..., 0.6549, 0.6667, 0.6706]],\n",
            "\n",
            "        [[0.4980, 0.6471, 0.5961,  ..., 0.6980, 0.6863, 0.6784],\n",
            "         [0.5294, 0.5961, 0.5725,  ..., 0.7373, 0.7216, 0.7059],\n",
            "         [0.6039, 0.5412, 0.5333,  ..., 0.7176, 0.7020, 0.6902],\n",
            "         ...,\n",
            "         [0.6235, 0.4980, 0.5490,  ..., 0.6627, 0.6745, 0.6745],\n",
            "         [0.4627, 0.4510, 0.5333,  ..., 0.6706, 0.6824, 0.6863],\n",
            "         [0.6157, 0.4039, 0.5412,  ..., 0.6980, 0.7176, 0.7216]]])\n",
            "---------------\n",
            "torch.Size([3, 256, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set , test_set = random_split(full_dataset, [0.8, 0.2])"
      ],
      "metadata": {
        "id": "OFKYUgQ6aAme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "int(len(full_dataset)*0.8), len(train_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyRcF6ZNabCQ",
        "outputId": "221ec7c5-8681-41eb-ecb0-15febca51859"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1721, 1722)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_set, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "yqhiQflmarcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN Model Basics"
      ],
      "metadata": {
        "id": "Ne-CXtB9fHY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class myCNN(nn.Module):\n",
        "  def __init__(self, in_channels, no_of_classes):\n",
        "    super().__init__()\n",
        "\n",
        "    self.features = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=in_channels, out_channels=32, kernel_size=3, padding=1, stride=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
        "        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1, stride=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=64*64*64, out_features=128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=128, out_features=32),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=32, out_features=no_of_classes)\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    x = self.features(x)\n",
        "    x = self.classifier(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "e10s1Yr_arZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a concise **cheat sheet** of formulas to compute **output size** for each layer in CNNs\n",
        "\n",
        "---\n",
        "\n",
        "### üìò **Convolutional Layer Output Size**\n",
        "\n",
        "For a 2D convolution:\n",
        "\n",
        "$\n",
        "\\text{Output Size} = \\left\\lfloor \\frac{(W - K + 2P)}{S} \\right\\rfloor + 1\n",
        "$\n",
        "\n",
        "Where:\n",
        "\n",
        "- \\(W\\) = input width (or height)\n",
        "- \\(K\\) = kernel size\n",
        "- \\(P\\) = padding\n",
        "- \\(S\\) = stride\n",
        "\n",
        "---\n",
        "\n",
        "### üìò **MaxPool Layer Output Size**\n",
        "\n",
        "Same formula as convolution:\n",
        "\n",
        "$\n",
        "\\text{Output Size} = \\left\\lfloor \\frac{(W - K)}{S} \\right\\rfloor + 1\n",
        "$\n",
        "\n",
        "(because usually padding is 0 in pooling)\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ **Apply it to your network** (Assuming input is $3 \\times 256 \\times 256)$:\n",
        "\n",
        "#### **Conv2d(3, 32, 3, padding=1, stride=1)**  \n",
        "$\n",
        "\\frac{(256 - 3 + 2 \\cdot 1)}{1} + 1 = 256\n",
        "\\Rightarrow 32 \\times 256 \\times 256\n",
        "$\n",
        "\n",
        "#### **MaxPool2d(2, stride=2)**  \n",
        "$\n",
        "\\frac{(256 - 2)}{2} + 1 = 128\n",
        "\\Rightarrow 32 \\times 128 \\times 128\n",
        "$\n",
        "\n",
        "#### **Conv2d(32, 64, 3, padding=1)**  \n",
        "$\n",
        "\\frac{(128 - 3 + 2)}{1} + 1 = 128\n",
        "\\Rightarrow 64 \\times 128 \\times 128\n",
        "$\n",
        "\n",
        "#### **MaxPool2d(2, stride=2)**  \n",
        "$\n",
        "\\frac{(128 - 2)}{2} + 1 = 64\n",
        "\\Rightarrow 64 \\times 64 \\times 64\n",
        "$\n",
        "\n",
        "Which matches your classifier's `nn.Linear(64*64*64, 128)`\n",
        "\n",
        "---\n",
        "\n",
        "### üß† Pro Tip for Exams:\n",
        "Memorize this **compact version**:\n",
        "$\n",
        "\\text{Conv: } \\left\\lfloor \\frac{W - K + 2P}{S} \\right\\rfloor + 1, \\quad\n",
        "\\text{Pool: } \\left\\lfloor \\frac{W - K}{S} \\right\\rfloor + 1\n",
        "$\n",
        "\n",
        "Use it to track dimensions step-by-step.\n"
      ],
      "metadata": {
        "id": "a6xNqhW9gwi-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsuTTqY9t74x",
        "outputId": "de9ef220-202a-4443-cbc2-6e6e4318a633"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "#summary(myCNN(3,3), (3, 256, 256)) #cpu\n",
        "summary(myCNN(3,3).to(device), (3, 256, 256))#gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhVIUXtgarW5",
        "outputId": "ab784b04-80af-4963-d614-674898c5bdaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 256, 256]             896\n",
            "              ReLU-2         [-1, 32, 256, 256]               0\n",
            "         MaxPool2d-3         [-1, 32, 128, 128]               0\n",
            "            Conv2d-4         [-1, 64, 128, 128]          18,496\n",
            "              ReLU-5         [-1, 64, 128, 128]               0\n",
            "         MaxPool2d-6           [-1, 64, 64, 64]               0\n",
            "           Flatten-7               [-1, 262144]               0\n",
            "            Linear-8                  [-1, 128]      33,554,560\n",
            "              ReLU-9                  [-1, 128]               0\n",
            "           Linear-10                   [-1, 32]           4,128\n",
            "             ReLU-11                   [-1, 32]               0\n",
            "           Linear-12                    [-1, 3]              99\n",
            "================================================================\n",
            "Total params: 33,578,179\n",
            "Trainable params: 33,578,179\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.75\n",
            "Forward/backward pass size (MB): 56.00\n",
            "Params size (MB): 128.09\n",
            "Estimated Total Size (MB): 184.84\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### mini-batch SGD"
      ],
      "metadata": {
        "id": "asIGBMo4uO4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "model = myCNN(3,3).to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.01)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "epochs = 20"
      ],
      "metadata": {
        "id": "S7XoyE19arUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "for epoch in range(11):\n",
        "  loss_per_epoch = 0\n",
        "  for features, labels in train_loader:\n",
        "    features = features.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    y_pred = model.forward(features)\n",
        "    loss = loss_fn(y_pred, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    loss_per_epoch += loss\n",
        "  print(f\"Loss for Epoch-{epoch}: {loss_per_epoch}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9WI9bxjarR4",
        "outputId": "791adf05-ac30-4265-ce9a-0f9f8077ad90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for Epoch-0: 8.265432357788086\n",
            "Loss for Epoch-1: 7.4238128662109375\n",
            "Loss for Epoch-2: 7.302855491638184\n",
            "Loss for Epoch-3: 10.916462898254395\n",
            "Loss for Epoch-4: 6.17396879196167\n",
            "Loss for Epoch-5: 5.186753749847412\n",
            "Loss for Epoch-6: 4.94274377822876\n",
            "Loss for Epoch-7: 10.23117446899414\n",
            "Loss for Epoch-8: 4.806823253631592\n",
            "Loss for Epoch-9: 7.192502498626709\n",
            "Loss for Epoch-10: 3.922546148300171\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0midwU4arPZ",
        "outputId": "ae870fe2-4e13-46f5-d98e-11cae1d51ea4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "myCNN(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): ReLU()\n",
              "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=262144, out_features=128, bias=True)\n",
              "    (2): ReLU()\n",
              "    (3): Linear(in_features=128, out_features=32, bias=True)\n",
              "    (4): ReLU()\n",
              "    (5): Linear(in_features=32, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  total_loss = 0\n",
        "  for features, labels in test_loader:\n",
        "    features = features.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    y_pred = model.forward(features)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    loss = loss_fn(y_pred, labels)\n",
        "    total_loss += loss\n",
        "  print(total_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AEnWaZIarM5",
        "outputId": "2bff73e2-c5a5-4d95-f8ef-ecc077f80510"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.7563, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evalution and Visualization"
      ],
      "metadata": {
        "id": "Ptnd9wNYw9nl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation on test data\n",
        "total = 0\n",
        "correct = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "  for batch_features, batch_labels in test_loader:\n",
        "\n",
        "    # move data to gpu\n",
        "    batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
        "\n",
        "    outputs = model(batch_features)\n",
        "\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    total = total + batch_labels.shape[0]\n",
        "\n",
        "    correct = correct + (predicted == batch_labels).sum().item()\n",
        "\n",
        "print(correct/total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FF5SK8ZzarKX",
        "outputId": "a6e5f7c5-c5c2-44ae-cc95-754160762eac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.913953488372093\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_features, batch_labels in train_loader:\n",
        "        batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
        "        outputs = model(batch_features)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        y_true.extend(batch_labels.cpu().numpy())\n",
        "        y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=full_dataset.classes, yticklabels=full_dataset.classes)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "-6YKuHY9arIA",
        "outputId": "b9cbb640-dfc0-4747-b3ed-6bf9e1b40394"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Day 4 Workshop"
      ],
      "metadata": {
        "id": "dfhRrxWq3ui-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eAMrvATLaK4",
        "outputId": "8fe8ee4d-d25e-4385-da16-acfab8d4c9a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n",
            "    ColabKernelApp.launch_instance()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
            "    await self.process_one()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
            "    await dispatch(*args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
            "    await result\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n",
            "    reply_content = await reply_content\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n",
            "    res = shell.run_cell(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n",
            "    return super().run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
            "    return runner(coro)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-2-e5df3faeb233>\", line 2, in <cell line: 0>\n",
            "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
            "<ipython-input-2-e5df3faeb233>:2: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.0.1 torchtext==0.15.2 portalocker==2.8.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FFIrxmwiarFa",
        "outputId": "e719e045-a4ce-40b2-d460-d99b7ccd6d9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.0.1\n",
            "  Downloading torch-2.0.1-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Collecting torchtext==0.15.2\n",
            "  Downloading torchtext-0.15.2-cp311-cp311-manylinux1_x86_64.whl.metadata (7.4 kB)\n",
            "Collecting portalocker==2.8.2\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (4.13.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.0.0 (from torch==2.0.1)\n",
            "  Downloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext==0.15.2) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext==0.15.2) (2.32.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext==0.15.2) (2.0.2)\n",
            "Collecting torchdata==0.6.1 (from torchtext==0.15.2)\n",
            "  Downloading torchdata-0.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (75.2.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.45.1)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.6.1->torchtext==0.15.2) (2.3.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1) (3.31.6)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.1)\n",
            "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.1) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.15.2) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.15.2) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.15.2) (2025.1.31)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1) (1.3.0)\n",
            "Downloading torch-2.0.1-cp311-cp311-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchtext-0.15.2-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m99.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m109.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchdata-0.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m112.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lit, portalocker, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchdata, torchtext\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 portalocker-2.8.2 torch-2.0.1 torchdata-0.6.1 torchtext-0.15.2 triton-2.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen"
                ]
              },
              "id": "9d5cfc69f27445768e1784618a09c5f2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Loading and Exploration"
      ],
      "metadata": {
        "id": "LE45ahIC5fg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.datasets import IMDB\n",
        "train_iter = IMDB(split='train')\n",
        "test_iter = IMDB(split='test')"
      ],
      "metadata": {
        "id": "rf7mgFmVarDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in train_iter:\n",
        "  print(x)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcSjG8U5arAr",
        "outputId": "67394c4f-ecdc-439a-de57-d980d3dbf97c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_iter) #iterator and sharded datapipe"
      ],
      "metadata": {
        "id": "t8bC3P7m6Q5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tokenizer Function"
      ],
      "metadata": {
        "id": "A1I88SPk8T1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "tokenizer = get_tokenizer(\"basic_english\")"
      ],
      "metadata": {
        "id": "lfn0wLQiaq5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Build the vocabulary"
      ],
      "metadata": {
        "id": "s6BtAh228gQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "def yield_tokens(data_iter):\n",
        "  for _, text in data_iter:\n",
        "    yield tokenizer(text)\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<pad>\",\"<unk>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HktaoH5jaq2w",
        "outputId": "02261fc7-9d71-45b7-d16f-fd1ae430cf11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/datapipes/iter/combining.py:297: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
            "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPprP8N4aq0R",
        "outputId": "a0111144-0968-421c-e391-8a3cd994d204"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "68812"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab[\"<pad>\"],vocab[\"<unk>\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8AQ5qMNaqx5",
        "outputId": "02cca2b1-e55f-4f9a-fd75-d0c26009884c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab[\"controversy\"],vocab[\"i\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULBvj2CZaqvj",
        "outputId": "e8b1805a-639d-4a72-9219-792277f8f942"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7332, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Building a simple RNN model for sentiment Analyis"
      ],
      "metadata": {
        "id": "8TxKx__Y9ZO4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notes on RNN layer:-\n",
        "- Always make sure the first layer has batch_first=True\n",
        "- Make sure to use embeddinggs before RNN layer\n",
        "- RNN layer returns the states and outputs. States are just outputs for all time steps. Here States --> Outputs, outputs --> Hidden. Use the second tuple of RNN Basically\n",
        "\n",
        "#### Here‚Äôs a **concise clarification**:\n",
        "\n",
        "#### üß† In PyTorch's `nn.RNN`:\n",
        "\n",
        "```python\n",
        "output, hidden = rnn(input)\n",
        "```\n",
        "\n",
        "- **`output`**: Contains the **outputs at *all* timesteps**.  \n",
        "  Shape: `(seq_len, batch, hidden_size)`\n",
        "\n",
        "- **`hidden`**: Contains the **final hidden state(s)** for the last timestep.  \n",
        "  Shape: `(num_layers * num_directions, batch, hidden_size)`\n",
        "\n",
        "---\n",
        "\n",
        "#### ‚ö†Ô∏è So, to clarify:\n",
        "- `hidden` is **not just the previous timestep‚Äôs output**, but the **last hidden state**, useful for tasks like classification or stateful sequences.\n",
        "- If you want outputs from *all* timesteps, use `output`.\n",
        "\n",
        "---\n",
        "\n",
        "#### üß¨ Analogy:\n",
        "Think of `output` as the **entire video of the RNN‚Äôs thinking** across time, while `hidden` is just **the final frame** summarizing everything it saw.\n",
        "\n",
        "Let me know if you'd like an example with code!"
      ],
      "metadata": {
        "id": "FAAU9nIFB7ZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.nn.utils.rnn import pad_sequence\n"
      ],
      "metadata": {
        "id": "UnA8-DEIEZmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_batch(batch):\n",
        "  label_list, text_list = [], []\n",
        "  for label, text in batch:\n",
        "    label_list.append(0 if label == 1 else 1)\n",
        "    processed_text = torch.tensor(vocab(tokenizer(text)))\n",
        "    text_list.append(processed_text)\n",
        "  label_list = torch.tensor(label_list)\n",
        "  text_list = pad_sequence(text_list, batch_first=True)\n",
        "  return label_list, text_list\n"
      ],
      "metadata": {
        "id": "n1kYtndzEkZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "train_loader = DataLoader(train_iter, batch_size=16, shuffle=True, collate_fn=collate_batch)\n",
        "test_loader = DataLoader(test_iter, batch_size=16, shuffle=False, collate_fn=collate_batch)"
      ],
      "metadata": {
        "id": "agciVOlwK87O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class sentimentModel(nn.Module):\n",
        "  def __init__(self,embeddings_length,classes,padding_idx):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(\n",
        "        num_embeddings=embeddings_length,\n",
        "        embedding_dim=64,\n",
        "        padding_idx=padding_idx\n",
        "    )\n",
        "    self.rnn = nn.RNN(input_size=64, hidden_size=32, num_layers=1, batch_first=True)\n",
        "    self.linear = nn.Linear(in_features=32, out_features=2) #in features = hidden_size or no of rnn units in rnn layer\n",
        "\n",
        "  def forward(self,text_data):\n",
        "    embeddings = self.embedding(text_data)\n",
        "    output, hidden = self.rnn(embeddings)\n",
        "    return self.linear(hidden[-1])"
      ],
      "metadata": {
        "id": "nIf-0B5Laqtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How RNN returns output"
      ],
      "metadata": {
        "id": "qlO27wqrM4bH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.randn(16, 1700, 64) # 16 movies having 1700 word or tokens with padding and  each word having 64 size embedding\n",
        "rnn_layer =   nn.RNN(input_size = 64, hidden_size =32, num_layers = 2, batch_first = True)\n",
        "states, output = rnn_layer(tensor)\n",
        "states.shape, output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qq0VQuOmaqq_",
        "outputId": "73d185b2-3965-4df1-ba39-67d50ff0871f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([16, 1700, 32]), torch.Size([2, 16, 32]))"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.randn(16, 1700, 64) # 16 movies having 1700 word or tokens with padding and  each word having 64 size embedding\n",
        "rnn_layer =   nn.RNN(input_size = 64, hidden_size =32, num_layers = 1, batch_first = True)\n",
        "states, output = rnn_layer(tensor)\n",
        "states.shape, output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9w9vPs2haqoy",
        "outputId": "c82f4a32-ce6a-4182-e8af-fe92916375f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([16, 1700, 32]), torch.Size([1, 16, 32]))"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aufYxjcJaqlU",
        "outputId": "32ceb36c-bb17-418c-fe94-b5c8aad3eaf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "model = sentimentModel(embeddings_length=len(vocab), classes=2, padding_idx=vocab[\"<pad>\"]).to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.01)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "epochs = 20"
      ],
      "metadata": {
        "id": "7UfYBSZQaqhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "for epoch in range(epochs+1):\n",
        "  loss_per_epoch = 0\n",
        "  for labels, features in train_loader:\n",
        "    features = features.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    y_pred = model.forward(features)\n",
        "\n",
        "    loss = loss_fn(y_pred, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    loss_per_epoch += loss\n",
        "  print(f\"Loss for Epoch-{epoch}: {loss_per_epoch}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrlJPG_oaqeZ",
        "outputId": "e009567b-d849-4c48-cf1a-6a2272be247c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 4, 32])\n",
            "Loss for Epoch-14: 0.17440305650234222\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 4, 32])\n",
            "Loss for Epoch-15: 0.1627320647239685\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 4, 32])\n",
            "Loss for Epoch-16: 0.14840947091579437\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 4, 32])\n",
            "Loss for Epoch-17: 0.14352628588676453\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 4, 32])\n",
            "Loss for Epoch-18: 0.13242243230342865\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 4, 32])\n",
            "Loss for Epoch-19: 0.12838824093341827\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 4, 32])\n",
            "Loss for Epoch-20: 0.11728232353925705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "total = 0\n",
        "correct = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "  for batch_labels, batch_features in train_loader:\n",
        "\n",
        "    # move data to gpu\n",
        "    batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
        "\n",
        "    outputs = model(batch_features)\n",
        "\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    total = total + batch_labels.shape[0]\n",
        "\n",
        "    correct = correct + (predicted == batch_labels).sum().item()\n",
        "\n",
        "print(correct/total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjQzDABHapq5",
        "outputId": "a898fb7d-357b-4e96-ad12-c607f097d4ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 4, 32])\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#9 evaluate on test data\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "  loss_per_epoch = 0\n",
        "  for labels, features in test_loader:\n",
        "    features = features.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "\n",
        "    # forward pass\n",
        "    y_pred = model.forward(features)\n",
        "\n",
        "    # loss computation\n",
        "    loss_func = nn.CrossEntropyLoss()\n",
        "    loss = loss_func(y_pred, labels)\n",
        "\n",
        "    loss_per_epoch += loss\n",
        "\n",
        "  print(\"loss per epoch =\", loss_per_epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16gKkc1D3tbU",
        "outputId": "fe16c9dc-4efb-4fbb-ebf6-deb3a88f84f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 8, 32])\n",
            "loss per epoch = tensor(7017.8711, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy on test data\n",
        "total = 0\n",
        "correct = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "  for batch_labels, batch_features in test_loader:\n",
        "\n",
        "    # move data to gpu\n",
        "    batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
        "\n",
        "    outputs = model(batch_features)\n",
        "\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    total = total + batch_labels.shape[0]\n",
        "\n",
        "    correct = correct + (predicted == batch_labels).sum().item()\n",
        "\n",
        "print(correct/total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0gK3Pg8NLTm",
        "outputId": "54e44269-864e-4f99-b9f7-b3ff01e73993"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 16, 32])\n",
            "Hidden.shape: torch.Size([1, 8, 32])\n",
            "0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fhxmz_hIV1Jp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Revision For OPPE"
      ],
      "metadata": {
        "id": "_k36tcf6HTr0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Intial Warming Up"
      ],
      "metadata": {
        "id": "JiuW_n_mHd1b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple Linear Layer with MSE and how gradients work"
      ],
      "metadata": {
        "id": "El9SVbLRHi6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "#Define a Simple Linear Layer fundamentally\n",
        "x = torch.tensor([[1., 2.], [3., 4.]], requires_grad=False)\n",
        "W = torch.tensor([[5., 6.], [7., 8.]], requires_grad=True) #if using required_grad, make sure to use floating\n",
        "y_true = torch.tensor([[4.0]]) #target\n",
        "print(x.shape,\"\\n\",W.t().shape)\n",
        "b = torch.tensor([[1]], requires_grad=False)\n",
        "z = x@W.t() + b\n",
        "y_pred = z\n",
        "\n",
        "loss = nn.MSELoss()(y_pred, y_true)\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print(\"Gradient wrt w\", W.grad)\n",
        "print(\"Gradient wrt b\", b.grad)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaIjhem9HYqf",
        "outputId": "4b8b15e9-4889-467a-8ba8-89ed0a48f08e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2]) \n",
            " torch.Size([2, 2])\n",
            "Gradient wrt w tensor([[ 61.,  86.],\n",
            "        [ 85., 120.]])\n",
            "Gradient wrt b None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another PyTorch snippet demonstratingthe essentials: tensor creation, moving to GPU, defining a simple neural network (feedforward), and leveraging autograd for gradient computation."
      ],
      "metadata": {
        "id": "EF2KhSd0Jki4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "x = torch.randn(64, 28*28, device=device)\n",
        "\n",
        "class SimpleNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(28*28, 100)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.fc2 = nn.Linear(100, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.fc1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "\n",
        "model = SimpleNN()\n",
        "y_true = torch.randint(0,10,(64,), device=device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "y_pred = model(x)\n",
        "loss = criterion(y_pred, y_true)\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print(model.fc1.weight.grad.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmhn4oyrHyYY",
        "outputId": "d110278b-ce05-4e95-af9f-03665a415de2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 784])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How do Tensors work?"
      ],
      "metadata": {
        "id": "ly9gUEKMc9Ya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "x = torch.tensor([[0, 2], [1, 1]], dtype=torch.float32, requires_grad=True)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAd16E8xLRdP",
        "outputId": "79904957-cc53-4cc9-9813-72b1be875fa4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.stride()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iy3GQAVyLWsP",
        "outputId": "f26c1198-ccbe-405b-91cd-1725c479bc2f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpCKnr0rddtF",
        "outputId": "d1329c38-1d61-42c0-bb3a-15e3ead8b45a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.requires_grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68fjkegTdgdN",
        "outputId": "5090d60c-2fb5-4853-af3e-d211c651c5db"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = x[0]\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyxiYFB3diFV",
        "outputId": "69af0831-8cd8-4044-ea40-9e0661d47c1f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 2.], grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.t(), x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqXsO6xqdlTF",
        "outputId": "78733df4-662b-48b7-af53-4c86660e79e1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 1.],\n",
              "         [2., 1.]], grad_fn=<TBackward0>),\n",
              " tensor([[0., 2.],\n",
              "         [1., 1.]], requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.matmul(x,x.t())\n",
        "z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIi2emxudrBu",
        "outputId": "de9df897-65b2-4181-b58d-b43c42a275e9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4., 2.],\n",
              "        [2., 2.]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scalar = torch.tensor(9)\n",
        "scalar, scalar.shape, scalar.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1ZF7OUcd0D9",
        "outputId": "a0e12064-7b42-49fe-d56f-b561d6c17ad7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(9), torch.Size([]), 0)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vec = torch.tensor([9])\n",
        "vec2 = torch.tensor([[9]])\n",
        "vec.shape, vec2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayB7TUlRd9nV",
        "outputId": "52288e8c-09ef-4366-911c-abd3c2a3197c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1]), torch.Size([1, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vec.ndim, vec2.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dJzHIVeeOle",
        "outputId": "2cf30e79-449d-49e8-bca8-cfccfda29ef7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vec2.squeeze().ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdTpFiBgejWC",
        "outputId": "e14b99bc-a451-4f8f-abea-b823a64f01bd"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vec2.squeeze().unsqueeze(dim=0).ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiQubrtfeS8V",
        "outputId": "2a42943c-dafa-4f2a-e6b1-8d6ae5c5cff1"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mat = torch.tensor([[0, 2], [1, 2]])\n",
        "mat.shape, mat.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3Pw8vqxeUK9",
        "outputId": "0139ed10-b901-4e3f-bd91-3e0db286f974"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2, 2]), 2)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mat.unsqueeze(dim=0).shape, mat.unsqueeze(dim=1).shape, mat.unsqueeze(dim=2).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRMDVegUe3rN",
        "outputId": "c9dec058-d9d5-4bea-9ef2-fa708be5f335"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 2, 2]), torch.Size([2, 1, 2]), torch.Size([2, 2, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "mat_gpu = mat.to(device)"
      ],
      "metadata": {
        "id": "ybojPW7Ye8jh"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([1, 2], dtype= torch.float32, requires_grad=True)\n",
        "y = (params ** 2).sum()\n",
        "y # check the backward method"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUI_A5kXfY3F",
        "outputId": "b88bd23d-1a6e-4e3a-cd7f-0c4a3140152f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5., grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = (params**2)\n",
        "b = a.sum()\n",
        "a, b # check the backward method"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nC4ZKUNFfmo1",
        "outputId": "0ea9ec15-e2a1-473b-ffca-97455714a87a"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 4.], grad_fn=<PowBackward0>), tensor(5., grad_fn=<SumBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.backward()"
      ],
      "metadata": {
        "id": "Rdivdktvf8VF"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7WohnekgBWl",
        "outputId": "a8d4096d-1c59-48c9-f9ce-463756f0b07f"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2., 4.])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b.backward()"
      ],
      "metadata": {
        "id": "vgwWfYmKgDxV"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVktilr8gHQ9",
        "outputId": "ea29ab9e-586f-4960-c56e-ce167075dd8c"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4., 8.])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([[0.1, 0.2, 0.3],\n",
        "                  [0.4, 0.5, 0.6],\n",
        "                  [0.7, 0.8, 0.9]])\n"
      ],
      "metadata": {
        "id": "CAQqgYPPgKTu"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsVEtZMjm3qW",
        "outputId": "12e92fd6-c059-46fd-b6c8-63107c13fa51"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rChn6beum4M9",
        "outputId": "2f1dea05-94e2-45a8-8f72-5376375bb535"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuPA42OUm6hF",
        "outputId": "65368a6a-3559-4261-bfde-048ad1d0ee19"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.stride()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sWzaPKIm7t9",
        "outputId": "768fb3e5-fe10-4d89-f6e0-59691654bf56"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6z_hutNnDl3",
        "outputId": "34310a00-5fff-4c52-a9e4-f99fde994c96"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1000, 0.2000, 0.3000],\n",
              "        [0.4000, 0.5000, 0.6000],\n",
              "        [0.7000, 0.8000, 0.9000]])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "row = x[1]"
      ],
      "metadata": {
        "id": "IJv81KYqm9nc"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "row"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxjFNI9QnBGd",
        "outputId": "0d4a51ff-8845-4279-c397-8611ced75cd6"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4000, 0.5000, 0.6000])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "row.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4W4MvcWKncK9",
        "outputId": "321abd6f-d7a7-4297-eaee-78fbe3e86be1"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPJ_diUqndI8",
        "outputId": "1b898427-a67a-46bf-d856-a54f73177830"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1000, 0.2000, 0.3000],\n",
              "        [0.4000, 0.5000, 0.6000],\n",
              "        [0.7000, 0.8000, 0.9000]])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzSLif_8neqv",
        "outputId": "132fe16e-c7bf-4378-c63a-c368aed9dee9"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.5000)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.sum(dim=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KlRk4vSnf0V",
        "outputId": "30d861ab-0a2d-432c-b985-1a05e4bced67"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.2000, 1.5000, 1.8000])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.sum(dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEahBueNniDU",
        "outputId": "86d639a1-3808-45bb-cc5c-1a6b1d44708d"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.6000, 1.5000, 2.4000])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([\n",
        "    [[1, 2], [3, 4], [5, 6]],\n",
        "    [[7, 8], [9, 10], [11, 12]]\n",
        "], dtype=torch.float32)"
      ],
      "metadata": {
        "id": "UY7rsflknkhE"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape\",x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VnKuMrGnvis",
        "outputId": "17c67184-eb5b-42a3-f9c0-01a504c69215"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape torch.Size([2, 3, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.stride()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZCWvyDSnyhe",
        "outputId": "8197e72f-dc4d-4ef1-a0b8-f368084141a8"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 2, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.rand(2,5,3,4,2,4)"
      ],
      "metadata": {
        "id": "vCEhshswnzv0"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.stride(), (5*3*4*2*4*1,3*4*2*4*1,4*2*4*1,2*4*1,4*1,1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yc-qOZhPoI6N",
        "outputId": "c1cc119e-b987-4406-ba60-b5605bfc715e"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((480, 96, 32, 8, 4, 1), (480, 96, 32, 8, 4, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3Sw0SW6pjwL",
        "outputId": "eed13cdb-b060-410a-fb00-998a963af990"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.sum(dim=0),x.sum(dim=0).shape #sum over batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqRN4DlboPRc",
        "outputId": "33c66396-c8bb-4710-c09f-98c5a508e4d3"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 8., 10.],\n",
              "         [12., 14.],\n",
              "         [16., 18.]]),\n",
              " torch.Size([3, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.sum(dim=1),x.sum(dim=1).shape #over rows"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyRcgPFApfsM",
        "outputId": "7288195d-0361-44d8-efc1-f8694696d8b8"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 9., 12.],\n",
              "         [27., 30.]]),\n",
              " torch.Size([2, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.sum(dim=2),x.sum(dim=2).shape #over column. Basically remove that dim in shape and you get resulting shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBmv39bupiFc",
        "outputId": "8f064d36-8881-4998-c2da-ca3e4c7e6b64"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 3.,  7., 11.],\n",
              "         [15., 19., 23.]]),\n",
              " torch.Size([2, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = x.clone()"
      ],
      "metadata": {
        "id": "Ei00FR_Ppo98"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x[0,0,0]),print(z[0,0,0])\n",
        "z[0,0,0] = 999\n",
        "print(x[0,0,0]),print(z[0,0,0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "662MlA-sp_hE",
        "outputId": "d77ba717-0cf8-4e89-9fad-101e7895faff"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.)\n",
            "tensor(1.)\n",
            "tensor(1.)\n",
            "tensor(999.)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's move on to Auto Grad"
      ],
      "metadata": {
        "id": "Zheqp5DPqSLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "x = torch.tensor([1.0, 2.0], requires_grad=False)\n",
        "W = torch.tensor([[0.5, 1.0], [1.5, 2.0]], requires_grad=True)\n",
        "b = torch.tensor([0.1, 0.2], requires_grad=True)"
      ],
      "metadata": {
        "id": "ABU7c_biqKg-"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnHTUiHsqZhl",
        "outputId": "39749742-feb6-4a23-a409-0d80d8a54272"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UGoPfj1qaM8",
        "outputId": "47efb2d9-1273-42bb-a4e7-cc8c234db0b9"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLbnw35iqbGV",
        "outputId": "47e036f3-bf6f-49fa-f14a-2f2ea8df2916"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.matmul(W,x)"
      ],
      "metadata": {
        "id": "DSk5l-NLqcks"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z = a + b"
      ],
      "metadata": {
        "id": "6_xWQyazqoQO"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.sigmoid(z)"
      ],
      "metadata": {
        "id": "cg8nI8mvqgj8"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a , z , y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uSnpNKeqjIT",
        "outputId": "f812ab07-b0f1-4884-9c54-7b8e859e817f"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([2.5000, 5.5000], grad_fn=<MvBackward0>),\n",
              " tensor([2.6000, 5.7000], grad_fn=<AddBackward0>),\n",
              " tensor([0.9309, 0.9967], grad_fn=<SigmoidBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = y.sum()"
      ],
      "metadata": {
        "id": "2x-980EMqjhc"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0btR8u8q1S0",
        "outputId": "46e1c48a-5629-40b7-ce15-7a9f2cd10a32"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.9275, grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()"
      ],
      "metadata": {
        "id": "zdmCDsd5q1rc"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b32TZ8FDq3Vk",
        "outputId": "3a93722a-cb12-491a-f6c0-b2d65430345f"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0644, 0.1287],\n",
              "        [0.0033, 0.0066]])"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORCPPnSTq5Mk",
        "outputId": "0cd0a691-f519-4f63-83c2-fa00e183380a"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0644, 0.0033])"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomLayer(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.weight = torch.nn.Parameter(torch.randn(3,3))\n",
        "\n",
        "  def forward(self, x):\n",
        "    return x@self.weight\n",
        "\n",
        "x = torch.randn(5,3, requires_grad=True)\n",
        "\n",
        "layer = CustomLayer()\n",
        "\n",
        "y = layer(x)\n",
        "\n",
        "loss = y.sum()\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "t6eS70Ijq6C8"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer.weight.grad.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHGvmstmwl3M",
        "outputId": "5134ded2-b5f7-42a3-f475-f8b38001de0d"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.grad.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Z5NFkeawvbE",
        "outputId": "4b7f1de1-5f87-4255-b009-f7e339145ec0"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What are compuational Graphs?\n",
        "<br>üß† PyTorch Code\n",
        "\n",
        "Below is a concise PyTorch snippet demonstrating a computational graph for a simple neural network layer, highlighting gradient computation."
      ],
      "metadata": {
        "id": "XmYe2FHsxXyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Leaf tensors\n",
        "x = torch.tensor([1.0, 2.0], requires_grad=False)  # Input\n",
        "W = torch.tensor([[0.5, 1.0], [1.5, 2.0]], requires_grad=True)  # Weights\n",
        "b = torch.tensor([0.1, 0.2], requires_grad=True)  # Bias\n",
        "x1 = torch.tensor([1.0, 2.0], requires_grad=False)  # Input\n",
        "W1 = torch.tensor([[0.5, 1.0], [1.5, 2.0]], requires_grad=True)  # Weights\n",
        "b1 = torch.tensor([0.1, 0.2], requires_grad=True)  # Bias\n",
        "\n",
        "# Operations forming computational graph\n",
        "z = torch.matmul(W, x) + b  # Non-leaf tensor\n",
        "z1 = torch.matmul(W1, x1) + b1\n",
        "y = torch.sigmoid(z)  # Non-leaf tensor\n",
        "y_1 = torch.sigmoid(z1)\n",
        "y_1.retain_grad()\n",
        "loss = y.sum()  # Scalar loss\n",
        "loss2 = y_1.sum()\n",
        "# Backward pass\n",
        "loss.backward()\n",
        "\n",
        "# Access gradients (leaf tensors only)\n",
        "print(\"Gradient w.r.t. W:\\n\", W.grad)\n",
        "print(\"Gradient w.r.t. b:\\n\", b.grad)\n",
        "print(\"y.grad (non-leaf, None):\\n\", y.grad) #If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad()\n",
        "\n",
        "loss2.backward()\n",
        "print(\"y_1.grad (non-leaf, None):\\n\", y_1.grad)\n",
        "print(\"------ \\n\"*4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKlLdp6pwxkM",
        "outputId": "87ae2ebd-ffd7-439e-82c3-31b496a83961"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient w.r.t. W:\n",
            " tensor([[0.0644, 0.1287],\n",
            "        [0.0033, 0.0066]])\n",
            "Gradient w.r.t. b:\n",
            " tensor([0.0644, 0.0033])\n",
            "y.grad (non-leaf, None):\n",
            " None\n",
            "y_1.grad (non-leaf, None):\n",
            " tensor([1., 1.])\n",
            "------ \n",
            "------ \n",
            "------ \n",
            "------ \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-161-f70f5f255302>:25: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /pytorch/build/aten/src/ATen/core/TensorBody.h:489.)\n",
            "  print(\"y.grad (non-leaf, None):\\n\", y.grad) #If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.linspace(0., 2.*torch.pi, steps=25, requires_grad=True)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-q5k3IsyC05",
        "outputId": "743a8881-e7d6-485b-bff9-2acd579a9081"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0000, 0.2618, 0.5236, 0.7854, 1.0472, 1.3090, 1.5708, 1.8326, 2.0944,\n",
              "        2.3562, 2.6180, 2.8798, 3.1416, 3.4034, 3.6652, 3.9270, 4.1888, 4.4506,\n",
              "        4.7124, 4.9742, 5.2360, 5.4978, 5.7596, 6.0214, 6.2832],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.sin(a) *2\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOJFvdYJzkRc",
        "outputId": "65a06a0e-d478-4d14-9c22-0ac3402985ce"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0000e+00,  5.1764e-01,  1.0000e+00,  1.4142e+00,  1.7321e+00,\n",
              "         1.9319e+00,  2.0000e+00,  1.9319e+00,  1.7321e+00,  1.4142e+00,\n",
              "         1.0000e+00,  5.1764e-01, -1.7485e-07, -5.1764e-01, -1.0000e+00,\n",
              "        -1.4142e+00, -1.7321e+00, -1.9319e+00, -2.0000e+00, -1.9319e+00,\n",
              "        -1.7321e+00, -1.4142e+00, -1.0000e+00, -5.1764e-01,  3.4969e-07],\n",
              "       grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = y.sum()\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AK2MRzppzqZ8",
        "outputId": "321fd79d-3464-40a4-f475-8959fd870986"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.9009e-07, grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()"
      ],
      "metadata": {
        "id": "-dznmp-Gztqz"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJGEuiBhzxZj",
        "outputId": "859fd0b8-306b-4e3e-e7bb-d2bdaf966d9c"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 2.0000e+00,  1.9319e+00,  1.7321e+00,  1.4142e+00,  1.0000e+00,\n",
              "         5.1764e-01, -8.7423e-08, -5.1764e-01, -1.0000e+00, -1.4142e+00,\n",
              "        -1.7321e+00, -1.9319e+00, -2.0000e+00, -1.9319e+00, -1.7321e+00,\n",
              "        -1.4142e+00, -1.0000e+00, -5.1764e-01,  2.3850e-08,  5.1764e-01,\n",
              "         1.0000e+00,  1.4142e+00,  1.7321e+00,  1.9319e+00,  2.0000e+00])"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How do we use Auto Grad in Model Training?"
      ],
      "metadata": {
        "id": "xHsbmxAjz3AI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TinyModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear1 = nn.Linear(100,200)\n",
        "    self.linear2 = nn.Linear(200,10)\n",
        "  def forward(self, x):\n",
        "    x = self.linear2(self.linear1(x))\n",
        "    return x\n",
        "\n"
      ],
      "metadata": {
        "id": "mfzF0KoRz9sH"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TinyModel()\n",
        "data  = torch.rand(32,100)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "labels = torch.rand(32,10)"
      ],
      "metadata": {
        "id": "nlx1LewozzSb"
      },
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(3):\n",
        "  optimizer.zero_grad()\n",
        "  output = model(data)\n",
        "  loss = loss_fn(output,labels)\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ],
      "metadata": {
        "id": "KKnjDvF8z75E"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "torch.no_grad():\n",
        "  #disables auto grad\n",
        "```"
      ],
      "metadata": {
        "id": "r05xoSMe2qkA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handling Non-Scalar Outputs**  \n",
        "- `.backward()` requires a scalar output. For non-scalar tensors, you must supply a gradient argument representing the vector-Jacobian product"
      ],
      "metadata": {
        "id": "V0U6XJXd1pfh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(3, requires_grad=True)\n",
        "y = x*2\n",
        "while y.data.norm() < 1000:\n",
        "  y = y*2\n",
        "v = torch.tensor([0.1, 1.0, 0.0001])\n",
        "y.backward(v)\n",
        "print(x.grad)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dzfb7FF0gb7",
        "outputId": "0eb33e22-274a-4afb-d6dc-b085876459a4"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.0480e+02, 2.0480e+03, 2.0480e-01])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Hooks for Debugging**:  \n",
        "  - Register hooks (e.g., `tensor.register_hook()`) to monitor/modify gradients during backward passes.  \n",
        "  - Critical for visualizing gradient flow in complex networks (e.g., diagnosing vanishing gradients)."
      ],
      "metadata": {
        "id": "8L9nb8E-73Og"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Leaf tensors\n",
        "x = torch.tensor([3.0], requires_grad=True)  # Input\n",
        "w = torch.tensor([0.5], requires_grad=True)  # Weight\n",
        "b = torch.tensor([1.0], requires_grad=True)  # Bias\n",
        "eta = 0.1  # Learning rate"
      ],
      "metadata": {
        "id": "sCZezVaz7lHD"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grads = []\n",
        "def hook(grad):\n",
        "  grads.append(grad.item())"
      ],
      "metadata": {
        "id": "D7lmkj1C7898"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z = w*x + b\n",
        "z.register_hook(hook)\n",
        "y = torch.sigmoid(z)\n",
        "loss = y.sum()"
      ],
      "metadata": {
        "id": "Y4Krc23t8CZr"
      },
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()"
      ],
      "metadata": {
        "id": "biuwftPy8Of7"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  w -= eta * w.grad\n",
        "  b -= eta * b.grad\n",
        "  w.grad.zero_()\n",
        "  b.grad.zero_()\n",
        "\n"
      ],
      "metadata": {
        "id": "WbTJivMr8P5j"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGAvIRa-8i2U",
        "outputId": "196a4467-9145-42dd-e449-c9ef0809fcb8"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.])"
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grads"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0M7r7dU8kDD",
        "outputId": "b836f8fd-8f6c-4004-e665-151c690b362a"
      },
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0701037123799324]"
            ]
          },
          "metadata": {},
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4>nn.Module<h4>"
      ],
      "metadata": {
        "id": "JKDJ07bc-8Kg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class LinearLayer(nn.Module):\n",
        "  def __init__(self, in_features, out_features):\n",
        "    super(LinearLayer, self).__init__()\n",
        "    self.W = nn.Parameter(torch.randn(out_features, in_features))\n",
        "    self.b = nn.Parameter(torch.randn(out_features))\n",
        "\n",
        "  def forward(self, x):\n",
        "    print(x.shape,self.W.t().shape,)\n",
        "    return torch.matmul(x, self.W.t()) + self.b\n",
        "\n",
        "    # mat_mul = torch.matmul(x.t(), W)\n",
        "    # print(mat_mul.shape)\n",
        "    # print(self.b.shape)\n",
        "    # return mat_mul + self.b\n",
        "\n",
        "class SimpleNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SimpleNet, self).__init__()\n",
        "    self.layer1 = LinearLayer(2, 10)\n",
        "    self.layer2 = LinearLayer(10, 1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    print(\"Flag1\")\n",
        "    x = self.layer1(x)\n",
        "    print(\"Flag2\")\n",
        "    x = self.sigmoid(x)\n",
        "    print(\"Flag3\")\n",
        "    x = self.layer2(x)\n",
        "    print(\"Flag4\")\n",
        "    return x\n",
        "\n",
        "model = SimpleNet()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "x = torch.randn(5, 2)\n",
        "y = torch.ones(5, 1)\n",
        "\n",
        "model.train()\n",
        "optimizer.zero_grad()\n",
        "output = model(x)\n",
        "loss = criterion(output, y)\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "\n",
        "print(\"Loss:\", loss.item())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbHnKo5T8k7r",
        "outputId": "ece2f945-ae4c-4609-98d8-47e65ea623d4"
      },
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flag1\n",
            "torch.Size([5, 2]) torch.Size([2, 10])\n",
            "Flag2\n",
            "Flag3\n",
            "torch.Size([5, 10]) torch.Size([10, 1])\n",
            "Flag4\n",
            "Loss: 4.161233425140381\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Guess you can do it like this also\n",
        "class CustomLinear(nn.Module):\n",
        "  def __init__(self, in_features, out_features):\n",
        "    super().__init__()\n",
        "    self.weight = nn.Parameter(torch.randn(in_features, out_features))\n",
        "    self.bias = nn.Parameter(torch.randn(out_features))\n",
        "\n",
        "  def forward(self, x):\n",
        "    return torch.matmul(x, self.weight) + self.bias"
      ],
      "metadata": {
        "id": "YNaSfiPyOhKb"
      },
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "class SimpleNN(nn.Module):\n",
        "  def __init__(self, input_dim=784, hidden_dim=128, output_dim=10):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Linear(input_dim, hidden_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim, output_dim)\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    return self.layers(x)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HxR-VVKnUGHh"
      },
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del(model)\n",
        "model = SimpleNN()\n",
        "x = torch.randn(32, 784)\n",
        "y_pred = model(x)\n",
        "print(y_pred.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPVKAZ1xV7DK",
        "outputId": "caad44d3-1aec-4bbc-9538-41aecbb54e4d"
      },
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "Nzyo3_hqWEaK"
      },
      "execution_count": 241,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MNISTNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MNISTNet, self).__init__()\n",
        "    self.linear = nn.Linear(784, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # print()\n",
        "    # print(x.shape)\n",
        "    x = x.view(-1, 784)\n",
        "    # print(x.shape)\n",
        "    x = self.linear(x)\n",
        "    return x\n",
        "\n",
        "train_dataset = datasets.MNIST(root=\"./data\", train=True, transform=transforms.ToTensor(), download=True)\n",
        "#Ideally you also use dataloader here\n",
        "train_loader = DataLoader(train_dataset, batch_size = 8, shuffle=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "RGSP9GbugUOx"
      },
      "execution_count": 264,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = next(iter(train_loader))"
      ],
      "metadata": {
        "id": "GzE1DJCThEUL"
      },
      "execution_count": 255,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del(model)\n",
        "model = MNISTNet()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "output = model(x)\n",
        "loss = criterion(output,y)\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "\n",
        "print(f\"Loss:{loss.item()} \\n model weights grad shape:{model.linear.weight.grad.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3dyl4v4hIlB",
        "outputId": "740985f7-6d4a-44df-f8dd-888f2b6597f8"
      },
      "execution_count": 275,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:2.366114616394043 \n",
            " model weights grad shape:torch.Size([10, 784])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building a custom Linear layer `torch.nn.Parameter`"
      ],
      "metadata": {
        "id": "480QF2NWmxEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomLinear(nn.Module):\n",
        "  def __init__(self, in_features, out_features):\n",
        "    super().__init__()\n",
        "    self.weight = nn.Parameter(torch.randn(out_features, in_features))\n",
        "    self.bias = nn.Parameter(torch.randn(out_features))\n",
        "\n",
        "  def forward(self, x):\n",
        "    return torch.matmul(x,self.weight.t()) + self.bias"
      ],
      "metadata": {
        "id": "JglFLN5Dmw19"
      },
      "execution_count": 276,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomLinear(784,10)\n",
        "model(torch.randn(32,784)).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dX66Dn8hOAx",
        "outputId": "8d204eb7-e6b8-4c23-92ab-f6b047a7ff97"
      },
      "execution_count": 277,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 277
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How do we monitor gradients? Say when we need to investigate exploding/vanishing Gradients?"
      ],
      "metadata": {
        "id": "htROMh2AntAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_hook(grad):\n",
        "  print(f\"Gradient shape:{grad.shape}\")#ideally store it\n",
        "\n",
        "x, y = next(iter(train_loader))\n",
        "model.weight.register_hook(gradient_hook)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mbhv-JAZnpUh",
        "outputId": "d69a656e-3d14-49b6-f053-82df8a7d2fd1"
      },
      "execution_count": 286,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.hooks.RemovableHandle at 0x7c4aa5140050>"
            ]
          },
          "metadata": {},
          "execution_count": 286
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Full ahh code example"
      ],
      "metadata": {
        "id": "QAAhDNcPrvZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class CustomNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Linear(784, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128, 10)\n",
        "      )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.flatten(x)\n",
        "    return self.layers(x)\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "train_data = datasets.MNIST(root=\"data\", train=True, download=True, transform=transform)\n",
        "test_data = datasets.MNIST(root=\"data\", train=False, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=64)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "aKj_pGtdoFhh"
      },
      "execution_count": 299,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomNN().to(device)"
      ],
      "metadata": {
        "id": "o0Tl9H1IsBXp"
      },
      "execution_count": 300,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n"
      ],
      "metadata": {
        "id": "7GfihNurwYaA"
      },
      "execution_count": 301,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm, trange\n",
        "def train(epochs):\n",
        "  model.train()\n",
        "  for epoch in trange(epochs):\n",
        "    for batch, (x, y) in tqdm(enumerate(train_loader)):\n",
        "      x, y = x.to(device), y.to(device)\n",
        "\n",
        "      outputs = model(x)\n",
        "      loss = criterion(outputs, y)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      if batch % 100 == 0:\n",
        "        print(\"--------- \\n\"*3)\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Batch {batch}, Loss: {loss.item():.4f}\")\n",
        "        print(\"--------- \\n\"*3)\n"
      ],
      "metadata": {
        "id": "lexI9WE9wkTQ"
      },
      "execution_count": 326,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evalute():\n",
        "  model.eval()\n",
        "  correct = 0\n",
        "  batch_accuracy_list = []\n",
        "  running_Correct = 0\n",
        "  with torch.no_grad():\n",
        "    for x, y in tqdm(test_loader):\n",
        "      batch_accuracy = 0\n",
        "      x , y = x.to(device), y.to(device)\n",
        "      outputs = model(x)\n",
        "      _,predicted = torch.max(outputs.data, 1)\n",
        "      correct += (predicted == y).sum()\n",
        "      batch_accuracy = (predicted == y).sum()/len(y) #length of batch\n",
        "      batch_accuracy_list.append(batch_accuracy)\n",
        "  accuracy_per_batch = correct/len(test_loader) #correct per batch\n",
        "  accuracy = correct/len(test_data) #this not batches but indivial samples. test_loader is batches\n",
        "  return batch_accuracy_list,accuracy_per_batch, accuracy"
      ],
      "metadata": {
        "id": "t8gH0CKJy6i_"
      },
      "execution_count": 327,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x,y =  next(iter(test_loader))\n",
        "outputs = model(x)\n",
        "values, indices = torch.max(outputs.data, 1)\n",
        "print(indices.shape, y.shape)\n",
        "(indices == y).sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brfqRhpozmj3",
        "outputId": "57981a9c-da2d-4c16-8345-2b393e60b0c6"
      },
      "execution_count": 312,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64]) torch.Size([64])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(10)"
            ]
          },
          "metadata": {},
          "execution_count": 312
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_loader), len(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8yqguUaz1HI",
        "outputId": "62ecbf12-3f77-44d9-a850-691e1ead99ab"
      },
      "execution_count": 315,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(157, 64)"
            ]
          },
          "metadata": {},
          "execution_count": 315
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train(epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f512ilg0mIQ",
        "outputId": "71597526-ebe8-48e1-e763-d18d6c22bddb"
      },
      "execution_count": 317,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [00:00<?, ?it/s]\n",
            "0it [00:00, ?it/s]\u001b[A\n",
            "3it [00:00, 28.96it/s]\u001b[A\n",
            "8it [00:00, 40.93it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 1/5, Batch 0, Loss: 2.3210\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "13it [00:00, 43.35it/s]\u001b[A\n",
            "19it [00:00, 46.61it/s]\u001b[A\n",
            "24it [00:00, 47.66it/s]\u001b[A\n",
            "29it [00:00, 38.26it/s]\u001b[A\n",
            "34it [00:00, 38.67it/s]\u001b[A\n",
            "39it [00:00, 39.01it/s]\u001b[A\n",
            "44it [00:01, 41.55it/s]\u001b[A\n",
            "49it [00:01, 41.63it/s]\u001b[A\n",
            "55it [00:01, 44.05it/s]\u001b[A\n",
            "60it [00:01, 44.86it/s]\u001b[A\n",
            "66it [00:01, 46.73it/s]\u001b[A\n",
            "72it [00:01, 48.65it/s]\u001b[A\n",
            "78it [00:01, 49.83it/s]\u001b[A\n",
            "84it [00:01, 50.31it/s]\u001b[A\n",
            "90it [00:02, 49.50it/s]\u001b[A\n",
            "95it [00:02, 49.09it/s]\u001b[A\n",
            "100it [00:02, 45.78it/s]\u001b[A\n",
            "105it [00:02, 46.47it/s]\u001b[A\n",
            "111it [00:02, 48.48it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 1/5, Batch 100, Loss: 0.2623\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "116it [00:02, 48.45it/s]\u001b[A\n",
            "123it [00:02, 52.53it/s]\u001b[A\n",
            "130it [00:02, 56.25it/s]\u001b[A\n",
            "137it [00:02, 58.47it/s]\u001b[A\n",
            "144it [00:02, 60.94it/s]\u001b[A\n",
            "151it [00:03, 61.26it/s]\u001b[A\n",
            "158it [00:03, 59.38it/s]\u001b[A\n",
            "164it [00:03, 57.94it/s]\u001b[A\n",
            "170it [00:03, 50.50it/s]\u001b[A\n",
            "176it [00:03, 51.21it/s]\u001b[A\n",
            "182it [00:03, 47.87it/s]\u001b[A\n",
            "187it [00:04, 36.06it/s]\u001b[A\n",
            "192it [00:04, 35.10it/s]\u001b[A\n",
            "196it [00:04, 32.47it/s]\u001b[A\n",
            "202it [00:04, 37.59it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 1/5, Batch 200, Loss: 0.3540\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "207it [00:04, 33.06it/s]\u001b[A\n",
            "211it [00:04, 30.01it/s]\u001b[A\n",
            "217it [00:04, 35.49it/s]\u001b[A\n",
            "221it [00:05, 35.03it/s]\u001b[A\n",
            "225it [00:05, 32.48it/s]\u001b[A\n",
            "229it [00:05, 28.08it/s]\u001b[A\n",
            "233it [00:05, 28.38it/s]\u001b[A\n",
            "236it [00:05, 28.07it/s]\u001b[A\n",
            "239it [00:05, 26.73it/s]\u001b[A\n",
            "243it [00:05, 28.79it/s]\u001b[A\n",
            "246it [00:05, 28.49it/s]\u001b[A\n",
            "250it [00:06, 30.53it/s]\u001b[A\n",
            "254it [00:06, 31.45it/s]\u001b[A\n",
            "258it [00:06, 29.78it/s]\u001b[A\n",
            "262it [00:06, 32.03it/s]\u001b[A\n",
            "266it [00:06, 31.14it/s]\u001b[A\n",
            "270it [00:06, 31.24it/s]\u001b[A\n",
            "275it [00:06, 35.40it/s]\u001b[A\n",
            "280it [00:06, 38.86it/s]\u001b[A\n",
            "285it [00:07, 39.07it/s]\u001b[A\n",
            "290it [00:07, 40.50it/s]\u001b[A\n",
            "295it [00:07, 42.86it/s]\u001b[A\n",
            "300it [00:07, 43.40it/s]\u001b[A\n",
            "305it [00:07, 44.47it/s]\u001b[A\n",
            "310it [00:07, 44.04it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 1/5, Batch 300, Loss: 0.1756\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "315it [00:07, 45.66it/s]\u001b[A\n",
            "321it [00:07, 47.30it/s]\u001b[A\n",
            "326it [00:07, 47.98it/s]\u001b[A\n",
            "331it [00:08, 48.09it/s]\u001b[A\n",
            "336it [00:08, 47.22it/s]\u001b[A\n",
            "341it [00:08, 46.91it/s]\u001b[A\n",
            "346it [00:08, 47.72it/s]\u001b[A\n",
            "351it [00:08, 47.83it/s]\u001b[A\n",
            "357it [00:08, 49.65it/s]\u001b[A\n",
            "362it [00:08, 48.99it/s]\u001b[A\n",
            "368it [00:08, 51.31it/s]\u001b[A\n",
            "375it [00:08, 54.58it/s]\u001b[A\n",
            "382it [00:08, 57.07it/s]\u001b[A\n",
            "388it [00:09, 57.62it/s]\u001b[A\n",
            "394it [00:09, 57.85it/s]\u001b[A\n",
            "400it [00:09, 58.31it/s]\u001b[A\n",
            "406it [00:09, 57.83it/s]\u001b[A\n",
            "413it [00:09, 58.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 1/5, Batch 400, Loss: 0.2552\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "419it [00:09, 59.08it/s]\u001b[A\n",
            "425it [00:09, 54.59it/s]\u001b[A\n",
            "431it [00:09, 54.58it/s]\u001b[A\n",
            "437it [00:09, 53.93it/s]\u001b[A\n",
            "443it [00:10, 52.69it/s]\u001b[A\n",
            "449it [00:10, 52.72it/s]\u001b[A\n",
            "455it [00:10, 52.91it/s]\u001b[A\n",
            "461it [00:10, 53.32it/s]\u001b[A\n",
            "467it [00:10, 52.92it/s]\u001b[A\n",
            "473it [00:10, 52.58it/s]\u001b[A\n",
            "479it [00:10, 51.02it/s]\u001b[A\n",
            "485it [00:10, 50.62it/s]\u001b[A\n",
            "491it [00:11, 50.64it/s]\u001b[A\n",
            "497it [00:11, 49.71it/s]\u001b[A\n",
            "502it [00:11, 49.02it/s]\u001b[A\n",
            "507it [00:11, 49.08it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 1/5, Batch 500, Loss: 0.3958\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "513it [00:11, 49.13it/s]\u001b[A\n",
            "519it [00:11, 49.82it/s]\u001b[A\n",
            "525it [00:11, 51.07it/s]\u001b[A\n",
            "531it [00:11, 47.49it/s]\u001b[A\n",
            "537it [00:11, 48.88it/s]\u001b[A\n",
            "543it [00:12, 49.91it/s]\u001b[A\n",
            "549it [00:12, 48.82it/s]\u001b[A\n",
            "555it [00:12, 50.26it/s]\u001b[A\n",
            "561it [00:12, 50.75it/s]\u001b[A\n",
            "567it [00:12, 50.82it/s]\u001b[A\n",
            "573it [00:12, 51.09it/s]\u001b[A\n",
            "579it [00:12, 50.36it/s]\u001b[A\n",
            "585it [00:13, 34.28it/s]\u001b[A\n",
            "590it [00:13, 31.94it/s]\u001b[A\n",
            "594it [00:13, 29.61it/s]\u001b[A\n",
            "598it [00:13, 26.75it/s]\u001b[A\n",
            "601it [00:13, 25.06it/s]\u001b[A\n",
            "604it [00:13, 22.50it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 1/5, Batch 600, Loss: 0.2793\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "607it [00:14, 22.22it/s]\u001b[A\n",
            "610it [00:14, 20.70it/s]\u001b[A\n",
            "613it [00:14, 22.33it/s]\u001b[A\n",
            "617it [00:14, 23.75it/s]\u001b[A\n",
            "622it [00:14, 28.47it/s]\u001b[A\n",
            "628it [00:14, 35.37it/s]\u001b[A\n",
            "634it [00:14, 41.16it/s]\u001b[A\n",
            "639it [00:14, 41.67it/s]\u001b[A\n",
            "645it [00:15, 46.19it/s]\u001b[A\n",
            "651it [00:15, 48.78it/s]\u001b[A\n",
            "658it [00:15, 53.41it/s]\u001b[A\n",
            "664it [00:15, 54.30it/s]\u001b[A\n",
            "670it [00:15, 55.76it/s]\u001b[A\n",
            "677it [00:15, 57.28it/s]\u001b[A\n",
            "683it [00:15, 57.86it/s]\u001b[A\n",
            "689it [00:15, 57.50it/s]\u001b[A\n",
            "695it [00:15, 57.08it/s]\u001b[A\n",
            "703it [00:16, 62.13it/s]\u001b[A\n",
            "713it [00:16, 71.60it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 1/5, Batch 700, Loss: 0.2972\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "721it [00:16, 64.29it/s]\u001b[A\n",
            "728it [00:16, 61.39it/s]\u001b[A\n",
            "735it [00:16, 57.72it/s]\u001b[A\n",
            "741it [00:16, 55.10it/s]\u001b[A\n",
            "747it [00:16, 53.98it/s]\u001b[A\n",
            "753it [00:17, 43.16it/s]\u001b[A\n",
            "758it [00:17, 34.78it/s]\u001b[A\n",
            "762it [00:17, 32.95it/s]\u001b[A\n",
            "766it [00:17, 30.36it/s]\u001b[A\n",
            "770it [00:17, 27.69it/s]\u001b[A\n",
            "773it [00:17, 27.88it/s]\u001b[A\n",
            "778it [00:17, 31.33it/s]\u001b[A\n",
            "782it [00:18, 30.72it/s]\u001b[A\n",
            "786it [00:18, 27.17it/s]\u001b[A\n",
            "789it [00:18, 26.81it/s]\u001b[A\n",
            "792it [00:18, 24.62it/s]\u001b[A\n",
            "795it [00:18, 24.94it/s]\u001b[A\n",
            "798it [00:18, 24.74it/s]\u001b[A\n",
            "802it [00:18, 27.30it/s]\u001b[A\n",
            "806it [00:19, 30.35it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 1/5, Batch 800, Loss: 0.0819\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "810it [00:19, 30.15it/s]\u001b[A\n",
            "814it [00:19, 32.12it/s]\u001b[A\n",
            "819it [00:19, 35.39it/s]\u001b[A\n",
            "823it [00:19, 35.50it/s]\u001b[A\n",
            "827it [00:19, 35.36it/s]\u001b[A\n",
            "831it [00:19, 30.91it/s]\u001b[A\n",
            "835it [00:19, 30.13it/s]\u001b[A\n",
            "841it [00:20, 34.60it/s]\u001b[A\n",
            "845it [00:20, 31.09it/s]\u001b[A\n",
            "849it [00:20, 29.07it/s]\u001b[A\n",
            "852it [00:20, 28.58it/s]\u001b[A\n",
            "857it [00:20, 33.65it/s]\u001b[A\n",
            "864it [00:20, 41.52it/s]\u001b[A\n",
            "870it [00:20, 46.30it/s]\u001b[A\n",
            "875it [00:20, 44.57it/s]\u001b[A\n",
            "881it [00:21, 47.91it/s]\u001b[A\n",
            "887it [00:21, 51.18it/s]\u001b[A\n",
            "893it [00:21, 50.84it/s]\u001b[A\n",
            "900it [00:21, 53.99it/s]\u001b[A\n",
            "906it [00:21, 50.29it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 1/5, Batch 900, Loss: 0.1305\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "912it [00:21, 51.37it/s]\u001b[A\n",
            "919it [00:21, 54.08it/s]\u001b[A\n",
            "925it [00:21, 54.45it/s]\u001b[A\n",
            "938it [00:21, 42.65it/s]\n",
            " 20%|‚ñà‚ñà        | 1/5 [00:22<01:28, 22.01s/it]\n",
            "0it [00:00, ?it/s]\u001b[A\n",
            "10it [00:00, 91.49it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 2/5, Batch 0, Loss: 0.1448\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "20it [00:00, 86.55it/s]\u001b[A\n",
            "30it [00:00, 91.34it/s]\u001b[A\n",
            "40it [00:00, 89.02it/s]\u001b[A\n",
            "49it [00:00, 85.94it/s]\u001b[A\n",
            "59it [00:00, 89.85it/s]\u001b[A\n",
            "69it [00:00, 92.72it/s]\u001b[A\n",
            "79it [00:00, 93.90it/s]\u001b[A\n",
            "89it [00:00, 94.03it/s]\u001b[A\n",
            "99it [00:01, 93.59it/s]\u001b[A\n",
            "109it [00:01, 91.14it/s]\u001b[A\n",
            "119it [00:01, 91.85it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 2/5, Batch 100, Loss: 0.0809\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "129it [00:01, 90.64it/s]\u001b[A\n",
            "139it [00:01, 87.43it/s]\u001b[A\n",
            "149it [00:01, 89.81it/s]\u001b[A\n",
            "159it [00:01, 92.49it/s]\u001b[A\n",
            "169it [00:01, 94.13it/s]\u001b[A\n",
            "179it [00:01, 94.80it/s]\u001b[A\n",
            "189it [00:02, 95.50it/s]\u001b[A\n",
            "199it [00:02, 93.36it/s]\u001b[A\n",
            "209it [00:02, 92.44it/s]\u001b[A\n",
            "219it [00:02, 92.00it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 2/5, Batch 200, Loss: 0.1937\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "229it [00:02, 91.92it/s]\u001b[A\n",
            "239it [00:02, 88.74it/s]\u001b[A\n",
            "249it [00:02, 91.10it/s]\u001b[A\n",
            "259it [00:02, 92.79it/s]\u001b[A\n",
            "269it [00:02, 92.97it/s]\u001b[A\n",
            "279it [00:03, 94.19it/s]\u001b[A\n",
            "289it [00:03, 91.47it/s]\u001b[A\n",
            "299it [00:03, 91.58it/s]\u001b[A\n",
            "309it [00:03, 91.77it/s]\u001b[A\n",
            "319it [00:03, 91.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 2/5, Batch 300, Loss: 0.1587\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "329it [00:03, 90.41it/s]\u001b[A\n",
            "339it [00:03, 89.82it/s]\u001b[A\n",
            "349it [00:03, 92.03it/s]\u001b[A\n",
            "359it [00:03, 93.14it/s]\u001b[A\n",
            "369it [00:04, 92.96it/s]\u001b[A\n",
            "379it [00:04, 91.34it/s]\u001b[A\n",
            "389it [00:04, 91.59it/s]\u001b[A\n",
            "399it [00:04, 92.35it/s]\u001b[A\n",
            "409it [00:04, 93.89it/s]\u001b[A\n",
            "419it [00:04, 94.97it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 2/5, Batch 400, Loss: 0.1903\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "429it [00:04, 90.14it/s]\u001b[A\n",
            "440it [00:04, 93.46it/s]\u001b[A\n",
            "451it [00:04, 96.06it/s]\u001b[A\n",
            "461it [00:04, 97.11it/s]\u001b[A\n",
            "471it [00:05, 95.49it/s]\u001b[A\n",
            "481it [00:05, 95.37it/s]\u001b[A\n",
            "491it [00:05, 95.10it/s]\u001b[A\n",
            "501it [00:05, 94.60it/s]\u001b[A\n",
            "511it [00:05, 94.37it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 2/5, Batch 500, Loss: 0.2966\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "521it [00:05, 94.12it/s]\u001b[A\n",
            "531it [00:05, 86.13it/s]\u001b[A\n",
            "541it [00:05, 89.03it/s]\u001b[A\n",
            "551it [00:05, 90.54it/s]\u001b[A\n",
            "561it [00:06, 91.79it/s]\u001b[A\n",
            "571it [00:06, 91.87it/s]\u001b[A\n",
            "581it [00:06, 90.99it/s]\u001b[A\n",
            "591it [00:06, 92.07it/s]\u001b[A\n",
            "601it [00:06, 92.49it/s]\u001b[A\n",
            "611it [00:06, 93.40it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 2/5, Batch 600, Loss: 0.0777\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "621it [00:06, 90.48it/s]\u001b[A\n",
            "632it [00:06, 93.92it/s]\u001b[A\n",
            "642it [00:06, 94.88it/s]\u001b[A\n",
            "652it [00:07, 94.91it/s]\u001b[A\n",
            "662it [00:07, 95.23it/s]\u001b[A\n",
            "672it [00:07, 93.50it/s]\u001b[A\n",
            "682it [00:07, 94.08it/s]\u001b[A\n",
            "692it [00:07, 94.06it/s]\u001b[A\n",
            "702it [00:07, 93.07it/s]\u001b[A\n",
            "712it [00:07, 94.49it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 2/5, Batch 700, Loss: 0.1227\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "722it [00:07, 91.13it/s]\u001b[A\n",
            "733it [00:07, 93.99it/s]\u001b[A\n",
            "743it [00:08, 95.23it/s]\u001b[A\n",
            "753it [00:08, 94.01it/s]\u001b[A\n",
            "763it [00:08, 93.46it/s]\u001b[A\n",
            "773it [00:08, 94.50it/s]\u001b[A\n",
            "783it [00:08, 90.73it/s]\u001b[A\n",
            "793it [00:08, 79.00it/s]\u001b[A\n",
            "802it [00:08, 73.89it/s]\u001b[A\n",
            "810it [00:08, 71.11it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 2/5, Batch 800, Loss: 0.0950\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "818it [00:09, 70.73it/s]\u001b[A\n",
            "826it [00:09, 69.97it/s]\u001b[A\n",
            "834it [00:09, 67.81it/s]\u001b[A\n",
            "842it [00:09, 68.94it/s]\u001b[A\n",
            "849it [00:09, 68.31it/s]\u001b[A\n",
            "856it [00:09, 68.44it/s]\u001b[A\n",
            "864it [00:09, 71.34it/s]\u001b[A\n",
            "872it [00:09, 73.31it/s]\u001b[A\n",
            "880it [00:09, 71.86it/s]\u001b[A\n",
            "888it [00:10, 72.51it/s]\u001b[A\n",
            "896it [00:10, 72.89it/s]\u001b[A\n",
            "904it [00:10, 68.31it/s]\u001b[A\n",
            "911it [00:10, 65.62it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 2/5, Batch 900, Loss: 0.0662\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "918it [00:10, 64.74it/s]\u001b[A\n",
            "925it [00:10, 62.33it/s]\u001b[A\n",
            "938it [00:10, 86.61it/s]\n",
            " 40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:32<00:46, 15.44s/it]\n",
            "0it [00:00, ?it/s]\u001b[A\n",
            "6it [00:00, 49.66it/s]\u001b[A\n",
            "12it [00:00, 53.37it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 3/5, Batch 0, Loss: 0.0707\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "22it [00:00, 71.16it/s]\u001b[A\n",
            "31it [00:00, 77.91it/s]\u001b[A\n",
            "41it [00:00, 83.52it/s]\u001b[A\n",
            "51it [00:00, 86.39it/s]\u001b[A\n",
            "61it [00:00, 90.08it/s]\u001b[A\n",
            "71it [00:00, 91.94it/s]\u001b[A\n",
            "81it [00:00, 94.26it/s]\u001b[A\n",
            "91it [00:01, 95.06it/s]\u001b[A\n",
            "101it [00:01, 94.48it/s]\u001b[A\n",
            "111it [00:01, 90.76it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 3/5, Batch 100, Loss: 0.0634\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "121it [00:01, 90.04it/s]\u001b[A\n",
            "131it [00:01, 90.98it/s]\u001b[A\n",
            "141it [00:01, 92.42it/s]\u001b[A\n",
            "151it [00:01, 93.99it/s]\u001b[A\n",
            "161it [00:01, 95.38it/s]\u001b[A\n",
            "171it [00:01, 95.38it/s]\u001b[A\n",
            "181it [00:02, 95.67it/s]\u001b[A\n",
            "191it [00:02, 96.41it/s]\u001b[A\n",
            "201it [00:02, 91.21it/s]\u001b[A\n",
            "211it [00:02, 92.98it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 3/5, Batch 200, Loss: 0.1540\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "221it [00:02, 90.56it/s]\u001b[A\n",
            "231it [00:02, 92.18it/s]\u001b[A\n",
            "241it [00:02, 92.75it/s]\u001b[A\n",
            "251it [00:02, 94.48it/s]\u001b[A\n",
            "262it [00:02, 96.44it/s]\u001b[A\n",
            "272it [00:02, 96.58it/s]\u001b[A\n",
            "282it [00:03, 96.43it/s]\u001b[A\n",
            "292it [00:03, 97.08it/s]\u001b[A\n",
            "302it [00:03, 91.68it/s]\u001b[A\n",
            "312it [00:03, 91.84it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 3/5, Batch 300, Loss: 0.0960\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "322it [00:03, 91.89it/s]\u001b[A\n",
            "332it [00:03, 92.53it/s]\u001b[A\n",
            "342it [00:03, 93.35it/s]\u001b[A\n",
            "352it [00:03, 94.05it/s]\u001b[A\n",
            "362it [00:03, 95.31it/s]\u001b[A\n",
            "372it [00:04, 96.01it/s]\u001b[A\n",
            "382it [00:04, 96.47it/s]\u001b[A\n",
            "392it [00:04, 97.06it/s]\u001b[A\n",
            "402it [00:04, 90.25it/s]\u001b[A\n",
            "412it [00:04, 91.61it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 3/5, Batch 400, Loss: 0.0809\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "422it [00:04, 90.40it/s]\u001b[A\n",
            "432it [00:04, 91.68it/s]\u001b[A\n",
            "442it [00:04, 93.67it/s]\u001b[A\n",
            "452it [00:04, 95.24it/s]\u001b[A\n",
            "462it [00:05, 95.55it/s]\u001b[A\n",
            "472it [00:05, 95.05it/s]\u001b[A\n",
            "482it [00:05, 94.46it/s]\u001b[A\n",
            "492it [00:05, 89.07it/s]\u001b[A\n",
            "502it [00:05, 90.37it/s]\u001b[A\n",
            "512it [00:05, 91.40it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 3/5, Batch 500, Loss: 0.1145\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "522it [00:05, 91.22it/s]\u001b[A\n",
            "532it [00:05, 93.48it/s]\u001b[A\n",
            "542it [00:05, 95.05it/s]\u001b[A\n",
            "552it [00:05, 96.23it/s]\u001b[A\n",
            "562it [00:06, 96.88it/s]\u001b[A\n",
            "572it [00:06, 97.39it/s]\u001b[A\n",
            "582it [00:06, 95.74it/s]\u001b[A\n",
            "592it [00:06, 91.99it/s]\u001b[A\n",
            "602it [00:06, 90.79it/s]\u001b[A\n",
            "612it [00:06, 91.77it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 3/5, Batch 600, Loss: 0.0514\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "622it [00:06, 92.89it/s]\u001b[A\n",
            "632it [00:06, 94.18it/s]\u001b[A\n",
            "642it [00:06, 94.90it/s]\u001b[A\n",
            "652it [00:07, 94.24it/s]\u001b[A\n",
            "662it [00:07, 95.20it/s]\u001b[A\n",
            "672it [00:07, 93.75it/s]\u001b[A\n",
            "682it [00:07, 93.01it/s]\u001b[A\n",
            "692it [00:07, 88.56it/s]\u001b[A\n",
            "702it [00:07, 89.37it/s]\u001b[A\n",
            "712it [00:07, 90.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 3/5, Batch 700, Loss: 0.0352\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "722it [00:07, 91.50it/s]\u001b[A\n",
            "732it [00:07, 93.01it/s]\u001b[A\n",
            "742it [00:08, 94.31it/s]\u001b[A\n",
            "752it [00:08, 94.91it/s]\u001b[A\n",
            "762it [00:08, 92.30it/s]\u001b[A\n",
            "772it [00:08, 93.46it/s]\u001b[A\n",
            "782it [00:08, 89.74it/s]\u001b[A\n",
            "792it [00:08, 90.91it/s]\u001b[A\n",
            "802it [00:08, 90.49it/s]\u001b[A\n",
            "812it [00:08, 91.46it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 3/5, Batch 800, Loss: 0.1853\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "822it [00:08, 92.34it/s]\u001b[A\n",
            "832it [00:09, 93.94it/s]\u001b[A\n",
            "842it [00:09, 94.20it/s]\u001b[A\n",
            "852it [00:09, 92.65it/s]\u001b[A\n",
            "862it [00:09, 93.26it/s]\u001b[A\n",
            "872it [00:09, 92.88it/s]\u001b[A\n",
            "882it [00:09, 88.57it/s]\u001b[A\n",
            "892it [00:09, 89.82it/s]\u001b[A\n",
            "902it [00:09, 90.34it/s]\u001b[A\n",
            "912it [00:09, 92.30it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 3/5, Batch 900, Loss: 0.0757\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "922it [00:09, 92.84it/s]\u001b[A\n",
            "938it [00:10, 92.22it/s]\n",
            " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:43<00:26, 13.04s/it]\n",
            "0it [00:00, ?it/s]\u001b[A\n",
            "8it [00:00, 70.00it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 4/5, Batch 0, Loss: 0.1901\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "15it [00:00, 60.93it/s]\u001b[A\n",
            "22it [00:00, 61.21it/s]\u001b[A\n",
            "29it [00:00, 58.77it/s]\u001b[A\n",
            "36it [00:00, 61.36it/s]\u001b[A\n",
            "43it [00:00, 63.49it/s]\u001b[A\n",
            "51it [00:00, 66.47it/s]\u001b[A\n",
            "59it [00:00, 68.05it/s]\u001b[A\n",
            "67it [00:01, 68.78it/s]\u001b[A\n",
            "74it [00:01, 67.55it/s]\u001b[A\n",
            "81it [00:01, 67.31it/s]\u001b[A\n",
            "88it [00:01, 67.19it/s]\u001b[A\n",
            "95it [00:01, 67.07it/s]\u001b[A\n",
            "102it [00:01, 65.61it/s]\u001b[A\n",
            "110it [00:01, 68.39it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 4/5, Batch 100, Loss: 0.2001\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "118it [00:01, 69.75it/s]\u001b[A\n",
            "125it [00:01, 68.71it/s]\u001b[A\n",
            "132it [00:02, 65.69it/s]\u001b[A\n",
            "139it [00:02, 64.22it/s]\u001b[A\n",
            "146it [00:02, 64.80it/s]\u001b[A\n",
            "153it [00:02, 60.42it/s]\u001b[A\n",
            "160it [00:02, 60.48it/s]\u001b[A\n",
            "167it [00:02, 57.93it/s]\u001b[A\n",
            "173it [00:02, 56.77it/s]\u001b[A\n",
            "180it [00:02, 58.80it/s]\u001b[A\n",
            "190it [00:02, 68.80it/s]\u001b[A\n",
            "199it [00:03, 74.59it/s]\u001b[A\n",
            "209it [00:03, 79.49it/s]\u001b[A\n",
            "219it [00:03, 83.49it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 4/5, Batch 200, Loss: 0.0310\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "228it [00:03, 85.18it/s]\u001b[A\n",
            "238it [00:03, 87.74it/s]\u001b[A\n",
            "248it [00:03, 90.11it/s]\u001b[A\n",
            "258it [00:03, 87.35it/s]\u001b[A\n",
            "268it [00:03, 89.78it/s]\u001b[A\n",
            "278it [00:03, 91.44it/s]\u001b[A\n",
            "288it [00:03, 92.33it/s]\u001b[A\n",
            "298it [00:04, 92.44it/s]\u001b[A\n",
            "308it [00:04, 93.20it/s]\u001b[A\n",
            "318it [00:04, 92.51it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 4/5, Batch 300, Loss: 0.0459\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "328it [00:04, 91.82it/s]\u001b[A\n",
            "338it [00:04, 92.70it/s]\u001b[A\n",
            "348it [00:04, 93.40it/s]\u001b[A\n",
            "358it [00:04, 90.36it/s]\u001b[A\n",
            "368it [00:04, 91.66it/s]\u001b[A\n",
            "378it [00:04, 92.05it/s]\u001b[A\n",
            "388it [00:05, 92.40it/s]\u001b[A\n",
            "398it [00:05, 92.16it/s]\u001b[A\n",
            "408it [00:05, 90.08it/s]\u001b[A\n",
            "418it [00:05, 90.69it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 4/5, Batch 400, Loss: 0.0360\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "428it [00:05, 90.52it/s]\u001b[A\n",
            "438it [00:05, 91.94it/s]\u001b[A\n",
            "448it [00:05, 88.77it/s]\u001b[A\n",
            "458it [00:05, 90.07it/s]\u001b[A\n",
            "468it [00:05, 91.18it/s]\u001b[A\n",
            "478it [00:06, 92.35it/s]\u001b[A\n",
            "488it [00:06, 92.16it/s]\u001b[A\n",
            "498it [00:06, 91.30it/s]\u001b[A\n",
            "508it [00:06, 90.87it/s]\u001b[A\n",
            "518it [00:06, 91.55it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 4/5, Batch 500, Loss: 0.0300\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "528it [00:06, 91.11it/s]\u001b[A\n",
            "538it [00:06, 92.21it/s]\u001b[A\n",
            "548it [00:06, 89.15it/s]\u001b[A\n",
            "558it [00:06, 91.00it/s]\u001b[A\n",
            "568it [00:07, 92.21it/s]\u001b[A\n",
            "578it [00:07, 91.72it/s]\u001b[A\n",
            "588it [00:07, 89.36it/s]\u001b[A\n",
            "597it [00:07, 89.15it/s]\u001b[A\n",
            "606it [00:07, 89.33it/s]\u001b[A\n",
            "616it [00:07, 91.50it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 4/5, Batch 600, Loss: 0.0338\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "626it [00:07, 92.09it/s]\u001b[A\n",
            "636it [00:07, 88.85it/s]\u001b[A\n",
            "646it [00:07, 90.18it/s]\u001b[A\n",
            "656it [00:08, 90.63it/s]\u001b[A\n",
            "666it [00:08, 89.61it/s]\u001b[A\n",
            "676it [00:08, 91.27it/s]\u001b[A\n",
            "686it [00:08, 91.32it/s]\u001b[A\n",
            "696it [00:08, 91.46it/s]\u001b[A\n",
            "706it [00:08, 91.68it/s]\u001b[A\n",
            "716it [00:08, 92.97it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 4/5, Batch 700, Loss: 0.0981\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "726it [00:08, 92.75it/s]\u001b[A\n",
            "736it [00:08, 88.95it/s]\u001b[A\n",
            "746it [00:09, 90.97it/s]\u001b[A\n",
            "756it [00:09, 90.36it/s]\u001b[A\n",
            "766it [00:09, 90.57it/s]\u001b[A\n",
            "776it [00:09, 91.29it/s]\u001b[A\n",
            "786it [00:09, 91.32it/s]\u001b[A\n",
            "796it [00:09, 92.25it/s]\u001b[A\n",
            "806it [00:09, 93.70it/s]\u001b[A\n",
            "816it [00:09, 93.81it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 4/5, Batch 800, Loss: 0.0806\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "826it [00:09, 89.59it/s]\u001b[A\n",
            "836it [00:10, 91.99it/s]\u001b[A\n",
            "846it [00:10, 89.74it/s]\u001b[A\n",
            "856it [00:10, 91.62it/s]\u001b[A\n",
            "866it [00:10, 92.18it/s]\u001b[A\n",
            "876it [00:10, 91.91it/s]\u001b[A\n",
            "886it [00:10, 92.49it/s]\u001b[A\n",
            "896it [00:10, 93.10it/s]\u001b[A\n",
            "906it [00:10, 94.16it/s]\u001b[A\n",
            "916it [00:10, 94.39it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 4/5, Batch 900, Loss: 0.0970\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "926it [00:10, 88.45it/s]\u001b[A\n",
            "938it [00:11, 84.33it/s]\n",
            " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:54<00:12, 12.28s/it]\n",
            "0it [00:00, ?it/s]\u001b[A\n",
            "10it [00:00, 94.94it/s]\u001b[A\n",
            "20it [00:00, 94.25it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 5/5, Batch 0, Loss: 0.0378\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "30it [00:00, 91.98it/s]\u001b[A\n",
            "40it [00:00, 93.23it/s]\u001b[A\n",
            "50it [00:00, 93.97it/s]\u001b[A\n",
            "60it [00:00, 95.14it/s]\u001b[A\n",
            "70it [00:00, 95.16it/s]\u001b[A\n",
            "80it [00:00, 91.28it/s]\u001b[A\n",
            "90it [00:00, 92.71it/s]\u001b[A\n",
            "100it [00:01, 92.44it/s]\u001b[A\n",
            "110it [00:01, 91.29it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 5/5, Batch 100, Loss: 0.0194\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "120it [00:01, 90.84it/s]\u001b[A\n",
            "130it [00:01, 90.70it/s]\u001b[A\n",
            "140it [00:01, 92.06it/s]\u001b[A\n",
            "150it [00:01, 92.93it/s]\u001b[A\n",
            "160it [00:01, 85.96it/s]\u001b[A\n",
            "169it [00:01, 74.48it/s]\u001b[A\n",
            "177it [00:02, 71.16it/s]\u001b[A\n",
            "185it [00:02, 68.46it/s]\u001b[A\n",
            "192it [00:02, 67.85it/s]\u001b[A\n",
            "199it [00:02, 67.23it/s]\u001b[A\n",
            "206it [00:02, 67.55it/s]\u001b[A\n",
            "214it [00:02, 69.45it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 5/5, Batch 200, Loss: 0.0621\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "222it [00:02, 70.29it/s]\u001b[A\n",
            "230it [00:02, 69.08it/s]\u001b[A\n",
            "237it [00:02, 68.19it/s]\u001b[A\n",
            "244it [00:03, 66.32it/s]\u001b[A\n",
            "252it [00:03, 67.98it/s]\u001b[A\n",
            "259it [00:03, 67.57it/s]\u001b[A\n",
            "266it [00:03, 67.37it/s]\u001b[A\n",
            "273it [00:03, 66.04it/s]\u001b[A\n",
            "280it [00:03, 62.96it/s]\u001b[A\n",
            "287it [00:03, 61.03it/s]\u001b[A\n",
            "294it [00:03, 58.50it/s]\u001b[A\n",
            "300it [00:03, 53.45it/s]\u001b[A\n",
            "306it [00:04, 55.04it/s]\u001b[A\n",
            "312it [00:04, 55.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 5/5, Batch 300, Loss: 0.0437\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "318it [00:04, 55.58it/s]\u001b[A\n",
            "324it [00:04, 56.04it/s]\u001b[A\n",
            "334it [00:04, 67.16it/s]\u001b[A\n",
            "344it [00:04, 75.90it/s]\u001b[A\n",
            "354it [00:04, 82.44it/s]\u001b[A\n",
            "364it [00:04, 86.95it/s]\u001b[A\n",
            "373it [00:04, 87.10it/s]\u001b[A\n",
            "382it [00:05, 84.09it/s]\u001b[A\n",
            "392it [00:05, 87.69it/s]\u001b[A\n",
            "402it [00:05, 89.60it/s]\u001b[A\n",
            "412it [00:05, 89.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 5/5, Batch 400, Loss: 0.0498\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "422it [00:05, 90.42it/s]\u001b[A\n",
            "432it [00:05, 91.45it/s]\u001b[A\n",
            "442it [00:05, 92.90it/s]\u001b[A\n",
            "452it [00:05, 93.34it/s]\u001b[A\n",
            "462it [00:05, 93.18it/s]\u001b[A\n",
            "472it [00:06, 93.56it/s]\u001b[A\n",
            "482it [00:06, 89.48it/s]\u001b[A\n",
            "491it [00:06, 88.61it/s]\u001b[A\n",
            "501it [00:06, 89.22it/s]\u001b[A\n",
            "511it [00:06, 91.08it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 5/5, Batch 500, Loss: 0.0347\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "521it [00:06, 91.69it/s]\u001b[A\n",
            "531it [00:06, 93.83it/s]\u001b[A\n",
            "541it [00:06, 93.92it/s]\u001b[A\n",
            "551it [00:06, 94.09it/s]\u001b[A\n",
            "561it [00:06, 93.96it/s]\u001b[A\n",
            "571it [00:07, 91.35it/s]\u001b[A\n",
            "581it [00:07, 89.02it/s]\u001b[A\n",
            "591it [00:07, 89.85it/s]\u001b[A\n",
            "601it [00:07, 89.76it/s]\u001b[A\n",
            "610it [00:07, 89.30it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 5/5, Batch 600, Loss: 0.1270\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "620it [00:07, 90.56it/s]\u001b[A\n",
            "630it [00:07, 91.14it/s]\u001b[A\n",
            "640it [00:07, 91.68it/s]\u001b[A\n",
            "650it [00:07, 91.82it/s]\u001b[A\n",
            "660it [00:08, 91.42it/s]\u001b[A\n",
            "670it [00:08, 86.26it/s]\u001b[A\n",
            "680it [00:08, 88.00it/s]\u001b[A\n",
            "690it [00:08, 88.93it/s]\u001b[A\n",
            "700it [00:08, 90.33it/s]\u001b[A\n",
            "710it [00:08, 91.66it/s]\u001b[A\n",
            "720it [00:08, 91.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 5/5, Batch 700, Loss: 0.0420\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "730it [00:08, 92.26it/s]\u001b[A\n",
            "740it [00:08, 91.94it/s]\u001b[A\n",
            "750it [00:09, 92.45it/s]\u001b[A\n",
            "760it [00:09, 88.49it/s]\u001b[A\n",
            "770it [00:09, 89.34it/s]\u001b[A\n",
            "779it [00:09, 88.43it/s]\u001b[A\n",
            "789it [00:09, 89.61it/s]\u001b[A\n",
            "799it [00:09, 90.90it/s]\u001b[A\n",
            "809it [00:09, 90.33it/s]\u001b[A\n",
            "819it [00:09, 91.67it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 5/5, Batch 800, Loss: 0.1304\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "829it [00:09, 92.18it/s]\u001b[A\n",
            "839it [00:10, 91.89it/s]\u001b[A\n",
            "849it [00:10, 90.93it/s]\u001b[A\n",
            "859it [00:10, 87.94it/s]\u001b[A\n",
            "868it [00:10, 87.95it/s]\u001b[A\n",
            "878it [00:10, 89.25it/s]\u001b[A\n",
            "888it [00:10, 91.10it/s]\u001b[A\n",
            "898it [00:10, 92.69it/s]\u001b[A\n",
            "908it [00:10, 92.56it/s]\u001b[A\n",
            "918it [00:10, 93.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n",
            "Epoch 5/5, Batch 900, Loss: 0.0844\n",
            "--------- \n",
            "--------- \n",
            "--------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "928it [00:11, 90.65it/s]\u001b[A\n",
            "938it [00:11, 84.16it/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [01:05<00:00, 13.06s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_accuracy_list,accuracy_per_batch, accuracy = evalute()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtGetskK2ScY",
        "outputId": "055c2d98-f615-470b-e631-b70b276ed8f5"
      },
      "execution_count": 328,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:01<00:00, 123.17it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_per_batch #This seems wrong oh weell"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgzTsB752lPp",
        "outputId": "50c7c69c-6a5a-4bdc-8265-f12390c5d5e6"
      },
      "execution_count": 333,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(62.0701)"
            ]
          },
          "metadata": {},
          "execution_count": 333
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor(batch_accuracy_list).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7zSXkaW2-TR",
        "outputId": "9ae1b3a3-bbea-4cd1-c1fd-4edf0fa5bd30"
      },
      "execution_count": 331,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9746)"
            ]
          },
          "metadata": {},
          "execution_count": 331
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1Tv_aEg3Lmd",
        "outputId": "2f4362a5-b387-4d2c-d037-79a52754e3b6"
      },
      "execution_count": 332,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9745)"
            ]
          },
          "metadata": {},
          "execution_count": 332
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_predictions():\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        X, y = next(iter(test_loader))\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        outputs = model(X)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "    fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
        "    for idx, ax in enumerate(axes.flat):\n",
        "        ax.imshow(X[idx].cpu().squeeze(), cmap='gray')\n",
        "        ax.set_title(f\"Pred: {preds[idx].item()}, True: {y[idx].item()}\")\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_predictions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 891
        },
        "id": "d6kJJsWH3hHC",
        "outputId": "65760d1f-8b6a-4361-9fcb-7be6ac626c04"
      },
      "execution_count": 334,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 16 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABI4AAASmCAYAAABIlODCAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAlK9JREFUeJzs3Xvc1/P9P/DnVVc6S6VSoRJZGHLImZpGq7Qh6huGmeMMa4QiRthiDsshG2OIWaPNxrB8Y3KYc+aQQ1NOoRyiEtX1/v3h17X17bW931d9rlPd77dbf1yf63G9Xs/PR718rsf1/nyusizLsgAAAACA/6NBbQ8AAAAAQN2kOAIAAAAgSXEEAAAAQJLiCAAAAIAkxREAAAAASYojAAAAAJIURwAAAAAkKY4AAAAASFIcAQAAAJCkOKqnunbtGkcccURtjwGwEucTUFc5n4C6yvlEXaY4WgU33nhjlJWVVf5p0qRJ9OjRI0488cR4//33a3u8XOeee+4K8//fP4888kiV1uvTp89/XW/5n3PPPbd67tBq+m8zf/Ob36zt8aBK6vv5NGPGjBg5cmRsu+220bJly+jYsWMMHDgwnnrqqVVa74gjjih0PtXVJ2p33nlnDB06NDbZZJNo1qxZbL755vHjH/84Pvnkk9oeDaqsvp9PEREXXHBBDB48ODp06LDaz23q+/n0yiuvxI9+9KPYddddo0mTJlFWVhazZs2q7bFglawJ51NFRUWMGzcuunXrFk2aNImtt946brvttlVaq75/fxcR8fLLL0f//v2jRYsW0aZNmzjssMNi7ty5tT1WvVVe2wPUZ+edd15069YtFi9eHNOmTYtrrrkm7rnnnnjhhReiWbNmtT3ef3TAAQfEpptuutLto0aNigULFsSOO+5YpfVGjx4d3//+9ys/fvLJJ+MXv/hFjBo1Knr27Fl5+9Zbb73qQ1ejm2++eaXbnnrqqbjiiitin332qYWJYPXV1/Ppuuuui+uvvz4OPPDAOOGEE2L+/Plx7bXXxs477xz33ntv9OvXr0rrHXvssSt8zRtvvBFjxoyJY445JvbYY4/K27t3716y+1BKxxxzTHTq1CkOPfTQ2HjjjeMf//hHXHnllXHPPffEM888E02bNq3tEaHK6uv5FBFx1llnxQYbbBC9evWK++67b7XWqu/n02OPPRa/+MUvYosttoiePXvGc889V9sjwWqrz+fT6NGj46c//WkcffTRseOOO8Yf//jHGD58eJSVlcWwYcOqvFZ9/v7u7bffjj333DNatWoVF154YSxYsCAuueSS+Mc//hFPPPFErLPOOrU9Yv2TUWU33HBDFhHZk08+ucLtI0aMyCIiu/XWW//j1y5YsKAkM3Tp0iU7/PDDS7JWlmXZm2++mZWVlWVHH330aq81adKkLCKyqVOn/tdcqR6L6nDUUUdlZWVl2VtvvVXbo0CV1Pfz6amnnso+++yzFW6bN29e1q5du2y33XZb7dmefPLJLCKyG2644b/m6sr5lDpHf/Ob32QRkf3qV7+q+YFgNdT38ynLsuyNN97IsizL5s6dm0VEds4555Rkriyrf+fThx9+mH366adZlmXZxRdfnEVE5eMD9U19P5/efvvtrFGjRtkPfvCDytsqKiqyPfbYI9twww2zpUuXrtZs9e37u+OPPz5r2rRpNnv27Mrb/vrXv2YRkV177bW1OFn95aVqJfSNb3wjIr76iVHEV5cgt2jRImbOnBkDBgyIli1bxiGHHBIRX11KePnll8eWW24ZTZo0iQ4dOsSxxx4bH3/88QprZlkWY8eOjQ033DCaNWsWffv2jRdffDG5/8yZM2PmzJmrNPttt90WWZZVzldqy18e99JLL8Xw4cOjdevWsfvuu0fEV5dC9unTZ6WvOeKII6Jr164r3Fb0cZs/f37MmDEj5s+fX+VZv/jii7jjjjtir732ig033LDKXw91UX05n7bffvto0aLFCre1bds29thjj3j55ZerfL+LWH55+kMPPRQnnHBCtG/fvvLffuocivjXmfZ/3XLLLbH99ttH06ZNo02bNjFs2LB46623VsgsWrQoZsyYEfPmzcudLXU27r///hER1fZ4QE2rL+dTRCTPg+pUl8+nNm3aRMuWLVftjkE9UV/Opz/+8Y+xZMmSOOGEEypvKysri+OPPz7efvvteOyxx1bp/v83dfn7uzvuuCMGDRoUG2+8ceVt/fr1ix49esTvfve7qt9ZvMdRKS3/R922bdvK25YuXRr77rtvtG/fPi655JI48MADI+Kry5NPO+202G233eKKK66II488MiZOnBj77rtvLFmypPLrx4wZE2effXZss802cfHFF8cmm2wS++yzTyxcuHCl/ffee+/Ye++9V2n2iRMnxkYbbRR77rnnKn19UQcddFAsWrQoLrzwwjj66KOr/PVFH7fJkydHz549Y/LkyVXe45577olPPvmk2ko0qA31+XyKiHjvvfdi/fXXX+WvL+KEE06Il156KcaMGRNnnHFGlb/+ggsuiO9+97ux2WabxaWXXhqnnHJKPPDAA7Hnnnuu8J5ETzzxRPTs2TOuvPLKVZrzvffei4io9scDakp9P59qQn05n2BNU1/Op2effTaaN2++wsvIIiJ69+5d+fnqUte+v3vnnXfigw8+iB122GGlz/Xu3btaH4s1mfc4Wg3z58+PefPmxeLFi+ORRx6J8847L5o2bRqDBg2qzHzxxRdx0EEHxUUXXVR527Rp0+K6666LiRMnxvDhwytv79u3b/Tv3z8mTZoUw4cPj7lz58a4ceNi4MCB8ac//anyp0ejR4+OCy+8sGT348UXX4znn38+Ro4cmfwJVSlts802ceutt67S1xZ93FbXxIkTo3HjxjFkyJDVXgtqy5pyPkVEPPzww/HYY4/FWWedVdJ1/682bdrEAw88EA0bNqzy186ePTvOOeecGDt2bIwaNary9gMOOCB69eoVV1999Qq3r46f/exn0bBhQ2cU9daadD7VlPpyPkF9V1/Ppzlz5lS+af+/69ixY0REvPvuu6u8dp669v3dnDlzIuJf9/3fdezYMT766KP44osvonHjxqs089rKFUeroV+/ftGuXbvYaKONYtiwYdGiRYuYPHlydO7ceYXc8ccfv8LHkyZNilatWsU3v/nNmDdvXuWf5S/RmDp1akRETJkyJb788sv44Q9/uMIhcMoppyTnmTVr1ir9NouJEydGRNTIFTbHHXfcKn9t0cct4qvLILMsq/JvIvn000/j7rvvjgEDBsR66623yrNCbVtTzqcPPvgghg8fHt26dYuRI0dW+eur4uijj16lb8oivvrtZxUVFXHwwQev8LhtsMEGsdlmm61wPvXp0yeyLFul30Ry6623xvXXXx8//vGPY7PNNlulWaG2rSnnU02qD+cTrAnq6/n0+eefJ4uQJk2aVH6+utS17++W39faejzWVK44Wg1XXXVV9OjRI8rLy6NDhw6x+eabR4MGK3Zx5eXlK71PzmuvvRbz58+P9u3bJ9f94IMPIuKrnxBFxErfHLRr1y5at25dkvuQZVnceuutsdVWW9XIu+J369Ztlb+26OO2Ou64445YvHixl6lR760J59PChQtj0KBB8dlnn8W0adNWeu+jUlvd8ynLsv9Y5jRq1GiV117u4YcfjqOOOir23XffuOCCC1Z7Pagta8L5VNPq+vkEa4r6ej41bdo0vvjii5VuX7x4ceXnq0td+/5u+X2trcdjTaU4Wg29e/dOvnby3zVu3Hilw6aioiLat29feaXP/9WuXbuSzZjnkUceidmzZ69wqWV1Sv0jLSsriyzLVrp92bJlK3xcE4/bxIkTo1WrVitcjgr1UX0/n7788ss44IAD4vnnn4/77rsvttpqq2rf8z+dTymp86msrCz+8pe/JK8KWN3Sa/r06TF48ODYaqut4ve//32Ul/vfN/VXfT+fakNdPp9gTVJfz6eOHTvG1KlTI8uyFc6G5S/b6tSpU7XtXde+v1v+ErXl9/3fzZkzJ9q0aeNlaqvAM89a0L1795gyZUrstttu/7Xt7NKlS0R81cRusskmlbfPnTt3pXeZX1UTJ06MsrKykrw30Kpq3bp1/POf/1zp9uWN/HJFH7dVNWfOnJg6dWocccQRDhPWWnXhfKqoqIjvfve78cADD8Tvfve72GuvvVZrvdXRunXrFd44drnU+ZRlWXTr1i169OhR0hlmzpwZ/fv3j/bt28c999zjmzzWWnXhfKpL6sL5BHylts+nbbfdNq677rp4+eWXY4sttqi8/e9//3vl52tSbX5/17lz52jXrl089dRTK33uiSeeqPHHYk3hPY5qwcEHHxzLli2L888/f6XPLV26tPJJQL9+/aJRo0Yxfvz4FRrbyy+/PLluVX6dbETEkiVLYtKkSbH77ruv8KsKa1r37t1jxowZMXfu3Mrbpk+fHo888sgKuaKPW0TVfl3jcr/97W+joqLCy9RYq9WF8+mHP/xh3H777XH11VfHAQccUOX7UErdu3eP+fPnx/PPP19525w5c1b6jR4HHHBANGzYMH7yk5+s9BO2LMviww8/rPy4Kr/u+r333ot99tknGjRoEPfdd98afUUF5KkL51NdUtvnE/AvtX0+ffvb345GjRrF1VdfXXlblmUxYcKE6Ny5c+y6665Vu0Orqba/vzvwwAPjz3/+c7z11luVtz3wwAPx6quvxkEHHbQK9whXHNWCvfbaK4499ti46KKL4rnnnot99tknGjVqFK+99lpMmjQprrjiihgyZEi0a9cuTj311Ljoooti0KBBMWDAgHj22WfjL3/5S/LXMC//VY1F3+Dxvvvuiw8//PC/FiU33nhjHHnkkXHDDTdU+Y2mi/re974Xl156aey7775x1FFHxQcffBATJkyILbfcMj799NPKXNHHLeKrX9dY1bknTpwYnTp1ij59+lTDvYT6obbPp8svvzyuvvrq2GWXXaJZs2Zxyy23rPD5/fffP5o3bx4REQ8++GD07ds3zjnnnGp7I9dhw4bF6aefHvvvv3+cdNJJsWjRorjmmmuiR48e8cwzz1TmunfvHmPHjo0zzzwzZs2aFd/5zneiZcuW8cYbb8TkyZPjmGOOiVNPPTUivvppV9G5+/fvH//85z9j5MiRMW3atJg2bVrl5zp06BDf/OY3q+V+Q11U2+dTRMTNN98cs2fPjkWLFkVExN/+9rcYO3ZsREQcdthhlVcTrA3n0/z582P8+PEREZXfDF555ZWx3nrrxXrrrRcnnnhitdxvqItq+3zacMMN45RTTomLL744lixZEjvuuGP84Q9/iIcffjgmTpy4wstU14bv70aNGhWTJk2Kvn37xsknnxwLFiyIiy++OL7+9a/HkUceWS33eU2nOKolEyZMiO233z6uvfbaGDVqVJSXl0fXrl3j0EMPjd12260yN3bs2GjSpElMmDAhpk6dGjvttFPcf//9MXDgwNWeYeLEidGoUaP/2rouWLAgItK/zrBUevbsGTfddFOMGTMmRowYEVtssUXcfPPNceutt8aDDz64Qrbo41ZVr7zySjz99NMxYsSIlV6zDGub2jyfnnvuuYiIeOyxx+Kxxx5b6fNvvPFGZXFUE+dT27ZtY/LkyTFixIgYOXJkdOvWLS666KJ47bXXVvjGLCLijDPOiB49esRll10WP/nJTyIiYqONNop99tknBg8evEr7T58+PSIixo0bt9Ln9tprL8URa53afv50/fXXx0MPPVT58dSpUyt/68/uu+9eWRytDefTxx9/HGefffYKt/385z+PiK9ejqM4Ym1T2+fTT3/602jdunVce+21ceONN8Zmm20Wt9xyy0pvSbI2fH+30UYbxUMPPRQjRoyIM844I9ZZZ50YOHBg/PznP/eWJKuoLEu9axX8fwcffHDMmjUrnnjiidoeBWAFI0eOjNtuuy1ef/11TwKAOsX5BNRVvr9jVbjiiP8oy7J48MEHV3qpCEBdMHXq1Dj77LN9UwbUOc4noC7y/R2ryhVHAAAAACR5MxcAAAAAkhRHAAAAACQpjgAAAABIUhwBAAAAkKQ4AgAAACCpvGiwrKysOucA6om6+IsYnU9AhPMJqLucT0BdVeR8csURAAAAAEmKIwAAAACSFEcAAAAAJCmOAAAAAEhSHAEAAACQpDgCAAAAIElxBAAAAECS4ggAAACAJMURAAAAAEmKIwAAAACSFEcAAAAAJCmOAAAAAEhSHAEAAACQpDgCAAAAIElxBAAAAECS4ggAAACAJMURAAAAAEmKIwAAAACSFEcAAAAAJCmOAAAAAEhSHAEAAACQpDgCAAAAIElxBAAAAECS4ggAAACAJMURAAAAAEmKIwAAAACSFEcAAAAAJJXX9gAA1C+nnnpqoVzTpk1zM1tvvXVuZsiQIYX2K+Kaa67JzTz22GO5mZtvvrkU4wAAQJ3niiMAAAAAkhRHAAAAACQpjgAAAABIUhwBAAAAkKQ4AgAAACBJcQQAAABAkuIIAAAAgCTFEQAAAABJZVmWZYWCZWXVPQtQDxQ8MmqU86l0br/99tzMkCFDamCS2jNz5szcTL9+/XIzb775ZinGoQqcT6zpevTokZuZMWNGbubkk08utN/48eML5cjnfKKUmjdvnpu5+OKLczPHHntsof2efvrp3MxBBx2Um5k9e3ah/ahZRc4nVxwBAAAAkKQ4AgAAACBJcQQAAABAkuIIAAAAgCTFEQAAAABJiiMAAAAAkhRHAAAAACQpjgAAAABIKq/tAQCoGbfffntuZsiQITUwyb/MmDEjN3PfffflZjbZZJNC++233365me7du+dmDjnkkNzMRRddVGgmgKJ69eqVm6moqMjNvP3226UYB6glHTt2zM0cffTRuZki50VExPbbb5+bGTRoUG7mqquuKrQfdY8rjgAAAABIUhwBAAAAkKQ4AgAAACBJcQQAAABAkuIIAAAAgCTFEQAAAABJiiMAAAAAkhRHAAAAACSV1/YAAKy+HXbYITez//77l2SvF198sVBu8ODBuZl58+blZhYsWJCbWWeddQrN9Pjjj+dmttlmm9xM27ZtC+0HUErbbrttbmbhwoW5mcmTJ5dgGqA6tGvXLjfzm9/8pgYmgX9xxREAAAAASYojAAAAAJIURwAAAAAkKY4AAAAASFIcAQAAAJCkOAIAAAAgSXEEAAAAQJLiCAAAAIAkxREAAAAASeW1PUBdMGTIkEK5o48+Ojfz7rvv5mYWL16cm5k4cWKhmd57773czOuvv15oLaD+6tixY26mrKwsN/Piiy/mZvbdd99CM82ZM6dQrhR+/OMfF8ptscUWJdnv7rvvLsk6AMtttdVWuZkTTzwxN3PzzTeXYhygxE466aRCue985zu5md69e6/mNKW355575mYaNMi/bmX69OmF9vvb3/5WKEdpuOIIAAAAgCTFEQAAAABJiiMAAAAAkhRHAAAAACQpjgAAAABIUhwBAAAAkKQ4AgAAACBJcQQAAABAUlmWZVmhYFlZdc9Sa/75z38WynXt2rV6B1kFn332WW7mxRdfrIFJ6r+33347NzNu3LjczFNPPVWKceqsgkdGjVqTz6dS6tKlS26myJny0UcflWKckpo+fXqh3FZbbVWS/fr165ebmTp1akn2ojjnE/XZkCFDcjO/+93vcjN9+/bNzTz00EOFZqJ0nE8sW7asUK6ioqKaJ6m6Bg3yrzcp1dyzZ88ulBs6dGhu5umnn17dcdYKRc4nVxwBAAAAkKQ4AgAAACBJcQQAAABAkuIIAAAAgCTFEQAAAABJiiMAAAAAkhRHAAAAACQpjgAAAABIKq/tAeqCo48+ulBu6623zs28/PLLuZmePXvmZrbbbrtCM/Xp0yc3s/POO+dm3nrrrdzMRhttVGSkklm6dGluZu7cuYXW6tix4+qOExERb775Zm7mqaeeKsleUGqzZ8+u7RFWyWmnnZab6dGjR8n2+/vf/16SDEBVjBw5MjdT5Bz3PARq3j333JObadCg/l6z8eGHH+ZmFixYkJvp0qVLbqZbt26FZnriiSdyMw0bNiy0Fvnq799eAAAAAKqV4ggAAACAJMURAAAAAEmKIwAAAACSFEcAAAAAJCmOAAAAAEhSHAEAAACQpDgCAAAAIKm8tgeoCx544IGS5vLce++9JVknIqJ169a5mW233TY38/TTT+dmdtxxxyIjlczixYtzM6+++mqhtV5++eXcTJs2bXIzM2fOLLQfUMygQYNyM+edd15uZp111im03wcffJCbOfPMM3MzixYtKrQfQNeuXQvldthhh9xMkec9CxcuLLQfUMxee+2Vm9l8881zMxUVFYX2K5orhQkTJhTK3X///bmZ+fPn52a+8Y1v5GZGjx5daKYijj/++NzMNddcU7L91mSuOAIAAAAgSXEEAAAAQJLiCAAAAIAkxREAAAAASYojAAAAAJIURwAAAAAkKY4AAAAASFIcAQAAAJCkOAIAAAAgqby2B2D1fPzxx7mZqVOnlmSvBx54oCTrlNKBBx5YKNe6devczD/+8Y/czO23315oP6CYHXbYITezzjrrlGy/Iv+GH3rooZLtB7DXXnuVbK25c+eWbC0gomvXrrmZ3/72t7mZ9ddfvwTTFDd79uzczB133JGb+clPflJov0WLFhXK5Sky9zHHHFNorXbt2uVmxo0bl5tp0qRJbubKK68sNNOSJUsK5eojVxwBAAAAkKQ4AgAAACBJcQQAAABAkuIIAAAAgCTFEQAAAABJiiMAAAAAkhRHAAAAACQpjgAAAABIKq/tAeA/ad++fW7m6quvLrRWgwb5Hel5552Xm/noo48K7QdE/OEPf8jN7LPPPiXZ66abbiqUO+uss0qyH0BRX//610u21rhx40q2FhBRXp7/7fD6669fA5P8y0MPPZSbGTZsWG5m3rx5pRinpGbPnp2bueiiiwqtdemll+ZmmjVrlpspcq7eddddhWaaOXNmoVx95IojAAAAAJIURwAAAAAkKY4AAAAASFIcAQAAAJCkOAIAAAAgSXEEAAAAQJLiCAAAAIAkxREAAAAASeW1PQD8Jz/4wQ9yM+3atSu01scff5ybeeWVVwqtBWu7jh07FsrtuuuuuZnGjRvnZubNm5ebGTt2bKGZFixYUCgHUMTOO++cmznyyCMLrfXss8/mZv76178WWguoe5566qlCue9973u5mSLPjeqru+66q1DukEMOyc3suOOOqzsO/58rjgAAAABIUhwBAAAAkKQ4AgAAACBJcQQAAABAkuIIAAAAgCTFEQAAAABJiiMAAAAAkhRHAAAAACSV1/YArJ1222233MwZZ5xRsv2+853v5GZeeOGFku0Ha7I77rijUK5t27Yl2e+WW27JzcycObMkewFURb9+/XIzbdq0KbTWvffem5tZvHhxobWA0mnQoDTXWuy0004lWWdNV1ZWVihX5L9Lqf7bnXvuuYVyhx12WEn2q4tccQQAAABAkuIIAAAAgCTFEQAAAABJiiMAAAAAkhRHAAAAACQpjgAAAABIUhwBAAAAkKQ4AgAAACBJcQQAAABAUnltD8DaacCAAbmZRo0a5WYeeOCBQvs99thjhXKwths8eHBuZrvttivZfg8++GBu5pxzzinZfgCltM022+RmsiwrtNbvf//71R0HqKLjjjsuN1NRUVEDk7DcfvvtVyjXq1ev3EyR/3ZFMueee26RkdZorjgCAAAAIElxBAAAAECS4ggAAACAJMURAAAAAEmKIwAAAACSFEcAAAAAJCmOAAAAAEhSHAEAAACQVF7bA7Dmadq0aW6mf//+uZkvv/wyN3POOecUmmnJkiWFcrAma9u2bW5m1KhRuZlGjRqVYpyIiHjuuedyMwsWLCjZfgBFbbDBBrmZPfbYIzfzyiuvFNpv8uTJhXJA6ey33361PcIao127drmZLbbYIjdT5LloKc2dOzc343tJVxwBAAAA8B8ojgAAAABIUhwBAAAAkKQ4AgAAACBJcQQAAABAkuIIAAAAgCTFEQAAAABJiiMAAAAAksprewDWPKeddlpuplevXrmZe++9Nzfz6KOPFpoJiPjxj3+cm9lxxx1Ltt8f/vCH3Mw555xTsv0ASumII47IzbRv3z4385e//KUE0wDUbaNHj87N/OAHP6iBSf5l1qxZuZnDDz88N/Pmm2+WYJr6zRVHAAAAACQpjgAAAABIUhwBAAAAkKQ4AgAAACBJcQQAAABAkuIIAAAAgCTFEQAAAABJiiMAAAAAksprewDqj4EDBxbKnX322bmZTz/9NDdz3nnnFdoPKGbEiBE1ut+JJ56Ym1mwYEENTAJQdV26dCnJOh9//HFJ1gGoLffcc09uZvPNN6+BSarmpZdeys1MmzatBiap/1xxBAAAAECS4ggAAACAJMURAAAAAEmKIwAAAACSFEcAAAAAJCmOAAAAAEhSHAEAAACQpDgCAAAAIElxBAAAAEBSeW0PQN3Qtm3b3MwvfvGLQms1bNgwN3PPPffkZh5//PFC+wF1U5s2bXIzS5YsqYFJqmb+/Pm5mSJzN2rUqNB+rVq1KpTLs9566+VmRowYUZK9ilq2bFlu5vTTTy+01qJFi1Z3HKiSQYMGlWSdP/3pTyVZByi9srKy3EyDBqW51uJb3/pWSdaJiPjlL3+Zm+nUqVPJ9ivyGFRUVJRsv1LZb7/9anuENYYrjgAAAABIUhwBAAAAkKQ4AgAAACBJcQQAAABAkuIIAAAAgCTFEQAAAABJiiMAAAAAkhRHAAAAACSV1/YAVL+GDRvmZu69997cTLdu3QrtN3PmzNzM2WefXWgtoP56/vnna3uEVTJp0qTczJw5c3IzHTp0KLTf0KFDC+XWVO+9916h3AUXXFDNk7A22X333XMzG2ywQQ1MAtSma665Jjczbty4kuz15z//uVCuoqKiJPuVap26ut+ECRNqdL+1nSuOAAAAAEhSHAEAAACQpDgCAAAAIElxBAAAAECS4ggAAACAJMURAAAAAEmKIwAAAACSFEcAAAAAJJXX9gBUv+7du+dmtt9++5LtN2LEiNzMzJkzS7YfUMw999yTm/n2t79dA5PUbQcddFBtj7CSpUuX5mYqKipKtt9dd92Vm3nqqadKstfDDz9cknWgKvbff//cTMOGDXMzzz77bG7mb3/7W6GZgJp355135mZOO+203Ey7du1KMU69Nnfu3NzMyy+/nJs55phjCu03Z86cQjlKwxVHAAAAACQpjgAAAABIUhwBAAAAkKQ4AgAAACBJcQQAAABAkuIIAAAAgCTFEQAAAABJiiMAAAAAksprewBWT5cuXXIz999/f0n2Ou200wrl/vznP5dkP6C0DjjggNzMyJEjczONGjUqxTiFbbnllrmZoUOH1sAk//LrX/86NzNr1qyS7XfHHXfkZmbMmFGy/aC+atasWaHcgAEDSrLf73//+9zMsmXLSrIXUHqzZ8/OzQwbNiw3853vfCc3c/LJJxcZqd664IILcjNXXXVVDUxCdXDFEQAAAABJiiMAAAAAkhRHAAAAACQpjgAAAABIUhwBAAAAkKQ4AgAAACBJcQQAAABAkuIIAAAAgCTFEQAAAABJZVmWZYWCZWXVPQur4IILLsjNnHnmmSXZq3fv3oVyTz31VEn2o24qeGTUKOcTEOF8IqJRo0aFcg899FBu5oMPPsjNDB8+PDezaNGiQjOxZnM+0b9//0K5Y445Jjez33775Wbuuuuu3Mwvf/nLQjMV+bvy0ksv5WbefPPNQvtRs4qcT644AgAAACBJcQQAAABAkuIIAAAAgCTFEQAAAABJiiMAAAAAkhRHAAAAACQpjgAAAABIUhwBAAAAkFSWZVlWKFhWVt2z8G923333Qrl77rknN9OiRYvVHSciInr37l0o99RTT5VkP+qmgkdGjXI+ARHOJ6Ducj4BdVWR88kVRwAAAAAkKY4AAAAASFIcAQAAAJCkOAIAAAAgSXEEAAAAQJLiCAAAAIAkxREAAAAASYojAAAAAJLKa3sA0vbYY49CuRYtWpRkv5kzZ+ZmFixYUJK9AAAAgPrBFUcAAAAAJCmOAAAAAEhSHAEAAACQpDgCAAAAIElxBAAAAECS4ggAAACAJMURAAAAAEmKIwAAAACSymt7AKrf9OnTczN77713buajjz4qxTgAAABAPeGKIwAAAACSFEcAAAAAJCmOAAAAAEhSHAEAAACQpDgCAAAAIElxBAAAAECS4ggAAACAJMURAAAAAEmKIwAAAACSyrIsywoFy8qqexagHih4ZNQo5xMQ4XwC6i7nE1BXFTmfXHEEAAAAQJLiCAAAAIAkxREAAAAASYojAAAAAJIURwAAAAAkKY4AAAAASFIcAQAAAJCkOAIAAAAgqSzLsqy2hwAAAACg7nHFEQAAAABJiiMAAAAAkhRHAAAAACQpjgAAAABIUhwBAAAAkKQ4AgAAACBJcQQAAABAkuIIAAAAgCTFEQAAAABJiiMAAAAAkhRHAAAAACQpjgAAAABIUhwBAAAAkKQ4AgAAACBJcVRPde3aNY444ojaHgNgJc4noK5yPgF1lfOJukxxtApuvPHGKCsrq/zTpEmT6NGjR5x44onx/vvv1/Z4VTZx4sQoKyuLFi1arNLX9+nTZ4XH4z/9Offcc0s7eDVYsmRJbLHFFlFWVhaXXHJJbY8DVbYmnE8XXHBBDB48ODp06LDaZ8cRRxxR6Hyqq0/UXnnllfjRj34Uu+66azRp0iTKyspi1qxZtT0WrJI14Xz6d54//YvnT9R3a8L59Prrr8eQIUOidevW0axZs9h9991j6tSpq7TWmnA+XXnlldGzZ89o3LhxdO7cOUaMGBELFy6s7bHqrfLaHqA+O++886Jbt26xePHimDZtWlxzzTVxzz33xAsvvBDNmjWr7fEKWbBgQYwcOTKaN2++ymuMHj06vv/971d+/OSTT8YvfvGLGDVqVPTs2bPy9q233nq1Zq0J48ePjzfffLO2x4DVVp/Pp7POOis22GCD6NWrV9x3332rtdaxxx4b/fr1q/z4jTfeiDFjxsQxxxwTe+yxR+Xt3bt3X619qstjjz0Wv/jFL2KLLbaInj17xnPPPVfbI8Fqq8/n03KeP63I8yfWFPX1fHrrrbdil112iYYNG8Zpp50WzZs3jxtuuCH22WefeOCBB2LPPfes0nr1/Xw6/fTTY9y4cTFkyJA4+eST46WXXorx48fHiy++uNrPLddaGVV2ww03ZBGRPfnkkyvcPmLEiCwisltvvfU/fu2CBQtKMkOXLl2yww8/fLXXOf3007PNN988O+SQQ7LmzZuv/mBZlk2aNCmLiGzq1Kn/NVeqx6JU3n///axVq1bZeeedl0VEdvHFF9f2SFBla8L59MYbb2RZlmVz587NIiI755xzSjJXlmXZk08+mUVEdsMNN/zXXF05nz788MPs008/zbIsyy6++OIsIiofH6hv1oTzaTnPn/7F8yfWBPX9fDrhhBOy8vLybMaMGZW3LVy4MNtoo42y7bbbbrVnq0/n07vvvpuVl5dnhx122Aq3jx8/PouI7K677qqlyeo3L1UroW984xsR8dVPtCO+eolEixYtYubMmTFgwIBo2bJlHHLIIRERUVFREZdffnlsueWW0aRJk+jQoUMce+yx8fHHH6+wZpZlMXbs2Nhwww2jWbNm0bdv33jxxReT+8+cOTNmzpxZeN7XXnstLrvssrj00kujvLx6Lz4799xzo6ysLF566aUYPnx4tG7dOnbfffeI+OpSyD59+qz0NUcccUR07dp1hduKPm7z58+PGTNmxPz58wvPeMYZZ8Tmm28ehx56aJXvH9R19el8+r//7qvb8svTH3rooTjhhBOiffv2seGGG0ZE+hyK+NeZ9n/dcsstsf3220fTpk2jTZs2MWzYsHjrrbdWyCxatChmzJgR8+bNy52tTZs20bJly1W7Y1BP1KfzKcLzp//L8yfWZPXlfHr44YejV69esfnmm1fe1qxZsxg8eHA888wz8dprr63S/f9v6ur59Nhjj8XSpUtj2LBhK9y+/OPf/va3VbynRHiPo5Ja/o+6bdu2lbctXbo09t1332jfvn1ccsklceCBB0bEVy+fOO2002K33XaLK664Io488siYOHFi7LvvvrFkyZLKrx8zZkycffbZsc0228TFF18cm2yySeyzzz7J12fuvffesffeexee95RTTom+ffvGgAEDVvUuV9lBBx0UixYtigsvvDCOPvroKn990cdt8uTJ0bNnz5g8eXKhdZ944on4zW9+E5dffnnym0Go7+rb+VQbTjjhhHjppZdizJgxccYZZ1T56y+44IL47ne/G5tttllceumlccopp1ReHv7JJ59U5p544ono2bNnXHnllSWcHuqv+nY+ef70L54/saarL+fTF198EU2bNl3p9uUvr3v66aerdseroK6dT1988UVExEqPR008Fmsy73G0GubPnx/z5s2LxYsXxyOPPBLnnXdeNG3aNAYNGlSZ+eKLL+Kggw6Kiy66qPK2adOmxXXXXRcTJ06M4cOHV97et2/f6N+/f0yaNCmGDx8ec+fOjXHjxsXAgQPjT3/6U+X/kEePHh0XXnjhas1+9913x/333x/Tp09frXWqaptttolbb711lb626ONWVVmWxQ9/+MMYOnRo7LLLLt54ljVCfT6fakubNm3igQceiIYNG1b5a2fPnh3nnHNOjB07NkaNGlV5+wEHHBC9evWKq6++eoXbYW1Wn88nz5/+xfMn1kT19XzafPPN4+GHH47PPvtshSuVp02bFhER77zzziqvnaeunU/Lr7p65JFHom/fvpW3P/zwwxFRvY/FmswVR6uhX79+0a5du9hoo41i2LBh0aJFi5g8eXJ07tx5hdzxxx+/wseTJk2KVq1axTe/+c2YN29e5Z/tt98+WrRoUfnu91OmTIkvv/wyfvjDH67wU5xTTjklOc+sWbMK/U/7yy+/jB/96Edx3HHHxRZbbFG1O72ajjvuuFX+2qKPW8RXl0FmWVboNyXdeOON8Y9//CN+9rOfrfJsUNfU1/OpNh199NGrVBpFRNx5551RUVERBx988AqP2wYbbBCbbbbZCudTnz59IsuyOv2bSKA61dfzyfOnFXn+xJqovp5Pxx9/fHzyyScxdOjQePbZZ+PVV1+NU045JZ566qmIiPj888+r8ChUTV07n7bbbrvYaaed4mc/+1nccMMNMWvWrPjLX/4Sxx57bDRq1KhaH4s1mSuOVsNVV10VPXr0iPLy8ujQoUNsvvnm0aDBil1ceXl55XtlLPfaa6/F/Pnzo3379sl1P/jgg4j46ifYERGbbbbZCp9v165dtG7depXnvuyyy2LevHnxk5/8ZJXXWFXdunVb5a8t+rhVxaeffhpnnnlmnHbaabHRRhut8mxQ19TX86k2re75lGXZSo/Hco0aNVrltWFNU1/PJ8+f/sXzJ9ZU9fV8+ta3vhXjx4+PM844I7bbbruIiNh0003jggsuiJEjR0aLFi1Wee08de18ioi44447YujQofG9730vIiIaNmwYI0aMiIceeiheeeWVVZ53baY4Wg29e/eOHXbY4b9mGjduvNJhU1FREe3bt4+JEycmv6Zdu3Ylm/H/mj9/fowdOzZOOOGE+PTTT+PTTz+NiK9+rWyWZTFr1qxo1qzZf/zHu7pSr70tKyuLLMtWun3ZsmUrfFwdj9sll1wSX375ZQwdOrSyzX/77bcjIuLjjz+OWbNmRadOnWKdddap8tpQm+rj+VTb/tP5lJI6n8rKyuIvf/lL8qql6nzCBvVNfTyfPH9akedPrKnq4/m03IknnhhHHnlkPP/887HOOuvEtttuG9dff31ERPTo0aPa9q1r51NEROfOnWPatGnx2muvxXvvvRebbbZZbLDBBtGpU6dqfSzWZIqjWtC9e/eYMmVK7Lbbbsl/aMt16dIlIr5qYjfZZJPK2+fOnbvSu8wX9fHHH8eCBQti3LhxMW7cuJU+361bt/j2t78df/jDH1Zp/VXRunXr+Oc//7nS7csb+eWKPm5V8eabb8bHH38cW2655Uqfu/DCC+PCCy+MZ599NrbddtuS7Ad1XW2eT3VR69atV3hj6+VS51OWZdGtWzdPSKCaeP60Is+foO6oK8+fmjdvHrvsskvlx1OmTImmTZvGbrvtttprV0Vtnk//brPNNqu8uuull16KOXPmFHopLivzHke14OCDD45ly5bF+eefv9Lnli5dWvlNSr9+/aJRo0Yxfvz4FRrbyy+/PLlukV/X2L59+5g8efJKf/r27RtNmjSJyZMnx5lnnrnK921VdO/ePWbMmBFz586tvG369OnxyCOPrJAr+rhFFP91jSeddNJKj8W1114bEV+9jnby5Mmrdfkl1De1eT7VRd27d4/58+fH888/X3nbnDlzVvqNHgcccEA0bNgwfvKTn6z0E7Ysy+LDDz+s/HjRokUxY8aMmDdvXvUOD2sYz59W5PkT1B118fnTo48+GnfeeWccddRR0apVq1VaY1XV5vmUUlFRESNHjoxmzZqt1nsyrc1ccVQL9tprrzj22GPjoosuiueeey722WefaNSoUbz22msxadKkuOKKK2LIkCHRrl27OPXUU+Oiiy6KQYMGxYABA+LZZ5+Nv/zlL7H++uuvtO7yX9X4395ArVmzZvGd73xnpdv/8Ic/xBNPPLHS52688cY48sgj44Ybbqi2dvZ73/teXHrppbHvvvvGUUcdFR988EFMmDAhttxyy8pLwSOKP24RX/26xiJzb7fddpWvA15u+eO35ZZbJh8rWJPV5vm03M033xyzZ8+ORYsWRUTE3/72txg7dmxERBx22GGVP6178MEHo2/fvnHOOedU2xtNDxs2LE4//fTYf//946STTopFixbFNddcEz169IhnnnmmMte9e/cYO3ZsnHnmmTFr1qz4zne+Ey1btow33ngjJk+eHMccc0yceuqpEfHVr68uOvf8+fNj/PjxERGVT7auvPLKWG+99WK99daLE088sVruN9RFnj+tyPMnqDtq+/nT7Nmz4+CDD47BgwfHBhtsEC+++GJMmDAhtt5665V+W9uafj5FRJx88smxePHi2HbbbWPJkiVx6623xhNPPBG/+c1vYuONN66W+7ymUxzVkgkTJsT2228f1157bYwaNSrKy8uja9euceihh65wKeHYsWOjSZMmMWHChJg6dWrstNNOcf/998fAgQNrZM4FCxZERETHjh2rbY+ePXvGTTfdFGPGjIkRI0bEFltsETfffHPceuut8eCDD66QLfq4Aauuts+n66+/Ph566KHKj6dOnVr5WzV23333yuKoJs6ntm3bxuTJk2PEiBExcuTI6NatW1x00UXx2muvrVAcRUScccYZ0aNHj7jssssq3zx3o402in322ScGDx68Svt//PHHcfbZZ69w289//vOI+Opyd8URa5vaPp+K8vwJ1j61eT6tu+660bFjx7jyyivjo48+is6dO8dJJ50Uo0ePjpYtW66QXRvOp169esXll18eEydOjAYNGkTv3r3jgQceiL59+5bg3q2dyrLUu1bB/3fwwQfHrFmz4oknnqjtUQBWMHLkyLjtttvi9ddfj8aNG9f2OACVPH8C6irnE6vCFUf8R1mWxYMPPhi33HJLbY8CsJKpU6fG2WefrTQC6hTPn4C6yvnEqnLFEQAAAABJfqsaAAAAAEmKIwAAAACSFEcAAAAAJCmOAAAAAEhSHAEAAACQpDgCAAAAIKm8aLCsrKw65wDqiSzLanuElTifgAjnE1B3OZ+AuqrI+eSKIwAAAACSFEcAAAAAJCmOAAAAAEhSHAEAAACQpDgCAAAAIElxBAAAAECS4ggAAACAJMURAAAAAEmKIwAAAACSFEcAAAAAJCmOAAAAAEhSHAEAAACQpDgCAAAAIElxBAAAAECS4ggAAACAJMURAAAAAEmKIwAAAACSFEcAAAAAJCmOAAAAAEhSHAEAAACQpDgCAAAAIElxBAAAAECS4ggAAACAJMURAAAAAEmKIwAAAACSFEcAAAAAJCmOAAAAAEhSHAEAAACQpDgCAAAAIElxBAAAAECS4ggAAACAJMURAAAAAEmKIwAAAACSFEcAAAAAJCmOAAAAAEhSHAEAAACQpDgCAAAAIElxBAAAAECS4ggAAACAJMURAAAAAEmKIwAAAACSFEcAAAAAJCmOAAAAAEhSHAEAAACQVF7bA5C23XbbFcrdeeeduZmuXbuu5jT13z777JObefnll3Mzb731VinGAeqw/fbbLzdz11135WZOPPHEQvtNmDAhN7Ns2bJCa8GarH379rmZ3/3ud4XWevTRR3Mzv/zlL3Mzs2bNKrTf2q5Vq1a5mT333LPQWvfee29uZsmSJYXWAqAYVxwBAAAAkKQ4AgAAACBJcQQAAABAkuIIAAAAgCTFEQAAAABJiiMAAAAAkhRHAAAAACQpjgAAAABIKq/tAUjbd999C+UaN25czZOsGfbbb7/czPe+973czLBhw0oxDlBL2rZtm5u5+uqrS7LXlVdeWSj361//Ojfz+eefr+44UKe1bt06N/Piiy/mZlq1alVov/fffz83M2vWrEJrre2KPOZPP/10bqZdu3aF9tt+++1zM6+//nqhtaAuWnfddXMzF110UW5mq622ys3069ev0ExLliwplGPN5YojAAAAAJIURwAAAAAkKY4AAAAASFIcAQAAAJCkOAIAAAAgSXEEAAAAQJLiCAAAAIAkxREAAAAASYojAAAAAJLKa3uAtVF5ef7DPmDAgBqYZO3x9NNP52ZGjBiRm2nevHluZuHChYVmAmrennvumZvZcMMNS7LXbbfdVii3ePHikuwHddX666+fm7n99ttzM23atMnNXH311YVm+uEPf1goR76zzjorN9OtW7fczLHHHltov9dff71QDuqaQw45pFDuggsuyM1stNFGqztORESsu+66hXIffvhhSfaj/nLFEQAAAABJiiMAAAAAkhRHAAAAACQpjgAAAABIUhwBAAAAkKQ4AgAAACBJcQQAAABAkuIIAAAAgKTy2h5gbdS3b9/czC677FJorXHjxq3uOGuF1q1b52a22GKL3EyzZs1yMwsXLiw0E1A6jRs3LpQbPXp0NU/yLzfffHOhXJZl1TwJ1K7tttsuN9OnT5+S7HXeeeeVZB2+suWWW+ZmfvzjH+dmJk+enJu5/fbbC80EddGGG26Ym7n88ssLrdW2bdvcTKmeO4wfP75Q7sQTT8zNfPTRR6s7DnWYK44AAAAASFIcAQAAAJCkOAIAAAAgSXEEAAAAQJLiCAAAAIAkxREAAAAASYojAAAAAJIURwAAAAAkldf2AGuarbbaKjdz22235WZmzpxZaL8LL7ywUG5t9+1vf7u2RwCq0de//vVCue23374k+y1dujQ385e//KUke0Fd1b59+0K5Aw88sCT7HXXUUbmZuXPnlmSvNd2WW25ZKDdlypSS7Dd58uTczGeffVaSvaA2nHrqqbmZNm3a1MAkVTN06NBCuf79++dmLrjggtzM+PHjczNffvlloZmoWa44AgAAACBJcQQAAABAkuIIAAAAgCTFEQAAAABJiiMAAAAAkhRHAAAAACQpjgAAAABIUhwBAAAAkFRe2wOsac4666zcTPPmzXMz/fv3L7TfggULCuXWVG3atCmU22uvvXIzFRUVqzsOUEsOPPDAGt3v/vvvr9H9oC76+c9/Xih36KGH5maefvrp3MykSZMK7Ue+PfbYo1CuQ4cOuZkbb7wxN3PLLbcU2g/qoi5duuRmjjzyyJLt9/zzz+dm3n///dxMv379SjFORES0atUqN3PqqafmZiZOnJibee+99wrNRM1yxREAAAAASYojAAAAAJIURwAAAAAkKY4AAAAASFIcAQAAAJCkOAIAAAAgSXEEAAAAQJLiCAAAAIAkxREAAAAASeW1PUB9MmTIkNzMgAEDcjOvv/56buapp54qNNPabvTo0YVyFRUVuZkHH3wwN/PJJ58U2g+oWXvuuWfJ1vryyy9zM0XPHliTZVlWKFfk/8HvvvtubqbIv801XdOmTXMzo0aNys2ccMIJhfYr8t/4e9/7XqG1oL7adtttczMtW7bMzTz88MOF9ttrr71yM02aNMnN/M///E9upsh5ERHRvXv33MwGG2yQm/njH/+Ym/nWt75VaKaPPvqoUI7ScMURAAAAAEmKIwAAAACSFEcAAAAAJCmOAAAAAEhSHAEAAACQpDgCAAAAIElxBAAAAECS4ggAAACApPLaHqA+Oeigg3IzzZo1y81cffXVpRhnjde1a9fczCGHHFJorWXLluVmxo4dm5tZsmRJof2A0tl1111Lkilq4cKFuZnnnnuuZPsBEQMHDszN3H///bmZTz75pNB+11xzTaFcTdprr71yM3369MnN7LzzziWY5iu///3vS7YW1FeNGzfOzWRZlpu57LLLSjFOREQsXrw4N3PDDTfkZop8fxsRsckmmxTK5Vm0aFFu5ssvvyzJXpSWK44AAAAASFIcAQAAAJCkOAIAAAAgSXEEAAAAQJLiCAAAAIAkxREAAAAASYojAAAAAJIURwAAAAAkldf2AHVBq1atCuV23nnnkux3zTXXlGSdNd0xxxyTm1l//fULrfXyyy/nZqZOnVpoLaBm7bjjjjW6nzMairniiisK5fr27Zub6dSpU25mzz33zM2UlZUVmmnw4MGFcjWpyOxZlpVkr3/+85+FcqNGjSrJflCf/c///E9J1hk4cGCh3B/+8IeS7FfEDjvsUGN7RUQ8/vjjuZkFCxbUwCRUlSuOAAAAAEhSHAEAAACQpDgCAAAAIElxBAAAAECS4ggAAACAJMURAAAAAEmKIwAAAACSFEcAAAAAJJXX9gB1QePGjQvlOnfunJu57bbbVncc/r/u3buXbK0XXnihZGsBNWuHHXYo2VqffPJJbuaaa64p2X6wJnv66acL5bbeeuvczLbbbpub6d+/f27mtNNOKzJSzJ07Nzfzm9/8ptBapXLzzTfnZqZPn16SvR599NFCuZkzZ5ZkP6jPinx/N3jw4NzMjjvuWGi/r33ta7mZr3/967mZ/fffPzfTunXrQjMVef5UZK2jjz46N1PkLIyIeOmllwrlKA1XHAEAAACQpDgCAAAAIElxBAAAAECS4ggAAACAJMURAAAAAEmKIwAAAACSFEcAAAAAJCmOAAAAAEhSHAEAAACQVJZlWVYoWFZW3bPUmqZNmxbKPfzww7mZRo0a5Wb69u2bm/noo48KzVRftW/fPjczZ86cku130kkn5Wauuuqqku23Jit4ZNSoNfl8WtPtvvvuuZmHHnooN9OgQbGfg8yePTs307Vr10JrUfc4n6jPNtlkk9zM66+/npt57rnncjP77rtvkZFi7ty5hXLkcz7VX23atMnNFPm32apVq0L7FfnvUqq/T1OmTCmU+8EPfpCb+fOf/5yb2WyzzXIzv/rVrwrNdNxxxxXKka/I3ydXHAEAAACQpDgCAAAAIElxBAAAAECS4ggAAACAJMURAAAAAEmKIwAAAACSFEcAAAAAJCmOAAAAAEgqr+0B6oLPP/+8UG7mzJm5mQMPPDA3c/fdd+dmLr300kIz1aStttqqUG6TTTbJzXTt2jU3k2VZof2KqKioKNlaQOm0bds2N9OgQel+xvHXv/61ZGsBlNKYMWNyM0WeG51++um5mblz5xaaCYj46KOPcjMHH3xwbub3v/99of1atWpVKJdn/PjxuZki50VExOLFi3Mzd955Z27mjDPOyM3su+++hWbq3r17bqbI9+8U44ojAAAAAJIURwAAAAAkKY4AAAAASFIcAQAAAJCkOAIAAAAgSXEEAAAAQJLiCAAAAIAkxREAAAAASWVZlmWFgmVl1T1Lnfe1r30tN3PeeeflZgYOHJibady4caGZatK8efMK5Yr8lVp//fVzM6X8O9eyZcvczOeff16y/dZkBY+MGuV8qr9uvvnm3Myhhx6am/nkk08K7ffNb34zN/PUU08VWou6x/lEXXTQQQcVyt1+++25mc8++yw307dv39zMM888U2gmSsf5RL9+/Qrlhg8fnpsp8rxnzJgxuZkFCxYUGamQpk2b5mZuvfXW3MzgwYML7XfLLbfkZg4//PBCa63tipxPrjgCAAAAIElxBAAAAECS4ggAAACAJMURAAAAAEmKIwAAAACSFEcAAAAAJCmOAAAAAEhSHAEAAACQVJZlWVYoWFZW3bOsNbbddtvczKabblr9g1TR73//+5Kt9Zvf/CY3c8ghh5Rsv/Ly8pKttbYreGTUKOdT3bThhhvmZmbPnp2badAg/2ccL7zwQqGZvv71rxfKUT85n6iLfv3rXxfKHXHEEbmZ2267LTdTyudPlI7zCSKGDRuWm5k4cWKhtd55553cTJHvuz/66KNC+63JipxPrjgCAAAAIElxBAAAAECS4ggAAACAJMURAAAAAEmKIwAAAACSFEcAAAAAJCmOAAAAAEhSHAEAAACQpDgCAAAAIKm8tgdYGz333HMlydRn//znP2t0v6222io388ILL9TAJLD22HXXXXMzDRqU5ucXf/jDH0qyDkCpfetb3yqUW7hwYW7m5z//+eqOA1Brfve73+VmBg8eXGitoUOH5mZOPPHE3Mx5551XaL+1nSuOAAAAAEhSHAEAAACQpDgCAAAAIElxBAAAAECS4ggAAACAJMURAAAAAEmKIwAAAACSFEcAAAAAJJXX9gCsncrKykqSKeqFF14o2VpAMW3bti3JOvPmzcvNXHHFFSXZC6AqjjvuuNxMhw4dCq31wQcf5GaeeeaZQmsB1EUVFRW5mXHjxhVa69vf/nZu5pxzzsnN/Pa3v83NvPrqq4VmWpO54ggAAACAJMURAAAAAEmKIwAAAACSFEcAAAAAJCmOAAAAAEhSHAEAAACQpDgCAAAAIElxBAAAAEBSeW0PwNopy7KSZIC6a9999y3JOm+++WZuZv78+SXZC6AqjjvuuNxM0eczd9999+qOExERLVu2zM20bt260FpFzl+AUnruuecK5caMGZObufjii3MzF154YW7msMMOKzTT559/XihXH7niCAAAAIAkxREAAAAASYojAAAAAJIURwAAAAAkKY4AAAAASFIcAQAAAJCkOAIAAAAgSXEEAAAAQFJ5bQ/A2qlJkyYlWefzzz8vyTpAcY0aNSqU6969e0n2W7x4cW5myZIlJdkLoLYsW7YsN3PIIYfkZn70ox/lZl588cVCMx1++OGFcgA17aabbsrNHHvssbmZAw44IDdz3nnnFZrp+eefL5Srj1xxBAAAAECS4ggAAACAJMURAAAAAEmKIwAAAACSFEcAAAAAJCmOAAAAAEhSHAEAAACQpDgCAAAAIElxBAAAAEBSeW0PwNrpyCOPzM188sknuZnzzz+/BNMAVVFRUVEo99RTT+Vmttpqq9zM66+/Xmg/gPrs+9//fm7mqKOOys1cf/31uRnPn4D6bu7cubmZfv365WZmzZqVmzn99NOLjBSHHHJIoVx95IojAAAAAJIURwAAAAAkKY4AAAAASFIcAQAAAJCkOAIAAAAgSXEEAAAAQJLiCAAAAIAkxREAAAAASeW1PQBrpyeffDI3c+mll+Zmpk6dWopxgCpYtmxZodzo0aNzM1mW5WaefvrpQvsB1LQTTzwxN3PeeecVWutvf/tbbuaaa67JzXz88ce5mS+//LLQTAD12ZtvvpmbmTJlSm5m8ODBhfbbYostcjMvvfRSobXqGlccAQAAAJCkOAIAAAAgSXEEAAAAQJLiCAAAAIAkxREAAAAASYojAAAAAJIURwAAAAAkKY4AAAAASCrLsiwrFCwrq+5ZgHqg4JFRo5xPQITzCai7nE9QN6277rq5menTpxda6+STT87N3HXXXYXWqklFzidXHAEAAACQpDgCAAAAIElxBAAAAECS4ggAAACAJMURAAAAAEmKIwAAAACSFEcAAAAAJCmOAAAAAEgqy7IsKxQsK6vuWYB6oOCRUaOcT0CE8wmou5xPQF1V5HxyxREAAAAASYojAAAAAJIURwAAAAAkKY4AAAAASFIcAQAAAJCkOAIAAAAgSXEEAAAAQJLiCAAAAIAkxREAAAAASYojAAAAAJIURwAAAAAkKY4AAAAASFIcAQAAAJCkOAIAAAAgSXEEAAAAQJLiCAAAAIAkxREAAAAASYojAAAAAJLKsizLansIAAAAAOoeVxwBAAAAkKQ4AgAAACBJcQQAAABAkuIIAAAAgCTFEQAAAABJiiMAAAAAkhRHAAAAACQpjgAAAABIUhwBAAAAkKQ4AgAAACBJcQQAAABAkuIIAAAAgCTFEQAAAABJiiMAAAAAkhRHAAAAACQpjuqprl27xhFHHFHbYwCsxPkE1FXOJ6Cucj5RlymOVsGNN94YZWVllX+aNGkSPXr0iBNPPDHef//92h4v16xZs1aY/9///Pa3v63yen369PmP6/37n3PPPbf0d6YEjjjiiOS8X/va12p7NKiy+n4+RUS8/vrrMWTIkGjdunU0a9Ysdt9995g6deoqrVXfz6eIiCuvvDJ69uwZjRs3js6dO8eIESNi4cKFtT0WVNmacD5VVFTEuHHjolu3btGkSZPYeuut47bbblultdaE8+nll1+O/v37R4sWLaJNmzZx2GGHxdy5c2t7LKiyNeF8ioiYOXNmDB8+PNq3bx9NmzaNzTbbLEaPHl3lddaE86mioiKuueaa2HbbbaNp06bRtm3b+MY3vhHTp0+v7dHqpfLaHqA+O++886Jbt26xePHimDZtWlxzzTVxzz33xAsvvBDNmjWr7fFy/c///E8MGDBghdt22WWXKq8zevTo+P73v1/58ZNPPhm/+MUvYtSoUdGzZ8/K27feeutVH7aaNW7cOK677roVbmvVqlUtTQOrr76eT2+99Vbssssu0bBhwzjttNOiefPmccMNN8Q+++wTDzzwQOy5555VWq++n0+nn356jBs3LoYMGRInn3xyvPTSSzF+/Ph48cUX47777qvt8WCV1NfzKeKrM+WnP/1pHH300bHjjjvGH//4xxg+fHiUlZXFsGHDqrxWfT6f3n777dhzzz2jVatWceGFF8aCBQvikksuiX/84x/xxBNPxDrrrFPbI0KV1efz6bnnnos+ffpE586d48c//nG0bds23nzzzXjrrbeqvFZ9P58iIr73ve/FxIkT47vf/W6ceOKJsXDhwnj22Wfjgw8+qO3R6qeMKrvhhhuyiMiefPLJFW4fMWJEFhHZrbfe+h+/dsGCBSWZoUuXLtnhhx++Sl/7xhtvZBGRXXzxxSWZ5f+aNGlSFhHZ1KlT/2uuVI/F6jr88MOz5s2b1/YYUBL1/Xw64YQTsvLy8mzGjBmVty1cuDDbaKONsu222261Z6tP59O7776blZeXZ4cddtgKt48fPz6LiOyuu+6qpclg1dT38+ntt9/OGjVqlP3gBz+ovK2ioiLbY489sg033DBbunTpas1Wn86nLMuy448/PmvatGk2e/bsytv++te/ZhGRXXvttbU4GVRdfT+fli1blm211VbZTjvtlC1atKgk8/y7+nY+3X777VlEZHfeeWdtj7LG8FK1EvrGN74RERFvvPFGRHz1EqgWLVrEzJkzY8CAAdGyZcs45JBDIuKrS+cuv/zy2HLLLaNJkybRoUOHOPbYY+Pjjz9eYc0sy2Ls2LGx4YYbRrNmzaJv377x4osvJvefOXNmzJw5s0ozL1y4ML788suq3tUqO/fcc6OsrCxeeumlGD58eLRu3Tp23333iPjqUsg+ffqs9DVHHHFEdO3adYXbij5u8+fPjxkzZsT8+fMLz7hs2bL49NNPq3zfoD6oL+fTww8/HL169YrNN9+88rZmzZrF4MGD45lnnonXXnttle7/f1NXz6fHHnssli5dutJVDMs/XpWXFkNdVF/Opz/+8Y+xZMmSOOGEEypvKysri+OPPz7efvvteOyxx1bp/v83dfV8ioi44447YtCgQbHxxhtX3tavX7/o0aNH/O53v6v6nYU6qL6cT/fff3+88MILcc4550TTpk1j0aJFsWzZstW567nq8vl06aWXRu/evWP//fePiooKL/EvAcVRCS3/R922bdvK25YuXRr77rtvtG/fPi655JI48MADIyLi2GOPjdNOOy122223uOKKK+LII4+MiRMnxr777htLliyp/PoxY8bE2WefHdtss01cfPHFsckmm8Q+++yT/Mu/9957x95771143p/85CfRokWLaNKkSey4445x//33r+pdL+yggw6KRYsWxYUXXhhHH310lb++6OM2efLk6NmzZ0yePLnQuosWLYp11103WrVqFW3atIkf/OAHsWDBgirPB3VVfTmfvvjii2jatOlKty+/PPzpp5+u2h2vgrp2Pn3xxRcRESs9HjXxWEBNqi/n07PPPhvNmzdf4WUaERG9e/eu/Hx1qWvn0zvvvBMffPBB7LDDDit9rnfv3tX6WEBNqi/n05QpUyLiq7ff2GGHHaJ58+bRrFmzGDZsWHz00Uer9RjkqWvn06effhpPPPFE7LjjjjFq1Kho1apVtGjRIjbZZBOl9mrwHkerYf78+TFv3rxYvHhxPPLII3HeeedF06ZNY9CgQZWZL774Ig466KC46KKLKm+bNm1aXHfddTFx4sQYPnx45e19+/aN/v37x6RJk2L48OExd+7cGDduXAwcODD+9Kc/RVlZWUR89ZrTCy+8cJXnbtCgQeyzzz6x//77R+fOneOf//xnXHrppfGtb30r7rrrrhg4cOAqr51nm222iVtvvXWVvrbo41ZVHTt2jJEjR8Z2220XFRUVce+998bVV18d06dPjwcffDDKy/0zof6pr+fT5ptvHg8//HB89tln0bJlyxXmivjqm5XqUtfOp+VXXT3yyCPRt2/fytsffvjhiKjexwKqU309n+bMmRMdOnSoXG+5jh07RkTEu+++u8pr56lr59OcOXMi4l/3/d917NgxPvroo/jiiy+icePGqzQz1Jb6ej4tvyL74IMPjv79+8eZZ54Z06dPj4suuijeeuutmDZt2kpnV6nUtfNp5syZkWVZ/Pa3v43y8vIYN25ctGrVKq644ooYNmxYrLvuutG/f/9Vmndt5jvi1dCvX78VPu7SpUtMnDgxOnfuvMLtxx9//AofT5o0KVq1ahXf/OY3Y968eZW3b7/99tGiRYuYOnVqDB8+PKZMmRJffvll/PCHP1zhH/opp5ySPFhmzZpVaO6NN954pTdVPeyww2KLLbaIH//4x9VaHB133HGr/LVFH7eIry6DLPrrLP/90I/46mUgPXr0iNGjR8fvf//7Kr/ZJdQF9fV8Ov744+NPf/pTDB06NC644IJo3rx5XH311fHUU09FRMTnn39eaJ1VUdfOp+222y522mmn+NnPfhadO3eOvn37xssvvxzHH398NGrUqFofC6hO9fV8+vzzz5NFSJMmTSo/X13q2vm0/L7mPR6KI+qb+no+LX+lxI477hi33HJLREQceOCB0axZszjzzDPjgQceWOm+lUpdO5+WPxYffvhhPP7447HTTjtFRMTgwYOjW7duMXbsWMXRKlAcrYarrroqevToEeXl5dGhQ4fYfPPNo0GDFV/9V15eHhtuuOEKt7322msxf/78aN++fXLd5e/0Pnv27IiI2GyzzVb4fLt27aJ169aluhsREdGmTZs48sgj46c//Wm8/fbbK81cKt26dVvlry36uJXCj370ozj77LNjypQpiiPqpfp6Pn3rW9+K8ePHxxlnnBHbbbddRERsuummccEFF8TIkSOjRYsWq7x2nrp4Pt1xxx0xdOjQ+N73vhcREQ0bNowRI0bEQw89FK+88soqzwu1qb6eT02bNq18Cem/W7x4ceXnq0tdO5+W39faejygutTn8yniq9+a/e+GDx8eZ555Zjz66KPVVhzV1fOpW7dulaVRRESLFi1iv/32i1tuuSWWLl3qVSVV5NFaDb17906+tvvfNW7ceKXDpqKiItq3bx8TJ05Mfk27du1KNmNVbLTRRhER8dFHH1VbcZR6ElFWVhZZlq10+/99Q7eafNyaNm0abdu2rfbXBEN1qc/n04knnhhHHnlkPP/887HOOuvEtttuG9dff31ERPTo0aPa9q2L51Pnzp1j2rRp8dprr8V7770Xm222WWywwQbRqVOnan0soDrV1/OpY8eOMXXq1MiybIUrBZa/bKtTp07VtnddO5+Wv0Rt+X3/d3PmzIk2bdq42oh6qb6eT8vPnw4dOqxw+/JC5v++0XQp1bXz6T89FhFfPR5LliyJhQsXRqtWraq89tpMcVQLunfvHlOmTInddtvtv/40pkuXLhHxVRO7ySabVN4+d+7cavnH/89//jMiar64at26deXe/255I79c0cetFD777LOYN29erZV4UFvqyvnUvHnz2GWXXSo/njJlSjRt2jR222231V67KurK+bTZZptV/nTypZdeijlz5hR+OS6sKWr7fNp2223juuuui5dffjm22GKLytv//ve/V36+JtXm+dS5c+do165d5cuI/90TTzxR448F1LbaPp+23377+NWvfrXS+x8uf++1ten7u06dOsUGG2yQfC/Id999N5o0abLC+2hSjN+qVgsOPvjgWLZsWZx//vkrfW7p0qXxySefRMRXr7Ft1KhRjB8/foXG9vLLL0+uW/TXNc6dO3el295555349a9/HVtvvXXyjQ6rU/fu3WPGjBkrzDV9+vR45JFHVsgVfdwiiv+6xsWLF8dnn3220u3nn39+ZFnm9a+sdWr7fEp59NFH484774yjjjqqxn86VJvnU0pFRUWMHDkymjVrtlrvKQD1UW2fT9/+9rejUaNGcfXVV1felmVZTJgwITp37hy77rpr1e7Qaqrt8+nAAw+MP//5z/HWW29V3vbAAw/Eq6++GgcddNAq3COov+rC+dS4ceO44YYboqKiovL26667LiIivvnNb1bh3qy+2j6fhg4dGm+99Vb89a9/rbxt3rx58cc//jG+8Y1vrHTFGAVkVNkNN9yQRUT25JNP/tfc4YcfnjVv3jz5uWOPPTaLiOxb3/pWdtlll2VXXnlldvLJJ2edOnXKJk2aVJk788wzs4jIBgwYkF155ZXZUUcdlXXq1Clbf/31s8MPP3yFNbt06ZJ16dIld/4jjjgi22OPPbJzzz03++Uvf5mNGjUqa9u2bbbOOutkU6dOTd7XG264IXfd5SZNmpRFxAprnXPOOVlEZHPnzl0p/9JLL2UNGjTIevXqlV155ZXZmDFjsvbt22df//rXV7o/RR+3onO/8cYb2XrrrZcdf/zx2RVXXJFdccUV2YABA7KIyPr3758tW7as8P2GuqC+n0+zZs3KevfunY0dOza77rrrsh/96EdZ06ZNs169emWffvpp8r6uqedTlmXZSSedlB1zzDHZ1VdfnV1xxRXZTjvtlJWVlWU33XRT4fsMdUV9P5+yLMtOO+20LCKyY445JvvVr36VDRw4MIuIbOLEicn7uiafT2+++WbWtm3brHv37tkvfvGL7MILL8xat26dff3rX88WL15c+H5DXbAmnE/nnXdeFhHZN7/5zeyqq67KjjnmmKysrCz7n//5n+R9XZPPp/feey/r2LFj1rJly+ycc87JLr300qxHjx5Z06ZNs+eee67w/eZfvFStlkyYMCG23377uPbaa2PUqFFRXl4eXbt2jUMPPXSFl2KMHTs2mjRpEhMmTIipU6fGTjvtFPfff/9q/eazffbZJyZMmBBXXXVVfPzxx7HeeuvFnnvuGWeddVblm9Eut/xd6avzKqSePXvGTTfdFGPGjIkRI0bEFltsETfffHPceuut8eCDD66QLfq4FbXeeuvFoEGD4q9//Wv85je/iWXLlsWmm24aF154YZx66qnaaNZKtXk+rbvuutGxY8e48sor46OPPorOnTvHSSedFKNHj17psuI1/XyKiOjVq1dcfvnlMXHixGjQoEH07t07Hnjggejbt28J7h3UP7V5PkVE/PSnP43WrVvHtddeGzfeeGNsttlmccstt6z066LXhvNpo402ioceeihGjBgRZ5xxRqyzzjoxcODA+PnPf+79jVgr1fb5dNZZZ0Xr1q1j/Pjxccopp8QGG2wQo0ePjjFjxqyQWxvOpw4dOsS0adPi1FNPjcsuuyyWLFkSu+yyS9xyyy2xzTbblOAern3KsizxrlXw/x188MExa9aseOKJJ2p7FIAVOJ+Ausr5BNRVzidWhSuO+I+yLIsHH3wwbrnlltoeBWAFziegrnI+AXWV84lV5YojAAAAAJK8gQsAAAAASYojAAAAAJIURwAAAAAkKY4AAAAASFIcAQAAAJBUXjRYVlZWnXMA9URd/EWMzicgwvkE1F3OJ6CuKnI+ueIIAAAAgCTFEQAAAABJiiMAAAAAkhRHAAAAACQpjgAAAABIUhwBAAAAkKQ4AgAAACBJcQQAAABAkuIIAAAAgCTFEQAAAABJiiMAAAAAkhRHAAAAACQpjgAAAABIUhwBAAAAkKQ4AgAAACBJcQQAAABAkuIIAAAAgCTFEQAAAABJiiMAAAAAkhRHAAAAACQpjgAAAABIUhwBAAAAkKQ4AgAAACBJcQQAAABAkuIIAAAAgCTFEQAAAABJiiMAAAAAksprewAAAABYkzVu3LhQ7pFHHsnN9OrVKzfzpz/9KTfzne98p8hI4IojAAAAANIURwAAAAAkKY4AAAAASFIcAQAAAJCkOAIAAAAgSXEEAAAAQJLiCAAAAIAkxREAAAAASeW1PQD8J61bt87NbLzxxjUwyb/Mnj07N/OjH/2o0FovvPBCbubVV1/NzUyfPr3QfgDAV3bffffczGOPPZab2XzzzXMzgwYNKjTTwIEDczN33313obXyPProo4Vy06ZNK8l+sKZr3Lhxbuayyy4rtNa2226bm8myLDfz9NNPF9oPinDFEQAAAABJiiMAAAAAkhRHAAAAACQpjgAAAABIUhwBAAAAkKQ4AgAAACBJcQQAAABAkuIIAAAAgKSyLMuyQsGysuqehTXEwIEDczODBw/OzfTp0yc3s+mmmxYZqWReffXV3EyXLl0KrdW4cePVHSciIho2bFiSdYoqeGTUKOcTEOF8WtOtu+66uZmJEycWWusb3/hGbubzzz/Pzayzzjq5mRYtWhSaqSYVuW8REYsWLcrNHH/88bmZ3//+94X2W5M5n9Zsp512Wm7moosuKrTW//7v/+ZmxowZk5t5/PHHC+0HRc4nVxwBAAAAkKQ4AgAAACBJcQQAAABAkuIIAAAAgCTFEQAAAABJiiMAAAAAkhRHAAAAACQpjgAAAABIKq/tAah+3bt3z8384Ac/yM0cffTRhfZr2rRpbqasrKzQWnVNjx49ansEAFgr/exnP8vNDBw4sGT7FXk+8/LLL+dm5s6dW2i/Tz/9tFAuT5HnWEUfpyKPwfXXX5+befXVV3Mzzz//fKGZoC7aYIMNSrbWlClTcjOPP/54yfaDIlxxBAAAAECS4ggAAACAJMURAAAAAEmKIwAAAACSFEcAAAAAJCmOAAAAAEhSHAEAAACQpDgCAAAAIElxBAAAAEBSeW0PQPXbcMMNczMnn3xyDUxSt82YMSM38+KLL9bAJMC/23TTTXMz66+/fqG19t9//9xMnz59cjMVFRW5mQkTJhQZKR555JHczOuvv15oLaivttxyy9zMkCFDSrbf22+/nZv57ne/m5sp8m/zk08+KTJSLFiwoFAuT4MG+T8XHjNmTKG1zjrrrNzMuuuum5s555xzcjPf//73C8308ccfF8pBTWrZsmVuZsmSJYXWmjJlyuqOAyXniiMAAAAAkhRHAAAAACQpjgAAAABIUhwBAAAAkKQ4AgAAACBJcQQAAABAkuIIAAAAgCTFEQAAAABJ5bU9wJpm/fXXz82cfPLJuZlHHnmk0H733ntvbuaLL77IzcyfPz83s3DhwkIzNW/ePDdz//3352ZeeOGF3Mzf//73QjM9++yzuZnPP/88N1P0MQAittpqq9zMiSeemJs54IADcjNFzt6attNOOxXKLV26NDfzyiuv5GamTZuWmyny/5+IiC+//LJQDkqlZcuWuZm2bdvmZrIsK7Tfz372s9zMgw8+WGituqaioiI3c+655xZaa5111snNnHrqqbmZ/fffPzfz61//utBMd999d6EclEqnTp1yM0cddVRu5tFHHy203zPPPFMoBzXJFUcAAAAAJCmOAAAAAEhSHAEAAACQpDgCAAAAIElxBAAAAECS4ggAAACAJMURAAAAAEmKIwAAAACSymt7gPqkefPmuZn7778/N7PNNtvkZvbff/9CMxXx+OOP52a222673MysWbMK7bfxxhvnZt5+++3cTEVFRaH9gNLZeuutczM/+MEPCq01dOjQ3My6665baK0877zzTqHcww8/nJt54403cjMjR47MzTz99NOFZurdu3dupk2bNrmZAQMG5GamT59eaKYJEyYUykGpNG7cuCTr/OY3vymUu+qqq0qy35pu1KhRuZkiZ323bt1yMwcccEChme6+++5COSiVs846q7ZHWKvsvPPOhXIbbbRRSfYr8tzo1VdfLcle9ZkrjgAAAABIUhwBAAAAkKQ4AgAAACBJcQQAAABAkuIIAAAAgCTFEQAAAABJiiMAAAAAkhRHAAAAACSV1/YAdcE666xTKHfrrbfmZrbZZpvczIUXXpibmTJlSqGZSmXWrFklW+vNN98s2VpA6Vx77bW5mf333z83s/7665dinIiIeOCBB3Iz//jHP3Izo0aNKrTf4sWLC+Xy7LrrrrmZ448/vtBav/71r3Mz2267bW7m/fffz81cddVVRUaKO+64Izczd+7cQmtBEeeff35J1vn73/9eknUo7r777svNHHfccbmZnXfeuRTjQMkNHDiwJOtcf/31JVmnrrrmmmtyM0Uey9atWxfar2nTpoVyeT799NPczGWXXVZorVL9v6wucsURAAAAAEmKIwAAAACSFEcAAAAAJCmOAAAAAEhSHAEAAACQpDgCAAAAIElxBAAAAECS4ggAAACAJMURAAAAAEnltT1AdWvRokVu5swzzyy01qBBg3Iz8+bNy81ccskluZlFixYVmglYszVp0qRQbuTIkbmZ73//+7mZsrKy3MzcuXMLzXTNNdfkZi6++OLczMKFCwvtV5Patm2bm2nYsGGhtc4999zczL333pub6dKlS6H9oKZtsskmuZlOnTrlZubPn5+b+cc//lFoJkrnf//3f3Mzxx13XA1MAlXXrFmz3Ex5ef63zO+8805u5sYbbywyUskUmXu77bYrtNbkyZNzMxtssEFupkGD/OtWij7PnDJlSm6myP3beOONczPHHHNMoZluuumm3Mzs2bMLrVXXuOIIAAAAgCTFEQAAAABJiiMAAAAAkhRHAAAAACQpjgAAAABIUhwBAAAAkKQ4AgAAACBJcQQAAABAUnltD1DdvvOd7+RmzjjjjEJrvfnmm7mZPfbYIzczf/78QvsB9OnTp1DutNNOy82UlZXlZt55553czIEHHlhopieeeKJQriY1bNgwN7PRRhvlZm666abczD333FNoptatWxfK5Sny3/fmm28utNYnn3yymtPAvxx66KG5mU022SQ3c8cdd+RmHn300UIzAUREfP/738/NdOjQITfzy1/+shTjFNapU6fczDHHHJObOeuss0oxTkREvPvuu7mZIs9Drr766kL7vf3224Vyee66667czIABAwqt1bFjx9zM7NmzC61V17jiCAAAAIAkxREAAAAASYojAAAAAJIURwAAAAAkKY4AAAAASFIcAQAAAJCkOAIAAAAgSXEEAAAAQFJ5bQ9Q3XbdddeSrfXss8/mZt5+++2S7QfQsGHDQrlly5aVZL+lS5fmZnbaaadCaw0ZMiQ387Wvfa3QWnk+//zzQrmePXuWJDNv3rzcTIcOHQrNVCrvv/9+bmbs2LGF1lqyZMnqjgOVhg0blpuZP39+buaKK64oxTgAlXr16lWSdV577bWSrFPUWWedlZs59thjczNZlhXa73//939zMz/60Y9yMy+++GKh/WpSTf+3q69ccQQAAABAkuIIAAAAgCTFEQAAAABJiiMAAAAAkhRHAAAAACQpjgAAAABIUhwBAAAAkKQ4AgAAACCpvLYHqG5Dhgwp2Vr9+/fPzZxzzjm5mT/+8Y+5meeee67ISMAa7n//938L5aZOnZqb6devX25m4403zs384he/KDRTlmWFcnmWLVuWm2nYsGFJ9iqqQ4cOJVuroqIiNzN58uTczEknnZSbmTNnTqGZoKbNmDEjNzNt2rQamARYm3Tq1Km2R1hJjx49cjNDhw4tyV6/+tWvCuVOPvnk3MyXX365uuPUWc8880xJc/WRK44AAAAASFIcAQAAAJCkOAIAAAAgSXEEAAAAQJLiCAAAAIAkxREAAAAASYojAAAAAJIURwAAAAAkKY4AAAAASCqv7QGqW7t27XIzFRUVhdZq3LhxbmbMmDG5mbPOOis3M2HChEIzPf7447mZjTfeODfz+uuv52ZefPHFQjMVseWWW+ZmHnvssdzM22+/XYpxoM76/PPPC+X233//3Mx6662XmznjjDNyM7vttluRkeLDDz/Mzbz55pu5mSJn7zbbbFNopt69exfK1aRf/vKXuZlRo0blZj755JMSTAPFNW/evFCuUaNG1TwJwKpp2bJlbqasrKwGJvmXH/7wh7mZIs/pbr311tzM8ccfX2SkNVqRvwNLliwptNaXX365uuPUWa44AgAAACBJcQQAAABAkuIIAAAAgCTFEQAAAABJiiMAAAAAkhRHAAAAACQpjgAAAABIUhwBAAAAkFRe2wNUt0suuSQ3M2LEiBqY5F8aNMjv60444YRCaxXN1Udz587NzTz44IOF1ho2bNhqTgP13yeffJKbOeOMM6p/kGpw0003Fcr17t27JPt99tlnuZmi/2+58cYbczPLli0rtBbUpIMPPrhQrnv37rmZefPmre441JLBgweXZJ2lS5eWZB2oiizLSpIppY4dO+ZmisxUZJ01XadOnXIzRx11VG7mzjvvLMU49ZorjgAAAABIUhwBAAAAkKQ4AgAAACBJcQQAAABAkuIIAAAAgCTFEQAAAABJiiMAAAAAkhRHAAAAACSV1/YA1e2MM87Izdx+++2F1rr11ltzM+Xl+Q/pRhttlJtp0ECn165du9zMkCFDCq111lln5WbGjh1baC2gZo0cOTI3M2zYsBqY5F+OO+643Mxtt91WA5MAVJ/tt98+NzNo0KCS7DVq1KiSrAP13bHHHpub2W233UqSOfPMMwvN9Mtf/jI38+GHHxZaqybdeeeduZlFixblZn7+85+XYpx6TTsBAAAAQJLiCAAAAIAkxREAAAAASYojAAAAAJIURwAAAAAkKY4AAAAASFIcAQAAAJCkOAIAAAAgqby2B6huy5Yty8089dRThdbq0aPH6o4TERF77713bqZRo0aF1jr33HNzMzvuuGOhteqjsrKyQrntt9++micBVsX3v//93MxZZ52VmykvL93/zl588cXczJ133lmy/QBqWtHnRSNGjMjNrLfeermZRx55JDdz3333FRkJCunUqVOhXMeOHat5kqr78MMPczPbbbddbuauu+7KzZx//vmFZurfv39uZtCgQbmZzz77rCTrRBR7ftirV6/czNixY3Mzjz/+eKGZ1mSuOAIAAAAgSXEEAAAAQJLiCAAAAIAkxREAAAAASYojAAAAAJIURwAAAAAkKY4AAAAASFIcAQAAAJCkOAIAAAAgqby2B1gbPfDAAyVba9ttt83N7LjjjrmZpUuX5mZuuOGGIiPFr371q9zMKaeckpsZPnx4of2Auql37965mZ///Oe5mRYtWpRinIiIWLBgQW7muOOOy8188cUXpRgH6rVZs2YVyn322WfVOwgraNiwYW7m1FNPLbTW0KFDczPvvPNOSfYr8lwUinr33XcL5V577bXcTJcuXXIz3/jGN3Iz1157baGZFi1alJuZM2dObqbI94CDBg0qNNPLL7+cm1lvvfVyM0We9x111FFFRir0OI0dOzY3c/755xfab23niiMAAAAAkhRHAAAAACQpjgAAAABIUhwBAAAAkKQ4AgAAACBJcQQAAABAkuIIAAAAgCTFEQAAAABJ5bU9AKvn/vvvz81ccMEFuZny8vy/CkcffXShmTbddNPcTJ8+fQqtVSpvv/12je4HROy33365mZYtW5Zkr4ULFxbKDR48ODfzyCOPrO44sFaYOnVqodw777yTm1l33XVzM+uvv35uZt68eYVmqou23nrr3MwJJ5yQm9luu+1yMzvssEOhmYo49NBDczN///vfS7YflNJRRx2Vm7n77rtzMwMGDMjN3HfffYVmuvTSS3Mzc+bMKbRWnp122qlQ7swzzyzJWmVlZbmZV155pdBMo0ePzs1Mnjy50Frkc8URAAAAAEmKIwAAAACSFEcAAAAAJCmOAAAAAEhSHAEAAACQpDgCAAAAIElxBAAAAECS4ggAAACApLIsy7JCwbKy6p6FVdC0adPczK9//evczMEHH1yKcUpq2bJluZm777670FqHHnpobmbhwoWF1lrbFTwyapTzqWa1bNmyUG7evHm5mUaNGq3uOBER8ctf/rJQ7rjjjivJftRNzqe66aWXXsrNfO1rX8vNPPPMM7mZOXPmFJqpLtp5551zM23bti3JXkXO54iIu+66Kzdz0kkn5WYWLVpUaL81mfOp/urYsWNuZurUqbmZTTfdtBTjFFbkv29N/7288cYbczOnn356obU+/PDD1ZyG5Yr8PXDFEQAAAABJiiMAAAAAkhRHAAAAACQpjgAAAABIUhwBAAAAkKQ4AgAAACBJcQQAAABAkuIIAAAAgKSyLMuyQsGysuqehWrSoUOH3Mx1112Xm9lhhx0K7de+ffvczKxZs3IzN998c27m3HPPLTARpVTwyKhRzqfSadGiRW7m5ZdfLrRW586dV3eciIh4/vnnczM777xzobUWL168uuNQhzmf6qb9998/N3PWWWflZnr16lWKceq1ioqK3MxHH32Um7n00ksL7ffTn/60UI58zqc123rrrZebGTp0aKG1Nt1009zM0UcfnZsp8v1dKf9eXn/99bmZGTNmlGw/SqfI3wNXHAEAAACQpDgCAAAAIElxBAAAAECS4ggAAACAJMURAAAAAEmKIwAAAACSFEcAAAAAJCmOAAAAAEhSHAEAAACQVJZlWVYoWFZW3bNQxx122GGFcjvvvHNu5ic/+Ulu5oMPPii0HzWr4JFRo5xPpTN48ODczB//+MdCa5Xq78ree++dm5k6dWpJ9qJ+cz7VX506dcrN3HvvvbmZrbbaqhTj1Ipf/epXuZlnn302NzNhwoRSjEOJOZ+AuqrI+eSKIwAAAACSFEcAAAAAJCmOAAAAAEhSHAEAAACQpDgCAAAAIElxBAAAAECS4ggAAACAJMURAAAAAEllWZZlhYJlZdU9C1APFDwyapTzqXSmT5+em/n6179esv0uvvji3Mzpp59esv1YszmfgLrK+QTUVUXOJ1ccAQAAAJCkOAIAAAAgSXEEAAAAQJLiCAAAAIAkxREAAAAASYojAAAAAJIURwAAAAAkKY4AAAAASCqv7QEAqDvatGmTmykrKyu01gcffJCbufzyywutBQAA1A5XHAEAAACQpDgCAAAAIElxBAAAAECS4ggAAACAJMURAAAAAEmKIwAAAACSFEcAAAAAJCmOAAAAAEgqr+0BAKg7Lr300pJkIiLOP//83MycOXMKrQUAANQOVxwBAAAAkKQ4AgAAACBJcQQAAABAkuIIAAAAgCTFEQAAAABJiiMAAAAAkhRHAAAAACQpjgAAAABIUhwBAAAAkFSWZVlWKFhWVt2zAPVAwSOjRjmfgAjnE1B3OZ+AuqrI+eSKIwAAAACSFEcAAAAAJCmOAAAAAEhSHAEAAACQpDgCAAAAIElxBAAAAECS4ggAAACAJMURAAAAAEllWZZltT0EAAAAAHWPK44AAAAASFIcAQAAAJCkOAIAAAAgSXEEAAAAQJLiCAAAAIAkxREAAAAASYojAAAAAJIURwAAAAAkKY4AAAAASFIcAQAAAJCkOAIAAAAgSXEEAAAAQJLiCAAAAIAkxREAAAAASYqjeqpr165xxBFH1PYYACtxPgF1lfMJqKucT9RliqNVcOONN0ZZWVnlnyZNmkSPHj3ixBNPjPfff7+2xyvk9ddfjyFDhkTr1q2jWbNmsfvuu8fUqVNXaa0+ffqs8Hj8pz/nnntuae9ECV155ZXRs2fPaNy4cXTu/P/au/c4Lcs6f+Df0UE5qJxVREUjThImIPYyU2F1UdQIRczY1DTFQDcVlVBDDiKaiGGoIVlqgu1rUVk185AsILi+Fjc0dzmUJyiLVlBDAfE09+8PfkzOctl9Mzxzgvf7v3nmM9f9fW7Gy3s+c8/ztI+RI0fGhg0b6nos2GY7wv5UUVERN910Uxx88MHRuHHjOPTQQ+MXv/hFtdbaEfan5cuXx4knnhh77LFHtGrVKs4666xYs2ZNXY8F22xH2J+uv/76GDhwYOyzzz7bvXd861vfKrQ/1dcfJH/3u9/FZZddFl/+8pejcePGUVZWFitXrqzrsaBaGvr+tHLlys/cQ/7lX/5lm9dr6NdPn7W/du3ata5Ha7DK63qAhmzChAlx8MEHx6ZNm2LRokXx4x//OH71q1/F//zP/0TTpk3rerzP9Mc//jGOPPLI2HXXXePKK6+MZs2axd133x39+/ePuXPnxjHHHLNN611zzTVx/vnnV378/PPPx49+9KO4+uqro1u3bpWPH3rooSV7DqX0ve99L2666aY4/fTT45JLLolly5bFtGnTYunSpfHkk0/W9XhQLQ11f4rYvKfceOONccEFF0SfPn3i4YcfjqFDh0ZZWVmceeaZ27xWQ96f3njjjTjmmGOiefPmMWnSpFi/fn3cfPPN8d///d+xePHi2G233ep6RNhmDXl/+v73vx/77rtv9OzZc7uvES688MI4/vjjKz9+/fXX49prr41hw4bF0UcfXfl4x44dt+s4NeW5556LH/3oR3HIIYdEt27d4sUXX6zrkWC7NeT9KSLiG9/4Rpx00klVHjvyyCO3eZ2Gfv0UEbH77rvHXXfdVeWx5s2b19E0O4CMbXb33XdnEZE9//zzVR4fOXJkFhHZ/fff/5lfu379+pLM0KFDh+ycc86p1teOGDEiKy8vz1asWFH52IYNG7IDDjgg69Wr13bPNnv27Cwisnnz5v3dXKnOxfb485//nJWXl2dnnXVWlcenTZuWRUT2yCOP1NFkUD0NfX964403skaNGmUXXXRR5WMVFRXZ0Ucfne2///7Zxx9/vF2zNaT9KcuybPjw4VmTJk2yVatWVT7261//OouI7M4776zDyWDbNfT9Kcuy7PXXX8+yLMvWrFmTRUQ2duzYksyVZVn2/PPPZxGR3X333X83V1/2p7feeit79913syzLssmTJ2cRUXl+oKFp6PvT66+/nkVENnny5JLM8n81tOunc845J2vWrFldj7FD8adqJfQP//APEbH5N0YRm2+R22OPPeLVV1+Nk046Kfbcc8/4p3/6p4jY/KcYU6dOje7du0fjxo1jn332iQsvvDDeeeedKmtmWRYTJ06M/fffP5o2bRr9+vWLpUuXJo//6quvxquvvpo758KFC6Nnz57RpUuXyseaNm0aAwcOjCVLlsTLL79cref/94wbNy7Kyspi2bJlMXTo0GjZsmV85StfiYjNt0L27dt3q6/51re+FQcddFCVx4qet3Xr1sWKFSti3bp1f3eu5557Lj7++OOt7mLY8nF1bu2E+qih7E8PP/xwfPTRRzFixIjKx8rKymL48OHxxhtvxHPPPVet5//31Nf9KSLiwQcfjFNOOSUOPPDAyseOP/746Ny5c/zrv/7rtj9ZqIcayv4UEVv9d1/Ttvz5zIIFC2LEiBGx9957x/777x8R6X0o4m972v81c+bM6N27dzRp0iRatWoVZ555Zvzxj3+sktm4cWOsWLEi1q5dmztbq1atYs8996zeE4MGoiHtT1ts2LAhPvzww219qtusPl8/bfHJJ5/Eu+++u83Pja0pjkpoy3/UrVu3rnzs448/jhNOOCH23nvvuPnmm2Pw4MERsfn25CuvvDKOOuqouPXWW+Pcc8+NWbNmxQknnBAfffRR5ddfe+21MWbMmPjiF78YkydPjs997nPRv3//5OvvHHfccXHcccflzvnBBx9EkyZNtnp8y+2Xv/nNb7btiW+DIUOGxMaNG2PSpElxwQUXbPPXFz1vc+bMiW7dusWcOXP+7noffPBBRMRW56M2zgXUpoayP73wwgvRrFmzKrdBR0QcccQRlZ+vKfVtf/rTn/4Ub775Zhx++OFbfe6II46o0XMBtamh7E91acSIEbFs2bK49tprY/To0dv89ddff32cffbZ0alTp7jlllvi0ksvrXx5gr/+9a+VucWLF0e3bt3itttuK+H00HA1tP1p/Pjxsccee0Tjxo2jT58+8dRTT1X3qRdW366ftti4cWPstdde0bx582jVqlVcdNFFsX79+m2ej828xtF2WLduXaxduzY2bdoUzz77bEyYMCGaNGkSp5xySmXmgw8+iCFDhsQNN9xQ+diiRYvirrvuilmzZsXQoUMrH+/Xr1+ceOKJMXv27Bg6dGisWbMmbrrppjj55JPj0Ucfrfzt0TXXXBOTJk2q9txdunSJhQsXxnvvvVflN0WLFi2KiM0/rNSUL37xi3H//fdX62uLnrdtseWuq2effTb69etX+fjChQsjombPBdSkhro/rV69uvJFZz+tXbt2ERHx5z//udpr56lv+9Pq1asj4m/P/dPatWsXb7/9dnzwwQex++67V2tmqCsNdX+qS61atYq5c+fGrrvuus1fu2rVqhg7dmxMnDgxrr766srHTzvttOjZs2fccccdVR6HnVlD3Z922WWX6N+/f5x66qnRvn37eO211+KWW26JAQMGxCOPPBInn3xytdfOU9+unyI2XyeNGjUqevXqFRUVFfHEE0/EHXfcEb/97W9j/vz5UV6uBtlWzth2+PQLGkZEdOjQIWbNmhXt27ev8vjw4cOrfDx79uxo3rx5/OM//mOVW4F79+4de+yxR8ybNy+GDh0aTz/9dHz44Yfxz//8z1V+iLr00kuTG0vRd7IYPnx4PProo/H1r389rr/++mjWrFnccccd8V//9V8REfH+++8XWqc6vvOd71T7a4uet4jNt0EWeReSXr16xZe+9KX4wQ9+EO3bt49+/frF8uXLY/jw4dGoUaMaPRdQkxrq/vT+++8ni5DGjRtXfr6m1Lf9actzzTsfiiMamoa6P9WlCy64oFqlUUTEQw89FBUVFXHGGWdUOW/77rtvdOrUKebNm1dZHPXt2zeyLCvJzNAQNdT96cADD9zqBfvPOuusOOSQQ+Lyyy+v0eKovl0/RUSVUi9i88uQdO7cOa655pp44IEHtvnNVlAcbZfbb789OnfuHOXl5bHPPvtEly5dYpddqv71X3l5eeXfom/x8ssvx7p162LvvfdOrvvmm29GxObfEEVEdOrUqcrn27ZtGy1btqz23AMGDIhp06bF6NGjo1evXhER8fnPfz6uv/76GDVqVOyxxx7VXjvPwQcfXO2vLXrettWDDz4YX//61+O8886LiIhdd901Ro4cGQsWLIjf/e531Z4X6lJD3Z+aNGlS+Sekn7Zp06bKz9eU+rY/bXmudXU+oKY01P2pLm3v/pRl2VbnY4tGjRpVe23Y0exI+1OrVq3i3HPPjRtvvDHeeOONrWYulfp2/fRZLrvsshgzZkw8/fTTiqNqUBxthyOOOCL52hOftvvuu2+12VRUVMTee+8ds2bNSn5N27ZtSzbjZ7n44ovj3HPPjZdeeil22223OOyww+KnP/1pRER07ty5xo6b+iGnrKws+dutTz75pMrHNXXe2rdvH4sWLYqXX345/vKXv0SnTp1i3333jf32269GzwXUpIa6P7Vr1y7mzZsXWZZV+U3clj/b2m+//Wrs2PVtf9ryJ2pbnvunrV69Olq1auVuIxqkhro/1aXP2p9SUvtTWVlZPP7448m7lmryF4bQ0Oxo+9MBBxwQERFvv/12jRVH9e366bM0adIkWrduHW+//XbJ1tyZKI7qQMeOHePpp5+Oo4466u/+trhDhw4RsbmJ/dznPlf5+Jo1a7Z6lfnqaNasWRx55JGVHz/99NPRpEmTOOqoo7Z77W3RsmXLeO2117Z6fEsjv0XR81ZdnTp1qmz/ly1bFqtXry58OyTsKOp6fzrssMPirrvuiuXLl8chhxxS+fh//ud/Vn6+NtXl/tS+ffto27Zt5Z8Rf9rixYtr/VxAXavr/am+admyZZUXtt4itT9lWRYHH3ywX4hBDamv+9OWa5jaLq7qy893n/bee+/F2rVrd+hfMtQk76pWB84444z45JNP4rrrrtvqcx9//HHlRcDxxx8fjRo1imnTplVpbKdOnZpctzpv17jFf/zHf8RDDz0U3/72t6N58+bVWqO6OnbsGCtWrIg1a9ZUPvbb3/42nn322Sq5ouctonpv17hFRUVFjBo1Kpo2bbpdf7MLDVFd709f+9rXolGjRnHHHXdUPpZlWUyfPj3at28fX/7yl7ftCW2nut6fBg8eHL/85S+rvGX23Llz4/e//30MGTKkGs8IGq663p/qm44dO8a6devipZdeqnxs9erVW73j0GmnnRa77rprjB8/fqs7ALIsi7feeqvy440bN8aKFSuqvNYIkK+u96dPX6ds8ac//Sl+9rOfxaGHHpp8o42aVJfXT5s2bYr33ntvq8evu+66yLIsTjzxxG18NkS446hOHHvssXHhhRfGDTfcEC+++GL0798/GjVqFC+//HLMnj07br311jj99NOjbdu2ccUVV8QNN9wQp5xySpx00knxwgsvxOOPPx5t2rTZat0tb9WY9yJqq1atijPOOCMGDhwY++67byxdujSmT58ehx566FYvynbPPffEueeeG3fffXeN3X1z3nnnxS233BInnHBCfPvb344333wzpk+fHt27d4933323Mlf0vEVsfrvGonNfcsklsWnTpjjssMPio48+ivvvvz8WL14c9957bxx44IE18pyhvqrr/Wn//fePSy+9NCZPnhwfffRR9OnTJ/7t3/4tFi5cGLNmzaryZxY7w/509dVXx+zZs6Nfv35xySWXxPr162Py5MnRo0ePOPfcc2vkOUN9Vdf7U0TEfffdF6tWrYqNGzdGRMQzzzwTEydOjIjNL0S75W6C+fPnR79+/WLs2LExbty40pyA/+PMM8+M733ve3HqqafGd7/73di4cWP8+Mc/js6dO8eSJUsqcx07doyJEyfGVVddFStXroxBgwbFnnvuGa+//nrMmTMnhg0bFldccUVEbL6bsejc69ati2nTpkVEVP4weNttt0WLFi2iRYsWcfHFF9fI84b6qK73p1GjRsWrr74axx13XOy3336xcuXKuPPOO2PDhg1x6623Vsnu6NdPf/nLX6Jnz57xjW98I7p27RoREU8++WT86le/ihNPPDG+9rWv1chz3tEpjurI9OnTo3fv3nHnnXfG1VdfHeXl5XHQQQfFN7/5zSp/KjZx4sRo3LhxTJ8+PebNmxdf+tKX4qmnntquV8bfa6+9ol27dnHbbbfF22+/He3bt4/vfve7cc0118See+5ZJbt+/fqISL8ddKl069Ytfv7zn8e1114bI0eOjEMOOSTuu+++uP/++2P+/PlVskXP27bo2bNnTJ06NWbNmhW77LJLHHHEETF37tzo169fCZ4dNDx1uT9FRNx4443RsmXLuPPOO+Oee+6JTp06xcyZM7d6O9adYX864IADYsGCBTFy5MgYPXp07LbbbnHyySfHlClTvL4RO6W63p9++tOfxoIFCyo/njdvXsybNy8iIr7yla9UFke1sT+1bt065syZEyNHjoxRo0bFwQcfHDfccEO8/PLLVYqjiIjRo0dH586d44c//GGMHz8+IjbvL/3794+BAwdW6/jvvPNOjBkzpspjU6ZMiYjNf46jOGJnU5f7U//+/WP69Olx++23xzvvvBMtWrSIY445Jr7//e9XvhnSFjv69VOLFi3ilFNOiV//+tdx7733xieffBKf//znY9KkSXHFFVds9fpUFFOWec9N/o4zzjgjVq5cGYsXL67rUQCqsD8B9dWoUaPiF7/4RbzyyitKXqBecf1EdbjjiM+UZVnMnz8/Zs6cWdejAFRhfwLqs3nz5sWYMWOURkC94vqJ6nLHEQAAAABJ/sAPAAAAgCTFEQAAAABJiiMAAAAAkhRHAAAAACQpjgAAAABIKi8aLCsrq8k5gAaiPr4Ro/0JiLA/AfWX/Qmor4rsT+44AgAAACBJcQQAAABAkuIIAAAAgCTFEQAAAABJiiMAAAAAkhRHAAAAACQpjgAAAABIUhwBAAAAkKQ4AgAAACBJcQQAAABAkuIIAAAAgCTFEQAAAABJiiMAAAAAkhRHAAAAACQpjgAAAABIUhwBAAAAkKQ4AgAAACBJcQQAAABAkuIIAAAAgCTFEQAAAABJiiMAAAAAkhRHAAAAACQpjgAAAABIUhwBAAAAkKQ4AgAAACBJcQQAAABAkuIIAAAAgCTFEQAAAABJiiMAAAAAkhRHAAAAACQpjgAAAABIUhwBAAAAkKQ4AgAAACBJcQQAAABAkuIIAAAAgCTFEQAAAABJ5XU9AAAANETjxo3LzYwdO7bQWvPnz8/N9OvXr9BawI6td+/euZlBgwblZgYPHlzoeF26dMnNlJWV5WayLMvNLFmypNBMy5cvz81MmjQpN7NixYpCx9vZueMIAAAAgCTFEQAAAABJiiMAAAAAkhRHAAAAACQpjgAAAABIUhwBAAAAkKQ4AgAAACBJcQQAAABAUnldDwDAzqtly5a5mcMOOyw3M2DAgELHu/LKK3MzFRUVuZkHHnggN7Nq1apCM02ZMiU387//+7+F1gJq17HHHluytfr27VuSzPz587d7FuBvhg0blpvp2rVrbuboo48uxTgREdGrV6/cTJZluZmysrJCxyuy1owZM3Izc+bMyc089dRThWaidrnjCAAAAIAkxREAAAAASYojAAAAAJIURwAAAAAkKY4AAAAASFIcAQAAAJCkOAIAAAAgSXEEAAAAQFJZlmVZoWBZWU3PAjQABbeMWmV/ql2NGjUqlLv88stzMxdddFFupl27doWOV0SR75Xa/h7/+c9/nps577zzamGShs/+RG2r7e+58ePH52bGjRtX84OwzexPDVdFRUVupsi/78aNGwsdb8WKFbmZhQsXlmSdNWvWFJppzpw5hXI0TEW+f91xBAAAAECS4ggAAACAJMURAAAAAEmKIwAAAACSFEcAAAAAJCmOAAAAAEhSHAEAAACQpDgCAAAAIElxBAAAAEBSWZZlWaFgWVlNz0INOeyww3Iz1113XW7mpJNOKnS8XXbJ7yMrKipyMw888EBu5pprrik00+rVq3Mz/fr1y83MnTs3N/P+++8XmqmhKrhl1Cr7U+26+OKLC+WmTp1as4NUwzPPPJObOeaYY2phkm1TXl5e1yM0CPYnalttf8/5fmq47E8NV5GfSQYNGpSbeeGFFwodr0+fPoVyUCpF9id3HAEAAACQpDgCAAAAIElxBAAAAECS4ggAAACAJMURAAAAAEmKIwAAAACSFEcAAAAAJCmOAAAAAEgqy7IsKxQsK6vpWfiURo0aFcode+yxuZm77747N9OuXbtCxyuiyPdKwW+7XDNnziyUO+CAA3Izffv2zc2cc845uZmiMzVUpfq3KyX7U+l07949N/Pv//7vhdZq3br19o5T2OjRowvlbr311tzMhAkTcjNXXnlloeOVSnl5ea0er6GyP1Hbavt7zvdTw2V/arjatm2bm1m8eHFuplmzZoWOd/jhh+dm/vCHPxRaC4oosj+54wgAAACAJMURAAAAAEmKIwAAAACSFEcAAAAAJCmOAAAAAEhSHAEAAACQpDgCAAAAIElxBAAAAEBSeV0PQFqvXr0K5Z544omSHG/16tW5mYsvvrjQWhs3btzecSIiokOHDrmZDRs2FFpr2rRpuZkPP/wwN1PkPEF91b1799zMDTfckJtp06ZNoeNlWZabWbVqVW5m4MCBuZnly5cXmqmioiI3c+211+Zm5syZk5t55JFHCs1U5Hy+9NJLuZlDDz200PGA0hk/fnxuZuzYsSU73rhx40qSAYpbs2ZNbmbGjBm5mYkTJxY6XpHrgj/84Q+F1oJScccRAAAAAEmKIwAAAACSFEcAAAAAJCmOAAAAAEhSHAEAAACQpDgCAAAAIElxBAAAAECS4ggAAACApPK6HmBn1L1799zMI488UrLjzZ07Nzdz1VVX5WaWLFlSinEK22+//XIzDz/8cKG1WrRokZuZPHlybqbIuYT6qlevXrmZk08+OTezyy7Ffufw4Ycf5mbuuOOO3MzSpUsLHa9UPvroo9zM4sWLczP33HNPoeNdfvnluZkePXrkZmbMmJGbGTZsWKGZgGLGjh1b1yMA9UCRa6OysrJCa3Xr1q1ka5XK8uXLczMbN26shUmoK+44AgAAACBJcQQAAABAkuIIAAAAgCTFEQAAAABJiiMAAAAAkhRHAAAAACQpjgAAAABIUhwBAAAAkKQ4AgAAACCpvK4H2BmNGTMmN9OmTZtCaz322GO5mZEjR+ZmXnnllULHq01f+MIXcjM9e/Ys2fGeeOKJkq0F9dGAAQNyM1mW5WYqKioKHW/+/Pm5mSlTphRaqyEaPXp0oVyRf5ci++Hhhx9e6HgAQHFt27bNzZx//vm5mSLXWBER9957b26mrKysJMcrsk5ExJw5c3Izs2bNKsk61E/uOAIAAAAgSXEEAAAAQJLiCAAAAIAkxREAAAAASYojAAAAAJIURwAAAAAkKY4AAAAASFIcAQAAAJBUXtcD7Gh+8pOf5GaGDBmSm9mwYUOh440ePTo388orrxRaqzY1atQoN3PVVVflZsrKygodb8GCBSXJQH3VunXr3MwRRxxRC5P8zX333Verx2uoipynH/zgB7UwCQDsXNq2bZubKfIzwoEHHpibWbJkSaGZli9fnptZtGhRobXyXHDBBYVyvXv3zs2cdtppuZksy3IzRa9Xi5ynjRs3FlqLfO44AgAAACBJcQQAAABAkuIIAAAAgCTFEQAAAABJiiMAAAAAkhRHAAAAACQpjgAAAABIUhwBAAAAkFRe1wPsaA4//PDcTJZluZn169cXOt6yZcsK5WpTo0aNcjPXXXddbuboo4/OzRQ5lxEREyZMKJSDhqp37965mYMOOqgkx1q4cGGh3GOPPVaS41FMy5YtczPt2rUrtNbq1au3dxwAqPe6dOlSksxDDz2UmxkyZEihmWrTjBkzCuXatGmTm/nmN7+Zmxk0aFBuZvHixUVGKvRzcJFzvmLFikLH29m54wgAAACAJMURAAAAAEmKIwAAAACSFEcAAAAAJCmOAAAAAEhSHAEAAACQpDgCAAAAIElxBAAAAEBSeV0PQMNx0EEHFcqNGDEiNzNy5MjtnGaz1atXF8q9+OKLJTke1Fe9e/eutWONHTu2UO6dd96p4Un4tAMOOCA384UvfKHQWkX3VqB2jRs3rq5HgB3KokWLcjO77rprLUxSv61duzY3M3Xq1JJkhg0bVmCiiAsuuCA388wzz+RmBgwYkJv5zW9+U2imHZk7jgAAAABIUhwBAAAAkKQ4AgAAACBJcQQAAABAkuIIAAAAgCTFEQAAAABJiiMAAAAAkhRHAAAAACQpjgAAAABIKq/rAXY0y5Yty8306NEjN9O6detCx3vhhRcK5UqhTZs2hXL77bdfbibLsu0dJyIi5s6dWyj317/+tSTHg/qqadOmuZmysrKSHGvBggUlWYfidtkl//c8FRUVtTAJAEDNmTFjRqHcQw89lJspcs362GOP5WaGDx9eaKY5c+YUyjVE7jgCAAAAIElxBAAAAECS4ggAAACAJMURAAAAAEmKIwAAAACSFEcAAAAAJCmOAAAAAEhSHAEAAACQVF7XA+xozj///NzMXnvtlZs56aSTCh2vR48ehXK1aeDAgbmZs88+OzczePDg3Mz06dMLzQQ7uj59+uRmsiyrhUmoCRUVFbkZ/74AwM5i7dq1uZnhw4fnZqZMmZKbufPOOwvN1KFDh9zM1KlTC61V37jjCAAAAIAkxREAAAAASYojAAAAAJIURwAAAAAkKY4AAAAASFIcAQAAAJCkOAIAAAAgSXEEAAAAQFJ5XQ+wo3n//fdzM1/96ldzM3379i10vMMPP7xQLs/SpUtzM48//nihtW6//fbczOmnn56b+f3vf5+befXVVwvNBLCjW79+fW7mrbfeqoVJAADq3jPPPJObGTBgQG5mwYIFhY53880352amTp1aaK36xh1HAAAAACQpjgAAAABIUhwBAAAAkKQ4AgAAACBJcQQAAABAkuIIAAAAgCTFEQAAAABJiiMAAAAAksrregDS5s+fX9JcbfrOd76Tm8myLDfz/PPP52bWrFlTaCaA+urss88uyTrjxo3LzSxZsqQkxwI2K3Id1rdv35Idr8h/50UyAGy2du3a3MyiRYsKrdW1a9ftHafecscRAAAAAEmKIwAAAACSFEcAAAAAJCmOAAAAAEhSHAEAAACQpDgCAAAAIElxBAAAAECS4ggAAACAJMURAAAAAEnldT0ADcdBBx1UsrXWr1+fm5k6dWrJjgc7utGjR+dmnnjiidxMmzZtcjM/+9nPCs103nnnFcrt7Iqc8zVr1uRmpk+fXopxAAB2Gl27ds3NDBo0qNBay5Yt285p6i93HAEAAACQpDgCAAAAIElxBAAAAECS4ggAAACAJMURAAAAAEmKIwAAAACSFEcAAAAAJCmOAAAAAEgqr+sBaDjGjBlTsrUeffTR3MySJUtKdjzY0b344ou5mSuvvDI3c8899+RmhgwZUmCiiNtuuy03syP/d/6Tn/ykUG6fffbJzcyePTs3s2nTpkLHA4rp27dvSTJAw3bZZZflZtasWZObmTlzZinGYRt06NAhN3P99dfnZpo2bVroeEWvkRsidxwBAAAAkKQ4AgAAACBJcQQAAABAkuIIAAAAgCTFEQAAAABJiiMAAAAAkhRHAAAAACQpjgAAAABIKq/rAagfunfvnpsZPHhwyY735JNPlmwtoJhnn302N3P//ffnZoYOHVroeMcee2xuZsmSJYXWqm/69euXmzn11FMLrfXmm2/mZiZMmFBoLaB0xo4dW9cjADWsyP+rb7755tzMjBkzcjMzZ84sNFND1bZt29xM0WujIoqs1atXr9xMkeuws88+u9BMK1asKJRriNxxBAAAAECS4ggAAACAJMURAAAAAEmKIwAAAACSFEcAAAAAJCmOAAAAAEhSHAEAAACQpDgCAAAAIKm8rgegfujVq1duZs899yy0VpZluZlNmzYVWgsonddeey03M2bMmNzMUUcdVeh4Y8eOzc20bds2N3P11VcXOl4RnTt3zs306dMnN/PDH/4wN9OiRYsiI8WUKVNyM8uWLSu0FlBM3759S5IppX79+uVm5s+fX/ODAFXsskv+vRbDhg3LzQwePLjQ8R566KHcTFlZWW6ma9euuZm1a9cWmmnQoEG5mSIzFfk5scg6ERHLly/PzcyaNSs3M2nSpNxM0fO0I3PHEQAAAABJiiMAAAAAkhRHAAAAACQpjgAAAABIUhwBAAAAkKQ4AgAAACBJcQQAAABAkuIIAAAAgCTFEQAAAABJ5XU9APVDmzZtcjNZlhVaa+nSpbmZBx54oNBaQO1auXJlbuaoo44qtNb06dNzMyNGjMjNDBgwoCTHioiYMGFCbqZ169aF1srzy1/+slBuxowZJTkeUPvGjx+fmxk3blzNDwJUy5w5c3IzJ554Ym5m0KBBJZhms1NPPTU307Zt29zMsmXLcjNFf74rcq2ydu3a3EyR813UihUrcjMbN24s2fF2du44AgAAACBJcQQAAABAkuIIAAAAgCTFEQAAAABJiiMAAAAAkhRHAAAAACQpjgAAAABIUhwBAAAAkFSWZVlWKFhWVtOzUIdeeOGF3EyPHj0KrTV69OjczM0331xoLeqfgltGrbI/1U/NmzfPzXTp0iU3M2bMmNzMgAEDCs00ZcqUQrk8Dz74YG5myZIlhdb6+OOPt3cc/j/7E1Bf2Z+A+qrI/uSOIwAAAACSFEcAAAAAJCmOAAAAAEhSHAEAAACQpDgCAAAAIElxBAAAAECS4ggAAACAJMURAAAAAEnldT0A9cOyZctyMz169KiFSYAdxbp163Izixcvzs189atfLcU4AABANbjjCAAAAIAkxREAAAAASYojAAAAAJIURwAAAAAkKY4AAAAASFIcAQAAAJCkOAIAAAAgSXEEAAAAQFJ5XQ9A/fDEE0/kZjp27Fhoreeff357xwEAAADqAXccAQAAAJCkOAIAAAAgSXEEAAAAQJLiCAAAAIAkxREAAAAASYojAAAAAJIURwAAAAAkKY4AAAAASFIcAQAAAJBUlmVZVihYVlbTswANQMEto1bZn4AI+xNQf9mfgPqqyP7kjiMAAAAAkhRHAAAAACQpjgAAAABIUhwBAAAAkKQ4AgAAACBJcQQAAABAkuIIAAAAgCTFEQAAAABJZVmWZXU9BAAAAAD1jzuOAAAAAEhSHAEAAACQpDgCAAAAIElxBAAAAECS4ggAAACAJMURAAAAAEmKIwAAAACSFEcAAAAAJCmOAAAAAEj6fytcoTg6aRfpAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's move to torchData"
      ],
      "metadata": {
        "id": "DF-10Pue3wlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Dataset Class for Custom Data**: The `Dataset` class (e.g., `torch.utils.data.Dataset`) enables custom data handling. Users define `__getitem__` to access samples and `__len__` for dataset size, converting raw data (e.g., images, text) into PyTorch tensors, supporting diverse formats.\n",
        "- **Transformations for Preprocessing**: `torchvision.transforms` preprocesses data (e.g., converting images to tensors, normalizing with mean and variance). For CIFAR-10, images (32x32x3) are transformed to tensors and normalized (e.g., mean=[0.5, 0.5, 0.5]), ensuring model-compatible inputs.\n",
        "- **Batching and Shuffling**: `DataLoader` batches samples (e.g., batch_size=4) and shuffles them for training to reduce overfitting, as seen in Lecture 8‚Äôs MNIST example. It adds a batch dimension (e.g., [4, 3, 32, 32] for CIFAR-10), streamlining model input.\n",
        "- **GPU Integration**: `DataLoader` moves data to GPUs (e.g., `data.to(device)`), aligning with models on GPUs for faster computation. This extends Lecture 8‚Äôs GPU usage, ensuring data and model reside on the same device to avoid costly CPU-GPU transfers.\n",
        "- **CNN Architecture for CIFAR-10**: The lecture implements a convolutional neural network (CNN) using `nn.Module` for CIFAR-10 classification (10 classes, 50,000 images). It includes `nn.Conv2d` (e.g., 3 to 6 channels), `nn.MaxPool2d`, and `nn.Linear` layers, demonstrating `DataLoader`‚Äôs role in feeding complex data.\n",
        "- **Convolutional Layers**: `nn.Conv2d` applies convolution with kernels (e.g., 6 kernels of size 5x5), reducing spatial dimensions unless padded. Parameters are initialized (e.g., Kaiming), and gradients are computed via autograd, as in Lecture 7.\n",
        "- **Training Loop with DataLoader**: The training loop uses `DataLoader` to iterate over batches, computing logits, cross-entropy loss, and gradients. `optimizer.step()` updates parameters, and `zero_grad()` prevents gradient accumulation, refining Lecture 8‚Äôs loop.\n",
        "- **Evaluation Mode**: Models switch to evaluation mode (`model.eval()`) for testing, disabling gradient computation, akin to `torch.no_grad()` from Lecture 6. This ensures test data doesn‚Äôt update parameters, a critical step missed initially in the lecture.\n",
        "- **Performance Metrics**: The CNN achieves ~54% accuracy on CIFAR-10 after one epoch, reasonable given the dataset‚Äôs complexity (small 32x32 images). Accuracy and loss are tracked per batch, extending Lecture 8‚Äôs visualization techniques.\n",
        "- **Custom Dataset Handling**: For non-standard datasets, users convert data to `Dataset` format, then use `DataLoader`. The lecture references a separate notebook for this, building on Lecture 8‚Äôs `torchvision` datasets like MNIST.\n",
        "- **Scalability for Large Projects**: `DataLoader` is vital for large-scale NLP or vision projects, where preprocessing (e.g., tokenization, normalization) is complex. It separates data handling from model training, improving code modularity and performance.\n",
        "- **Multiprocessing and Hardware Utilization**: `DataLoader` leverages multiple CPU cores (e.g., 40 multiprocessors on a Tesla T4 GPU) for data loading, optimizing hardware usage. This supports industry practices like multi-GPU training, previewed for Lecture 10.\n"
      ],
      "metadata": {
        "id": "h9FN40gIEDVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
        "                         std=[0.2023, 0.1994, 0.2010])\n",
        "])\n"
      ],
      "metadata": {
        "id": "6zFah1dy3mtm"
      },
      "execution_count": 349,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "num_workers = os.cpu_count()\n",
        "num_workers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fn0BijR3Gr_U",
        "outputId": "7effa810-8e80-447b-9747-2c9ac9b30822"
      },
      "execution_count": 339,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 339
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform = transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=num_workers)"
      ],
      "metadata": {
        "id": "KIXPTbwpE2Tf"
      },
      "execution_count": 350,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyCNNModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MyCNNModel, self).__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Conv2d(3,6,5),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2, 2),\n",
        "        nn.Conv2d(6, 16, 5),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2, 2))\n",
        "    self.layers2= nn.Sequential(\n",
        "        nn.Linear(16*5*5, 120),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(120, 84 ),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(84,10)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    batch_size = x.size()[0]\n",
        "    x = self.layers(x)\n",
        "    x = x.view(batch_size,-1)\n",
        "    x = self.layers2(x)\n",
        "    return x\n",
        "    # return self.layers2(x)"
      ],
      "metadata": {
        "id": "bLmQjU4KGwDO"
      },
      "execution_count": 396,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check if model works\n",
        "model = MyCNNModel().to(device)\n",
        "for layer in model.layers:\n",
        "  print(layer.__class__)\n",
        "for data in trainloader:\n",
        "  x,y = data\n",
        "  # x = model.Conv2d(x)\n",
        "  # x = model.ReLU(x)\n",
        "  # x = model.MaxPool2d(x)\n",
        "  # x = model.ReLU(x)\n",
        "  # print(a.shape)\n",
        "  # for layer in model.layers:\n",
        "  #   print(layer.__class__)\n",
        "  #   x = layer(x)\n",
        "  #   print(x.shape)\n",
        "  x = model(x)\n",
        "  print(x.shape)\n",
        "  break\n",
        "#It does, do not trust random ass ai code lol"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjoNVO9bJ5TW",
        "outputId": "f8e2d1d4-5fb2-451c-943f-f9853d6acda7"
      },
      "execution_count": 402,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.activation.ReLU'>\n",
            "<class 'torch.nn.modules.pooling.MaxPool2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.activation.ReLU'>\n",
            "<class 'torch.nn.modules.pooling.MaxPool2d'>\n",
            "torch.Size([64, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "model.train()\n",
        "for batch_no, data in enumerate(trainloader):\n",
        "  optimizer.zero_grad()\n",
        "  inputs, labels = data\n",
        "  inputs, labels = inputs.to(device), labels.to(device)\n",
        "  outputs = model(inputs)\n",
        "  loss = criterion(outputs, labels)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  print(f\"Batch no:{batch_no} --> TrainingLoass: {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffY5AKLJJ-Pm",
        "outputId": "11a83179-eb9a-447e-d644-8f3733a1b366"
      },
      "execution_count": 403,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch no:0 --> TrainingLoass: 2.2983717918395996\n",
            "Batch no:1 --> TrainingLoass: 2.3110361099243164\n",
            "Batch no:2 --> TrainingLoass: 2.303562641143799\n",
            "Batch no:3 --> TrainingLoass: 2.3009274005889893\n",
            "Batch no:4 --> TrainingLoass: 2.3083152770996094\n",
            "Batch no:5 --> TrainingLoass: 2.3081705570220947\n",
            "Batch no:6 --> TrainingLoass: 2.3071846961975098\n",
            "Batch no:7 --> TrainingLoass: 2.3060142993927\n",
            "Batch no:8 --> TrainingLoass: 2.3006293773651123\n",
            "Batch no:9 --> TrainingLoass: 2.3069281578063965\n",
            "Batch no:10 --> TrainingLoass: 2.311885118484497\n",
            "Batch no:11 --> TrainingLoass: 2.2974963188171387\n",
            "Batch no:12 --> TrainingLoass: 2.305880308151245\n",
            "Batch no:13 --> TrainingLoass: 2.302652359008789\n",
            "Batch no:14 --> TrainingLoass: 2.3014562129974365\n",
            "Batch no:15 --> TrainingLoass: 2.293881416320801\n",
            "Batch no:16 --> TrainingLoass: 2.3026838302612305\n",
            "Batch no:17 --> TrainingLoass: 2.3088905811309814\n",
            "Batch no:18 --> TrainingLoass: 2.3044044971466064\n",
            "Batch no:19 --> TrainingLoass: 2.3082308769226074\n",
            "Batch no:20 --> TrainingLoass: 2.2987821102142334\n",
            "Batch no:21 --> TrainingLoass: 2.2992918491363525\n",
            "Batch no:22 --> TrainingLoass: 2.2897050380706787\n",
            "Batch no:23 --> TrainingLoass: 2.299910306930542\n",
            "Batch no:24 --> TrainingLoass: 2.31606125831604\n",
            "Batch no:25 --> TrainingLoass: 2.30070424079895\n",
            "Batch no:26 --> TrainingLoass: 2.307488441467285\n",
            "Batch no:27 --> TrainingLoass: 2.3113045692443848\n",
            "Batch no:28 --> TrainingLoass: 2.3207805156707764\n",
            "Batch no:29 --> TrainingLoass: 2.30479097366333\n",
            "Batch no:30 --> TrainingLoass: 2.3014817237854004\n",
            "Batch no:31 --> TrainingLoass: 2.298612117767334\n",
            "Batch no:32 --> TrainingLoass: 2.307310104370117\n",
            "Batch no:33 --> TrainingLoass: 2.2945303916931152\n",
            "Batch no:34 --> TrainingLoass: 2.2991175651550293\n",
            "Batch no:35 --> TrainingLoass: 2.2989346981048584\n",
            "Batch no:36 --> TrainingLoass: 2.3012516498565674\n",
            "Batch no:37 --> TrainingLoass: 2.297192335128784\n",
            "Batch no:38 --> TrainingLoass: 2.3007614612579346\n",
            "Batch no:39 --> TrainingLoass: 2.3072571754455566\n",
            "Batch no:40 --> TrainingLoass: 2.3057427406311035\n",
            "Batch no:41 --> TrainingLoass: 2.3129794597625732\n",
            "Batch no:42 --> TrainingLoass: 2.2898616790771484\n",
            "Batch no:43 --> TrainingLoass: 2.2956628799438477\n",
            "Batch no:44 --> TrainingLoass: 2.307392120361328\n",
            "Batch no:45 --> TrainingLoass: 2.309035301208496\n",
            "Batch no:46 --> TrainingLoass: 2.290555477142334\n",
            "Batch no:47 --> TrainingLoass: 2.297431468963623\n",
            "Batch no:48 --> TrainingLoass: 2.3057353496551514\n",
            "Batch no:49 --> TrainingLoass: 2.3002383708953857\n",
            "Batch no:50 --> TrainingLoass: 2.3011093139648438\n",
            "Batch no:51 --> TrainingLoass: 2.288588285446167\n",
            "Batch no:52 --> TrainingLoass: 2.302368402481079\n",
            "Batch no:53 --> TrainingLoass: 2.2983858585357666\n",
            "Batch no:54 --> TrainingLoass: 2.3221352100372314\n",
            "Batch no:55 --> TrainingLoass: 2.303887128829956\n",
            "Batch no:56 --> TrainingLoass: 2.3104262351989746\n",
            "Batch no:57 --> TrainingLoass: 2.2986629009246826\n",
            "Batch no:58 --> TrainingLoass: 2.3080646991729736\n",
            "Batch no:59 --> TrainingLoass: 2.286989212036133\n",
            "Batch no:60 --> TrainingLoass: 2.3131065368652344\n",
            "Batch no:61 --> TrainingLoass: 2.2994723320007324\n",
            "Batch no:62 --> TrainingLoass: 2.298403263092041\n",
            "Batch no:63 --> TrainingLoass: 2.3167383670806885\n",
            "Batch no:64 --> TrainingLoass: 2.2921805381774902\n",
            "Batch no:65 --> TrainingLoass: 2.3025128841400146\n",
            "Batch no:66 --> TrainingLoass: 2.3033878803253174\n",
            "Batch no:67 --> TrainingLoass: 2.308600664138794\n",
            "Batch no:68 --> TrainingLoass: 2.295210599899292\n",
            "Batch no:69 --> TrainingLoass: 2.317183256149292\n",
            "Batch no:70 --> TrainingLoass: 2.2869598865509033\n",
            "Batch no:71 --> TrainingLoass: 2.305940866470337\n",
            "Batch no:72 --> TrainingLoass: 2.3003292083740234\n",
            "Batch no:73 --> TrainingLoass: 2.2940919399261475\n",
            "Batch no:74 --> TrainingLoass: 2.306779384613037\n",
            "Batch no:75 --> TrainingLoass: 2.3180458545684814\n",
            "Batch no:76 --> TrainingLoass: 2.3052854537963867\n",
            "Batch no:77 --> TrainingLoass: 2.3018686771392822\n",
            "Batch no:78 --> TrainingLoass: 2.2931106090545654\n",
            "Batch no:79 --> TrainingLoass: 2.3053877353668213\n",
            "Batch no:80 --> TrainingLoass: 2.2933695316314697\n",
            "Batch no:81 --> TrainingLoass: 2.301652669906616\n",
            "Batch no:82 --> TrainingLoass: 2.2987875938415527\n",
            "Batch no:83 --> TrainingLoass: 2.316451072692871\n",
            "Batch no:84 --> TrainingLoass: 2.2898547649383545\n",
            "Batch no:85 --> TrainingLoass: 2.2904036045074463\n",
            "Batch no:86 --> TrainingLoass: 2.3017170429229736\n",
            "Batch no:87 --> TrainingLoass: 2.297349691390991\n",
            "Batch no:88 --> TrainingLoass: 2.3128583431243896\n",
            "Batch no:89 --> TrainingLoass: 2.3092033863067627\n",
            "Batch no:90 --> TrainingLoass: 2.291374444961548\n",
            "Batch no:91 --> TrainingLoass: 2.3015363216400146\n",
            "Batch no:92 --> TrainingLoass: 2.301701068878174\n",
            "Batch no:93 --> TrainingLoass: 2.3058247566223145\n",
            "Batch no:94 --> TrainingLoass: 2.2970926761627197\n",
            "Batch no:95 --> TrainingLoass: 2.3059773445129395\n",
            "Batch no:96 --> TrainingLoass: 2.2875709533691406\n",
            "Batch no:97 --> TrainingLoass: 2.2919461727142334\n",
            "Batch no:98 --> TrainingLoass: 2.314138889312744\n",
            "Batch no:99 --> TrainingLoass: 2.3042197227478027\n",
            "Batch no:100 --> TrainingLoass: 2.301788330078125\n",
            "Batch no:101 --> TrainingLoass: 2.3073012828826904\n",
            "Batch no:102 --> TrainingLoass: 2.301661252975464\n",
            "Batch no:103 --> TrainingLoass: 2.304616928100586\n",
            "Batch no:104 --> TrainingLoass: 2.3013999462127686\n",
            "Batch no:105 --> TrainingLoass: 2.2963099479675293\n",
            "Batch no:106 --> TrainingLoass: 2.298521041870117\n",
            "Batch no:107 --> TrainingLoass: 2.298112392425537\n",
            "Batch no:108 --> TrainingLoass: 2.2990102767944336\n",
            "Batch no:109 --> TrainingLoass: 2.310166120529175\n",
            "Batch no:110 --> TrainingLoass: 2.2990238666534424\n",
            "Batch no:111 --> TrainingLoass: 2.2881500720977783\n",
            "Batch no:112 --> TrainingLoass: 2.3103368282318115\n",
            "Batch no:113 --> TrainingLoass: 2.307500123977661\n",
            "Batch no:114 --> TrainingLoass: 2.2876880168914795\n",
            "Batch no:115 --> TrainingLoass: 2.307421922683716\n",
            "Batch no:116 --> TrainingLoass: 2.287285566329956\n",
            "Batch no:117 --> TrainingLoass: 2.302424669265747\n",
            "Batch no:118 --> TrainingLoass: 2.3030450344085693\n",
            "Batch no:119 --> TrainingLoass: 2.305846691131592\n",
            "Batch no:120 --> TrainingLoass: 2.284726858139038\n",
            "Batch no:121 --> TrainingLoass: 2.3112998008728027\n",
            "Batch no:122 --> TrainingLoass: 2.292832136154175\n",
            "Batch no:123 --> TrainingLoass: 2.2962589263916016\n",
            "Batch no:124 --> TrainingLoass: 2.290098190307617\n",
            "Batch no:125 --> TrainingLoass: 2.3012990951538086\n",
            "Batch no:126 --> TrainingLoass: 2.3010993003845215\n",
            "Batch no:127 --> TrainingLoass: 2.2891769409179688\n",
            "Batch no:128 --> TrainingLoass: 2.2812938690185547\n",
            "Batch no:129 --> TrainingLoass: 2.2852349281311035\n",
            "Batch no:130 --> TrainingLoass: 2.2897157669067383\n",
            "Batch no:131 --> TrainingLoass: 2.2950475215911865\n",
            "Batch no:132 --> TrainingLoass: 2.2896878719329834\n",
            "Batch no:133 --> TrainingLoass: 2.301273822784424\n",
            "Batch no:134 --> TrainingLoass: 2.293302059173584\n",
            "Batch no:135 --> TrainingLoass: 2.2893242835998535\n",
            "Batch no:136 --> TrainingLoass: 2.3153529167175293\n",
            "Batch no:137 --> TrainingLoass: 2.293135404586792\n",
            "Batch no:138 --> TrainingLoass: 2.305983543395996\n",
            "Batch no:139 --> TrainingLoass: 2.301440954208374\n",
            "Batch no:140 --> TrainingLoass: 2.2948005199432373\n",
            "Batch no:141 --> TrainingLoass: 2.2972309589385986\n",
            "Batch no:142 --> TrainingLoass: 2.2856130599975586\n",
            "Batch no:143 --> TrainingLoass: 2.2947943210601807\n",
            "Batch no:144 --> TrainingLoass: 2.297651529312134\n",
            "Batch no:145 --> TrainingLoass: 2.286628484725952\n",
            "Batch no:146 --> TrainingLoass: 2.298274278640747\n",
            "Batch no:147 --> TrainingLoass: 2.293024778366089\n",
            "Batch no:148 --> TrainingLoass: 2.2993338108062744\n",
            "Batch no:149 --> TrainingLoass: 2.29219913482666\n",
            "Batch no:150 --> TrainingLoass: 2.2934775352478027\n",
            "Batch no:151 --> TrainingLoass: 2.304858684539795\n",
            "Batch no:152 --> TrainingLoass: 2.2883384227752686\n",
            "Batch no:153 --> TrainingLoass: 2.2941246032714844\n",
            "Batch no:154 --> TrainingLoass: 2.2902448177337646\n",
            "Batch no:155 --> TrainingLoass: 2.2965645790100098\n",
            "Batch no:156 --> TrainingLoass: 2.302128553390503\n",
            "Batch no:157 --> TrainingLoass: 2.295898675918579\n",
            "Batch no:158 --> TrainingLoass: 2.2917919158935547\n",
            "Batch no:159 --> TrainingLoass: 2.285924196243286\n",
            "Batch no:160 --> TrainingLoass: 2.3037757873535156\n",
            "Batch no:161 --> TrainingLoass: 2.29495906829834\n",
            "Batch no:162 --> TrainingLoass: 2.2853238582611084\n",
            "Batch no:163 --> TrainingLoass: 2.294872283935547\n",
            "Batch no:164 --> TrainingLoass: 2.305373430252075\n",
            "Batch no:165 --> TrainingLoass: 2.295403242111206\n",
            "Batch no:166 --> TrainingLoass: 2.293163537979126\n",
            "Batch no:167 --> TrainingLoass: 2.292062520980835\n",
            "Batch no:168 --> TrainingLoass: 2.3006575107574463\n",
            "Batch no:169 --> TrainingLoass: 2.2893805503845215\n",
            "Batch no:170 --> TrainingLoass: 2.2930688858032227\n",
            "Batch no:171 --> TrainingLoass: 2.296504259109497\n",
            "Batch no:172 --> TrainingLoass: 2.2846603393554688\n",
            "Batch no:173 --> TrainingLoass: 2.2995011806488037\n",
            "Batch no:174 --> TrainingLoass: 2.285644054412842\n",
            "Batch no:175 --> TrainingLoass: 2.2874186038970947\n",
            "Batch no:176 --> TrainingLoass: 2.3069562911987305\n",
            "Batch no:177 --> TrainingLoass: 2.295325994491577\n",
            "Batch no:178 --> TrainingLoass: 2.2971458435058594\n",
            "Batch no:179 --> TrainingLoass: 2.296231985092163\n",
            "Batch no:180 --> TrainingLoass: 2.304037570953369\n",
            "Batch no:181 --> TrainingLoass: 2.2965736389160156\n",
            "Batch no:182 --> TrainingLoass: 2.2961175441741943\n",
            "Batch no:183 --> TrainingLoass: 2.288181781768799\n",
            "Batch no:184 --> TrainingLoass: 2.2856791019439697\n",
            "Batch no:185 --> TrainingLoass: 2.3024048805236816\n",
            "Batch no:186 --> TrainingLoass: 2.289438486099243\n",
            "Batch no:187 --> TrainingLoass: 2.293001413345337\n",
            "Batch no:188 --> TrainingLoass: 2.2876369953155518\n",
            "Batch no:189 --> TrainingLoass: 2.289808511734009\n",
            "Batch no:190 --> TrainingLoass: 2.300605058670044\n",
            "Batch no:191 --> TrainingLoass: 2.2917897701263428\n",
            "Batch no:192 --> TrainingLoass: 2.2981462478637695\n",
            "Batch no:193 --> TrainingLoass: 2.287245988845825\n",
            "Batch no:194 --> TrainingLoass: 2.287911891937256\n",
            "Batch no:195 --> TrainingLoass: 2.2845733165740967\n",
            "Batch no:196 --> TrainingLoass: 2.289325714111328\n",
            "Batch no:197 --> TrainingLoass: 2.307451009750366\n",
            "Batch no:198 --> TrainingLoass: 2.296806573867798\n",
            "Batch no:199 --> TrainingLoass: 2.2947349548339844\n",
            "Batch no:200 --> TrainingLoass: 2.2858633995056152\n",
            "Batch no:201 --> TrainingLoass: 2.2861783504486084\n",
            "Batch no:202 --> TrainingLoass: 2.2880916595458984\n",
            "Batch no:203 --> TrainingLoass: 2.2950923442840576\n",
            "Batch no:204 --> TrainingLoass: 2.279296636581421\n",
            "Batch no:205 --> TrainingLoass: 2.3020198345184326\n",
            "Batch no:206 --> TrainingLoass: 2.282500982284546\n",
            "Batch no:207 --> TrainingLoass: 2.2819976806640625\n",
            "Batch no:208 --> TrainingLoass: 2.2950758934020996\n",
            "Batch no:209 --> TrainingLoass: 2.3029165267944336\n",
            "Batch no:210 --> TrainingLoass: 2.3066749572753906\n",
            "Batch no:211 --> TrainingLoass: 2.316387176513672\n",
            "Batch no:212 --> TrainingLoass: 2.2874834537506104\n",
            "Batch no:213 --> TrainingLoass: 2.2991697788238525\n",
            "Batch no:214 --> TrainingLoass: 2.280571937561035\n",
            "Batch no:215 --> TrainingLoass: 2.301403760910034\n",
            "Batch no:216 --> TrainingLoass: 2.2826600074768066\n",
            "Batch no:217 --> TrainingLoass: 2.298771619796753\n",
            "Batch no:218 --> TrainingLoass: 2.2769837379455566\n",
            "Batch no:219 --> TrainingLoass: 2.281255006790161\n",
            "Batch no:220 --> TrainingLoass: 2.295104742050171\n",
            "Batch no:221 --> TrainingLoass: 2.291661024093628\n",
            "Batch no:222 --> TrainingLoass: 2.2878119945526123\n",
            "Batch no:223 --> TrainingLoass: 2.2871451377868652\n",
            "Batch no:224 --> TrainingLoass: 2.287306785583496\n",
            "Batch no:225 --> TrainingLoass: 2.300139904022217\n",
            "Batch no:226 --> TrainingLoass: 2.279381036758423\n",
            "Batch no:227 --> TrainingLoass: 2.2795608043670654\n",
            "Batch no:228 --> TrainingLoass: 2.28037428855896\n",
            "Batch no:229 --> TrainingLoass: 2.281682252883911\n",
            "Batch no:230 --> TrainingLoass: 2.2988760471343994\n",
            "Batch no:231 --> TrainingLoass: 2.2884397506713867\n",
            "Batch no:232 --> TrainingLoass: 2.277480125427246\n",
            "Batch no:233 --> TrainingLoass: 2.2741196155548096\n",
            "Batch no:234 --> TrainingLoass: 2.287764310836792\n",
            "Batch no:235 --> TrainingLoass: 2.290682315826416\n",
            "Batch no:236 --> TrainingLoass: 2.2562506198883057\n",
            "Batch no:237 --> TrainingLoass: 2.2969284057617188\n",
            "Batch no:238 --> TrainingLoass: 2.283236265182495\n",
            "Batch no:239 --> TrainingLoass: 2.28354549407959\n",
            "Batch no:240 --> TrainingLoass: 2.2973124980926514\n",
            "Batch no:241 --> TrainingLoass: 2.2815146446228027\n",
            "Batch no:242 --> TrainingLoass: 2.304806709289551\n",
            "Batch no:243 --> TrainingLoass: 2.278582811355591\n",
            "Batch no:244 --> TrainingLoass: 2.29237699508667\n",
            "Batch no:245 --> TrainingLoass: 2.2825138568878174\n",
            "Batch no:246 --> TrainingLoass: 2.299410343170166\n",
            "Batch no:247 --> TrainingLoass: 2.2963786125183105\n",
            "Batch no:248 --> TrainingLoass: 2.2867519855499268\n",
            "Batch no:249 --> TrainingLoass: 2.2834224700927734\n",
            "Batch no:250 --> TrainingLoass: 2.278082847595215\n",
            "Batch no:251 --> TrainingLoass: 2.2921557426452637\n",
            "Batch no:252 --> TrainingLoass: 2.271871328353882\n",
            "Batch no:253 --> TrainingLoass: 2.277885913848877\n",
            "Batch no:254 --> TrainingLoass: 2.2826004028320312\n",
            "Batch no:255 --> TrainingLoass: 2.2842867374420166\n",
            "Batch no:256 --> TrainingLoass: 2.2924346923828125\n",
            "Batch no:257 --> TrainingLoass: 2.2904818058013916\n",
            "Batch no:258 --> TrainingLoass: 2.2803993225097656\n",
            "Batch no:259 --> TrainingLoass: 2.2933456897735596\n",
            "Batch no:260 --> TrainingLoass: 2.323699712753296\n",
            "Batch no:261 --> TrainingLoass: 2.2625625133514404\n",
            "Batch no:262 --> TrainingLoass: 2.275876045227051\n",
            "Batch no:263 --> TrainingLoass: 2.293616533279419\n",
            "Batch no:264 --> TrainingLoass: 2.2975053787231445\n",
            "Batch no:265 --> TrainingLoass: 2.28153133392334\n",
            "Batch no:266 --> TrainingLoass: 2.2880051136016846\n",
            "Batch no:267 --> TrainingLoass: 2.2910337448120117\n",
            "Batch no:268 --> TrainingLoass: 2.2709360122680664\n",
            "Batch no:269 --> TrainingLoass: 2.288403034210205\n",
            "Batch no:270 --> TrainingLoass: 2.28352952003479\n",
            "Batch no:271 --> TrainingLoass: 2.298057794570923\n",
            "Batch no:272 --> TrainingLoass: 2.2850685119628906\n",
            "Batch no:273 --> TrainingLoass: 2.2878811359405518\n",
            "Batch no:274 --> TrainingLoass: 2.286121368408203\n",
            "Batch no:275 --> TrainingLoass: 2.2891714572906494\n",
            "Batch no:276 --> TrainingLoass: 2.3014426231384277\n",
            "Batch no:277 --> TrainingLoass: 2.2797374725341797\n",
            "Batch no:278 --> TrainingLoass: 2.2759056091308594\n",
            "Batch no:279 --> TrainingLoass: 2.2801785469055176\n",
            "Batch no:280 --> TrainingLoass: 2.290405511856079\n",
            "Batch no:281 --> TrainingLoass: 2.2840993404388428\n",
            "Batch no:282 --> TrainingLoass: 2.267768144607544\n",
            "Batch no:283 --> TrainingLoass: 2.2835631370544434\n",
            "Batch no:284 --> TrainingLoass: 2.2872021198272705\n",
            "Batch no:285 --> TrainingLoass: 2.285149335861206\n",
            "Batch no:286 --> TrainingLoass: 2.260791063308716\n",
            "Batch no:287 --> TrainingLoass: 2.296766996383667\n",
            "Batch no:288 --> TrainingLoass: 2.282299280166626\n",
            "Batch no:289 --> TrainingLoass: 2.2732291221618652\n",
            "Batch no:290 --> TrainingLoass: 2.2799782752990723\n",
            "Batch no:291 --> TrainingLoass: 2.2880616188049316\n",
            "Batch no:292 --> TrainingLoass: 2.2717955112457275\n",
            "Batch no:293 --> TrainingLoass: 2.292092800140381\n",
            "Batch no:294 --> TrainingLoass: 2.292066812515259\n",
            "Batch no:295 --> TrainingLoass: 2.2762858867645264\n",
            "Batch no:296 --> TrainingLoass: 2.2834296226501465\n",
            "Batch no:297 --> TrainingLoass: 2.2837131023406982\n",
            "Batch no:298 --> TrainingLoass: 2.2801527976989746\n",
            "Batch no:299 --> TrainingLoass: 2.2744174003601074\n",
            "Batch no:300 --> TrainingLoass: 2.267646312713623\n",
            "Batch no:301 --> TrainingLoass: 2.2692556381225586\n",
            "Batch no:302 --> TrainingLoass: 2.294321060180664\n",
            "Batch no:303 --> TrainingLoass: 2.2616214752197266\n",
            "Batch no:304 --> TrainingLoass: 2.271672487258911\n",
            "Batch no:305 --> TrainingLoass: 2.2780325412750244\n",
            "Batch no:306 --> TrainingLoass: 2.294762372970581\n",
            "Batch no:307 --> TrainingLoass: 2.2842416763305664\n",
            "Batch no:308 --> TrainingLoass: 2.264352798461914\n",
            "Batch no:309 --> TrainingLoass: 2.281972646713257\n",
            "Batch no:310 --> TrainingLoass: 2.265739917755127\n",
            "Batch no:311 --> TrainingLoass: 2.2663092613220215\n",
            "Batch no:312 --> TrainingLoass: 2.259584426879883\n",
            "Batch no:313 --> TrainingLoass: 2.278447151184082\n",
            "Batch no:314 --> TrainingLoass: 2.274805784225464\n",
            "Batch no:315 --> TrainingLoass: 2.281471014022827\n",
            "Batch no:316 --> TrainingLoass: 2.270808458328247\n",
            "Batch no:317 --> TrainingLoass: 2.2821497917175293\n",
            "Batch no:318 --> TrainingLoass: 2.2689590454101562\n",
            "Batch no:319 --> TrainingLoass: 2.276067018508911\n",
            "Batch no:320 --> TrainingLoass: 2.2634682655334473\n",
            "Batch no:321 --> TrainingLoass: 2.2801833152770996\n",
            "Batch no:322 --> TrainingLoass: 2.2855923175811768\n",
            "Batch no:323 --> TrainingLoass: 2.2950825691223145\n",
            "Batch no:324 --> TrainingLoass: 2.2743611335754395\n",
            "Batch no:325 --> TrainingLoass: 2.252715826034546\n",
            "Batch no:326 --> TrainingLoass: 2.2737574577331543\n",
            "Batch no:327 --> TrainingLoass: 2.2779393196105957\n",
            "Batch no:328 --> TrainingLoass: 2.23940372467041\n",
            "Batch no:329 --> TrainingLoass: 2.258871078491211\n",
            "Batch no:330 --> TrainingLoass: 2.249356985092163\n",
            "Batch no:331 --> TrainingLoass: 2.264984607696533\n",
            "Batch no:332 --> TrainingLoass: 2.2510294914245605\n",
            "Batch no:333 --> TrainingLoass: 2.2812082767486572\n",
            "Batch no:334 --> TrainingLoass: 2.298524856567383\n",
            "Batch no:335 --> TrainingLoass: 2.262258291244507\n",
            "Batch no:336 --> TrainingLoass: 2.2451369762420654\n",
            "Batch no:337 --> TrainingLoass: 2.2630817890167236\n",
            "Batch no:338 --> TrainingLoass: 2.299546003341675\n",
            "Batch no:339 --> TrainingLoass: 2.268369197845459\n",
            "Batch no:340 --> TrainingLoass: 2.2983899116516113\n",
            "Batch no:341 --> TrainingLoass: 2.2854082584381104\n",
            "Batch no:342 --> TrainingLoass: 2.2170403003692627\n",
            "Batch no:343 --> TrainingLoass: 2.261291027069092\n",
            "Batch no:344 --> TrainingLoass: 2.2564659118652344\n",
            "Batch no:345 --> TrainingLoass: 2.28840970993042\n",
            "Batch no:346 --> TrainingLoass: 2.2778522968292236\n",
            "Batch no:347 --> TrainingLoass: 2.2711002826690674\n",
            "Batch no:348 --> TrainingLoass: 2.2870194911956787\n",
            "Batch no:349 --> TrainingLoass: 2.2793240547180176\n",
            "Batch no:350 --> TrainingLoass: 2.2492787837982178\n",
            "Batch no:351 --> TrainingLoass: 2.276493549346924\n",
            "Batch no:352 --> TrainingLoass: 2.251535177230835\n",
            "Batch no:353 --> TrainingLoass: 2.2530646324157715\n",
            "Batch no:354 --> TrainingLoass: 2.2822906970977783\n",
            "Batch no:355 --> TrainingLoass: 2.231367349624634\n",
            "Batch no:356 --> TrainingLoass: 2.2679808139801025\n",
            "Batch no:357 --> TrainingLoass: 2.2103309631347656\n",
            "Batch no:358 --> TrainingLoass: 2.304807662963867\n",
            "Batch no:359 --> TrainingLoass: 2.257444381713867\n",
            "Batch no:360 --> TrainingLoass: 2.256551504135132\n",
            "Batch no:361 --> TrainingLoass: 2.3079137802124023\n",
            "Batch no:362 --> TrainingLoass: 2.2698328495025635\n",
            "Batch no:363 --> TrainingLoass: 2.270676851272583\n",
            "Batch no:364 --> TrainingLoass: 2.253934144973755\n",
            "Batch no:365 --> TrainingLoass: 2.2616260051727295\n",
            "Batch no:366 --> TrainingLoass: 2.262664556503296\n",
            "Batch no:367 --> TrainingLoass: 2.266676425933838\n",
            "Batch no:368 --> TrainingLoass: 2.2493276596069336\n",
            "Batch no:369 --> TrainingLoass: 2.2529211044311523\n",
            "Batch no:370 --> TrainingLoass: 2.249415397644043\n",
            "Batch no:371 --> TrainingLoass: 2.2537214756011963\n",
            "Batch no:372 --> TrainingLoass: 2.2746105194091797\n",
            "Batch no:373 --> TrainingLoass: 2.2191970348358154\n",
            "Batch no:374 --> TrainingLoass: 2.26096510887146\n",
            "Batch no:375 --> TrainingLoass: 2.2678990364074707\n",
            "Batch no:376 --> TrainingLoass: 2.2369961738586426\n",
            "Batch no:377 --> TrainingLoass: 2.2277021408081055\n",
            "Batch no:378 --> TrainingLoass: 2.2357895374298096\n",
            "Batch no:379 --> TrainingLoass: 2.238720417022705\n",
            "Batch no:380 --> TrainingLoass: 2.236154317855835\n",
            "Batch no:381 --> TrainingLoass: 2.2841362953186035\n",
            "Batch no:382 --> TrainingLoass: 2.3084185123443604\n",
            "Batch no:383 --> TrainingLoass: 2.2025599479675293\n",
            "Batch no:384 --> TrainingLoass: 2.237774133682251\n",
            "Batch no:385 --> TrainingLoass: 2.241910457611084\n",
            "Batch no:386 --> TrainingLoass: 2.2228219509124756\n",
            "Batch no:387 --> TrainingLoass: 2.2536582946777344\n",
            "Batch no:388 --> TrainingLoass: 2.234734058380127\n",
            "Batch no:389 --> TrainingLoass: 2.2295544147491455\n",
            "Batch no:390 --> TrainingLoass: 2.2540526390075684\n",
            "Batch no:391 --> TrainingLoass: 2.2424793243408203\n",
            "Batch no:392 --> TrainingLoass: 2.3025002479553223\n",
            "Batch no:393 --> TrainingLoass: 2.2506489753723145\n",
            "Batch no:394 --> TrainingLoass: 2.3012313842773438\n",
            "Batch no:395 --> TrainingLoass: 2.235337972640991\n",
            "Batch no:396 --> TrainingLoass: 2.2663302421569824\n",
            "Batch no:397 --> TrainingLoass: 2.243889331817627\n",
            "Batch no:398 --> TrainingLoass: 2.232311487197876\n",
            "Batch no:399 --> TrainingLoass: 2.2425174713134766\n",
            "Batch no:400 --> TrainingLoass: 2.2807586193084717\n",
            "Batch no:401 --> TrainingLoass: 2.2654664516448975\n",
            "Batch no:402 --> TrainingLoass: 2.2432687282562256\n",
            "Batch no:403 --> TrainingLoass: 2.212228536605835\n",
            "Batch no:404 --> TrainingLoass: 2.260058641433716\n",
            "Batch no:405 --> TrainingLoass: 2.222628116607666\n",
            "Batch no:406 --> TrainingLoass: 2.252873659133911\n",
            "Batch no:407 --> TrainingLoass: 2.2264790534973145\n",
            "Batch no:408 --> TrainingLoass: 2.2288966178894043\n",
            "Batch no:409 --> TrainingLoass: 2.2497313022613525\n",
            "Batch no:410 --> TrainingLoass: 2.2264909744262695\n",
            "Batch no:411 --> TrainingLoass: 2.2355825901031494\n",
            "Batch no:412 --> TrainingLoass: 2.238126039505005\n",
            "Batch no:413 --> TrainingLoass: 2.290196180343628\n",
            "Batch no:414 --> TrainingLoass: 2.2552926540374756\n",
            "Batch no:415 --> TrainingLoass: 2.2689054012298584\n",
            "Batch no:416 --> TrainingLoass: 2.236567974090576\n",
            "Batch no:417 --> TrainingLoass: 2.2025792598724365\n",
            "Batch no:418 --> TrainingLoass: 2.248255491256714\n",
            "Batch no:419 --> TrainingLoass: 2.325603723526001\n",
            "Batch no:420 --> TrainingLoass: 2.2437326908111572\n",
            "Batch no:421 --> TrainingLoass: 2.2873196601867676\n",
            "Batch no:422 --> TrainingLoass: 2.2306721210479736\n",
            "Batch no:423 --> TrainingLoass: 2.2442262172698975\n",
            "Batch no:424 --> TrainingLoass: 2.250742197036743\n",
            "Batch no:425 --> TrainingLoass: 2.2444636821746826\n",
            "Batch no:426 --> TrainingLoass: 2.2131619453430176\n",
            "Batch no:427 --> TrainingLoass: 2.209421396255493\n",
            "Batch no:428 --> TrainingLoass: 2.244474411010742\n",
            "Batch no:429 --> TrainingLoass: 2.2617528438568115\n",
            "Batch no:430 --> TrainingLoass: 2.2399730682373047\n",
            "Batch no:431 --> TrainingLoass: 2.2676799297332764\n",
            "Batch no:432 --> TrainingLoass: 2.1979763507843018\n",
            "Batch no:433 --> TrainingLoass: 2.215132474899292\n",
            "Batch no:434 --> TrainingLoass: 2.224731922149658\n",
            "Batch no:435 --> TrainingLoass: 2.2642018795013428\n",
            "Batch no:436 --> TrainingLoass: 2.2095818519592285\n",
            "Batch no:437 --> TrainingLoass: 2.245650291442871\n",
            "Batch no:438 --> TrainingLoass: 2.2064523696899414\n",
            "Batch no:439 --> TrainingLoass: 2.2151741981506348\n",
            "Batch no:440 --> TrainingLoass: 2.1593966484069824\n",
            "Batch no:441 --> TrainingLoass: 2.2375779151916504\n",
            "Batch no:442 --> TrainingLoass: 2.2236685752868652\n",
            "Batch no:443 --> TrainingLoass: 2.237783193588257\n",
            "Batch no:444 --> TrainingLoass: 2.2235093116760254\n",
            "Batch no:445 --> TrainingLoass: 2.1737775802612305\n",
            "Batch no:446 --> TrainingLoass: 2.249650478363037\n",
            "Batch no:447 --> TrainingLoass: 2.2105793952941895\n",
            "Batch no:448 --> TrainingLoass: 2.249476432800293\n",
            "Batch no:449 --> TrainingLoass: 2.212524890899658\n",
            "Batch no:450 --> TrainingLoass: 2.220621109008789\n",
            "Batch no:451 --> TrainingLoass: 2.1770200729370117\n",
            "Batch no:452 --> TrainingLoass: 2.20641827583313\n",
            "Batch no:453 --> TrainingLoass: 2.2198667526245117\n",
            "Batch no:454 --> TrainingLoass: 2.245591163635254\n",
            "Batch no:455 --> TrainingLoass: 2.2478036880493164\n",
            "Batch no:456 --> TrainingLoass: 2.215963125228882\n",
            "Batch no:457 --> TrainingLoass: 2.1957244873046875\n",
            "Batch no:458 --> TrainingLoass: 2.1753451824188232\n",
            "Batch no:459 --> TrainingLoass: 2.2415850162506104\n",
            "Batch no:460 --> TrainingLoass: 2.204810619354248\n",
            "Batch no:461 --> TrainingLoass: 2.2213566303253174\n",
            "Batch no:462 --> TrainingLoass: 2.1895670890808105\n",
            "Batch no:463 --> TrainingLoass: 2.2093312740325928\n",
            "Batch no:464 --> TrainingLoass: 2.1815531253814697\n",
            "Batch no:465 --> TrainingLoass: 2.164597988128662\n",
            "Batch no:466 --> TrainingLoass: 2.178807497024536\n",
            "Batch no:467 --> TrainingLoass: 2.179248094558716\n",
            "Batch no:468 --> TrainingLoass: 2.1996045112609863\n",
            "Batch no:469 --> TrainingLoass: 2.187497138977051\n",
            "Batch no:470 --> TrainingLoass: 2.186887502670288\n",
            "Batch no:471 --> TrainingLoass: 2.1820380687713623\n",
            "Batch no:472 --> TrainingLoass: 2.152161121368408\n",
            "Batch no:473 --> TrainingLoass: 2.174563407897949\n",
            "Batch no:474 --> TrainingLoass: 2.1844491958618164\n",
            "Batch no:475 --> TrainingLoass: 2.1398909091949463\n",
            "Batch no:476 --> TrainingLoass: 2.2177624702453613\n",
            "Batch no:477 --> TrainingLoass: 2.230102777481079\n",
            "Batch no:478 --> TrainingLoass: 2.1828420162200928\n",
            "Batch no:479 --> TrainingLoass: 2.2334177494049072\n",
            "Batch no:480 --> TrainingLoass: 2.1880009174346924\n",
            "Batch no:481 --> TrainingLoass: 2.252955436706543\n",
            "Batch no:482 --> TrainingLoass: 2.111776351928711\n",
            "Batch no:483 --> TrainingLoass: 2.1994876861572266\n",
            "Batch no:484 --> TrainingLoass: 2.2011477947235107\n",
            "Batch no:485 --> TrainingLoass: 2.170253038406372\n",
            "Batch no:486 --> TrainingLoass: 2.1429741382598877\n",
            "Batch no:487 --> TrainingLoass: 2.1690902709960938\n",
            "Batch no:488 --> TrainingLoass: 2.1887099742889404\n",
            "Batch no:489 --> TrainingLoass: 2.1903390884399414\n",
            "Batch no:490 --> TrainingLoass: 2.207138776779175\n",
            "Batch no:491 --> TrainingLoass: 2.209498882293701\n",
            "Batch no:492 --> TrainingLoass: 2.2254507541656494\n",
            "Batch no:493 --> TrainingLoass: 2.102971315383911\n",
            "Batch no:494 --> TrainingLoass: 2.1516475677490234\n",
            "Batch no:495 --> TrainingLoass: 2.1835367679595947\n",
            "Batch no:496 --> TrainingLoass: 2.1892714500427246\n",
            "Batch no:497 --> TrainingLoass: 2.1300060749053955\n",
            "Batch no:498 --> TrainingLoass: 2.1851253509521484\n",
            "Batch no:499 --> TrainingLoass: 2.175471782684326\n",
            "Batch no:500 --> TrainingLoass: 2.222628593444824\n",
            "Batch no:501 --> TrainingLoass: 2.1642515659332275\n",
            "Batch no:502 --> TrainingLoass: 2.1012020111083984\n",
            "Batch no:503 --> TrainingLoass: 2.2131507396698\n",
            "Batch no:504 --> TrainingLoass: 2.1728081703186035\n",
            "Batch no:505 --> TrainingLoass: 2.231696367263794\n",
            "Batch no:506 --> TrainingLoass: 2.133213758468628\n",
            "Batch no:507 --> TrainingLoass: 2.200702428817749\n",
            "Batch no:508 --> TrainingLoass: 2.1637370586395264\n",
            "Batch no:509 --> TrainingLoass: 2.1772654056549072\n",
            "Batch no:510 --> TrainingLoass: 2.17543625831604\n",
            "Batch no:511 --> TrainingLoass: 2.219075918197632\n",
            "Batch no:512 --> TrainingLoass: 2.089743137359619\n",
            "Batch no:513 --> TrainingLoass: 2.059873342514038\n",
            "Batch no:514 --> TrainingLoass: 2.0661659240722656\n",
            "Batch no:515 --> TrainingLoass: 2.198371648788452\n",
            "Batch no:516 --> TrainingLoass: 2.2017135620117188\n",
            "Batch no:517 --> TrainingLoass: 2.1766204833984375\n",
            "Batch no:518 --> TrainingLoass: 2.2610888481140137\n",
            "Batch no:519 --> TrainingLoass: 2.169590473175049\n",
            "Batch no:520 --> TrainingLoass: 2.102381706237793\n",
            "Batch no:521 --> TrainingLoass: 2.1158194541931152\n",
            "Batch no:522 --> TrainingLoass: 2.2012150287628174\n",
            "Batch no:523 --> TrainingLoass: 2.196331739425659\n",
            "Batch no:524 --> TrainingLoass: 2.1117193698883057\n",
            "Batch no:525 --> TrainingLoass: 2.188563346862793\n",
            "Batch no:526 --> TrainingLoass: 2.1421422958374023\n",
            "Batch no:527 --> TrainingLoass: 2.1679868698120117\n",
            "Batch no:528 --> TrainingLoass: 2.1251327991485596\n",
            "Batch no:529 --> TrainingLoass: 2.0927515029907227\n",
            "Batch no:530 --> TrainingLoass: 2.0741374492645264\n",
            "Batch no:531 --> TrainingLoass: 2.115959644317627\n",
            "Batch no:532 --> TrainingLoass: 2.1377551555633545\n",
            "Batch no:533 --> TrainingLoass: 2.0828335285186768\n",
            "Batch no:534 --> TrainingLoass: 2.1653895378112793\n",
            "Batch no:535 --> TrainingLoass: 2.1403684616088867\n",
            "Batch no:536 --> TrainingLoass: 2.17120361328125\n",
            "Batch no:537 --> TrainingLoass: 2.1189048290252686\n",
            "Batch no:538 --> TrainingLoass: 2.1520025730133057\n",
            "Batch no:539 --> TrainingLoass: 2.150963068008423\n",
            "Batch no:540 --> TrainingLoass: 2.156662940979004\n",
            "Batch no:541 --> TrainingLoass: 2.058849334716797\n",
            "Batch no:542 --> TrainingLoass: 2.1799440383911133\n",
            "Batch no:543 --> TrainingLoass: 2.072021484375\n",
            "Batch no:544 --> TrainingLoass: 2.1259851455688477\n",
            "Batch no:545 --> TrainingLoass: 2.138404130935669\n",
            "Batch no:546 --> TrainingLoass: 2.197833776473999\n",
            "Batch no:547 --> TrainingLoass: 2.0428905487060547\n",
            "Batch no:548 --> TrainingLoass: 2.11086106300354\n",
            "Batch no:549 --> TrainingLoass: 2.076983690261841\n",
            "Batch no:550 --> TrainingLoass: 2.1946589946746826\n",
            "Batch no:551 --> TrainingLoass: 2.0867741107940674\n",
            "Batch no:552 --> TrainingLoass: 2.1239356994628906\n",
            "Batch no:553 --> TrainingLoass: 2.08156156539917\n",
            "Batch no:554 --> TrainingLoass: 2.16434645652771\n",
            "Batch no:555 --> TrainingLoass: 2.1311988830566406\n",
            "Batch no:556 --> TrainingLoass: 2.141089677810669\n",
            "Batch no:557 --> TrainingLoass: 2.113241672515869\n",
            "Batch no:558 --> TrainingLoass: 2.0663981437683105\n",
            "Batch no:559 --> TrainingLoass: 2.1364188194274902\n",
            "Batch no:560 --> TrainingLoass: 2.060739755630493\n",
            "Batch no:561 --> TrainingLoass: 2.1804773807525635\n",
            "Batch no:562 --> TrainingLoass: 2.14695405960083\n",
            "Batch no:563 --> TrainingLoass: 2.129995584487915\n",
            "Batch no:564 --> TrainingLoass: 2.2180840969085693\n",
            "Batch no:565 --> TrainingLoass: 2.0646767616271973\n",
            "Batch no:566 --> TrainingLoass: 2.0299808979034424\n",
            "Batch no:567 --> TrainingLoass: 2.1035685539245605\n",
            "Batch no:568 --> TrainingLoass: 2.1887614727020264\n",
            "Batch no:569 --> TrainingLoass: 2.1086266040802\n",
            "Batch no:570 --> TrainingLoass: 2.1453051567077637\n",
            "Batch no:571 --> TrainingLoass: 2.0575904846191406\n",
            "Batch no:572 --> TrainingLoass: 2.076508045196533\n",
            "Batch no:573 --> TrainingLoass: 2.0531487464904785\n",
            "Batch no:574 --> TrainingLoass: 2.092867374420166\n",
            "Batch no:575 --> TrainingLoass: 2.0314478874206543\n",
            "Batch no:576 --> TrainingLoass: 2.185325860977173\n",
            "Batch no:577 --> TrainingLoass: 2.1763367652893066\n",
            "Batch no:578 --> TrainingLoass: 2.143909454345703\n",
            "Batch no:579 --> TrainingLoass: 2.1986167430877686\n",
            "Batch no:580 --> TrainingLoass: 2.121150493621826\n",
            "Batch no:581 --> TrainingLoass: 2.0861568450927734\n",
            "Batch no:582 --> TrainingLoass: 2.038043260574341\n",
            "Batch no:583 --> TrainingLoass: 2.07173490524292\n",
            "Batch no:584 --> TrainingLoass: 1.9609514474868774\n",
            "Batch no:585 --> TrainingLoass: 2.082266092300415\n",
            "Batch no:586 --> TrainingLoass: 2.0260844230651855\n",
            "Batch no:587 --> TrainingLoass: 2.0487821102142334\n",
            "Batch no:588 --> TrainingLoass: 2.000317335128784\n",
            "Batch no:589 --> TrainingLoass: 2.0791609287261963\n",
            "Batch no:590 --> TrainingLoass: 2.0854504108428955\n",
            "Batch no:591 --> TrainingLoass: 2.244905710220337\n",
            "Batch no:592 --> TrainingLoass: 2.192812204360962\n",
            "Batch no:593 --> TrainingLoass: 2.3107197284698486\n",
            "Batch no:594 --> TrainingLoass: 2.0461976528167725\n",
            "Batch no:595 --> TrainingLoass: 2.1515989303588867\n",
            "Batch no:596 --> TrainingLoass: 2.086942672729492\n",
            "Batch no:597 --> TrainingLoass: 2.14058256149292\n",
            "Batch no:598 --> TrainingLoass: 2.113860845565796\n",
            "Batch no:599 --> TrainingLoass: 2.022780179977417\n",
            "Batch no:600 --> TrainingLoass: 2.0851035118103027\n",
            "Batch no:601 --> TrainingLoass: 2.1250832080841064\n",
            "Batch no:602 --> TrainingLoass: 2.039417266845703\n",
            "Batch no:603 --> TrainingLoass: 2.0932788848876953\n",
            "Batch no:604 --> TrainingLoass: 2.043407678604126\n",
            "Batch no:605 --> TrainingLoass: 2.074907064437866\n",
            "Batch no:606 --> TrainingLoass: 2.154689311981201\n",
            "Batch no:607 --> TrainingLoass: 2.0811023712158203\n",
            "Batch no:608 --> TrainingLoass: 2.180856227874756\n",
            "Batch no:609 --> TrainingLoass: 2.1132395267486572\n",
            "Batch no:610 --> TrainingLoass: 2.055081605911255\n",
            "Batch no:611 --> TrainingLoass: 2.04447340965271\n",
            "Batch no:612 --> TrainingLoass: 1.9801647663116455\n",
            "Batch no:613 --> TrainingLoass: 2.0650289058685303\n",
            "Batch no:614 --> TrainingLoass: 2.0245234966278076\n",
            "Batch no:615 --> TrainingLoass: 1.9712815284729004\n",
            "Batch no:616 --> TrainingLoass: 2.069490671157837\n",
            "Batch no:617 --> TrainingLoass: 2.09196400642395\n",
            "Batch no:618 --> TrainingLoass: 2.058424949645996\n",
            "Batch no:619 --> TrainingLoass: 2.0339794158935547\n",
            "Batch no:620 --> TrainingLoass: 2.217571973800659\n",
            "Batch no:621 --> TrainingLoass: 1.873895287513733\n",
            "Batch no:622 --> TrainingLoass: 2.0804309844970703\n",
            "Batch no:623 --> TrainingLoass: 2.0998973846435547\n",
            "Batch no:624 --> TrainingLoass: 2.140475034713745\n",
            "Batch no:625 --> TrainingLoass: 2.122361183166504\n",
            "Batch no:626 --> TrainingLoass: 2.088080406188965\n",
            "Batch no:627 --> TrainingLoass: 2.1031382083892822\n",
            "Batch no:628 --> TrainingLoass: 2.0685579776763916\n",
            "Batch no:629 --> TrainingLoass: 2.0467429161071777\n",
            "Batch no:630 --> TrainingLoass: 2.0452873706817627\n",
            "Batch no:631 --> TrainingLoass: 2.0825562477111816\n",
            "Batch no:632 --> TrainingLoass: 2.0489094257354736\n",
            "Batch no:633 --> TrainingLoass: 2.0526206493377686\n",
            "Batch no:634 --> TrainingLoass: 2.0762274265289307\n",
            "Batch no:635 --> TrainingLoass: 1.962300181388855\n",
            "Batch no:636 --> TrainingLoass: 2.057202100753784\n",
            "Batch no:637 --> TrainingLoass: 1.9857707023620605\n",
            "Batch no:638 --> TrainingLoass: 2.059159278869629\n",
            "Batch no:639 --> TrainingLoass: 2.0488617420196533\n",
            "Batch no:640 --> TrainingLoass: 2.1259405612945557\n",
            "Batch no:641 --> TrainingLoass: 2.0665812492370605\n",
            "Batch no:642 --> TrainingLoass: 1.988203763961792\n",
            "Batch no:643 --> TrainingLoass: 1.9928216934204102\n",
            "Batch no:644 --> TrainingLoass: 2.1115071773529053\n",
            "Batch no:645 --> TrainingLoass: 2.0071868896484375\n",
            "Batch no:646 --> TrainingLoass: 2.0171663761138916\n",
            "Batch no:647 --> TrainingLoass: 2.1216771602630615\n",
            "Batch no:648 --> TrainingLoass: 1.9658241271972656\n",
            "Batch no:649 --> TrainingLoass: 2.019981861114502\n",
            "Batch no:650 --> TrainingLoass: 2.122103214263916\n",
            "Batch no:651 --> TrainingLoass: 2.0506513118743896\n",
            "Batch no:652 --> TrainingLoass: 1.9854974746704102\n",
            "Batch no:653 --> TrainingLoass: 2.1630659103393555\n",
            "Batch no:654 --> TrainingLoass: 1.8152650594711304\n",
            "Batch no:655 --> TrainingLoass: 2.0928738117218018\n",
            "Batch no:656 --> TrainingLoass: 1.8977923393249512\n",
            "Batch no:657 --> TrainingLoass: 2.1049118041992188\n",
            "Batch no:658 --> TrainingLoass: 2.102762222290039\n",
            "Batch no:659 --> TrainingLoass: 2.0495221614837646\n",
            "Batch no:660 --> TrainingLoass: 1.9570976495742798\n",
            "Batch no:661 --> TrainingLoass: 1.9758555889129639\n",
            "Batch no:662 --> TrainingLoass: 2.0381858348846436\n",
            "Batch no:663 --> TrainingLoass: 1.9751261472702026\n",
            "Batch no:664 --> TrainingLoass: 2.059183359146118\n",
            "Batch no:665 --> TrainingLoass: 2.1247751712799072\n",
            "Batch no:666 --> TrainingLoass: 2.1075804233551025\n",
            "Batch no:667 --> TrainingLoass: 2.13940691947937\n",
            "Batch no:668 --> TrainingLoass: 2.1152501106262207\n",
            "Batch no:669 --> TrainingLoass: 1.9372996091842651\n",
            "Batch no:670 --> TrainingLoass: 1.936498999595642\n",
            "Batch no:671 --> TrainingLoass: 2.02246356010437\n",
            "Batch no:672 --> TrainingLoass: 1.9869935512542725\n",
            "Batch no:673 --> TrainingLoass: 2.0006136894226074\n",
            "Batch no:674 --> TrainingLoass: 1.9675829410552979\n",
            "Batch no:675 --> TrainingLoass: 1.8970615863800049\n",
            "Batch no:676 --> TrainingLoass: 2.0688624382019043\n",
            "Batch no:677 --> TrainingLoass: 2.03505802154541\n",
            "Batch no:678 --> TrainingLoass: 2.0299644470214844\n",
            "Batch no:679 --> TrainingLoass: 1.907741665840149\n",
            "Batch no:680 --> TrainingLoass: 1.906417727470398\n",
            "Batch no:681 --> TrainingLoass: 1.9973137378692627\n",
            "Batch no:682 --> TrainingLoass: 1.9485342502593994\n",
            "Batch no:683 --> TrainingLoass: 2.1220357418060303\n",
            "Batch no:684 --> TrainingLoass: 1.9800316095352173\n",
            "Batch no:685 --> TrainingLoass: 1.9434411525726318\n",
            "Batch no:686 --> TrainingLoass: 2.0546517372131348\n",
            "Batch no:687 --> TrainingLoass: 2.077531576156616\n",
            "Batch no:688 --> TrainingLoass: 2.152941942214966\n",
            "Batch no:689 --> TrainingLoass: 1.984076976776123\n",
            "Batch no:690 --> TrainingLoass: 1.9257928133010864\n",
            "Batch no:691 --> TrainingLoass: 1.9238817691802979\n",
            "Batch no:692 --> TrainingLoass: 2.128140926361084\n",
            "Batch no:693 --> TrainingLoass: 2.0239644050598145\n",
            "Batch no:694 --> TrainingLoass: 2.036989212036133\n",
            "Batch no:695 --> TrainingLoass: 2.062110185623169\n",
            "Batch no:696 --> TrainingLoass: 2.064760684967041\n",
            "Batch no:697 --> TrainingLoass: 1.9616490602493286\n",
            "Batch no:698 --> TrainingLoass: 1.9377384185791016\n",
            "Batch no:699 --> TrainingLoass: 1.9371412992477417\n",
            "Batch no:700 --> TrainingLoass: 1.9305027723312378\n",
            "Batch no:701 --> TrainingLoass: 2.12164568901062\n",
            "Batch no:702 --> TrainingLoass: 2.0137898921966553\n",
            "Batch no:703 --> TrainingLoass: 1.9496062994003296\n",
            "Batch no:704 --> TrainingLoass: 1.8860434293746948\n",
            "Batch no:705 --> TrainingLoass: 2.0852224826812744\n",
            "Batch no:706 --> TrainingLoass: 1.9680083990097046\n",
            "Batch no:707 --> TrainingLoass: 2.035423994064331\n",
            "Batch no:708 --> TrainingLoass: 2.069103717803955\n",
            "Batch no:709 --> TrainingLoass: 1.9421350955963135\n",
            "Batch no:710 --> TrainingLoass: 1.9092323780059814\n",
            "Batch no:711 --> TrainingLoass: 1.9839674234390259\n",
            "Batch no:712 --> TrainingLoass: 1.9620282649993896\n",
            "Batch no:713 --> TrainingLoass: 2.1918094158172607\n",
            "Batch no:714 --> TrainingLoass: 1.8715221881866455\n",
            "Batch no:715 --> TrainingLoass: 2.0508458614349365\n",
            "Batch no:716 --> TrainingLoass: 2.0520293712615967\n",
            "Batch no:717 --> TrainingLoass: 2.097416400909424\n",
            "Batch no:718 --> TrainingLoass: 1.8920352458953857\n",
            "Batch no:719 --> TrainingLoass: 2.0214428901672363\n",
            "Batch no:720 --> TrainingLoass: 1.9123845100402832\n",
            "Batch no:721 --> TrainingLoass: 2.0782952308654785\n",
            "Batch no:722 --> TrainingLoass: 1.9777967929840088\n",
            "Batch no:723 --> TrainingLoass: 2.0376954078674316\n",
            "Batch no:724 --> TrainingLoass: 1.9420878887176514\n",
            "Batch no:725 --> TrainingLoass: 1.9237406253814697\n",
            "Batch no:726 --> TrainingLoass: 1.9895538091659546\n",
            "Batch no:727 --> TrainingLoass: 1.9662920236587524\n",
            "Batch no:728 --> TrainingLoass: 1.9675521850585938\n",
            "Batch no:729 --> TrainingLoass: 1.9376795291900635\n",
            "Batch no:730 --> TrainingLoass: 2.0138535499572754\n",
            "Batch no:731 --> TrainingLoass: 2.2359085083007812\n",
            "Batch no:732 --> TrainingLoass: 2.033703327178955\n",
            "Batch no:733 --> TrainingLoass: 2.041220188140869\n",
            "Batch no:734 --> TrainingLoass: 1.9917778968811035\n",
            "Batch no:735 --> TrainingLoass: 2.003922939300537\n",
            "Batch no:736 --> TrainingLoass: 2.0105068683624268\n",
            "Batch no:737 --> TrainingLoass: 2.0743091106414795\n",
            "Batch no:738 --> TrainingLoass: 2.0879554748535156\n",
            "Batch no:739 --> TrainingLoass: 1.9326947927474976\n",
            "Batch no:740 --> TrainingLoass: 1.9939823150634766\n",
            "Batch no:741 --> TrainingLoass: 2.1571359634399414\n",
            "Batch no:742 --> TrainingLoass: 2.1234099864959717\n",
            "Batch no:743 --> TrainingLoass: 1.9662467241287231\n",
            "Batch no:744 --> TrainingLoass: 2.113636016845703\n",
            "Batch no:745 --> TrainingLoass: 2.0004801750183105\n",
            "Batch no:746 --> TrainingLoass: 1.8587706089019775\n",
            "Batch no:747 --> TrainingLoass: 1.894313931465149\n",
            "Batch no:748 --> TrainingLoass: 2.015486001968384\n",
            "Batch no:749 --> TrainingLoass: 2.170924186706543\n",
            "Batch no:750 --> TrainingLoass: 1.9752192497253418\n",
            "Batch no:751 --> TrainingLoass: 2.151705265045166\n",
            "Batch no:752 --> TrainingLoass: 2.0597586631774902\n",
            "Batch no:753 --> TrainingLoass: 1.9835715293884277\n",
            "Batch no:754 --> TrainingLoass: 2.1444644927978516\n",
            "Batch no:755 --> TrainingLoass: 2.0135037899017334\n",
            "Batch no:756 --> TrainingLoass: 1.9121074676513672\n",
            "Batch no:757 --> TrainingLoass: 2.099698305130005\n",
            "Batch no:758 --> TrainingLoass: 2.031080961227417\n",
            "Batch no:759 --> TrainingLoass: 2.0076255798339844\n",
            "Batch no:760 --> TrainingLoass: 1.9973008632659912\n",
            "Batch no:761 --> TrainingLoass: 2.133819818496704\n",
            "Batch no:762 --> TrainingLoass: 2.1321518421173096\n",
            "Batch no:763 --> TrainingLoass: 1.9625585079193115\n",
            "Batch no:764 --> TrainingLoass: 1.815117597579956\n",
            "Batch no:765 --> TrainingLoass: 1.9962499141693115\n",
            "Batch no:766 --> TrainingLoass: 1.7581899166107178\n",
            "Batch no:767 --> TrainingLoass: 1.8958330154418945\n",
            "Batch no:768 --> TrainingLoass: 2.1069095134735107\n",
            "Batch no:769 --> TrainingLoass: 1.9894967079162598\n",
            "Batch no:770 --> TrainingLoass: 1.9050419330596924\n",
            "Batch no:771 --> TrainingLoass: 1.8728116750717163\n",
            "Batch no:772 --> TrainingLoass: 1.9682296514511108\n",
            "Batch no:773 --> TrainingLoass: 2.125871419906616\n",
            "Batch no:774 --> TrainingLoass: 2.0052387714385986\n",
            "Batch no:775 --> TrainingLoass: 1.8650243282318115\n",
            "Batch no:776 --> TrainingLoass: 1.943070411682129\n",
            "Batch no:777 --> TrainingLoass: 2.0726420879364014\n",
            "Batch no:778 --> TrainingLoass: 2.029942750930786\n",
            "Batch no:779 --> TrainingLoass: 1.8877753019332886\n",
            "Batch no:780 --> TrainingLoass: 2.032912015914917\n",
            "Batch no:781 --> TrainingLoass: 1.8675695657730103\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ok Model seems fine loss is reducing"
      ],
      "metadata": {
        "id": "oR4PhPGWPSNz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Loop"
      ],
      "metadata": {
        "id": "6EV5oILpR69x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\"\"\n",
        "for epoch in epochs:\n",
        "  for batch in dataloader:\n",
        "    inputs, labels = batch\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AgVWDWjR6fp",
        "outputId": "daf40b84-7967-4c8b-f676-9de9b9fcbf29"
      },
      "execution_count": 406,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "for epoch in epochs:\n",
            "  for batch in dataloader:\n",
            "    inputs, labels = batch\n",
            "    outputs = model(inputs)\n",
            "    loss = criterion(outputs, labels)\n",
            "    loss.backward()\n",
            "    optimizer.step()\n",
            "    optimizer.zero_grad()\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Whats the dataloader again?\n"
      ],
      "metadata": {
        "id": "7Wli2o_aSXzD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\"\"\n",
        "DataLoader(\n",
        "    dataset,\n",
        "    batch_size = batch_size,\n",
        "    shuffle = True\n",
        "    num_workers = 4,\n",
        "    pin_memory = True # what is this lol\n",
        "    drop_last=(len(dataset)%batch_size != 0)\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKY9AtORKQsW",
        "outputId": "7d6382fe-b982-4790-9c3b-4e1b52901a88"
      },
      "execution_count": 408,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataLoader(\n",
            "    dataset,\n",
            "    batch_size = batch_size,\n",
            "    shuffle = True\n",
            "    num_workers = 4,\n",
            "    pin_memory = True # what is this lol\n",
            "    drop_last=(len(dataset)%batch_size != 0)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What does transforms class do?"
      ],
      "metadata": {
        "id": "WpGN4H_MTB6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.4914, 0.4822, 0.4465],[0.2023, 0.1994, 0.2010])\n",
        "])"
      ],
      "metadata": {
        "id": "XTf7VR7dS6om"
      },
      "execution_count": 410,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XfknDMgTYqd",
        "outputId": "d8a91fd4-7391-420b-fcd0-5bc1c6e3532c"
      },
      "execution_count": 411,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Compose(\n",
              "    ToTensor()\n",
              "    Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.201])\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 411
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the same model as same architecture"
      ],
      "metadata": {
        "id": "eayfVNt4UCve"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Traninig Pipeline"
      ],
      "metadata": {
        "id": "vFT-LDHTUHjw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.201])\n",
        "])\n",
        "train_set = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
        "test_set = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=64, shuffle=True, num_workers=num_workers)\n",
        "test_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n"
      ],
      "metadata": {
        "id": "cuQo6q0dTc99"
      },
      "execution_count": 412,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device) #using MyCNNModel\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "jRl4tOu1Wj8o"
      },
      "execution_count": 414,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10):\n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "  for i , (inputs, labels) in enumerate(train_loader):\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    if i % 200 == 199: #else it will print at 0 lol\n",
        "      print(f'Epoch {epoch+1}, Batch {i+1}: Loss {running_loss/200:.3f}')\n",
        "      running_loss = 0.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOd3hmj7W3G7",
        "outputId": "1c4d8578-495b-4de8-85f0-a675c47b8964"
      },
      "execution_count": 415,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Batch 200: Loss 1.822\n",
            "Epoch 1, Batch 400: Loss 1.592\n",
            "Epoch 1, Batch 600: Loss 1.515\n",
            "Epoch 2, Batch 200: Loss 1.388\n",
            "Epoch 2, Batch 400: Loss 1.365\n",
            "Epoch 2, Batch 600: Loss 1.316\n",
            "Epoch 3, Batch 200: Loss 1.229\n",
            "Epoch 3, Batch 400: Loss 1.246\n",
            "Epoch 3, Batch 600: Loss 1.216\n",
            "Epoch 4, Batch 200: Loss 1.132\n",
            "Epoch 4, Batch 400: Loss 1.119\n",
            "Epoch 4, Batch 600: Loss 1.128\n",
            "Epoch 5, Batch 200: Loss 1.062\n",
            "Epoch 5, Batch 400: Loss 1.090\n",
            "Epoch 5, Batch 600: Loss 1.053\n",
            "Epoch 6, Batch 200: Loss 1.003\n",
            "Epoch 6, Batch 400: Loss 1.010\n",
            "Epoch 6, Batch 600: Loss 1.019\n",
            "Epoch 7, Batch 200: Loss 0.952\n",
            "Epoch 7, Batch 400: Loss 0.962\n",
            "Epoch 7, Batch 600: Loss 0.948\n",
            "Epoch 8, Batch 200: Loss 0.890\n",
            "Epoch 8, Batch 400: Loss 0.915\n",
            "Epoch 8, Batch 600: Loss 0.928\n",
            "Epoch 9, Batch 200: Loss 0.849\n",
            "Epoch 9, Batch 400: Loss 0.876\n",
            "Epoch 9, Batch 600: Loss 0.882\n",
            "Epoch 10, Batch 200: Loss 0.820\n",
            "Epoch 10, Batch 400: Loss 0.823\n",
            "Epoch 10, Batch 600: Loss 0.846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  for inputs, labels in test_loader:\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    outputs = model(inputs)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0) #batchsize\n",
        "    correct += (predicted == labels).sum().item()\n",
        "print(f'Test Accuracy: {100 * correct / total:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1QZEMBHX8vn",
        "outputId": "437f8ac8-e603-4e46-d073-9090922239d7"
      },
      "execution_count": 416,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 73.22%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`pin_memory=True` in a PyTorch `DataLoader` tells it to **allocate the data in page-locked (pinned) memory**, which allows **faster data transfer** from CPU to GPU.\n",
        "\n",
        "---\n",
        "\n",
        "### üîç What is Pinned Memory?\n",
        "\n",
        "* By default, memory in RAM can be **swapped** or **paged**, which is slow for GPU transfers.\n",
        "* **Pinned memory** is page-locked ‚Äî it cannot be swapped to disk ‚Äî so data transfer to GPU via `cuda()` is **asynchronous and much faster**.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ When should you use `pin_memory=True`?\n",
        "\n",
        "Use it **only if you're using a GPU**, and:\n",
        "\n",
        "* You're loading data on the CPU (which is always the case with `DataLoader`)\n",
        "* You're transferring data to GPU in your training loop like this:\n",
        "\n",
        "  ```python\n",
        "  for x, y in train_loader:\n",
        "      x, y = x.cuda(non_blocking=True), y.cuda(non_blocking=True)\n",
        "  ```\n",
        "\n",
        "The `non_blocking=True` flag lets you overlap data transfer and GPU computation.\n",
        "\n",
        "---\n",
        "\n",
        "### üö´ When *not* to use it:\n",
        "\n",
        "* If you're only using the CPU for training (e.g., no `.cuda()` calls), it won't help and might even waste memory.\n",
        "* On systems with very limited RAM, excessive pinning can lead to memory pressure.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "mk1DRgJxWbKB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pretrained CNNs and Transfer Learning"
      ],
      "metadata": {
        "id": "2SGAC7UcZkXr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zjbi4NfgWbiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OPPES"
      ],
      "metadata": {
        "id": "RnWrOMZ4e4fh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q1\n",
        "Create a 4x4 tensor with random floating-point values between 0 and 1 after setting the seed to 42. Compute the sum of all elements in the tensor.\n",
        "\n",
        "Ans: 10.3908 (Range: 10 to 11)"
      ],
      "metadata": {
        "id": "45OGXJwgArpr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.manual_seed(42)\n",
        "torch.rand(4,4).sum()"
      ],
      "metadata": {
        "id": "RjP_WwQBipZj",
        "outputId": "ad4e967e-0b08-40b7-8ca5-93f7347da5af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 418,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(10.3908)"
            ]
          },
          "metadata": {},
          "execution_count": 418
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "?torch.randn"
      ],
      "metadata": {
        "id": "80dRS65Oi6Z6"
      },
      "execution_count": 421,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "?torch.rand"
      ],
      "metadata": {
        "id": "Bnpy9jaNjAS8"
      },
      "execution_count": 422,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note always use ```torch.rand```"
      ],
      "metadata": {
        "id": "EJF47WiWjMqJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q2\n",
        "Create a tensor x with the value 3.0 and set requires_grad=True. Define y = x^2 + 2*x. Compute the gradient of y with respect to x.\n",
        "\n",
        "Ans: 8.0 (range: 7.5 to 8.5)"
      ],
      "metadata": {
        "id": "ijrWiN_SCBnf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(3.0,requires_grad=True)\n",
        "y = x**2 + 2*x\n"
      ],
      "metadata": {
        "id": "OYU-d1ESjP5L"
      },
      "execution_count": 429,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.backward()\n",
        "x.grad.item(),x.grad"
      ],
      "metadata": {
        "id": "i0EewF13jeD9",
        "outputId": "a5d7e6be-ca63-4671-c232-323e45b772c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 430,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.0, tensor(8.))"
            ]
          },
          "metadata": {},
          "execution_count": 430
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q3\n",
        "Use the following small dataset with fixed values:\n",
        "\n",
        "```\n",
        "features = torch.tensor([[0.5, 1.0], [1.0, 2.0], [1.5, 3.0], [2.0, 4.0]])\n",
        "labels = torch.tensor([[0.5], [1.0], [1.5], [2.0]])\n",
        "```\n",
        "\n",
        "Build a feed-forward neural network with 2 input features and 1 output, using a single hidden layer of 3 neurons. Use `torch.nn.Linear` layers and `ReLU` as the activation function.\n",
        "\n",
        "Enter the number of parameters in the network.\n",
        "\n",
        "Ans:"
      ],
      "metadata": {
        "id": "IB5G72qqCYK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch.nn\n",
        "# import torch.nn as nn\n",
        "# features = torch.tensor([[0.5, 1.0], [1.0, 2.0], [1.5, 3.0], [2.0, 4.0]])\n",
        "# labels = torch.tensor([[0.5], [1.0], [1.5], [2.0]])\n",
        "# class MyNN(nn.Module):\n",
        "#   def __init__(self):\n",
        "#     super(MyNN,self).__init__()\n",
        "#     self.layers = nn.Sequential(\n",
        "#       nn.Linear(2,3),\n",
        "#       nn.ReLU(),\n",
        "#       nn.Linear(3,1)\n",
        "#     )\n",
        "#   def forward(self,x):\n",
        "#     return self.layers(x)\n",
        "# model = MyNN()\n",
        "# import torch.nn as nn\n",
        "\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(2, 3)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(3, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Initialize network\n",
        "model = SimpleNN()\n",
        "\n",
        "\n",
        "num_params = 0\n",
        "for each in model.parameters():\n",
        "  # print(each.shape)\n",
        "  print(each.numel())\n",
        "  num_params += each.numel()\n",
        "print('total:', num_params)\n"
      ],
      "metadata": {
        "id": "3PJu4pPljtLH",
        "outputId": "05e50d46-4040-48be-f37a-394c91041bb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 479,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n",
            "3\n",
            "3\n",
            "1\n",
            "total: 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = 0\n",
        "for param in model.parameters():\n",
        "  total_params += param.numel()\n",
        "((2*3 + 3) + (3*1+1)),total_params"
      ],
      "metadata": {
        "id": "GKJbycc4kHJF",
        "outputId": "1c49ac27-0df4-4ac7-d484-4949e2d4f959",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 472,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 472
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q4\n",
        "\n",
        "Train the network for 100 epochs using Mean Squared Error (MSE) loss and Stochastic Gradient Descent (SGD) optimizer. Set the learning rate to 0.01.\n",
        "\n",
        "Enter the final loss after 100 epochs\n",
        "\n"
      ],
      "metadata": {
        "id": "mVZkqKenEXlL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.para,lr = 0.01)"
      ],
      "metadata": {
        "id": "I_NimHLAmdsI"
      },
      "execution_count": 473,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0qYfIrUrqG8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from tqdm import trange, tqdm\n",
        "# for epoch in range(100):\n",
        "#   optimizer.zero_grad()\n",
        "#   outputs = model(features)\n",
        "#   loss = criterion(outputs, labels)\n",
        "#   loss.backward()\n",
        "#   optimizer.step()\n",
        "\n",
        "# loss.item()\n",
        "\n",
        "\n",
        "# Code with fixed dataset and model\n",
        "import torch.optim as optim\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(features)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "final_loss = loss.item()\n",
        "final_loss"
      ],
      "metadata": {
        "id": "YK9u_ukhmtNo",
        "outputId": "c1c641df-8709-45ed-eefb-8a81d9050505",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 480,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.02777836099267006"
            ]
          },
          "metadata": {},
          "execution_count": 480
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q5\n",
        "\n",
        "Using the same network from Question 3, change the activation function in the hidden layer from ReLU to Sigmoid. Train for 100 epochs. How does the final loss compare to the one obtained with ReLU?\n",
        "\n",
        "A) Loss decreases.\\\n",
        "B) Loss increases.\\\n",
        "C) Loss stays the same.\\\n",
        "D) Cannot be determined.\n",
        "\n",
        "Ans: A"
      ],
      "metadata": {
        "id": "gDZBw6AmEwP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyNNSigmoid(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MyNNSigmoid,self).__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "      nn.Linear(2,3),\n",
        "      nn.Sigmoid(),\n",
        "      nn.Linear(3,1)\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    return self.layers(x)\n",
        "model = MyNNSigmoid()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(),lr = 0.01)\n",
        "for epoch in range(100):\n",
        "  optimizer.zero_grad()\n",
        "  outputs = model(features)\n",
        "  loss = criterion(outputs, labels)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "loss.item()"
      ],
      "metadata": {
        "id": "-xgbLHQApyPb",
        "outputId": "0a267a21-b935-4660-b673-b60424f9498c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 477,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.21113312244415283"
            ]
          },
          "metadata": {},
          "execution_count": 477
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q6\n",
        "\n",
        "Use this small fixed binary classification dataset:\n",
        "\n",
        "```\n",
        "features = torch.tensor([[0.5, 1.0], [1.0, 1.5], [1.5, 2.0], [2.0, 2.5]])\n",
        "labels = torch.tensor([[0], [1], [1], [0]])\n",
        "```\n",
        "Build a neural network with 2 input features, a hidden layer of 3 neurons, and an output layer for binary classification. Use the Sigmoid activation in the output layer. Train the network using binary cross-entropy loss for 100 epochs with learning rate 0.01. What is the final accuracy?\n",
        "\n",
        "Ans: 50 (Range: 49 to 51)"
      ],
      "metadata": {
        "id": "IHTkayTRGaMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = torch.tensor([[0.5, 1.0], [1.0, 1.5], [1.5, 2.0], [2.0, 2.5]])\n",
        "labels = torch.tensor([[0.], [1.], [1.], [0.]])\n",
        "\n",
        "class Q6Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Q6Model,self).__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Linear(2,3),\n",
        "        nn.Linear(3,1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    return self.layers(x)\n",
        "\n",
        "model = Q6Model()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.01)\n",
        "for epoch in range(100):\n",
        "  optimizer.zero_grad()\n",
        "  outputs = model(features)\n",
        "  loss = criterion(outputs,labels)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "(outputs.round() == labels).sum().item()/len(labels)*100\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pb6nZ9sHqxdD",
        "outputId": "09327b64-a5d3-48ec-906b-3c74d946ae5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 484,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50.0"
            ]
          },
          "metadata": {},
          "execution_count": 484
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q7\n",
        "\n",
        "Implement a CNN with one convolutional layer (32 filters, 3x3 kernel, stride = 1, padding = 0) followed by a max-pooling layer (2x2). If the input is of size [32, 1, 28, 28] (Use the input `torch.randn(32, 1, 28, 28)`), what will be the output size after the max-pooling layer?\n",
        "\n",
        "**Options**\n",
        "\n",
        "(A) `torch.Size([1, 32, 13, 13])`\n",
        "\n",
        "(B) `torch.Size([32, 1, 13, 13])`\n",
        "\n",
        "(C) `torch.Size([1, 32, 12, 12])`\n",
        "\n",
        "(D) `torch.Size([32, 32, 13, 13])`\n",
        "\n",
        "**Answer**\n",
        "\n",
        "D\n"
      ],
      "metadata": {
        "id": "lLbUJLcy_d7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "?nn.Conv2d"
      ],
      "metadata": {
        "id": "IpPWucfCtYvN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv2d = nn.Conv2d(1,32,3,1,0)\n",
        "pooling = nn.MaxPool2d(2,2)\n",
        "pooling(conv2d(torch.randn(32,1,28,28))).size()"
      ],
      "metadata": {
        "id": "579ywvUJsfdZ",
        "outputId": "0fcf5f8b-cf4f-47bc-c5f9-4c17ea0f0640",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 32, 13, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q8\n",
        "\n",
        "Using the `torchvision.datasets` module, load the CIFAR-10 training dataset and use `torchvision.transforms` to convert them into tensors.\n",
        "\n",
        "Use DataLoader to load the dataset with the following settings:\n",
        "* Batch size = 64\n",
        "* Shuffle = True\n",
        "\n",
        "How many training data points are there in the last batch?\n",
        "\n",
        "Ans: 16 No range is required"
      ],
      "metadata": {
        "id": "vuPBummdG1Jl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from  torchvision import datasets , transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_data = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transforms.ToTensor())\n"
      ],
      "metadata": {
        "id": "ru6JJMisw9jN",
        "outputId": "a1a43377-d4db-4657-b32d-7a262cbb5d61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 170M/170M [00:08<00:00, 21.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=64)\n",
        "last_batch = None\n",
        "for batch in train_loader:\n",
        "  last_batch = batch\n",
        ""
      ],
      "metadata": {
        "id": "Cnc5YVaLx33N",
        "outputId": "bf42fd66-2d67-45ac-a741-87a734e66706",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x,y = last_batch\n",
        "x.shape, y.shape"
      ],
      "metadata": {
        "id": "yA843x6CyV8r",
        "outputId": "50797f90-2f98-4d1e-aa68-6d1f7f0c5849",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([16, 3, 32, 32]), torch.Size([16]))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data)%64 #Cheating xD"
      ],
      "metadata": {
        "id": "l20bMnj_xthi",
        "outputId": "c2fef4e9-18e4-4b7d-f7fe-4b6eca746bb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q9\n",
        "\n",
        "What is the purpose of the `collate_fn` parameter in `torch.utils.data.DataLoader`?\n",
        "\n",
        "**Options**\n",
        "\n",
        "(A) To define how a batch of data should be collated from individual data samples.\n",
        "\n",
        "(B) To make the batch size compatible with model architecture.\n",
        "\n",
        "(C) To split data into training and validation sets.\n",
        "\n",
        "(D) To handle data augmentation\n",
        "\n",
        "\n",
        "Ans (A)\n"
      ],
      "metadata": {
        "id": "JXCzZ6-AJmks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "?DataLoader"
      ],
      "metadata": {
        "id": "BTXWkAtyylCe"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q10\n",
        "\n",
        "Use the following preprocessed dataset for training a simple RNN model:\n",
        "```\n",
        "X_train = torch.tensor([\n",
        "    [1, 2, 3, 4],\n",
        "    [2, 3, 4, 5],\n",
        "    [3, 4, 5, 6],\n",
        "    [4, 5, 6, 7]\n",
        "], dtype=torch.float32)\n",
        "\n",
        "y_train = torch.tensor([5, 6, 7, 8], dtype=torch.float32)\n",
        "```\n",
        "\n",
        "Use the manual seed to be 42.\n",
        "\n",
        "Define and Train the RNN Model:\n",
        "\n",
        "Model Structure:\n",
        "RNN Layer: This layer will process the input sequences. The number of hidden units in the RNN layer is 5.\n",
        "\n",
        "Fully Connected Layer: This layer will map the RNN output to the final output size.\n",
        "\n",
        "Output Size: The output size is 1\n",
        "\n",
        "Hidden Size: The hidden size (5)\n",
        "Loss Function: Mean Squared Error (MSE) is used for regression tasks.\n",
        "\n",
        "Optimizer: Stochastic Gradient Descent (SGD) is used with learning rate = 0.1.\n",
        "\n",
        "Training: Train the model for 2 epochs.\n",
        "\n",
        "Enter the loss after 2 epochs.\n",
        "\n",
        "\n",
        "Ans: $[20, 34]$"
      ],
      "metadata": {
        "id": "1I33nhn-RWHh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = torch.tensor([\n",
        "    [1, 2, 3, 4],\n",
        "    [2, 3, 4, 5],\n",
        "    [3, 4, 5, 6],\n",
        "    [4, 5, 6, 7]\n",
        "], dtype=torch.float32)\n",
        "X_train.shape"
      ],
      "metadata": {
        "id": "ef5vPNi69jmw",
        "outputId": "0ce9cd44-e2b6-47e9-9b32-c6a1242a2eb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randint(0, 10, size=(4, 4), dtype=torch.float32)\n",
        "x.unsqueeze(1).shape"
      ],
      "metadata": {
        "id": "dtzgBFrL-mpT",
        "outputId": "49906760-317a-42e5-8ee0-fb619cd12711",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 1, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How are we taking a an input 4,4 and making a batch of 4, with 1 row and 4 columns?"
      ],
      "metadata": {
        "id": "FBc0oTsv-y6V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF? ü§î‚ùì"
      ],
      "metadata": {
        "id": "rngMdbuS-8Vr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.unsqueeze(1).shape"
      ],
      "metadata": {
        "id": "msITve4C-XyS",
        "outputId": "84cb8071-ce9d-44bf-cf30-f16df0d2e8df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 1, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = torch.tensor([\n",
        "    [1, 2, 3, 4],\n",
        "    [2, 3, 4, 5],\n",
        "    [3, 4, 5, 6],\n",
        "    [4, 5, 6, 7]\n",
        "], dtype=torch.float32)\n",
        "\n",
        "y_train = torch.tensor([5, 6, 7, 8], dtype=torch.float32)\n",
        "\n",
        "class MyRNNModel(nn.Module):\n",
        "  def __init__(self, input_size = X_train.shape[1],  hidden_size=5,output_size = 1):\n",
        "    super(MyRNNModel,self).__init__()\n",
        "    self.rnn = nn.RNN(input_size, hidden_size,batch_first=True)\n",
        "    self.linear = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # out, _ = self.rnn(x.unsqueeze(1))\n",
        "    # out = self.fc(o)\n",
        "    return -1\n",
        "\n"
      ],
      "metadata": {
        "id": "nVHoQh-Qy567"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = X_train.size(1)\n",
        "hidden_size = 5\n",
        "output_size = 1\n",
        "model = MyRNNModel(input_size, hidden_size, output_size)"
      ],
      "metadata": {
        "id": "0sc3nIuJ_H6c"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "a,_ = model.rnn(X_train.unsqueeze(1))\n",
        "# b,_ = model.rnn(X_train)\n",
        "print(a.shape)\n",
        "a = model.linear(a[:,-1,:])\n",
        "print(a.shape)\n",
        "# b = model.linear(b)\n",
        "# print(b.shape)"
      ],
      "metadata": {
        "id": "OFC0E0h89Rm0",
        "outputId": "f0ffce9a-cea4-4d77-b6a9-b480911b1450",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 4])\n",
            "torch.Size([4, 1, 5])\n",
            "torch.Size([4, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a , b.squeeze()"
      ],
      "metadata": {
        "id": "6vbBbRiX9Rif",
        "outputId": "aaa581c1-4660-4421-eb46-378caa048a9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.0612, 0.5647, 0.6372, 0.6315, 0.0025],\n",
              "         [0.2364, 0.7558, 0.2809, 0.2451, 0.1077],\n",
              "         [0.2741, 0.7970, 0.2041, 0.1618, 0.1304],\n",
              "         [0.2797, 0.8031, 0.1927, 0.1495, 0.1337]], grad_fn=<AddmmBackward0>),\n",
              " tensor([[0.0612, 0.5647, 0.6372, 0.6315, 0.0025],\n",
              "         [0.2364, 0.7558, 0.2809, 0.2451, 0.1077],\n",
              "         [0.2741, 0.7970, 0.2041, 0.1618, 0.1304],\n",
              "         [0.2797, 0.8031, 0.1927, 0.1495, 0.1337]], grad_fn=<SqueezeBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.shape"
      ],
      "metadata": {
        "id": "on4MFRZfBX0M",
        "outputId": "79417858-ca20-4057-e8bc-e6e99bec0f95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "id": "CITnYB3FBY2G",
        "outputId": "0f35d315-0ee8-46b7-a728-8fed889bb1a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.rnn(x.unsqueeze(1))\n",
        "        print(out.shape)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        print(out.shape)\n",
        "        return out\n",
        "\n",
        "\n",
        "input_size = X_train.size(1)\n",
        "hidden_size = 5\n",
        "output_size = 1\n",
        "\n",
        "model = RNNModel(input_size, hidden_size, output_size)"
      ],
      "metadata": {
        "id": "q94xodTvBhS_"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(X_train)\n",
        "outputs.shape,y_train.shape"
      ],
      "metadata": {
        "id": "BtMD7sROBirt",
        "outputId": "312cb89a-f68e-4621-df48-928b0aaff609",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 1, 5])\n",
            "torch.Size([4, 1])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4, 1]), torch.Size([4]))"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q11\n",
        "\n",
        "You are provided with the following code snippets that use `torch.nn.RNN`. Identify which option will raise an error based on incorrect usage of the RNN module.\n",
        "\n",
        "```\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# RNN parameters\n",
        "input_size = 4  # Number of features in the input\n",
        "hidden_size = 5  # Number of hidden units\n",
        "num_layers = 2  # Number of RNN layers\n",
        "batch_size = 3  # Batch size\n",
        "sequence_length = 6  # Sequence length\n",
        "\n",
        "# Initialize RNN\n",
        "rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "\n",
        "# Random input data\n",
        "X = torch.randn(batch_size, sequence_length, input_size)\n",
        "\n",
        "# Forward pass\n",
        "out, h_n = rnn(X)\n",
        "\n",
        "```\n",
        "\n",
        "**Options**\n",
        "\n",
        "(A)\n",
        "```\n",
        "input_size = 5\n",
        "rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "out, h_n = rnn(X)\n",
        "```\n",
        "(B)\n",
        "```\n",
        "rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, num_layers=1, batch_first=False)\n",
        "out, h_n = rnn(X)\n",
        "```\n",
        "(C)\n",
        "```\n",
        "batch_size = 1\n",
        "X = torch.randn(batch_size, sequence_length, input_size)\n",
        "out, h_n = rnn(X)\n",
        "```\n",
        "(D)\n",
        "```\n",
        "hidden_size = 7\n",
        "rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "out, h_n = rnn(X)\n",
        "```\n",
        "\n",
        "Ans: (A), (B)"
      ],
      "metadata": {
        "id": "4DJI7MjuIZW6"
      }
    }
  ]
}